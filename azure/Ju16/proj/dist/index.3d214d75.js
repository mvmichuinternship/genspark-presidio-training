// modules are defined as an array
// [ module function, map of requires ]
//
// map of requires is short require name -> numeric require
//
// anything defined in a previous bundle is accessed via the
// orig method which is the require for previous bundles

(function (modules, entry, mainEntry, parcelRequireName, globalName) {
  /* eslint-disable no-undef */
  var globalObject =
    typeof globalThis !== 'undefined'
      ? globalThis
      : typeof self !== 'undefined'
      ? self
      : typeof window !== 'undefined'
      ? window
      : typeof global !== 'undefined'
      ? global
      : {};
  /* eslint-enable no-undef */

  // Save the require from previous bundle to this closure if any
  var previousRequire =
    typeof globalObject[parcelRequireName] === 'function' &&
    globalObject[parcelRequireName];

  var cache = previousRequire.cache || {};
  // Do not use `require` to prevent Webpack from trying to bundle this call
  var nodeRequire =
    typeof module !== 'undefined' &&
    typeof module.require === 'function' &&
    module.require.bind(module);

  function newRequire(name, jumped) {
    if (!cache[name]) {
      if (!modules[name]) {
        // if we cannot find the module within our internal map or
        // cache jump to the current global require ie. the last bundle
        // that was added to the page.
        var currentRequire =
          typeof globalObject[parcelRequireName] === 'function' &&
          globalObject[parcelRequireName];
        if (!jumped && currentRequire) {
          return currentRequire(name, true);
        }

        // If there are other bundles on this page the require from the
        // previous one is saved to 'previousRequire'. Repeat this as
        // many times as there are bundles until the module is found or
        // we exhaust the require chain.
        if (previousRequire) {
          return previousRequire(name, true);
        }

        // Try the node require function if it exists.
        if (nodeRequire && typeof name === 'string') {
          return nodeRequire(name);
        }

        var err = new Error("Cannot find module '" + name + "'");
        err.code = 'MODULE_NOT_FOUND';
        throw err;
      }

      localRequire.resolve = resolve;
      localRequire.cache = {};

      var module = (cache[name] = new newRequire.Module(name));

      modules[name][0].call(
        module.exports,
        localRequire,
        module,
        module.exports,
        this
      );
    }

    return cache[name].exports;

    function localRequire(x) {
      var res = localRequire.resolve(x);
      return res === false ? {} : newRequire(res);
    }

    function resolve(x) {
      var id = modules[name][1][x];
      return id != null ? id : x;
    }
  }

  function Module(moduleName) {
    this.id = moduleName;
    this.bundle = newRequire;
    this.exports = {};
  }

  newRequire.isParcelRequire = true;
  newRequire.Module = Module;
  newRequire.modules = modules;
  newRequire.cache = cache;
  newRequire.parent = previousRequire;
  newRequire.register = function (id, exports) {
    modules[id] = [
      function (require, module) {
        module.exports = exports;
      },
      {},
    ];
  };

  Object.defineProperty(newRequire, 'root', {
    get: function () {
      return globalObject[parcelRequireName];
    },
  });

  globalObject[parcelRequireName] = newRequire;

  for (var i = 0; i < entry.length; i++) {
    newRequire(entry[i]);
  }

  if (mainEntry) {
    // Expose entry point to Node, AMD or browser globals
    // Based on https://github.com/ForbesLindesay/umd/blob/master/template.js
    var mainExports = newRequire(mainEntry);

    // CommonJS
    if (typeof exports === 'object' && typeof module !== 'undefined') {
      module.exports = mainExports;

      // RequireJS
    } else if (typeof define === 'function' && define.amd) {
      define(function () {
        return mainExports;
      });

      // <script>
    } else if (globalName) {
      this[globalName] = mainExports;
    }
  }
})({"km5uZ":[function(require,module,exports) {
var global = arguments[3];
var HMR_HOST = null;
var HMR_PORT = null;
var HMR_SECURE = false;
var HMR_ENV_HASH = "d6ea1d42532a7575";
var HMR_USE_SSE = false;
module.bundle.HMR_BUNDLE_ID = "0a8ecb283d214d75";
"use strict";
/* global HMR_HOST, HMR_PORT, HMR_ENV_HASH, HMR_SECURE, HMR_USE_SSE, chrome, browser, __parcel__import__, __parcel__importScripts__, ServiceWorkerGlobalScope */ /*::
import type {
  HMRAsset,
  HMRMessage,
} from '@parcel/reporter-dev-server/src/HMRServer.js';
interface ParcelRequire {
  (string): mixed;
  cache: {|[string]: ParcelModule|};
  hotData: {|[string]: mixed|};
  Module: any;
  parent: ?ParcelRequire;
  isParcelRequire: true;
  modules: {|[string]: [Function, {|[string]: string|}]|};
  HMR_BUNDLE_ID: string;
  root: ParcelRequire;
}
interface ParcelModule {
  hot: {|
    data: mixed,
    accept(cb: (Function) => void): void,
    dispose(cb: (mixed) => void): void,
    // accept(deps: Array<string> | string, cb: (Function) => void): void,
    // decline(): void,
    _acceptCallbacks: Array<(Function) => void>,
    _disposeCallbacks: Array<(mixed) => void>,
  |};
}
interface ExtensionContext {
  runtime: {|
    reload(): void,
    getURL(url: string): string;
    getManifest(): {manifest_version: number, ...};
  |};
}
declare var module: {bundle: ParcelRequire, ...};
declare var HMR_HOST: string;
declare var HMR_PORT: string;
declare var HMR_ENV_HASH: string;
declare var HMR_SECURE: boolean;
declare var HMR_USE_SSE: boolean;
declare var chrome: ExtensionContext;
declare var browser: ExtensionContext;
declare var __parcel__import__: (string) => Promise<void>;
declare var __parcel__importScripts__: (string) => Promise<void>;
declare var globalThis: typeof self;
declare var ServiceWorkerGlobalScope: Object;
*/ var OVERLAY_ID = "__parcel__error__overlay__";
var OldModule = module.bundle.Module;
function Module(moduleName) {
    OldModule.call(this, moduleName);
    this.hot = {
        data: module.bundle.hotData[moduleName],
        _acceptCallbacks: [],
        _disposeCallbacks: [],
        accept: function(fn) {
            this._acceptCallbacks.push(fn || function() {});
        },
        dispose: function(fn) {
            this._disposeCallbacks.push(fn);
        }
    };
    module.bundle.hotData[moduleName] = undefined;
}
module.bundle.Module = Module;
module.bundle.hotData = {};
var checkedAssets /*: {|[string]: boolean|} */ , assetsToDispose /*: Array<[ParcelRequire, string]> */ , assetsToAccept /*: Array<[ParcelRequire, string]> */ ;
function getHostname() {
    return HMR_HOST || (location.protocol.indexOf("http") === 0 ? location.hostname : "localhost");
}
function getPort() {
    return HMR_PORT || location.port;
}
// eslint-disable-next-line no-redeclare
var parent = module.bundle.parent;
if ((!parent || !parent.isParcelRequire) && typeof WebSocket !== "undefined") {
    var hostname = getHostname();
    var port = getPort();
    var protocol = HMR_SECURE || location.protocol == "https:" && ![
        "localhost",
        "127.0.0.1",
        "0.0.0.0"
    ].includes(hostname) ? "wss" : "ws";
    var ws;
    if (HMR_USE_SSE) ws = new EventSource("/__parcel_hmr");
    else try {
        ws = new WebSocket(protocol + "://" + hostname + (port ? ":" + port : "") + "/");
    } catch (err) {
        if (err.message) console.error(err.message);
        ws = {};
    }
    // Web extension context
    var extCtx = typeof browser === "undefined" ? typeof chrome === "undefined" ? null : chrome : browser;
    // Safari doesn't support sourceURL in error stacks.
    // eval may also be disabled via CSP, so do a quick check.
    var supportsSourceURL = false;
    try {
        (0, eval)('throw new Error("test"); //# sourceURL=test.js');
    } catch (err) {
        supportsSourceURL = err.stack.includes("test.js");
    }
    // $FlowFixMe
    ws.onmessage = async function(event /*: {data: string, ...} */ ) {
        checkedAssets = {} /*: {|[string]: boolean|} */ ;
        assetsToAccept = [];
        assetsToDispose = [];
        var data /*: HMRMessage */  = JSON.parse(event.data);
        if (data.type === "update") {
            // Remove error overlay if there is one
            if (typeof document !== "undefined") removeErrorOverlay();
            let assets = data.assets.filter((asset)=>asset.envHash === HMR_ENV_HASH);
            // Handle HMR Update
            let handled = assets.every((asset)=>{
                return asset.type === "css" || asset.type === "js" && hmrAcceptCheck(module.bundle.root, asset.id, asset.depsByBundle);
            });
            if (handled) {
                console.clear();
                // Dispatch custom event so other runtimes (e.g React Refresh) are aware.
                if (typeof window !== "undefined" && typeof CustomEvent !== "undefined") window.dispatchEvent(new CustomEvent("parcelhmraccept"));
                await hmrApplyUpdates(assets);
                // Dispose all old assets.
                let processedAssets = {} /*: {|[string]: boolean|} */ ;
                for(let i = 0; i < assetsToDispose.length; i++){
                    let id = assetsToDispose[i][1];
                    if (!processedAssets[id]) {
                        hmrDispose(assetsToDispose[i][0], id);
                        processedAssets[id] = true;
                    }
                }
                // Run accept callbacks. This will also re-execute other disposed assets in topological order.
                processedAssets = {};
                for(let i = 0; i < assetsToAccept.length; i++){
                    let id = assetsToAccept[i][1];
                    if (!processedAssets[id]) {
                        hmrAccept(assetsToAccept[i][0], id);
                        processedAssets[id] = true;
                    }
                }
            } else fullReload();
        }
        if (data.type === "error") {
            // Log parcel errors to console
            for (let ansiDiagnostic of data.diagnostics.ansi){
                let stack = ansiDiagnostic.codeframe ? ansiDiagnostic.codeframe : ansiDiagnostic.stack;
                console.error("\uD83D\uDEA8 [parcel]: " + ansiDiagnostic.message + "\n" + stack + "\n\n" + ansiDiagnostic.hints.join("\n"));
            }
            if (typeof document !== "undefined") {
                // Render the fancy html overlay
                removeErrorOverlay();
                var overlay = createErrorOverlay(data.diagnostics.html);
                // $FlowFixMe
                document.body.appendChild(overlay);
            }
        }
    };
    if (ws instanceof WebSocket) {
        ws.onerror = function(e) {
            if (e.message) console.error(e.message);
        };
        ws.onclose = function() {
            console.warn("[parcel] \uD83D\uDEA8 Connection to the HMR server was lost");
        };
    }
}
function removeErrorOverlay() {
    var overlay = document.getElementById(OVERLAY_ID);
    if (overlay) {
        overlay.remove();
        console.log("[parcel] \u2728 Error resolved");
    }
}
function createErrorOverlay(diagnostics) {
    var overlay = document.createElement("div");
    overlay.id = OVERLAY_ID;
    let errorHTML = '<div style="background: black; opacity: 0.85; font-size: 16px; color: white; position: fixed; height: 100%; width: 100%; top: 0px; left: 0px; padding: 30px; font-family: Menlo, Consolas, monospace; z-index: 9999;">';
    for (let diagnostic of diagnostics){
        let stack = diagnostic.frames.length ? diagnostic.frames.reduce((p, frame)=>{
            return `${p}
<a href="/__parcel_launch_editor?file=${encodeURIComponent(frame.location)}" style="text-decoration: underline; color: #888" onclick="fetch(this.href); return false">${frame.location}</a>
${frame.code}`;
        }, "") : diagnostic.stack;
        errorHTML += `
      <div>
        <div style="font-size: 18px; font-weight: bold; margin-top: 20px;">
          \u{1F6A8} ${diagnostic.message}
        </div>
        <pre>${stack}</pre>
        <div>
          ${diagnostic.hints.map((hint)=>"<div>\uD83D\uDCA1 " + hint + "</div>").join("")}
        </div>
        ${diagnostic.documentation ? `<div>\u{1F4DD} <a style="color: violet" href="${diagnostic.documentation}" target="_blank">Learn more</a></div>` : ""}
      </div>
    `;
    }
    errorHTML += "</div>";
    overlay.innerHTML = errorHTML;
    return overlay;
}
function fullReload() {
    if ("reload" in location) location.reload();
    else if (extCtx && extCtx.runtime && extCtx.runtime.reload) extCtx.runtime.reload();
}
function getParents(bundle, id) /*: Array<[ParcelRequire, string]> */ {
    var modules = bundle.modules;
    if (!modules) return [];
    var parents = [];
    var k, d, dep;
    for(k in modules)for(d in modules[k][1]){
        dep = modules[k][1][d];
        if (dep === id || Array.isArray(dep) && dep[dep.length - 1] === id) parents.push([
            bundle,
            k
        ]);
    }
    if (bundle.parent) parents = parents.concat(getParents(bundle.parent, id));
    return parents;
}
function updateLink(link) {
    var href = link.getAttribute("href");
    if (!href) return;
    var newLink = link.cloneNode();
    newLink.onload = function() {
        if (link.parentNode !== null) // $FlowFixMe
        link.parentNode.removeChild(link);
    };
    newLink.setAttribute("href", // $FlowFixMe
    href.split("?")[0] + "?" + Date.now());
    // $FlowFixMe
    link.parentNode.insertBefore(newLink, link.nextSibling);
}
var cssTimeout = null;
function reloadCSS() {
    if (cssTimeout) return;
    cssTimeout = setTimeout(function() {
        var links = document.querySelectorAll('link[rel="stylesheet"]');
        for(var i = 0; i < links.length; i++){
            // $FlowFixMe[incompatible-type]
            var href /*: string */  = links[i].getAttribute("href");
            var hostname = getHostname();
            var servedFromHMRServer = hostname === "localhost" ? new RegExp("^(https?:\\/\\/(0.0.0.0|127.0.0.1)|localhost):" + getPort()).test(href) : href.indexOf(hostname + ":" + getPort());
            var absolute = /^https?:\/\//i.test(href) && href.indexOf(location.origin) !== 0 && !servedFromHMRServer;
            if (!absolute) updateLink(links[i]);
        }
        cssTimeout = null;
    }, 50);
}
function hmrDownload(asset) {
    if (asset.type === "js") {
        if (typeof document !== "undefined") {
            let script = document.createElement("script");
            script.src = asset.url + "?t=" + Date.now();
            if (asset.outputFormat === "esmodule") script.type = "module";
            return new Promise((resolve, reject)=>{
                var _document$head;
                script.onload = ()=>resolve(script);
                script.onerror = reject;
                (_document$head = document.head) === null || _document$head === void 0 || _document$head.appendChild(script);
            });
        } else if (typeof importScripts === "function") {
            // Worker scripts
            if (asset.outputFormat === "esmodule") return import(asset.url + "?t=" + Date.now());
            else return new Promise((resolve, reject)=>{
                try {
                    importScripts(asset.url + "?t=" + Date.now());
                    resolve();
                } catch (err) {
                    reject(err);
                }
            });
        }
    }
}
async function hmrApplyUpdates(assets) {
    global.parcelHotUpdate = Object.create(null);
    let scriptsToRemove;
    try {
        // If sourceURL comments aren't supported in eval, we need to load
        // the update from the dev server over HTTP so that stack traces
        // are correct in errors/logs. This is much slower than eval, so
        // we only do it if needed (currently just Safari).
        // https://bugs.webkit.org/show_bug.cgi?id=137297
        // This path is also taken if a CSP disallows eval.
        if (!supportsSourceURL) {
            let promises = assets.map((asset)=>{
                var _hmrDownload;
                return (_hmrDownload = hmrDownload(asset)) === null || _hmrDownload === void 0 ? void 0 : _hmrDownload.catch((err)=>{
                    // Web extension fix
                    if (extCtx && extCtx.runtime && extCtx.runtime.getManifest().manifest_version == 3 && typeof ServiceWorkerGlobalScope != "undefined" && global instanceof ServiceWorkerGlobalScope) {
                        extCtx.runtime.reload();
                        return;
                    }
                    throw err;
                });
            });
            scriptsToRemove = await Promise.all(promises);
        }
        assets.forEach(function(asset) {
            hmrApply(module.bundle.root, asset);
        });
    } finally{
        delete global.parcelHotUpdate;
        if (scriptsToRemove) scriptsToRemove.forEach((script)=>{
            if (script) {
                var _document$head2;
                (_document$head2 = document.head) === null || _document$head2 === void 0 || _document$head2.removeChild(script);
            }
        });
    }
}
function hmrApply(bundle /*: ParcelRequire */ , asset /*:  HMRAsset */ ) {
    var modules = bundle.modules;
    if (!modules) return;
    if (asset.type === "css") reloadCSS();
    else if (asset.type === "js") {
        let deps = asset.depsByBundle[bundle.HMR_BUNDLE_ID];
        if (deps) {
            if (modules[asset.id]) {
                // Remove dependencies that are removed and will become orphaned.
                // This is necessary so that if the asset is added back again, the cache is gone, and we prevent a full page reload.
                let oldDeps = modules[asset.id][1];
                for(let dep in oldDeps)if (!deps[dep] || deps[dep] !== oldDeps[dep]) {
                    let id = oldDeps[dep];
                    let parents = getParents(module.bundle.root, id);
                    if (parents.length === 1) hmrDelete(module.bundle.root, id);
                }
            }
            if (supportsSourceURL) // Global eval. We would use `new Function` here but browser
            // support for source maps is better with eval.
            (0, eval)(asset.output);
            // $FlowFixMe
            let fn = global.parcelHotUpdate[asset.id];
            modules[asset.id] = [
                fn,
                deps
            ];
        } else if (bundle.parent) hmrApply(bundle.parent, asset);
    }
}
function hmrDelete(bundle, id) {
    let modules = bundle.modules;
    if (!modules) return;
    if (modules[id]) {
        // Collect dependencies that will become orphaned when this module is deleted.
        let deps = modules[id][1];
        let orphans = [];
        for(let dep in deps){
            let parents = getParents(module.bundle.root, deps[dep]);
            if (parents.length === 1) orphans.push(deps[dep]);
        }
        // Delete the module. This must be done before deleting dependencies in case of circular dependencies.
        delete modules[id];
        delete bundle.cache[id];
        // Now delete the orphans.
        orphans.forEach((id)=>{
            hmrDelete(module.bundle.root, id);
        });
    } else if (bundle.parent) hmrDelete(bundle.parent, id);
}
function hmrAcceptCheck(bundle /*: ParcelRequire */ , id /*: string */ , depsByBundle /*: ?{ [string]: { [string]: string } }*/ ) {
    if (hmrAcceptCheckOne(bundle, id, depsByBundle)) return true;
    // Traverse parents breadth first. All possible ancestries must accept the HMR update, or we'll reload.
    let parents = getParents(module.bundle.root, id);
    let accepted = false;
    while(parents.length > 0){
        let v = parents.shift();
        let a = hmrAcceptCheckOne(v[0], v[1], null);
        if (a) // If this parent accepts, stop traversing upward, but still consider siblings.
        accepted = true;
        else {
            // Otherwise, queue the parents in the next level upward.
            let p = getParents(module.bundle.root, v[1]);
            if (p.length === 0) {
                // If there are no parents, then we've reached an entry without accepting. Reload.
                accepted = false;
                break;
            }
            parents.push(...p);
        }
    }
    return accepted;
}
function hmrAcceptCheckOne(bundle /*: ParcelRequire */ , id /*: string */ , depsByBundle /*: ?{ [string]: { [string]: string } }*/ ) {
    var modules = bundle.modules;
    if (!modules) return;
    if (depsByBundle && !depsByBundle[bundle.HMR_BUNDLE_ID]) {
        // If we reached the root bundle without finding where the asset should go,
        // there's nothing to do. Mark as "accepted" so we don't reload the page.
        if (!bundle.parent) return true;
        return hmrAcceptCheck(bundle.parent, id, depsByBundle);
    }
    if (checkedAssets[id]) return true;
    checkedAssets[id] = true;
    var cached = bundle.cache[id];
    assetsToDispose.push([
        bundle,
        id
    ]);
    if (!cached || cached.hot && cached.hot._acceptCallbacks.length) {
        assetsToAccept.push([
            bundle,
            id
        ]);
        return true;
    }
}
function hmrDispose(bundle /*: ParcelRequire */ , id /*: string */ ) {
    var cached = bundle.cache[id];
    bundle.hotData[id] = {};
    if (cached && cached.hot) cached.hot.data = bundle.hotData[id];
    if (cached && cached.hot && cached.hot._disposeCallbacks.length) cached.hot._disposeCallbacks.forEach(function(cb) {
        cb(bundle.hotData[id]);
    });
    delete bundle.cache[id];
}
function hmrAccept(bundle /*: ParcelRequire */ , id /*: string */ ) {
    // Execute the module.
    bundle(id);
    // Run the accept callbacks in the new version of the module.
    var cached = bundle.cache[id];
    if (cached && cached.hot && cached.hot._acceptCallbacks.length) cached.hot._acceptCallbacks.forEach(function(cb) {
        var assetsToAlsoAccept = cb(function() {
            return getParents(module.bundle.root, id);
        });
        if (assetsToAlsoAccept && assetsToAccept.length) {
            assetsToAlsoAccept.forEach(function(a) {
                hmrDispose(a[0], a[1]);
            });
            // $FlowFixMe[method-unbinding]
            assetsToAccept.push.apply(assetsToAccept, assetsToAlsoAccept);
        }
    });
}

},{}],"bB7Pu":[function(require,module,exports) {
const { BlobServiceClient } = require("bf2fee631817c7e7");
const createContainerButton = document.getElementById("create-container-button");
const deleteContainerButton = document.getElementById("delete-container-button");
const selectButton = document.getElementById("select-button");
const fileInput = document.getElementById("file-input");
const listButton = document.getElementById("list-button");
const deleteButton = document.getElementById("delete-button");
const status = document.getElementById("status");
const fileList = document.getElementById("file-list");
const reportStatus = (message)=>{
    status.innerHTML += `${message}<br/>`;
    status.scrollTop = status.scrollHeight;
};
// Update <placeholder> with your Blob service SAS URL string
const blobSasUrl = "https://mvstorageac.blob.core.windows.net/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-17T15:23:22Z&st=2024-07-16T07:23:22Z&sip=49.37.211.129&spr=https&sig=c2bLUP4Jg%2Fbeq0oaLjRDhSdO1FGOxmTxWGESMHF%2FlHA%3D";
// Create a new BlobServiceClient
const blobServiceClient = new BlobServiceClient(blobSasUrl);
// Create a unique name for the container by 
// appending the current time to the file name
const containerName = "container" + new Date().getTime();
// Get a container client from the BlobServiceClient
const containerClient = blobServiceClient.getContainerClient(containerName);
const createContainer = async ()=>{
    try {
        reportStatus(`Creating container "${containerName}"...`);
        await containerClient.create();
        reportStatus(`Done. URL:${containerClient.url}`);
    } catch (error) {
        reportStatus(error.message);
    }
};
const deleteContainer = async ()=>{
    try {
        reportStatus(`Deleting container "${containerName}"...`);
        await containerClient.delete();
        reportStatus(`Done.`);
    } catch (error) {
        reportStatus(error.message);
    }
};
createContainerButton.addEventListener("click", createContainer);
deleteContainerButton.addEventListener("click", deleteContainer);
const listFiles = async ()=>{
    fileList.size = 0;
    fileList.innerHTML = "";
    try {
        reportStatus("Retrieving file list...");
        let iter = containerClient.listBlobsFlat();
        let blobItem = await iter.next();
        while(!blobItem.done){
            fileList.size += 1;
            fileList.innerHTML += `<option>${blobItem.value.name}</option>`;
            blobItem = await iter.next();
        }
        if (fileList.size > 0) reportStatus("Done.");
        else reportStatus("The container does not contain any files.");
    } catch (error) {
        reportStatus(error.message);
    }
};
listButton.addEventListener("click", listFiles);
const uploadFiles = async ()=>{
    try {
        reportStatus("Uploading files...");
        const promises = [];
        for (const file of fileInput.files){
            const blockBlobClient = containerClient.getBlockBlobClient(file.name);
            promises.push(blockBlobClient.uploadBrowserData(file));
        }
        await Promise.all(promises);
        reportStatus("Done.");
        listFiles();
    } catch (error) {
        reportStatus(error.message);
    }
};
selectButton.addEventListener("click", ()=>fileInput.click());
fileInput.addEventListener("change", uploadFiles);
const deleteFiles = async ()=>{
    try {
        if (fileList.selectedOptions.length > 0) {
            reportStatus("Deleting files...");
            for (const option of fileList.selectedOptions)await containerClient.deleteBlob(option.text);
            reportStatus("Done.");
            listFiles();
        } else reportStatus("No files selected.");
    } catch (error) {
        reportStatus(error.message);
    }
};
deleteButton.addEventListener("click", deleteFiles);

},{"bf2fee631817c7e7":"6Mxp0"}],"6Mxp0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlockBlobTier", ()=>(0, _models.BlockBlobTier));
parcelHelpers.export(exports, "PremiumPageBlobTier", ()=>(0, _models.PremiumPageBlobTier));
parcelHelpers.export(exports, "Pipeline", ()=>(0, _pipeline.Pipeline));
parcelHelpers.export(exports, "isPipelineLike", ()=>(0, _pipeline.isPipelineLike));
parcelHelpers.export(exports, "newPipeline", ()=>(0, _pipeline.newPipeline));
parcelHelpers.export(exports, "StorageOAuthScopes", ()=>(0, _pipeline.StorageOAuthScopes));
parcelHelpers.export(exports, "BaseRequestPolicy", ()=>(0, _requestPolicy.BaseRequestPolicy));
parcelHelpers.export(exports, "logger", ()=>(0, _log.logger));
parcelHelpers.export(exports, "RestError", ()=>(0, _coreRestPipeline.RestError));
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _blobServiceClient = require("./BlobServiceClient");
parcelHelpers.exportAll(_blobServiceClient, exports);
var _clients = require("./Clients");
parcelHelpers.exportAll(_clients, exports);
var _containerClient = require("./ContainerClient");
parcelHelpers.exportAll(_containerClient, exports);
var _blobLeaseClient = require("./BlobLeaseClient");
parcelHelpers.exportAll(_blobLeaseClient, exports);
var _blobBatch = require("./BlobBatch");
parcelHelpers.exportAll(_blobBatch, exports);
var _blobBatchClient = require("./BlobBatchClient");
parcelHelpers.exportAll(_blobBatchClient, exports);
var _batchResponse = require("./BatchResponse");
parcelHelpers.exportAll(_batchResponse, exports);
var _storageBrowserPolicyFactory = require("./StorageBrowserPolicyFactory");
parcelHelpers.exportAll(_storageBrowserPolicyFactory, exports);
var _anonymousCredential = require("./credentials/AnonymousCredential");
parcelHelpers.exportAll(_anonymousCredential, exports);
var _credential = require("./credentials/Credential");
parcelHelpers.exportAll(_credential, exports);
var _models = require("./models");
var _pipeline = require("./Pipeline");
var _requestPolicy = require("./policies/RequestPolicy");
var _anonymousCredentialPolicy = require("./policies/AnonymousCredentialPolicy");
parcelHelpers.exportAll(_anonymousCredentialPolicy, exports);
var _credentialPolicy = require("./policies/CredentialPolicy");
parcelHelpers.exportAll(_credentialPolicy, exports);
var _storageRetryPolicyFactory = require("./StorageRetryPolicyFactory");
parcelHelpers.exportAll(_storageRetryPolicyFactory, exports);
var _generatedModels = require("./generatedModels");
parcelHelpers.exportAll(_generatedModels, exports);
var _log = require("./log");

},{"@azure/core-rest-pipeline":"d0mqv","./BlobServiceClient":"5lLVn","./Clients":false,"./ContainerClient":false,"./BlobLeaseClient":false,"./BlobBatch":false,"./BlobBatchClient":false,"./BatchResponse":false,"./StorageBrowserPolicyFactory":false,"./credentials/AnonymousCredential":false,"./credentials/Credential":false,"./models":false,"./Pipeline":false,"./policies/RequestPolicy":false,"./policies/AnonymousCredentialPolicy":false,"./policies/CredentialPolicy":false,"./StorageRetryPolicyFactory":false,"./generatedModels":false,"./log":false,"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d0mqv":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEmptyPipeline", ()=>(0, _pipelineJs.createEmptyPipeline));
parcelHelpers.export(exports, "createPipelineFromOptions", ()=>(0, _createPipelineFromOptionsJs.createPipelineFromOptions));
parcelHelpers.export(exports, "createDefaultHttpClient", ()=>(0, _defaultHttpClientJs.createDefaultHttpClient));
parcelHelpers.export(exports, "createHttpHeaders", ()=>(0, _httpHeadersJs.createHttpHeaders));
parcelHelpers.export(exports, "createPipelineRequest", ()=>(0, _pipelineRequestJs.createPipelineRequest));
parcelHelpers.export(exports, "RestError", ()=>(0, _restErrorJs.RestError));
parcelHelpers.export(exports, "isRestError", ()=>(0, _restErrorJs.isRestError));
parcelHelpers.export(exports, "decompressResponsePolicy", ()=>(0, _decompressResponsePolicyJs.decompressResponsePolicy));
parcelHelpers.export(exports, "decompressResponsePolicyName", ()=>(0, _decompressResponsePolicyJs.decompressResponsePolicyName));
parcelHelpers.export(exports, "exponentialRetryPolicy", ()=>(0, _exponentialRetryPolicyJs.exponentialRetryPolicy));
parcelHelpers.export(exports, "exponentialRetryPolicyName", ()=>(0, _exponentialRetryPolicyJs.exponentialRetryPolicyName));
parcelHelpers.export(exports, "setClientRequestIdPolicy", ()=>(0, _setClientRequestIdPolicyJs.setClientRequestIdPolicy));
parcelHelpers.export(exports, "setClientRequestIdPolicyName", ()=>(0, _setClientRequestIdPolicyJs.setClientRequestIdPolicyName));
parcelHelpers.export(exports, "logPolicy", ()=>(0, _logPolicyJs.logPolicy));
parcelHelpers.export(exports, "logPolicyName", ()=>(0, _logPolicyJs.logPolicyName));
parcelHelpers.export(exports, "multipartPolicy", ()=>(0, _multipartPolicyJs.multipartPolicy));
parcelHelpers.export(exports, "multipartPolicyName", ()=>(0, _multipartPolicyJs.multipartPolicyName));
parcelHelpers.export(exports, "proxyPolicy", ()=>(0, _proxyPolicyJs.proxyPolicy));
parcelHelpers.export(exports, "proxyPolicyName", ()=>(0, _proxyPolicyJs.proxyPolicyName));
parcelHelpers.export(exports, "getDefaultProxySettings", ()=>(0, _proxyPolicyJs.getDefaultProxySettings));
parcelHelpers.export(exports, "redirectPolicy", ()=>(0, _redirectPolicyJs.redirectPolicy));
parcelHelpers.export(exports, "redirectPolicyName", ()=>(0, _redirectPolicyJs.redirectPolicyName));
parcelHelpers.export(exports, "systemErrorRetryPolicy", ()=>(0, _systemErrorRetryPolicyJs.systemErrorRetryPolicy));
parcelHelpers.export(exports, "systemErrorRetryPolicyName", ()=>(0, _systemErrorRetryPolicyJs.systemErrorRetryPolicyName));
parcelHelpers.export(exports, "throttlingRetryPolicy", ()=>(0, _throttlingRetryPolicyJs.throttlingRetryPolicy));
parcelHelpers.export(exports, "throttlingRetryPolicyName", ()=>(0, _throttlingRetryPolicyJs.throttlingRetryPolicyName));
parcelHelpers.export(exports, "retryPolicy", ()=>(0, _retryPolicyJs.retryPolicy));
parcelHelpers.export(exports, "tracingPolicy", ()=>(0, _tracingPolicyJs.tracingPolicy));
parcelHelpers.export(exports, "tracingPolicyName", ()=>(0, _tracingPolicyJs.tracingPolicyName));
parcelHelpers.export(exports, "defaultRetryPolicy", ()=>(0, _defaultRetryPolicyJs.defaultRetryPolicy));
parcelHelpers.export(exports, "userAgentPolicy", ()=>(0, _userAgentPolicyJs.userAgentPolicy));
parcelHelpers.export(exports, "userAgentPolicyName", ()=>(0, _userAgentPolicyJs.userAgentPolicyName));
parcelHelpers.export(exports, "tlsPolicy", ()=>(0, _tlsPolicyJs.tlsPolicy));
parcelHelpers.export(exports, "tlsPolicyName", ()=>(0, _tlsPolicyJs.tlsPolicyName));
parcelHelpers.export(exports, "formDataPolicy", ()=>(0, _formDataPolicyJs.formDataPolicy));
parcelHelpers.export(exports, "formDataPolicyName", ()=>(0, _formDataPolicyJs.formDataPolicyName));
parcelHelpers.export(exports, "bearerTokenAuthenticationPolicy", ()=>(0, _bearerTokenAuthenticationPolicyJs.bearerTokenAuthenticationPolicy));
parcelHelpers.export(exports, "bearerTokenAuthenticationPolicyName", ()=>(0, _bearerTokenAuthenticationPolicyJs.bearerTokenAuthenticationPolicyName));
parcelHelpers.export(exports, "ndJsonPolicy", ()=>(0, _ndJsonPolicyJs.ndJsonPolicy));
parcelHelpers.export(exports, "ndJsonPolicyName", ()=>(0, _ndJsonPolicyJs.ndJsonPolicyName));
parcelHelpers.export(exports, "auxiliaryAuthenticationHeaderPolicy", ()=>(0, _auxiliaryAuthenticationHeaderPolicyJs.auxiliaryAuthenticationHeaderPolicy));
parcelHelpers.export(exports, "auxiliaryAuthenticationHeaderPolicyName", ()=>(0, _auxiliaryAuthenticationHeaderPolicyJs.auxiliaryAuthenticationHeaderPolicyName));
parcelHelpers.export(exports, "createFile", ()=>(0, _fileJs.createFile));
parcelHelpers.export(exports, "createFileFromStream", ()=>(0, _fileJs.createFileFromStream));
var _pipelineJs = require("./pipeline.js");
var _createPipelineFromOptionsJs = require("./createPipelineFromOptions.js");
var _defaultHttpClientJs = require("./defaultHttpClient.js");
var _httpHeadersJs = require("./httpHeaders.js");
var _pipelineRequestJs = require("./pipelineRequest.js");
var _restErrorJs = require("./restError.js");
var _decompressResponsePolicyJs = require("./policies/decompressResponsePolicy.js");
var _exponentialRetryPolicyJs = require("./policies/exponentialRetryPolicy.js");
var _setClientRequestIdPolicyJs = require("./policies/setClientRequestIdPolicy.js");
var _logPolicyJs = require("./policies/logPolicy.js");
var _multipartPolicyJs = require("./policies/multipartPolicy.js");
var _proxyPolicyJs = require("./policies/proxyPolicy.js");
var _redirectPolicyJs = require("./policies/redirectPolicy.js");
var _systemErrorRetryPolicyJs = require("./policies/systemErrorRetryPolicy.js");
var _throttlingRetryPolicyJs = require("./policies/throttlingRetryPolicy.js");
var _retryPolicyJs = require("./policies/retryPolicy.js");
var _tracingPolicyJs = require("./policies/tracingPolicy.js");
var _defaultRetryPolicyJs = require("./policies/defaultRetryPolicy.js");
var _userAgentPolicyJs = require("./policies/userAgentPolicy.js");
var _tlsPolicyJs = require("./policies/tlsPolicy.js");
var _formDataPolicyJs = require("./policies/formDataPolicy.js");
var _bearerTokenAuthenticationPolicyJs = require("./policies/bearerTokenAuthenticationPolicy.js");
var _ndJsonPolicyJs = require("./policies/ndJsonPolicy.js");
var _auxiliaryAuthenticationHeaderPolicyJs = require("./policies/auxiliaryAuthenticationHeaderPolicy.js");
var _fileJs = require("./util/file.js");

},{"./pipeline.js":"cFVIy","./createPipelineFromOptions.js":"crBcB","./defaultHttpClient.js":"l9pN8","./httpHeaders.js":"6kO5I","./pipelineRequest.js":"5jPfp","./restError.js":"4zR2D","./policies/decompressResponsePolicy.js":"aqGPB","./policies/exponentialRetryPolicy.js":"72bbW","./policies/setClientRequestIdPolicy.js":"bniwV","./policies/logPolicy.js":"9oEDS","./policies/multipartPolicy.js":"8iA8I","./policies/proxyPolicy.js":"8CnpE","./policies/redirectPolicy.js":"7nGeV","./policies/systemErrorRetryPolicy.js":"loJXt","./policies/throttlingRetryPolicy.js":"ar39k","./policies/retryPolicy.js":"jxxY0","./policies/tracingPolicy.js":"2kvXs","./policies/defaultRetryPolicy.js":"cccLy","./policies/userAgentPolicy.js":"AaMYP","./policies/tlsPolicy.js":"4amLW","./policies/formDataPolicy.js":"4TRyW","./policies/bearerTokenAuthenticationPolicy.js":"2U14w","./policies/ndJsonPolicy.js":"gSxn5","./policies/auxiliaryAuthenticationHeaderPolicy.js":"aG7O2","./util/file.js":"ivG8n","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cFVIy":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates a totally empty pipeline.
 * Useful for testing or creating a custom one.
 */ parcelHelpers.export(exports, "createEmptyPipeline", ()=>createEmptyPipeline);
const ValidPhaseNames = new Set([
    "Deserialize",
    "Serialize",
    "Retry",
    "Sign"
]);
/**
 * A private implementation of Pipeline.
 * Do not export this class from the package.
 * @internal
 */ class HttpPipeline {
    constructor(policies){
        var _a;
        this._policies = [];
        this._policies = (_a = policies === null || policies === void 0 ? void 0 : policies.slice(0)) !== null && _a !== void 0 ? _a : [];
        this._orderedPolicies = undefined;
    }
    addPolicy(policy, options = {}) {
        if (options.phase && options.afterPhase) throw new Error("Policies inside a phase cannot specify afterPhase.");
        if (options.phase && !ValidPhaseNames.has(options.phase)) throw new Error(`Invalid phase name: ${options.phase}`);
        if (options.afterPhase && !ValidPhaseNames.has(options.afterPhase)) throw new Error(`Invalid afterPhase name: ${options.afterPhase}`);
        this._policies.push({
            policy,
            options
        });
        this._orderedPolicies = undefined;
    }
    removePolicy(options) {
        const removedPolicies = [];
        this._policies = this._policies.filter((policyDescriptor)=>{
            if (options.name && policyDescriptor.policy.name === options.name || options.phase && policyDescriptor.options.phase === options.phase) {
                removedPolicies.push(policyDescriptor.policy);
                return false;
            } else return true;
        });
        this._orderedPolicies = undefined;
        return removedPolicies;
    }
    sendRequest(httpClient, request) {
        const policies = this.getOrderedPolicies();
        const pipeline = policies.reduceRight((next, policy)=>{
            return (req)=>{
                return policy.sendRequest(req, next);
            };
        }, (req)=>httpClient.sendRequest(req));
        return pipeline(request);
    }
    getOrderedPolicies() {
        if (!this._orderedPolicies) this._orderedPolicies = this.orderPolicies();
        return this._orderedPolicies;
    }
    clone() {
        return new HttpPipeline(this._policies);
    }
    static create() {
        return new HttpPipeline();
    }
    orderPolicies() {
        /**
         * The goal of this method is to reliably order pipeline policies
         * based on their declared requirements when they were added.
         *
         * Order is first determined by phase:
         *
         * 1. Serialize Phase
         * 2. Policies not in a phase
         * 3. Deserialize Phase
         * 4. Retry Phase
         * 5. Sign Phase
         *
         * Within each phase, policies are executed in the order
         * they were added unless they were specified to execute
         * before/after other policies or after a particular phase.
         *
         * To determine the final order, we will walk the policy list
         * in phase order multiple times until all dependencies are
         * satisfied.
         *
         * `afterPolicies` are the set of policies that must be
         * executed before a given policy. This requirement is
         * considered satisfied when each of the listed policies
         * have been scheduled.
         *
         * `beforePolicies` are the set of policies that must be
         * executed after a given policy. Since this dependency
         * can be expressed by converting it into a equivalent
         * `afterPolicies` declarations, they are normalized
         * into that form for simplicity.
         *
         * An `afterPhase` dependency is considered satisfied when all
         * policies in that phase have scheduled.
         *
         */ const result = [];
        // Track all policies we know about.
        const policyMap = new Map();
        function createPhase(name) {
            return {
                name,
                policies: new Set(),
                hasRun: false,
                hasAfterPolicies: false
            };
        }
        // Track policies for each phase.
        const serializePhase = createPhase("Serialize");
        const noPhase = createPhase("None");
        const deserializePhase = createPhase("Deserialize");
        const retryPhase = createPhase("Retry");
        const signPhase = createPhase("Sign");
        // a list of phases in order
        const orderedPhases = [
            serializePhase,
            noPhase,
            deserializePhase,
            retryPhase,
            signPhase
        ];
        // Small helper function to map phase name to each Phase
        function getPhase(phase) {
            if (phase === "Retry") return retryPhase;
            else if (phase === "Serialize") return serializePhase;
            else if (phase === "Deserialize") return deserializePhase;
            else if (phase === "Sign") return signPhase;
            else return noPhase;
        }
        // First walk each policy and create a node to track metadata.
        for (const descriptor of this._policies){
            const policy = descriptor.policy;
            const options = descriptor.options;
            const policyName = policy.name;
            if (policyMap.has(policyName)) throw new Error("Duplicate policy names not allowed in pipeline");
            const node = {
                policy,
                dependsOn: new Set(),
                dependants: new Set()
            };
            if (options.afterPhase) {
                node.afterPhase = getPhase(options.afterPhase);
                node.afterPhase.hasAfterPolicies = true;
            }
            policyMap.set(policyName, node);
            const phase = getPhase(options.phase);
            phase.policies.add(node);
        }
        // Now that each policy has a node, connect dependency references.
        for (const descriptor of this._policies){
            const { policy, options } = descriptor;
            const policyName = policy.name;
            const node = policyMap.get(policyName);
            if (!node) throw new Error(`Missing node for policy ${policyName}`);
            if (options.afterPolicies) for (const afterPolicyName of options.afterPolicies){
                const afterNode = policyMap.get(afterPolicyName);
                if (afterNode) {
                    // Linking in both directions helps later
                    // when we want to notify dependants.
                    node.dependsOn.add(afterNode);
                    afterNode.dependants.add(node);
                }
            }
            if (options.beforePolicies) for (const beforePolicyName of options.beforePolicies){
                const beforeNode = policyMap.get(beforePolicyName);
                if (beforeNode) {
                    // To execute before another node, make it
                    // depend on the current node.
                    beforeNode.dependsOn.add(node);
                    node.dependants.add(beforeNode);
                }
            }
        }
        function walkPhase(phase) {
            phase.hasRun = true;
            // Sets iterate in insertion order
            for (const node of phase.policies){
                if (node.afterPhase && (!node.afterPhase.hasRun || node.afterPhase.policies.size)) continue;
                if (node.dependsOn.size === 0) {
                    // If there's nothing else we're waiting for, we can
                    // add this policy to the result list.
                    result.push(node.policy);
                    // Notify anything that depends on this policy that
                    // the policy has been scheduled.
                    for (const dependant of node.dependants)dependant.dependsOn.delete(node);
                    policyMap.delete(node.policy.name);
                    phase.policies.delete(node);
                }
            }
        }
        function walkPhases() {
            for (const phase of orderedPhases){
                walkPhase(phase);
                // if the phase isn't complete
                if (phase.policies.size > 0 && phase !== noPhase) {
                    if (!noPhase.hasRun) // Try running noPhase to see if that unblocks this phase next tick.
                    // This can happen if a phase that happens before noPhase
                    // is waiting on a noPhase policy to complete.
                    walkPhase(noPhase);
                    // Don't proceed to the next phase until this phase finishes.
                    return;
                }
                if (phase.hasAfterPolicies) // Run any policies unblocked by this phase
                walkPhase(noPhase);
            }
        }
        // Iterate until we've put every node in the result list.
        let iteration = 0;
        while(policyMap.size > 0){
            iteration++;
            const initialResultLength = result.length;
            // Keep walking each phase in order until we can order every node.
            walkPhases();
            // The result list *should* get at least one larger each time
            // after the first full pass.
            // Otherwise, we're going to loop forever.
            if (result.length <= initialResultLength && iteration > 1) throw new Error("Cannot satisfy policy dependencies due to requirements cycle.");
        }
        return result;
    }
}
function createEmptyPipeline() {
    return HttpPipeline.create();
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gkKU3":[function(require,module,exports) {
exports.interopDefault = function(a) {
    return a && a.__esModule ? a : {
        default: a
    };
};
exports.defineInteropFlag = function(a) {
    Object.defineProperty(a, "__esModule", {
        value: true
    });
};
exports.exportAll = function(source, dest) {
    Object.keys(source).forEach(function(key) {
        if (key === "default" || key === "__esModule" || Object.prototype.hasOwnProperty.call(dest, key)) return;
        Object.defineProperty(dest, key, {
            enumerable: true,
            get: function() {
                return source[key];
            }
        });
    });
    return dest;
};
exports.export = function(dest, destName, get) {
    Object.defineProperty(dest, destName, {
        enumerable: true,
        get: get
    });
};

},{}],"crBcB":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Create a new pipeline with a default set of customizable policies.
 * @param options - Options to configure a custom pipeline.
 */ parcelHelpers.export(exports, "createPipelineFromOptions", ()=>createPipelineFromOptions);
var _logPolicyJs = require("./policies/logPolicy.js");
var _pipelineJs = require("./pipeline.js");
var _redirectPolicyJs = require("./policies/redirectPolicy.js");
var _userAgentPolicyJs = require("./policies/userAgentPolicy.js");
var _multipartPolicyJs = require("./policies/multipartPolicy.js");
var _decompressResponsePolicyJs = require("./policies/decompressResponsePolicy.js");
var _defaultRetryPolicyJs = require("./policies/defaultRetryPolicy.js");
var _formDataPolicyJs = require("./policies/formDataPolicy.js");
var _coreUtil = require("@azure/core-util");
var _proxyPolicyJs = require("./policies/proxyPolicy.js");
var _setClientRequestIdPolicyJs = require("./policies/setClientRequestIdPolicy.js");
var _tlsPolicyJs = require("./policies/tlsPolicy.js");
var _tracingPolicyJs = require("./policies/tracingPolicy.js");
function createPipelineFromOptions(options) {
    var _a;
    const pipeline = (0, _pipelineJs.createEmptyPipeline)();
    if (0, _coreUtil.isNodeLike) {
        if (options.tlsOptions) pipeline.addPolicy((0, _tlsPolicyJs.tlsPolicy)(options.tlsOptions));
        pipeline.addPolicy((0, _proxyPolicyJs.proxyPolicy)(options.proxyOptions));
        pipeline.addPolicy((0, _decompressResponsePolicyJs.decompressResponsePolicy)());
    }
    pipeline.addPolicy((0, _formDataPolicyJs.formDataPolicy)(), {
        beforePolicies: [
            (0, _multipartPolicyJs.multipartPolicyName)
        ]
    });
    pipeline.addPolicy((0, _userAgentPolicyJs.userAgentPolicy)(options.userAgentOptions));
    pipeline.addPolicy((0, _setClientRequestIdPolicyJs.setClientRequestIdPolicy)((_a = options.telemetryOptions) === null || _a === void 0 ? void 0 : _a.clientRequestIdHeaderName));
    // The multipart policy is added after policies with no phase, so that
    // policies can be added between it and formDataPolicy to modify
    // properties (e.g., making the boundary constant in recorded tests).
    pipeline.addPolicy((0, _multipartPolicyJs.multipartPolicy)(), {
        afterPhase: "Deserialize"
    });
    pipeline.addPolicy((0, _defaultRetryPolicyJs.defaultRetryPolicy)(options.retryOptions), {
        phase: "Retry"
    });
    pipeline.addPolicy((0, _tracingPolicyJs.tracingPolicy)(Object.assign(Object.assign({}, options.userAgentOptions), options.loggingOptions)), {
        afterPhase: "Retry"
    });
    if (0, _coreUtil.isNodeLike) // Both XHR and Fetch expect to handle redirects automatically,
    // so only include this policy when we're in Node.
    pipeline.addPolicy((0, _redirectPolicyJs.redirectPolicy)(options.redirectOptions), {
        afterPhase: "Retry"
    });
    pipeline.addPolicy((0, _logPolicyJs.logPolicy)(options.loggingOptions), {
        afterPhase: "Sign"
    });
    return pipeline;
}

},{"./policies/logPolicy.js":"9oEDS","./pipeline.js":"cFVIy","./policies/redirectPolicy.js":"7nGeV","./policies/userAgentPolicy.js":"AaMYP","./policies/multipartPolicy.js":"8iA8I","./policies/decompressResponsePolicy.js":"aqGPB","./policies/defaultRetryPolicy.js":"cccLy","./policies/formDataPolicy.js":"4TRyW","@azure/core-util":"b31OK","./policies/proxyPolicy.js":"8CnpE","./policies/setClientRequestIdPolicy.js":"bniwV","./policies/tlsPolicy.js":"4amLW","./policies/tracingPolicy.js":"2kvXs","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9oEDS":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "logPolicyName", ()=>logPolicyName);
/**
 * A policy that logs all requests and responses.
 * @param options - Options to configure logPolicy.
 */ parcelHelpers.export(exports, "logPolicy", ()=>logPolicy);
var _logJs = require("../log.js");
var _sanitizerJs = require("../util/sanitizer.js");
const logPolicyName = "logPolicy";
function logPolicy(options = {}) {
    var _a;
    const logger = (_a = options.logger) !== null && _a !== void 0 ? _a : (0, _logJs.logger).info;
    const sanitizer = new (0, _sanitizerJs.Sanitizer)({
        additionalAllowedHeaderNames: options.additionalAllowedHeaderNames,
        additionalAllowedQueryParameters: options.additionalAllowedQueryParameters
    });
    return {
        name: logPolicyName,
        async sendRequest (request, next) {
            if (!logger.enabled) return next(request);
            logger(`Request: ${sanitizer.sanitize(request)}`);
            const response = await next(request);
            logger(`Response status code: ${response.status}`);
            logger(`Headers: ${sanitizer.sanitize(response.headers)}`);
            return response;
        }
    };
}

},{"../log.js":"ajkUj","../util/sanitizer.js":"eLdTc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ajkUj":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "logger", ()=>logger);
var _logger = require("@azure/logger");
const logger = (0, _logger.createClientLogger)("core-rest-pipeline");

},{"@azure/logger":"cnBke","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cnBke":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AzureLogger", ()=>AzureLogger);
/**
 * Immediately enables logging at the specified log level. If no level is specified, logging is disabled.
 * @param level - The log level to enable for logging.
 * Options from most verbose to least verbose are:
 * - verbose
 * - info
 * - warning
 * - error
 */ parcelHelpers.export(exports, "setLogLevel", ()=>setLogLevel);
/**
 * Retrieves the currently specified log level.
 */ parcelHelpers.export(exports, "getLogLevel", ()=>getLogLevel);
/**
 * Creates a logger for use by the Azure SDKs that inherits from `AzureLogger`.
 * @param namespace - The name of the SDK package.
 * @hidden
 */ parcelHelpers.export(exports, "createClientLogger", ()=>createClientLogger);
var _debugJs = require("./debug.js");
var _debugJsDefault = parcelHelpers.interopDefault(_debugJs);
var process = require("5a5fae4304583155");
const registeredLoggers = new Set();
const logLevelFromEnv = (typeof process !== "undefined" && process.env && undefined, undefined);
let azureLogLevel;
const AzureLogger = (0, _debugJsDefault.default)("azure");
AzureLogger.log = (...args)=>{
    (0, _debugJsDefault.default).log(...args);
};
const AZURE_LOG_LEVELS = [
    "verbose",
    "info",
    "warning",
    "error"
];
if (logLevelFromEnv) {
    // avoid calling setLogLevel because we don't want a mis-set environment variable to crash
    if (isAzureLogLevel(logLevelFromEnv)) setLogLevel(logLevelFromEnv);
    else console.error(`AZURE_LOG_LEVEL set to unknown log level '${logLevelFromEnv}'; logging is not enabled. Acceptable values: ${AZURE_LOG_LEVELS.join(", ")}.`);
}
function setLogLevel(level) {
    if (level && !isAzureLogLevel(level)) throw new Error(`Unknown log level '${level}'. Acceptable values: ${AZURE_LOG_LEVELS.join(",")}`);
    azureLogLevel = level;
    const enabledNamespaces = [];
    for (const logger of registeredLoggers)if (shouldEnable(logger)) enabledNamespaces.push(logger.namespace);
    (0, _debugJsDefault.default).enable(enabledNamespaces.join(","));
}
function getLogLevel() {
    return azureLogLevel;
}
const levelMap = {
    verbose: 400,
    info: 300,
    warning: 200,
    error: 100
};
function createClientLogger(namespace) {
    const clientRootLogger = AzureLogger.extend(namespace);
    patchLogMethod(AzureLogger, clientRootLogger);
    return {
        error: createLogger(clientRootLogger, "error"),
        warning: createLogger(clientRootLogger, "warning"),
        info: createLogger(clientRootLogger, "info"),
        verbose: createLogger(clientRootLogger, "verbose")
    };
}
function patchLogMethod(parent, child) {
    child.log = (...args)=>{
        parent.log(...args);
    };
}
function createLogger(parent, level) {
    const logger = Object.assign(parent.extend(level), {
        level
    });
    patchLogMethod(parent, logger);
    if (shouldEnable(logger)) {
        const enabledNamespaces = (0, _debugJsDefault.default).disable();
        (0, _debugJsDefault.default).enable(enabledNamespaces + "," + logger.namespace);
    }
    registeredLoggers.add(logger);
    return logger;
}
function shouldEnable(logger) {
    return Boolean(azureLogLevel && levelMap[logger.level] <= levelMap[azureLogLevel]);
}
function isAzureLogLevel(logLevel) {
    return AZURE_LOG_LEVELS.includes(logLevel);
}

},{"5a5fae4304583155":"d5jf4","./debug.js":"7mZPt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d5jf4":[function(require,module,exports) {
// shim for using process in browser
var process = module.exports = {};
// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.
var cachedSetTimeout;
var cachedClearTimeout;
function defaultSetTimout() {
    throw new Error("setTimeout has not been defined");
}
function defaultClearTimeout() {
    throw new Error("clearTimeout has not been defined");
}
(function() {
    try {
        if (typeof setTimeout === "function") cachedSetTimeout = setTimeout;
        else cachedSetTimeout = defaultSetTimout;
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === "function") cachedClearTimeout = clearTimeout;
        else cachedClearTimeout = defaultClearTimeout;
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
})();
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) //normal enviroments in sane situations
    return setTimeout(fun, 0);
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch (e) {
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch (e) {
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }
}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) //normal enviroments in sane situations
    return clearTimeout(marker);
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e) {
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e) {
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }
}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;
function cleanUpNextTick() {
    if (!draining || !currentQueue) return;
    draining = false;
    if (currentQueue.length) queue = currentQueue.concat(queue);
    else queueIndex = -1;
    if (queue.length) drainQueue();
}
function drainQueue() {
    if (draining) return;
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;
    var len = queue.length;
    while(len){
        currentQueue = queue;
        queue = [];
        while(++queueIndex < len)if (currentQueue) currentQueue[queueIndex].run();
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}
process.nextTick = function(fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) for(var i = 1; i < arguments.length; i++)args[i - 1] = arguments[i];
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) runTimeout(drainQueue);
};
// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function() {
    this.fun.apply(null, this.array);
};
process.title = "browser";
process.browser = true;
process.env = {};
process.argv = [];
process.version = ""; // empty string to avoid regexp issues
process.versions = {};
function noop() {}
process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;
process.listeners = function(name) {
    return [];
};
process.binding = function(name) {
    throw new Error("process.binding is not supported");
};
process.cwd = function() {
    return "/";
};
process.chdir = function(dir) {
    throw new Error("process.chdir is not supported");
};
process.umask = function() {
    return 0;
};

},{}],"7mZPt":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _logJs = require("./log.js");
var process = require("7f1d0e51c4858939");
const debugEnvVariable = (typeof process !== "undefined" && process.env && undefined, undefined);
let enabledString;
let enabledNamespaces = [];
let skippedNamespaces = [];
const debuggers = [];
if (debugEnvVariable) enable(debugEnvVariable);
const debugObj = Object.assign((namespace)=>{
    return createDebugger(namespace);
}, {
    enable,
    enabled,
    disable,
    log: (0, _logJs.log)
});
function enable(namespaces) {
    enabledString = namespaces;
    enabledNamespaces = [];
    skippedNamespaces = [];
    const wildcard = /\*/g;
    const namespaceList = namespaces.split(",").map((ns)=>ns.trim().replace(wildcard, ".*?"));
    for (const ns of namespaceList)if (ns.startsWith("-")) skippedNamespaces.push(new RegExp(`^${ns.substr(1)}$`));
    else enabledNamespaces.push(new RegExp(`^${ns}$`));
    for (const instance of debuggers)instance.enabled = enabled(instance.namespace);
}
function enabled(namespace) {
    if (namespace.endsWith("*")) return true;
    for (const skipped of skippedNamespaces){
        if (skipped.test(namespace)) return false;
    }
    for (const enabledNamespace of enabledNamespaces){
        if (enabledNamespace.test(namespace)) return true;
    }
    return false;
}
function disable() {
    const result = enabledString || "";
    enable("");
    return result;
}
function createDebugger(namespace) {
    const newDebugger = Object.assign(debug, {
        enabled: enabled(namespace),
        destroy,
        log: debugObj.log,
        namespace,
        extend
    });
    function debug(...args) {
        if (!newDebugger.enabled) return;
        if (args.length > 0) args[0] = `${namespace} ${args[0]}`;
        newDebugger.log(...args);
    }
    debuggers.push(newDebugger);
    return newDebugger;
}
function destroy() {
    const index = debuggers.indexOf(this);
    if (index >= 0) {
        debuggers.splice(index, 1);
        return true;
    }
    return false;
}
function extend(namespace) {
    const newDebugger = createDebugger(`${this.namespace}:${namespace}`);
    newDebugger.log = this.log;
    return newDebugger;
}
exports.default = debugObj;

},{"7f1d0e51c4858939":"d5jf4","./log.js":"qqVRt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"qqVRt":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "log", ()=>(0, _logCommonJs.log));
var _logCommonJs = require("./log.common.js");

},{"./log.common.js":"kclwX","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kclwX":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "log", ()=>log);
function log(...args) {
    if (args.length > 0) {
        const firstArg = String(args[0]);
        if (firstArg.includes(":error")) console.error(...args);
        else if (firstArg.includes(":warning")) console.warn(...args);
        else if (firstArg.includes(":info")) console.info(...args);
        else if (firstArg.includes(":verbose")) console.debug(...args);
        else console.debug(...args);
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eLdTc":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @internal
 */ parcelHelpers.export(exports, "Sanitizer", ()=>Sanitizer);
var _coreUtil = require("@azure/core-util");
const RedactedString = "REDACTED";
// Make sure this list is up-to-date with the one under core/logger/Readme#Keyconcepts
const defaultAllowedHeaderNames = [
    "x-ms-client-request-id",
    "x-ms-return-client-request-id",
    "x-ms-useragent",
    "x-ms-correlation-request-id",
    "x-ms-request-id",
    "client-request-id",
    "ms-cv",
    "return-client-request-id",
    "traceparent",
    "Access-Control-Allow-Credentials",
    "Access-Control-Allow-Headers",
    "Access-Control-Allow-Methods",
    "Access-Control-Allow-Origin",
    "Access-Control-Expose-Headers",
    "Access-Control-Max-Age",
    "Access-Control-Request-Headers",
    "Access-Control-Request-Method",
    "Origin",
    "Accept",
    "Accept-Encoding",
    "Cache-Control",
    "Connection",
    "Content-Length",
    "Content-Type",
    "Date",
    "ETag",
    "Expires",
    "If-Match",
    "If-Modified-Since",
    "If-None-Match",
    "If-Unmodified-Since",
    "Last-Modified",
    "Pragma",
    "Request-Id",
    "Retry-After",
    "Server",
    "Transfer-Encoding",
    "User-Agent",
    "WWW-Authenticate"
];
const defaultAllowedQueryParameters = [
    "api-version"
];
class Sanitizer {
    constructor({ additionalAllowedHeaderNames: allowedHeaderNames = [], additionalAllowedQueryParameters: allowedQueryParameters = [] } = {}){
        allowedHeaderNames = defaultAllowedHeaderNames.concat(allowedHeaderNames);
        allowedQueryParameters = defaultAllowedQueryParameters.concat(allowedQueryParameters);
        this.allowedHeaderNames = new Set(allowedHeaderNames.map((n)=>n.toLowerCase()));
        this.allowedQueryParameters = new Set(allowedQueryParameters.map((p)=>p.toLowerCase()));
    }
    sanitize(obj) {
        const seen = new Set();
        return JSON.stringify(obj, (key, value)=>{
            // Ensure Errors include their interesting non-enumerable members
            if (value instanceof Error) return Object.assign(Object.assign({}, value), {
                name: value.name,
                message: value.message
            });
            if (key === "headers") return this.sanitizeHeaders(value);
            else if (key === "url") return this.sanitizeUrl(value);
            else if (key === "query") return this.sanitizeQuery(value);
            else if (key === "body") // Don't log the request body
            return undefined;
            else if (key === "response") // Don't log response again
            return undefined;
            else if (key === "operationSpec") // When using sendOperationRequest, the request carries a massive
            // field with the autorest spec. No need to log it.
            return undefined;
            else if (Array.isArray(value) || (0, _coreUtil.isObject)(value)) {
                if (seen.has(value)) return "[Circular]";
                seen.add(value);
            }
            return value;
        }, 2);
    }
    sanitizeUrl(value) {
        if (typeof value !== "string" || value === null || value === "") return value;
        const url = new URL(value);
        if (!url.search) return value;
        for (const [key] of url.searchParams)if (!this.allowedQueryParameters.has(key.toLowerCase())) url.searchParams.set(key, RedactedString);
        return url.toString();
    }
    sanitizeHeaders(obj) {
        const sanitized = {};
        for (const key of Object.keys(obj))if (this.allowedHeaderNames.has(key.toLowerCase())) sanitized[key] = obj[key];
        else sanitized[key] = RedactedString;
        return sanitized;
    }
    sanitizeQuery(value) {
        if (typeof value !== "object" || value === null) return value;
        const sanitized = {};
        for (const k of Object.keys(value))if (this.allowedQueryParameters.has(k.toLowerCase())) sanitized[k] = value[k];
        else sanitized[k] = RedactedString;
        return sanitized;
    }
}

},{"@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"b31OK":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "delay", ()=>(0, _delayJs.delay));
parcelHelpers.export(exports, "cancelablePromiseRace", ()=>(0, _aborterUtilsJs.cancelablePromiseRace));
parcelHelpers.export(exports, "createAbortablePromise", ()=>(0, _createAbortablePromiseJs.createAbortablePromise));
parcelHelpers.export(exports, "getRandomIntegerInclusive", ()=>(0, _randomJs.getRandomIntegerInclusive));
parcelHelpers.export(exports, "isObject", ()=>(0, _objectJs.isObject));
parcelHelpers.export(exports, "isError", ()=>(0, _errorJs.isError));
parcelHelpers.export(exports, "getErrorMessage", ()=>(0, _errorJs.getErrorMessage));
parcelHelpers.export(exports, "computeSha256Hash", ()=>(0, _sha256Js.computeSha256Hash));
parcelHelpers.export(exports, "computeSha256Hmac", ()=>(0, _sha256Js.computeSha256Hmac));
parcelHelpers.export(exports, "isDefined", ()=>(0, _typeGuardsJs.isDefined));
parcelHelpers.export(exports, "isObjectWithProperties", ()=>(0, _typeGuardsJs.isObjectWithProperties));
parcelHelpers.export(exports, "objectHasProperty", ()=>(0, _typeGuardsJs.objectHasProperty));
parcelHelpers.export(exports, "randomUUID", ()=>(0, _uuidUtilsJs.randomUUID));
parcelHelpers.export(exports, "isBrowser", ()=>(0, _checkEnvironmentJs.isBrowser));
parcelHelpers.export(exports, "isBun", ()=>(0, _checkEnvironmentJs.isBun));
parcelHelpers.export(exports, "isNode", ()=>(0, _checkEnvironmentJs.isNode));
parcelHelpers.export(exports, "isNodeLike", ()=>(0, _checkEnvironmentJs.isNodeLike));
parcelHelpers.export(exports, "isNodeRuntime", ()=>(0, _checkEnvironmentJs.isNodeRuntime));
parcelHelpers.export(exports, "isDeno", ()=>(0, _checkEnvironmentJs.isDeno));
parcelHelpers.export(exports, "isReactNative", ()=>(0, _checkEnvironmentJs.isReactNative));
parcelHelpers.export(exports, "isWebWorker", ()=>(0, _checkEnvironmentJs.isWebWorker));
parcelHelpers.export(exports, "uint8ArrayToString", ()=>(0, _bytesEncodingJs.uint8ArrayToString));
parcelHelpers.export(exports, "stringToUint8Array", ()=>(0, _bytesEncodingJs.stringToUint8Array));
var _delayJs = require("./delay.js");
var _aborterUtilsJs = require("./aborterUtils.js");
var _createAbortablePromiseJs = require("./createAbortablePromise.js");
var _randomJs = require("./random.js");
var _objectJs = require("./object.js");
var _errorJs = require("./error.js");
var _sha256Js = require("./sha256.js");
var _typeGuardsJs = require("./typeGuards.js");
var _uuidUtilsJs = require("./uuidUtils.js");
var _checkEnvironmentJs = require("./checkEnvironment.js");
var _bytesEncodingJs = require("./bytesEncoding.js");

},{"./delay.js":"hbslV","./aborterUtils.js":"8YijF","./createAbortablePromise.js":"4ieNk","./random.js":"8dwr1","./object.js":"2ZOx0","./error.js":"liUda","./sha256.js":"jbbgt","./typeGuards.js":"3J9Lj","./uuidUtils.js":"fdfdr","./checkEnvironment.js":"a8Cb2","./bytesEncoding.js":"gKJ0Y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hbslV":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A wrapper for setTimeout that resolves a promise after timeInMs milliseconds.
 * @param timeInMs - The number of milliseconds to be delayed.
 * @param options - The options for delay - currently abort options
 * @returns Promise that is resolved after timeInMs
 */ parcelHelpers.export(exports, "delay", ()=>delay);
var _createAbortablePromiseJs = require("./createAbortablePromise.js");
const StandardAbortMessage = "The delay was aborted.";
function delay(timeInMs, options) {
    let token;
    const { abortSignal, abortErrorMsg } = options !== null && options !== void 0 ? options : {};
    return (0, _createAbortablePromiseJs.createAbortablePromise)((resolve)=>{
        token = setTimeout(resolve, timeInMs);
    }, {
        cleanupBeforeAbort: ()=>clearTimeout(token),
        abortSignal,
        abortErrorMsg: abortErrorMsg !== null && abortErrorMsg !== void 0 ? abortErrorMsg : StandardAbortMessage
    });
}

},{"./createAbortablePromise.js":"4ieNk","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ieNk":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates an abortable promise.
 * @param buildPromise - A function that takes the resolve and reject functions as parameters.
 * @param options - The options for the abortable promise.
 * @returns A promise that can be aborted.
 */ parcelHelpers.export(exports, "createAbortablePromise", ()=>createAbortablePromise);
var _abortController = require("@azure/abort-controller");
function createAbortablePromise(buildPromise, options) {
    const { cleanupBeforeAbort, abortSignal, abortErrorMsg } = options !== null && options !== void 0 ? options : {};
    return new Promise((resolve, reject)=>{
        function rejectOnAbort() {
            reject(new (0, _abortController.AbortError)(abortErrorMsg !== null && abortErrorMsg !== void 0 ? abortErrorMsg : "The operation was aborted."));
        }
        function removeListeners() {
            abortSignal === null || abortSignal === void 0 || abortSignal.removeEventListener("abort", onAbort);
        }
        function onAbort() {
            cleanupBeforeAbort === null || cleanupBeforeAbort === void 0 || cleanupBeforeAbort();
            removeListeners();
            rejectOnAbort();
        }
        if (abortSignal === null || abortSignal === void 0 ? void 0 : abortSignal.aborted) return rejectOnAbort();
        try {
            buildPromise((x)=>{
                removeListeners();
                resolve(x);
            }, (x)=>{
                removeListeners();
                reject(x);
            });
        } catch (err) {
            reject(err);
        }
        abortSignal === null || abortSignal === void 0 || abortSignal.addEventListener("abort", onAbort);
    });
}

},{"@azure/abort-controller":"4gQup","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4gQup":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbortError", ()=>(0, _abortErrorJs.AbortError));
var _abortErrorJs = require("./AbortError.js");

},{"./AbortError.js":"a4LXS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a4LXS":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * This error is thrown when an asynchronous operation has been aborted.
 * Check for this error by testing the `name` that the name property of the
 * error matches `"AbortError"`.
 *
 * @example
 * ```ts
 * const controller = new AbortController();
 * controller.abort();
 * try {
 *   doAsyncWork(controller.signal)
 * } catch (e) {
 *   if (e.name === 'AbortError') {
 *     // handle abort error here.
 *   }
 * }
 * ```
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbortError", ()=>AbortError);
class AbortError extends Error {
    constructor(message){
        super(message);
        this.name = "AbortError";
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8YijF":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * promise.race() wrapper that aborts rest of promises as soon as the first promise settles.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "cancelablePromiseRace", ()=>cancelablePromiseRace);
async function cancelablePromiseRace(abortablePromiseBuilders, options) {
    var _a, _b;
    const aborter = new AbortController();
    function abortHandler() {
        aborter.abort();
    }
    (_a = options === null || options === void 0 ? void 0 : options.abortSignal) === null || _a === void 0 || _a.addEventListener("abort", abortHandler);
    try {
        return await Promise.race(abortablePromiseBuilders.map((p)=>p({
                abortSignal: aborter.signal
            })));
    } finally{
        aborter.abort();
        (_b = options === null || options === void 0 ? void 0 : options.abortSignal) === null || _b === void 0 || _b.removeEventListener("abort", abortHandler);
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8dwr1":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Returns a random integer value between a lower and upper bound,
 * inclusive of both bounds.
 * Note that this uses Math.random and isn't secure. If you need to use
 * this for any kind of security purpose, find a better source of random.
 * @param min - The smallest integer value allowed.
 * @param max - The largest integer value allowed.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getRandomIntegerInclusive", ()=>getRandomIntegerInclusive);
function getRandomIntegerInclusive(min, max) {
    // Make sure inputs are integers.
    min = Math.ceil(min);
    max = Math.floor(max);
    // Pick a random offset from zero to the size of the range.
    // Since Math.random() can never return 1, we have to make the range one larger
    // in order to be inclusive of the maximum value after we take the floor.
    const offset = Math.floor(Math.random() * (max - min + 1));
    return offset + min;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ZOx0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Helper to determine when an input is a generic JS object.
 * @returns true when input is an object type that is not null, Array, RegExp, or Date.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isObject", ()=>isObject);
function isObject(input) {
    return typeof input === "object" && input !== null && !Array.isArray(input) && !(input instanceof RegExp) && !(input instanceof Date);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"liUda":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Typeguard for an error object shape (has name and message)
 * @param e - Something caught by a catch clause.
 */ parcelHelpers.export(exports, "isError", ()=>isError);
/**
 * Given what is thought to be an error object, return the message if possible.
 * If the message is missing, returns a stringified version of the input.
 * @param e - Something thrown from a try block
 * @returns The error message or a string of the input
 */ parcelHelpers.export(exports, "getErrorMessage", ()=>getErrorMessage);
var _objectJs = require("./object.js");
function isError(e) {
    if ((0, _objectJs.isObject)(e)) {
        const hasName = typeof e.name === "string";
        const hasMessage = typeof e.message === "string";
        return hasName && hasMessage;
    }
    return false;
}
function getErrorMessage(e) {
    if (isError(e)) return e.message;
    else {
        let stringified;
        try {
            if (typeof e === "object" && e) stringified = JSON.stringify(e);
            else stringified = String(e);
        } catch (err) {
            stringified = "[unable to stringify input]";
        }
        return `Unknown error ${stringified}`;
    }
}

},{"./object.js":"2ZOx0","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jbbgt":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _sha256CommonJs = require("./sha256.common.js");
parcelHelpers.exportAll(_sha256CommonJs, exports);

},{"./sha256.common.js":"hTAQW","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hTAQW":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Generates a SHA-256 HMAC signature.
 * @param key - The HMAC key represented as a base64 string, used to generate the cryptographic HMAC hash.
 * @param stringToSign - The data to be signed.
 * @param encoding - The textual encoding to use for the returned HMAC digest.
 */ parcelHelpers.export(exports, "computeSha256Hmac", ()=>computeSha256Hmac);
/**
 * Generates a SHA-256 hash.
 * @param content - The data to be included in the hash.
 * @param encoding - The textual encoding to use for the returned hash.
 */ parcelHelpers.export(exports, "computeSha256Hash", ()=>computeSha256Hash);
var _bytesEncodingJs = require("./bytesEncoding.js");
let subtleCrypto;
/**
 * Returns a cached reference to the Web API crypto.subtle object.
 * @internal
 */ function getCrypto() {
    if (subtleCrypto) return subtleCrypto;
    if (!self.crypto || !self.crypto.subtle) throw new Error("Your browser environment does not support cryptography functions.");
    subtleCrypto = self.crypto.subtle;
    return subtleCrypto;
}
async function computeSha256Hmac(key, stringToSign, encoding) {
    const crypto = getCrypto();
    const keyBytes = (0, _bytesEncodingJs.stringToUint8Array)(key, "base64");
    const stringToSignBytes = (0, _bytesEncodingJs.stringToUint8Array)(stringToSign, "utf-8");
    const cryptoKey = await crypto.importKey("raw", keyBytes, {
        name: "HMAC",
        hash: {
            name: "SHA-256"
        }
    }, false, [
        "sign"
    ]);
    const signature = await crypto.sign({
        name: "HMAC",
        hash: {
            name: "SHA-256"
        }
    }, cryptoKey, stringToSignBytes);
    return (0, _bytesEncodingJs.uint8ArrayToString)(new Uint8Array(signature), encoding);
}
async function computeSha256Hash(content, encoding) {
    const contentBytes = (0, _bytesEncodingJs.stringToUint8Array)(content, "utf-8");
    const digest = await getCrypto().digest({
        name: "SHA-256"
    }, contentBytes);
    return (0, _bytesEncodingJs.uint8ArrayToString)(new Uint8Array(digest), encoding);
}

},{"./bytesEncoding.js":"gKJ0Y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gKJ0Y":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _bytesEncodingCommonJs = require("./bytesEncoding.common.js");
parcelHelpers.exportAll(_bytesEncodingCommonJs, exports);

},{"./bytesEncoding.common.js":"9t84P","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9t84P":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The helper that transforms bytes with specific character encoding into string
 * @param bytes - the uint8array bytes
 * @param format - the format we use to encode the byte
 * @returns a string of the encoded string
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "uint8ArrayToString", ()=>uint8ArrayToString);
/**
 * The helper that transforms string to specific character encoded bytes array.
 * @param value - the string to be converted
 * @param format - the format we use to decode the value
 * @returns a uint8array
 */ parcelHelpers.export(exports, "stringToUint8Array", ()=>stringToUint8Array);
/**
 * Decodes a Uint8Array into a Base64 string.
 * @internal
 */ parcelHelpers.export(exports, "uint8ArrayToBase64", ()=>uint8ArrayToBase64);
/**
 * Decodes a Uint8Array into a Base64Url string.
 * @internal
 */ parcelHelpers.export(exports, "uint8ArrayToBase64Url", ()=>uint8ArrayToBase64Url);
/**
 * Decodes a Uint8Array into a javascript string.
 * @internal
 */ parcelHelpers.export(exports, "uint8ArrayToUtf8String", ()=>uint8ArrayToUtf8String);
/**
 * Decodes a Uint8Array into a hex string
 * @internal
 */ parcelHelpers.export(exports, "uint8ArrayToHexString", ()=>uint8ArrayToHexString);
/**
 * Encodes a JavaScript string into a Uint8Array.
 * @internal
 */ parcelHelpers.export(exports, "utf8StringToUint8Array", ()=>utf8StringToUint8Array);
/**
 * Encodes a Base64 string into a Uint8Array.
 * @internal
 */ parcelHelpers.export(exports, "base64ToUint8Array", ()=>base64ToUint8Array);
/**
 * Encodes a Base64Url string into a Uint8Array.
 * @internal
 */ parcelHelpers.export(exports, "base64UrlToUint8Array", ()=>base64UrlToUint8Array);
/**
 * Encodes a hex string into a Uint8Array
 * @internal
 */ parcelHelpers.export(exports, "hexStringToUint8Array", ()=>hexStringToUint8Array);
function uint8ArrayToString(bytes, format) {
    switch(format){
        case "utf-8":
            return uint8ArrayToUtf8String(bytes);
        case "base64":
            return uint8ArrayToBase64(bytes);
        case "base64url":
            return uint8ArrayToBase64Url(bytes);
        case "hex":
            return uint8ArrayToHexString(bytes);
    }
}
function stringToUint8Array(value, format) {
    switch(format){
        case "utf-8":
            return utf8StringToUint8Array(value);
        case "base64":
            return base64ToUint8Array(value);
        case "base64url":
            return base64UrlToUint8Array(value);
        case "hex":
            return hexStringToUint8Array(value);
    }
}
function uint8ArrayToBase64(bytes) {
    return btoa([
        ...bytes
    ].map((x)=>String.fromCharCode(x)).join(""));
}
function uint8ArrayToBase64Url(bytes) {
    return uint8ArrayToBase64(bytes).replace(/\+/g, "-").replace(/\//g, "_").replace(/=/g, "");
}
function uint8ArrayToUtf8String(bytes) {
    const decoder = new TextDecoder();
    const dataString = decoder.decode(bytes);
    return dataString;
}
function uint8ArrayToHexString(bytes) {
    return [
        ...bytes
    ].map((x)=>x.toString(16).padStart(2, "0")).join("");
}
function utf8StringToUint8Array(value) {
    return new TextEncoder().encode(value);
}
function base64ToUint8Array(value) {
    return new Uint8Array([
        ...atob(value)
    ].map((x)=>x.charCodeAt(0)));
}
function base64UrlToUint8Array(value) {
    const base64String = value.replace(/-/g, "+").replace(/_/g, "/");
    return base64ToUint8Array(base64String);
}
const hexDigits = new Set("0123456789abcdefABCDEF");
function hexStringToUint8Array(value) {
    // If value has odd length, the last character will be ignored, consistent with NodeJS Buffer behavior
    const bytes = new Uint8Array(value.length / 2);
    for(let i = 0; i < value.length / 2; ++i){
        const highNibble = value[2 * i];
        const lowNibble = value[2 * i + 1];
        if (!hexDigits.has(highNibble) || !hexDigits.has(lowNibble)) // Replicate Node Buffer behavior by exiting early when we encounter an invalid byte
        return bytes.slice(0, i);
        bytes[i] = parseInt(`${highNibble}${lowNibble}`, 16);
    }
    return bytes;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3J9Lj":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Helper TypeGuard that checks if something is defined or not.
 * @param thing - Anything
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isDefined", ()=>isDefined);
/**
 * Helper TypeGuard that checks if the input is an object with the specified properties.
 * @param thing - Anything.
 * @param properties - The name of the properties that should appear in the object.
 */ parcelHelpers.export(exports, "isObjectWithProperties", ()=>isObjectWithProperties);
/**
 * Helper TypeGuard that checks if the input is an object with the specified property.
 * @param thing - Any object.
 * @param property - The name of the property that should appear in the object.
 */ parcelHelpers.export(exports, "objectHasProperty", ()=>objectHasProperty);
function isDefined(thing) {
    return typeof thing !== "undefined" && thing !== null;
}
function isObjectWithProperties(thing, properties) {
    if (!isDefined(thing) || typeof thing !== "object") return false;
    for (const property of properties){
        if (!objectHasProperty(thing, property)) return false;
    }
    return true;
}
function objectHasProperty(thing, property) {
    return isDefined(thing) && typeof thing === "object" && property in thing;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fdfdr":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Generated Universally Unique Identifier
 *
 * @returns RFC4122 v4 UUID.
 */ parcelHelpers.export(exports, "randomUUID", ()=>randomUUID);
var _uuidUtilsCommonJs = require("./uuidUtils.common.js");
var _a;
// NOTE: This could be undefined if not used in a secure context
const uuidFunction = typeof ((_a = globalThis === null || globalThis === void 0 ? void 0 : globalThis.crypto) === null || _a === void 0 ? void 0 : _a.randomUUID) === "function" ? globalThis.crypto.randomUUID.bind(globalThis.crypto) : (0, _uuidUtilsCommonJs.generateUUID);
function randomUUID() {
    return uuidFunction();
}

},{"./uuidUtils.common.js":"dio1m","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dio1m":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Generated Universally Unique Identifier
 *
 * @returns RFC4122 v4 UUID.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "generateUUID", ()=>generateUUID);
/**
 * Generated Universally Unique Identifier
 *
 * @returns RFC4122 v4 UUID.
 */ parcelHelpers.export(exports, "randomUUID", ()=>randomUUID);
function generateUUID() {
    let uuid = "";
    for(let i = 0; i < 32; i++){
        // Generate a random number between 0 and 15
        const randomNumber = Math.floor(Math.random() * 16);
        // Set the UUID version to 4 in the 13th position
        if (i === 12) uuid += "4";
        else if (i === 16) // Set the UUID variant to "10" in the 17th position
        uuid += randomNumber & 0x3 | 0x8;
        else // Add a random hexadecimal digit to the UUID string
        uuid += randomNumber.toString(16);
        // Add hyphens to the UUID string at the appropriate positions
        if (i === 7 || i === 11 || i === 15 || i === 19) uuid += "-";
    }
    return uuid;
}
function randomUUID() {
    return generateUUID();
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a8Cb2":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isBrowser", ()=>isBrowser);
parcelHelpers.export(exports, "isWebWorker", ()=>isWebWorker);
parcelHelpers.export(exports, "isDeno", ()=>isDeno);
parcelHelpers.export(exports, "isBun", ()=>isBun);
parcelHelpers.export(exports, "isNodeLike", ()=>isNodeLike);
parcelHelpers.export(exports, "isNode", ()=>isNode);
parcelHelpers.export(exports, "isNodeRuntime", ()=>isNodeRuntime);
parcelHelpers.export(exports, "isReactNative", ()=>isReactNative);
var _a, _b, _c, _d;
const isBrowser = typeof window !== "undefined" && typeof window.document !== "undefined";
const isWebWorker = typeof self === "object" && typeof (self === null || self === void 0 ? void 0 : self.importScripts) === "function" && (((_a = self.constructor) === null || _a === void 0 ? void 0 : _a.name) === "DedicatedWorkerGlobalScope" || ((_b = self.constructor) === null || _b === void 0 ? void 0 : _b.name) === "ServiceWorkerGlobalScope" || ((_c = self.constructor) === null || _c === void 0 ? void 0 : _c.name) === "SharedWorkerGlobalScope");
const isDeno = typeof Deno !== "undefined" && typeof Deno.version !== "undefined" && typeof Deno.version.deno !== "undefined";
const isBun = typeof Bun !== "undefined" && typeof Bun.version !== "undefined";
const isNodeLike = typeof globalThis.process !== "undefined" && Boolean(globalThis.process.version) && Boolean((_d = globalThis.process.versions) === null || _d === void 0 ? void 0 : _d.node);
const isNode = isNodeLike;
const isNodeRuntime = isNodeLike && !isBun && !isDeno;
const isReactNative = typeof navigator !== "undefined" && (navigator === null || navigator === void 0 ? void 0 : navigator.product) === "ReactNative";

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7nGeV":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The programmatic identifier of the redirectPolicy.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "redirectPolicyName", ()=>redirectPolicyName);
/**
 * A policy to follow Location headers from the server in order
 * to support server-side redirection.
 * In the browser, this policy is not used.
 * @param options - Options to control policy behavior.
 */ parcelHelpers.export(exports, "redirectPolicy", ()=>redirectPolicy);
const redirectPolicyName = "redirectPolicy";
/**
 * Methods that are allowed to follow redirects 301 and 302
 */ const allowedRedirect = [
    "GET",
    "HEAD"
];
function redirectPolicy(options = {}) {
    const { maxRetries = 20 } = options;
    return {
        name: redirectPolicyName,
        async sendRequest (request, next) {
            const response = await next(request);
            return handleRedirect(next, response, maxRetries);
        }
    };
}
async function handleRedirect(next, response, maxRetries, currentRetries = 0) {
    const { request, status, headers } = response;
    const locationHeader = headers.get("location");
    if (locationHeader && (status === 300 || status === 301 && allowedRedirect.includes(request.method) || status === 302 && allowedRedirect.includes(request.method) || status === 303 && request.method === "POST" || status === 307) && currentRetries < maxRetries) {
        const url = new URL(locationHeader, request.url);
        request.url = url.toString();
        // POST request with Status code 303 should be converted into a
        // redirected GET request if the redirect url is present in the location header
        if (status === 303) {
            request.method = "GET";
            request.headers.delete("Content-Length");
            delete request.body;
        }
        request.headers.delete("Authorization");
        const res = await next(request);
        return handleRedirect(next, res, maxRetries, currentRetries + 1);
    }
    return response;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"AaMYP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "userAgentPolicyName", ()=>userAgentPolicyName);
/**
 * A policy that sets the User-Agent header (or equivalent) to reflect
 * the library version.
 * @param options - Options to customize the user agent value.
 */ parcelHelpers.export(exports, "userAgentPolicy", ()=>userAgentPolicy);
var _userAgentJs = require("../util/userAgent.js");
const UserAgentHeaderName = (0, _userAgentJs.getUserAgentHeaderName)();
const userAgentPolicyName = "userAgentPolicy";
function userAgentPolicy(options = {}) {
    const userAgentValue = (0, _userAgentJs.getUserAgentValue)(options.userAgentPrefix);
    return {
        name: userAgentPolicyName,
        async sendRequest (request, next) {
            if (!request.headers.has(UserAgentHeaderName)) request.headers.set(UserAgentHeaderName, await userAgentValue);
            return next(request);
        }
    };
}

},{"../util/userAgent.js":"5OVOJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5OVOJ":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @internal
 */ parcelHelpers.export(exports, "getUserAgentHeaderName", ()=>getUserAgentHeaderName);
/**
 * @internal
 */ parcelHelpers.export(exports, "getUserAgentValue", ()=>getUserAgentValue);
var _userAgentPlatformJs = require("./userAgentPlatform.js");
var _constantsJs = require("../constants.js");
function getUserAgentString(telemetryInfo) {
    const parts = [];
    for (const [key, value] of telemetryInfo){
        const token = value ? `${key}/${value}` : key;
        parts.push(token);
    }
    return parts.join(" ");
}
function getUserAgentHeaderName() {
    return (0, _userAgentPlatformJs.getHeaderName)();
}
async function getUserAgentValue(prefix) {
    const runtimeInfo = new Map();
    runtimeInfo.set("core-rest-pipeline", (0, _constantsJs.SDK_VERSION));
    await (0, _userAgentPlatformJs.setPlatformSpecificData)(runtimeInfo);
    const defaultAgent = getUserAgentString(runtimeInfo);
    const userAgentValue = prefix ? `${prefix} ${defaultAgent}` : defaultAgent;
    return userAgentValue;
}

},{"./userAgentPlatform.js":"5IX72","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5IX72":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * @internal
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getHeaderName", ()=>getHeaderName);
/**
 * @internal
 */ parcelHelpers.export(exports, "setPlatformSpecificData", ()=>setPlatformSpecificData);
function getHeaderName() {
    return "x-ms-useragent";
}
function getBrowserInfo(userAgent) {
    const browserRegexes = [
        {
            name: "Firefox",
            regex: /Firefox\/([\d.]+)/
        },
        {
            name: "Safari",
            regex: /Version\/([\d.]+).*Safari/
        }
    ];
    for (const browser of browserRegexes){
        const match = userAgent.match(browser.regex);
        if (match) return {
            brand: browser.name,
            version: match[1]
        };
    }
    return undefined;
}
function getBrandVersionString(brands) {
    const brandOrder = [
        "Google Chrome",
        "Microsoft Edge",
        "Opera",
        "Brave",
        "Chromium"
    ];
    for (const brand of brandOrder){
        const foundBrand = brands.find((b)=>b.brand === brand);
        if (foundBrand) return foundBrand;
    }
    return undefined;
}
async function setPlatformSpecificData(map) {
    const localNavigator = globalThis.navigator;
    let osPlatform = "unknown";
    if (localNavigator === null || localNavigator === void 0 ? void 0 : localNavigator.userAgentData) {
        const entropyValues = await localNavigator.userAgentData.getHighEntropyValues([
            "architecture",
            "platformVersion"
        ]);
        osPlatform = `${entropyValues.architecture}-${entropyValues.platform}-${entropyValues.platformVersion}`;
        // Get the brand and version
        const brand = getBrandVersionString(localNavigator.userAgentData.brands);
        if (brand) map.set(brand.brand, brand.version);
    } else if (localNavigator === null || localNavigator === void 0 ? void 0 : localNavigator.platform) {
        osPlatform = localNavigator.platform;
        const brand = getBrowserInfo(localNavigator.userAgent);
        if (brand) map.set(brand.brand, brand.version);
    } else if (typeof globalThis.EdgeRuntime === "string") map.set("EdgeRuntime", globalThis.EdgeRuntime);
    map.set("OS", osPlatform);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jZG4U":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "SDK_VERSION", ()=>SDK_VERSION);
parcelHelpers.export(exports, "DEFAULT_RETRY_POLICY_COUNT", ()=>DEFAULT_RETRY_POLICY_COUNT);
const SDK_VERSION = "1.16.2";
const DEFAULT_RETRY_POLICY_COUNT = 3;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8iA8I":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "multipartPolicyName", ()=>multipartPolicyName);
/**
 * Pipeline policy for multipart requests
 */ parcelHelpers.export(exports, "multipartPolicy", ()=>multipartPolicy);
var _coreUtil = require("@azure/core-util");
var _concatJs = require("../util/concat.js");
var _typeGuardsJs = require("../util/typeGuards.js");
function generateBoundary() {
    return `----AzSDKFormBoundary${(0, _coreUtil.randomUUID)()}`;
}
function encodeHeaders(headers) {
    let result = "";
    for (const [key, value] of headers)result += `${key}: ${value}\r\n`;
    return result;
}
function getLength(source) {
    if (source instanceof Uint8Array) return source.byteLength;
    else if ((0, _typeGuardsJs.isBlob)(source)) // if was created using createFile then -1 means we have an unknown size
    return source.size === -1 ? undefined : source.size;
    else return undefined;
}
function getTotalLength(sources) {
    let total = 0;
    for (const source of sources){
        const partLength = getLength(source);
        if (partLength === undefined) return undefined;
        else total += partLength;
    }
    return total;
}
async function buildRequestBody(request, parts, boundary) {
    const sources = [
        (0, _coreUtil.stringToUint8Array)(`--${boundary}`, "utf-8"),
        ...parts.flatMap((part)=>[
                (0, _coreUtil.stringToUint8Array)("\r\n", "utf-8"),
                (0, _coreUtil.stringToUint8Array)(encodeHeaders(part.headers), "utf-8"),
                (0, _coreUtil.stringToUint8Array)("\r\n", "utf-8"),
                part.body,
                (0, _coreUtil.stringToUint8Array)(`\r\n--${boundary}`, "utf-8")
            ]),
        (0, _coreUtil.stringToUint8Array)("--\r\n\r\n", "utf-8")
    ];
    const contentLength = getTotalLength(sources);
    if (contentLength) request.headers.set("Content-Length", contentLength);
    request.body = await (0, _concatJs.concat)(sources);
}
const multipartPolicyName = "multipartPolicy";
const maxBoundaryLength = 70;
const validBoundaryCharacters = new Set(`abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'()+,-./:=?`);
function assertValidBoundary(boundary) {
    if (boundary.length > maxBoundaryLength) throw new Error(`Multipart boundary "${boundary}" exceeds maximum length of 70 characters`);
    if (Array.from(boundary).some((x)=>!validBoundaryCharacters.has(x))) throw new Error(`Multipart boundary "${boundary}" contains invalid characters`);
}
function multipartPolicy() {
    return {
        name: multipartPolicyName,
        async sendRequest (request, next) {
            var _a;
            if (!request.multipartBody) return next(request);
            if (request.body) throw new Error("multipartBody and regular body cannot be set at the same time");
            let boundary = request.multipartBody.boundary;
            const contentTypeHeader = (_a = request.headers.get("Content-Type")) !== null && _a !== void 0 ? _a : "multipart/mixed";
            const parsedHeader = contentTypeHeader.match(/^(multipart\/[^ ;]+)(?:; *boundary=(.+))?$/);
            if (!parsedHeader) throw new Error(`Got multipart request body, but content-type header was not multipart: ${contentTypeHeader}`);
            const [, contentType, parsedBoundary] = parsedHeader;
            if (parsedBoundary && boundary && parsedBoundary !== boundary) throw new Error(`Multipart boundary was specified as ${parsedBoundary} in the header, but got ${boundary} in the request body`);
            boundary !== null && boundary !== void 0 ? boundary : boundary = parsedBoundary;
            if (boundary) assertValidBoundary(boundary);
            else boundary = generateBoundary();
            request.headers.set("Content-Type", `${contentType}; boundary=${boundary}`);
            await buildRequestBody(request, request.multipartBody.parts, boundary);
            request.multipartBody = undefined;
            return next(request);
        }
    };
}

},{"@azure/core-util":"b31OK","../util/concat.js":"lh5Pp","../util/typeGuards.js":"74uwK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lh5Pp":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _concatCommonJs = require("./concat.common.js");
parcelHelpers.exportAll(_concatCommonJs, exports);

},{"./concat.common.js":"5ET09","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5ET09":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Utility function that concatenates a set of binary inputs into one combined output.
 *
 * @param sources - array of sources for the concatenation
 * @returns - in Node, a (() =\> NodeJS.ReadableStream) which, when read, produces a concatenation of all the inputs.
 *           In browser, returns a `Blob` representing all the concatenated inputs.
 *
 * @internal
 */ parcelHelpers.export(exports, "concat", ()=>concat);
var _fileJs = require("./file.js");
var _typeGuardsJs = require("./typeGuards.js");
/**
 * Drain the content of the given ReadableStream into a Blob.
 * The blob's content may end up in memory or on disk dependent on size.
 */ function drain(stream) {
    return new Response(stream).blob();
}
async function toBlobPart(source) {
    if (source instanceof Blob || source instanceof Uint8Array) return source;
    if ((0, _typeGuardsJs.isWebReadableStream)(source)) return drain(source);
    // If it's not a true Blob, and it's not a Uint8Array, we can assume the source
    // is a fake File created by createFileFromStream and we can get the original stream
    // using getRawContent.
    const rawContent = (0, _fileJs.getRawContent)(source);
    // Shouldn't happen but guard for it anyway
    if ((0, _typeGuardsJs.isNodeReadableStream)(rawContent)) throw new Error("Encountered unexpected type. In the browser, `concat` supports Web ReadableStream, Blob, Uint8Array, and files created using `createFile` only.");
    return toBlobPart(rawContent);
}
async function concat(sources) {
    const parts = [];
    for (const source of sources)parts.push(await toBlobPart(typeof source === "function" ? source() : source));
    return new Blob(parts);
}

},{"./file.js":"ivG8n","./typeGuards.js":"74uwK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ivG8n":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Extract the raw content from a given blob-like object. If the input was created using createFile
 * or createFileFromStream, the exact content passed into createFile/createFileFromStream will be used.
 * For true instances of Blob and File, returns the blob's content as a Web ReadableStream<Uint8Array>.
 *
 * @internal
 */ parcelHelpers.export(exports, "getRawContent", ()=>getRawContent);
/**
 * Create an object that implements the File interface. This object is intended to be
 * passed into RequestBodyType.formData, and is not guaranteed to work as expected in
 * other situations.
 *
 * Use this function to:
 * - Create a File object for use in RequestBodyType.formData in environments where the
 *   global File object is unavailable.
 * - Create a File-like object from a readable stream without reading the stream into memory.
 *
 * @param stream - the content of the file as a callback returning a stream. When a File object made using createFile is
 *                  passed in a request's form data map, the stream will not be read into memory
 *                  and instead will be streamed when the request is made. In the event of a retry, the
 *                  stream needs to be read again, so this callback SHOULD return a fresh stream if possible.
 * @param name - the name of the file.
 * @param options - optional metadata about the file, e.g. file name, file size, MIME type.
 */ parcelHelpers.export(exports, "createFileFromStream", ()=>createFileFromStream);
/**
 * Create an object that implements the File interface. This object is intended to be
 * passed into RequestBodyType.formData, and is not guaranteed to work as expected in
 * other situations.
 *
 * Use this function create a File object for use in RequestBodyType.formData in environments where the global File object is unavailable.
 *
 * @param content - the content of the file as a Uint8Array in memory.
 * @param name - the name of the file.
 * @param options - optional metadata about the file, e.g. file name, file size, MIME type.
 */ parcelHelpers.export(exports, "createFile", ()=>createFile);
var _coreUtil = require("@azure/core-util");
var _typeGuardsJs = require("./typeGuards.js");
const unimplementedMethods = {
    arrayBuffer: ()=>{
        throw new Error("Not implemented");
    },
    slice: ()=>{
        throw new Error("Not implemented");
    },
    text: ()=>{
        throw new Error("Not implemented");
    }
};
/**
 * Private symbol used as key on objects created using createFile containing the
 * original source of the file object.
 *
 * This is used in Node to access the original Node stream without using Blob#stream, which
 * returns a web stream. This is done to avoid a couple of bugs to do with Blob#stream and
 * Readable#to/fromWeb in Node versions we support:
 * - https://github.com/nodejs/node/issues/42694 (fixed in Node 18.14)
 * - https://github.com/nodejs/node/issues/48916 (fixed in Node 20.6)
 *
 * Once these versions are no longer supported, we may be able to stop doing this.
 *
 * @internal
 */ const rawContent = Symbol("rawContent");
function hasRawContent(x) {
    return typeof x[rawContent] === "function";
}
function getRawContent(blob) {
    if (hasRawContent(blob)) return blob[rawContent]();
    else return blob.stream();
}
function createFileFromStream(stream, name, options = {}) {
    var _a, _b, _c, _d;
    return Object.assign(Object.assign({}, unimplementedMethods), {
        type: (_a = options.type) !== null && _a !== void 0 ? _a : "",
        lastModified: (_b = options.lastModified) !== null && _b !== void 0 ? _b : new Date().getTime(),
        webkitRelativePath: (_c = options.webkitRelativePath) !== null && _c !== void 0 ? _c : "",
        size: (_d = options.size) !== null && _d !== void 0 ? _d : -1,
        name,
        stream: ()=>{
            const s = stream();
            if ((0, _typeGuardsJs.isNodeReadableStream)(s)) throw new Error("Not supported: a Node stream was provided as input to createFileFromStream.");
            return s;
        },
        [rawContent]: stream
    });
}
function createFile(content, name, options = {}) {
    var _a, _b, _c;
    if (0, _coreUtil.isNodeLike) return Object.assign(Object.assign({}, unimplementedMethods), {
        type: (_a = options.type) !== null && _a !== void 0 ? _a : "",
        lastModified: (_b = options.lastModified) !== null && _b !== void 0 ? _b : new Date().getTime(),
        webkitRelativePath: (_c = options.webkitRelativePath) !== null && _c !== void 0 ? _c : "",
        size: content.byteLength,
        name,
        arrayBuffer: async ()=>content.buffer,
        stream: ()=>new Blob([
                content
            ]).stream(),
        [rawContent]: ()=>content
    });
    else return new File([
        content
    ], name, options);
}

},{"@azure/core-util":"b31OK","./typeGuards.js":"74uwK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"74uwK":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isNodeReadableStream", ()=>isNodeReadableStream);
parcelHelpers.export(exports, "isWebReadableStream", ()=>isWebReadableStream);
parcelHelpers.export(exports, "isReadableStream", ()=>isReadableStream);
parcelHelpers.export(exports, "isBlob", ()=>isBlob);
function isNodeReadableStream(x) {
    return Boolean(x && typeof x["pipe"] === "function");
}
function isWebReadableStream(x) {
    return Boolean(x && typeof x.getReader === "function" && typeof x.tee === "function");
}
function isReadableStream(x) {
    return isNodeReadableStream(x) || isWebReadableStream(x);
}
function isBlob(x) {
    return typeof x.stream === "function";
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aqGPB":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/*
 * NOTE: When moving this file, please update "browser" section in package.json
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "decompressResponsePolicyName", ()=>decompressResponsePolicyName);
/**
 * decompressResponsePolicy is not supported in the browser and attempting
 * to use it will raise an error.
 */ parcelHelpers.export(exports, "decompressResponsePolicy", ()=>decompressResponsePolicy);
const decompressResponsePolicyName = "decompressResponsePolicy";
function decompressResponsePolicy() {
    throw new Error("decompressResponsePolicy is not supported in browser environment");
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cccLy":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "defaultRetryPolicyName", ()=>defaultRetryPolicyName);
/**
 * A policy that retries according to three strategies:
 * - When the server sends a 429 response with a Retry-After header.
 * - When there are errors in the underlying transport layer (e.g. DNS lookup failures).
 * - Or otherwise if the outgoing request fails, it will retry with an exponentially increasing delay.
 */ parcelHelpers.export(exports, "defaultRetryPolicy", ()=>defaultRetryPolicy);
var _exponentialRetryStrategyJs = require("../retryStrategies/exponentialRetryStrategy.js");
var _throttlingRetryStrategyJs = require("../retryStrategies/throttlingRetryStrategy.js");
var _retryPolicyJs = require("./retryPolicy.js");
var _constantsJs = require("../constants.js");
const defaultRetryPolicyName = "defaultRetryPolicy";
function defaultRetryPolicy(options = {}) {
    var _a;
    return {
        name: defaultRetryPolicyName,
        sendRequest: (0, _retryPolicyJs.retryPolicy)([
            (0, _throttlingRetryStrategyJs.throttlingRetryStrategy)(),
            (0, _exponentialRetryStrategyJs.exponentialRetryStrategy)(options)
        ], {
            maxRetries: (_a = options.maxRetries) !== null && _a !== void 0 ? _a : (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT)
        }).sendRequest
    };
}

},{"../retryStrategies/exponentialRetryStrategy.js":"8AL5c","../retryStrategies/throttlingRetryStrategy.js":"g1val","./retryPolicy.js":"jxxY0","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8AL5c":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A retry strategy that retries with an exponentially increasing delay in these two cases:
 * - When there are errors in the underlying transport layer (e.g. DNS lookup failures).
 * - Or otherwise if the outgoing request fails (408, greater or equal than 500, except for 501 and 505).
 */ parcelHelpers.export(exports, "exponentialRetryStrategy", ()=>exponentialRetryStrategy);
/**
 * A response is a retry response if it has status codes:
 * - 408, or
 * - Greater or equal than 500, except for 501 and 505.
 */ parcelHelpers.export(exports, "isExponentialRetryResponse", ()=>isExponentialRetryResponse);
/**
 * Determines whether an error from a pipeline response was triggered in the network layer.
 */ parcelHelpers.export(exports, "isSystemError", ()=>isSystemError);
var _coreUtil = require("@azure/core-util");
var _throttlingRetryStrategyJs = require("./throttlingRetryStrategy.js");
// intervals are in milliseconds
const DEFAULT_CLIENT_RETRY_INTERVAL = 1000;
const DEFAULT_CLIENT_MAX_RETRY_INTERVAL = 64000;
function exponentialRetryStrategy(options = {}) {
    var _a, _b;
    const retryInterval = (_a = options.retryDelayInMs) !== null && _a !== void 0 ? _a : DEFAULT_CLIENT_RETRY_INTERVAL;
    const maxRetryInterval = (_b = options.maxRetryDelayInMs) !== null && _b !== void 0 ? _b : DEFAULT_CLIENT_MAX_RETRY_INTERVAL;
    let retryAfterInMs = retryInterval;
    return {
        name: "exponentialRetryStrategy",
        retry ({ retryCount, response, responseError }) {
            const matchedSystemError = isSystemError(responseError);
            const ignoreSystemErrors = matchedSystemError && options.ignoreSystemErrors;
            const isExponential = isExponentialRetryResponse(response);
            const ignoreExponentialResponse = isExponential && options.ignoreHttpStatusCodes;
            const unknownResponse = response && ((0, _throttlingRetryStrategyJs.isThrottlingRetryResponse)(response) || !isExponential);
            if (unknownResponse || ignoreExponentialResponse || ignoreSystemErrors) return {
                skipStrategy: true
            };
            if (responseError && !matchedSystemError && !isExponential) return {
                errorToThrow: responseError
            };
            // Exponentially increase the delay each time
            const exponentialDelay = retryAfterInMs * Math.pow(2, retryCount);
            // Don't let the delay exceed the maximum
            const clampedExponentialDelay = Math.min(maxRetryInterval, exponentialDelay);
            // Allow the final value to have some "jitter" (within 50% of the delay size) so
            // that retries across multiple clients don't occur simultaneously.
            retryAfterInMs = clampedExponentialDelay / 2 + (0, _coreUtil.getRandomIntegerInclusive)(0, clampedExponentialDelay / 2);
            return {
                retryAfterInMs
            };
        }
    };
}
function isExponentialRetryResponse(response) {
    return Boolean(response && response.status !== undefined && (response.status >= 500 || response.status === 408) && response.status !== 501 && response.status !== 505);
}
function isSystemError(err) {
    if (!err) return false;
    return err.code === "ETIMEDOUT" || err.code === "ESOCKETTIMEDOUT" || err.code === "ECONNREFUSED" || err.code === "ECONNRESET" || err.code === "ENOENT" || err.code === "ENOTFOUND";
}

},{"@azure/core-util":"b31OK","./throttlingRetryStrategy.js":"g1val","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g1val":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A response is a retry response if it has a throttling status code (429 or 503),
 * as long as one of the [ "Retry-After" or "retry-after-ms" or "x-ms-retry-after-ms" ] headers has a valid value.
 */ parcelHelpers.export(exports, "isThrottlingRetryResponse", ()=>isThrottlingRetryResponse);
parcelHelpers.export(exports, "throttlingRetryStrategy", ()=>throttlingRetryStrategy);
var _helpersJs = require("../util/helpers.js");
/**
 * The header that comes back from Azure services representing
 * the amount of time (minimum) to wait to retry (in seconds or timestamp after which we can retry).
 */ const RetryAfterHeader = "Retry-After";
/**
 * The headers that come back from Azure services representing
 * the amount of time (minimum) to wait to retry.
 *
 * "retry-after-ms", "x-ms-retry-after-ms" : milliseconds
 * "Retry-After" : seconds or timestamp
 */ const AllRetryAfterHeaders = [
    "retry-after-ms",
    "x-ms-retry-after-ms",
    RetryAfterHeader
];
/**
 * A response is a throttling retry response if it has a throttling status code (429 or 503),
 * as long as one of the [ "Retry-After" or "retry-after-ms" or "x-ms-retry-after-ms" ] headers has a valid value.
 *
 * Returns the `retryAfterInMs` value if the response is a throttling retry response.
 * If not throttling retry response, returns `undefined`.
 *
 * @internal
 */ function getRetryAfterInMs(response) {
    if (!(response && [
        429,
        503
    ].includes(response.status))) return undefined;
    try {
        // Headers: "retry-after-ms", "x-ms-retry-after-ms", "Retry-After"
        for (const header of AllRetryAfterHeaders){
            const retryAfterValue = (0, _helpersJs.parseHeaderValueAsNumber)(response, header);
            if (retryAfterValue === 0 || retryAfterValue) {
                // "Retry-After" header ==> seconds
                // "retry-after-ms", "x-ms-retry-after-ms" headers ==> milli-seconds
                const multiplyingFactor = header === RetryAfterHeader ? 1000 : 1;
                return retryAfterValue * multiplyingFactor; // in milli-seconds
            }
        }
        // RetryAfterHeader ("Retry-After") has a special case where it might be formatted as a date instead of a number of seconds
        const retryAfterHeader = response.headers.get(RetryAfterHeader);
        if (!retryAfterHeader) return;
        const date = Date.parse(retryAfterHeader);
        const diff = date - Date.now();
        // negative diff would mean a date in the past, so retry asap with 0 milliseconds
        return Number.isFinite(diff) ? Math.max(0, diff) : undefined;
    } catch (e) {
        return undefined;
    }
}
function isThrottlingRetryResponse(response) {
    return Number.isFinite(getRetryAfterInMs(response));
}
function throttlingRetryStrategy() {
    return {
        name: "throttlingRetryStrategy",
        retry ({ response }) {
            const retryAfterInMs = getRetryAfterInMs(response);
            if (!Number.isFinite(retryAfterInMs)) return {
                skipStrategy: true
            };
            return {
                retryAfterInMs
            };
        }
    };
}

},{"../util/helpers.js":"hgA7h","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hgA7h":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A wrapper for setTimeout that resolves a promise after delayInMs milliseconds.
 * @param delayInMs - The number of milliseconds to be delayed.
 * @param value - The value to be resolved with after a timeout of t milliseconds.
 * @param options - The options for delay - currently abort options
 *                  - abortSignal - The abortSignal associated with containing operation.
 *                  - abortErrorMsg - The abort error message associated with containing operation.
 * @returns Resolved promise
 */ parcelHelpers.export(exports, "delay", ()=>delay);
/**
 * @internal
 * @returns the parsed value or undefined if the parsed value is invalid.
 */ parcelHelpers.export(exports, "parseHeaderValueAsNumber", ()=>parseHeaderValueAsNumber);
var _abortController = require("@azure/abort-controller");
const StandardAbortMessage = "The operation was aborted.";
function delay(delayInMs, value, options) {
    return new Promise((resolve, reject)=>{
        let timer = undefined;
        let onAborted = undefined;
        const rejectOnAbort = ()=>{
            return reject(new (0, _abortController.AbortError)((options === null || options === void 0 ? void 0 : options.abortErrorMsg) ? options === null || options === void 0 ? void 0 : options.abortErrorMsg : StandardAbortMessage));
        };
        const removeListeners = ()=>{
            if ((options === null || options === void 0 ? void 0 : options.abortSignal) && onAborted) options.abortSignal.removeEventListener("abort", onAborted);
        };
        onAborted = ()=>{
            if (timer) clearTimeout(timer);
            removeListeners();
            return rejectOnAbort();
        };
        if ((options === null || options === void 0 ? void 0 : options.abortSignal) && options.abortSignal.aborted) return rejectOnAbort();
        timer = setTimeout(()=>{
            removeListeners();
            resolve(value);
        }, delayInMs);
        if (options === null || options === void 0 ? void 0 : options.abortSignal) options.abortSignal.addEventListener("abort", onAborted);
    });
}
function parseHeaderValueAsNumber(response, headerName) {
    const value = response.headers.get(headerName);
    if (!value) return;
    const valueAsNum = Number(value);
    if (Number.isNaN(valueAsNum)) return;
    return valueAsNum;
}

},{"@azure/abort-controller":"58LhO","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"58LhO":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbortError", ()=>(0, _abortErrorJs.AbortError));
var _abortErrorJs = require("./AbortError.js");

},{"./AbortError.js":"7Kzp5","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7Kzp5":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * This error is thrown when an asynchronous operation has been aborted.
 * Check for this error by testing the `name` that the name property of the
 * error matches `"AbortError"`.
 *
 * @example
 * ```ts
 * const controller = new AbortController();
 * controller.abort();
 * try {
 *   doAsyncWork(controller.signal)
 * } catch (e) {
 *   if (e.name === 'AbortError') {
 *     // handle abort error here.
 *   }
 * }
 * ```
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbortError", ()=>AbortError);
class AbortError extends Error {
    constructor(message){
        super(message);
        this.name = "AbortError";
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jxxY0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * retryPolicy is a generic policy to enable retrying requests when certain conditions are met
 */ parcelHelpers.export(exports, "retryPolicy", ()=>retryPolicy);
var _helpersJs = require("../util/helpers.js");
var _logger = require("@azure/logger");
var _abortController = require("@azure/abort-controller");
var _constantsJs = require("../constants.js");
const retryPolicyLogger = (0, _logger.createClientLogger)("core-rest-pipeline retryPolicy");
/**
 * The programmatic identifier of the retryPolicy.
 */ const retryPolicyName = "retryPolicy";
function retryPolicy(strategies, options = {
    maxRetries: (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT)
}) {
    const logger = options.logger || retryPolicyLogger;
    return {
        name: retryPolicyName,
        async sendRequest (request, next) {
            var _a, _b;
            let response;
            let responseError;
            let retryCount = -1;
            // eslint-disable-next-line no-constant-condition
            retryRequest: while(true){
                retryCount += 1;
                response = undefined;
                responseError = undefined;
                try {
                    logger.info(`Retry ${retryCount}: Attempting to send request`, request.requestId);
                    response = await next(request);
                    logger.info(`Retry ${retryCount}: Received a response from request`, request.requestId);
                } catch (e) {
                    logger.error(`Retry ${retryCount}: Received an error from request`, request.requestId);
                    // RestErrors are valid targets for the retry strategies.
                    // If none of the retry strategies can work with them, they will be thrown later in this policy.
                    // If the received error is not a RestError, it is immediately thrown.
                    responseError = e;
                    if (!e || responseError.name !== "RestError") throw e;
                    response = responseError.response;
                }
                if ((_a = request.abortSignal) === null || _a === void 0 ? void 0 : _a.aborted) {
                    logger.error(`Retry ${retryCount}: Request aborted.`);
                    const abortError = new (0, _abortController.AbortError)();
                    throw abortError;
                }
                if (retryCount >= ((_b = options.maxRetries) !== null && _b !== void 0 ? _b : (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT))) {
                    logger.info(`Retry ${retryCount}: Maximum retries reached. Returning the last received response, or throwing the last received error.`);
                    if (responseError) throw responseError;
                    else if (response) return response;
                    else throw new Error("Maximum retries reached with no response or error to throw");
                }
                logger.info(`Retry ${retryCount}: Processing ${strategies.length} retry strategies.`);
                strategiesLoop: for (const strategy of strategies){
                    const strategyLogger = strategy.logger || retryPolicyLogger;
                    strategyLogger.info(`Retry ${retryCount}: Processing retry strategy ${strategy.name}.`);
                    const modifiers = strategy.retry({
                        retryCount,
                        response,
                        responseError
                    });
                    if (modifiers.skipStrategy) {
                        strategyLogger.info(`Retry ${retryCount}: Skipped.`);
                        continue strategiesLoop;
                    }
                    const { errorToThrow, retryAfterInMs, redirectTo } = modifiers;
                    if (errorToThrow) {
                        strategyLogger.error(`Retry ${retryCount}: Retry strategy ${strategy.name} throws error:`, errorToThrow);
                        throw errorToThrow;
                    }
                    if (retryAfterInMs || retryAfterInMs === 0) {
                        strategyLogger.info(`Retry ${retryCount}: Retry strategy ${strategy.name} retries after ${retryAfterInMs}`);
                        await (0, _helpersJs.delay)(retryAfterInMs, undefined, {
                            abortSignal: request.abortSignal
                        });
                        continue retryRequest;
                    }
                    if (redirectTo) {
                        strategyLogger.info(`Retry ${retryCount}: Retry strategy ${strategy.name} redirects to ${redirectTo}`);
                        request.url = redirectTo;
                        continue retryRequest;
                    }
                }
                if (responseError) {
                    logger.info(`None of the retry strategies could work with the received error. Throwing it.`);
                    throw responseError;
                }
                if (response) {
                    logger.info(`None of the retry strategies could work with the received response. Returning it.`);
                    return response;
                }
            // If all the retries skip and there's no response,
            // we're still in the retry loop, so a new request will be sent
            // until `maxRetries` is reached.
            }
        }
    };
}

},{"../util/helpers.js":"hgA7h","@azure/logger":"cnBke","@azure/abort-controller":"58LhO","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4TRyW":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "formDataPolicyName", ()=>formDataPolicyName);
/**
 * A policy that encodes FormData on the request into the body.
 */ parcelHelpers.export(exports, "formDataPolicy", ()=>formDataPolicy);
var _coreUtil = require("@azure/core-util");
var _httpHeadersJs = require("../httpHeaders.js");
const formDataPolicyName = "formDataPolicy";
function formDataToFormDataMap(formData) {
    var _a;
    const formDataMap = {};
    for (const [key, value] of formData.entries()){
        (_a = formDataMap[key]) !== null && _a !== void 0 ? _a : formDataMap[key] = [];
        formDataMap[key].push(value);
    }
    return formDataMap;
}
function formDataPolicy() {
    return {
        name: formDataPolicyName,
        async sendRequest (request, next) {
            if ((0, _coreUtil.isNodeLike) && typeof FormData !== "undefined" && request.body instanceof FormData) {
                request.formData = formDataToFormDataMap(request.body);
                request.body = undefined;
            }
            if (request.formData) {
                const contentType = request.headers.get("Content-Type");
                if (contentType && contentType.indexOf("application/x-www-form-urlencoded") !== -1) request.body = wwwFormUrlEncode(request.formData);
                else await prepareFormData(request.formData, request);
                request.formData = undefined;
            }
            return next(request);
        }
    };
}
function wwwFormUrlEncode(formData) {
    const urlSearchParams = new URLSearchParams();
    for (const [key, value] of Object.entries(formData)){
        if (Array.isArray(value)) for (const subValue of value)urlSearchParams.append(key, subValue.toString());
        else urlSearchParams.append(key, value.toString());
    }
    return urlSearchParams.toString();
}
async function prepareFormData(formData, request) {
    // validate content type (multipart/form-data)
    const contentType = request.headers.get("Content-Type");
    if (contentType && !contentType.startsWith("multipart/form-data")) // content type is specified and is not multipart/form-data. Exit.
    return;
    request.headers.set("Content-Type", contentType !== null && contentType !== void 0 ? contentType : "multipart/form-data");
    // set body to MultipartRequestBody using content from FormDataMap
    const parts = [];
    for (const [fieldName, values] of Object.entries(formData))for (const value of Array.isArray(values) ? values : [
        values
    ]){
        if (typeof value === "string") parts.push({
            headers: (0, _httpHeadersJs.createHttpHeaders)({
                "Content-Disposition": `form-data; name="${fieldName}"`
            }),
            body: (0, _coreUtil.stringToUint8Array)(value, "utf-8")
        });
        else if (value === undefined || value === null || typeof value !== "object") throw new Error(`Unexpected value for key ${fieldName}: ${value}. Value should be serialized to string first.`);
        else {
            // using || instead of ?? here since if value.name is empty we should create a file name
            const fileName = value.name || "blob";
            const headers = (0, _httpHeadersJs.createHttpHeaders)();
            headers.set("Content-Disposition", `form-data; name="${fieldName}"; filename="${fileName}"`);
            // again, || is used since an empty value.type means the content type is unset
            headers.set("Content-Type", value.type || "application/octet-stream");
            parts.push({
                headers,
                body: value
            });
        }
    }
    request.multipartBody = {
        parts
    };
}

},{"@azure/core-util":"b31OK","../httpHeaders.js":"6kO5I","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6kO5I":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates an object that satisfies the `HttpHeaders` interface.
 * @param rawHeaders - A simple object representing initial headers
 */ parcelHelpers.export(exports, "createHttpHeaders", ()=>createHttpHeaders);
function normalizeName(name) {
    return name.toLowerCase();
}
function* headerIterator(map) {
    for (const entry of map.values())yield [
        entry.name,
        entry.value
    ];
}
class HttpHeadersImpl {
    constructor(rawHeaders){
        this._headersMap = new Map();
        if (rawHeaders) for (const headerName of Object.keys(rawHeaders))this.set(headerName, rawHeaders[headerName]);
    }
    /**
     * Set a header in this collection with the provided name and value. The name is
     * case-insensitive.
     * @param name - The name of the header to set. This value is case-insensitive.
     * @param value - The value of the header to set.
     */ set(name, value) {
        this._headersMap.set(normalizeName(name), {
            name,
            value: String(value).trim()
        });
    }
    /**
     * Get the header value for the provided header name, or undefined if no header exists in this
     * collection with the provided name.
     * @param name - The name of the header. This value is case-insensitive.
     */ get(name) {
        var _a;
        return (_a = this._headersMap.get(normalizeName(name))) === null || _a === void 0 ? void 0 : _a.value;
    }
    /**
     * Get whether or not this header collection contains a header entry for the provided header name.
     * @param name - The name of the header to set. This value is case-insensitive.
     */ has(name) {
        return this._headersMap.has(normalizeName(name));
    }
    /**
     * Remove the header with the provided headerName.
     * @param name - The name of the header to remove.
     */ delete(name) {
        this._headersMap.delete(normalizeName(name));
    }
    /**
     * Get the JSON object representation of this HTTP header collection.
     */ toJSON(options = {}) {
        const result = {};
        if (options.preserveCase) for (const entry of this._headersMap.values())result[entry.name] = entry.value;
        else for (const [normalizedName, entry] of this._headersMap)result[normalizedName] = entry.value;
        return result;
    }
    /**
     * Get the string representation of this HTTP header collection.
     */ toString() {
        return JSON.stringify(this.toJSON({
            preserveCase: true
        }));
    }
    /**
     * Iterate over tuples of header [name, value] pairs.
     */ [Symbol.iterator]() {
        return headerIterator(this._headersMap);
    }
}
function createHttpHeaders(rawHeaders) {
    return new HttpHeadersImpl(rawHeaders);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8CnpE":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _proxyPolicyCommonJs = require("./proxyPolicy.common.js");
parcelHelpers.exportAll(_proxyPolicyCommonJs, exports);

},{"./proxyPolicy.common.js":"cLZUP","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cLZUP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "proxyPolicyName", ()=>proxyPolicyName);
parcelHelpers.export(exports, "getDefaultProxySettings", ()=>getDefaultProxySettings);
/**
 * proxyPolicy is not supported in the browser and attempting
 * to use it will raise an error.
 */ parcelHelpers.export(exports, "proxyPolicy", ()=>proxyPolicy);
/**
 * A function to reset the cached agents.
 * proxyPolicy is not supported in the browser and attempting
 * to use it will raise an error.
 * @internal
 */ parcelHelpers.export(exports, "resetCachedProxyAgents", ()=>resetCachedProxyAgents);
const proxyPolicyName = "proxyPolicy";
const errorMessage = "proxyPolicy is not supported in browser environment";
function getDefaultProxySettings() {
    throw new Error(errorMessage);
}
function proxyPolicy() {
    throw new Error(errorMessage);
}
function resetCachedProxyAgents() {
    throw new Error(errorMessage);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bniwV":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The programmatic identifier of the setClientRequestIdPolicy.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setClientRequestIdPolicyName", ()=>setClientRequestIdPolicyName);
/**
 * Each PipelineRequest gets a unique id upon creation.
 * This policy passes that unique id along via an HTTP header to enable better
 * telemetry and tracing.
 * @param requestIdHeaderName - The name of the header to pass the request ID to.
 */ parcelHelpers.export(exports, "setClientRequestIdPolicy", ()=>setClientRequestIdPolicy);
const setClientRequestIdPolicyName = "setClientRequestIdPolicy";
function setClientRequestIdPolicy(requestIdHeaderName = "x-ms-client-request-id") {
    return {
        name: setClientRequestIdPolicyName,
        async sendRequest (request, next) {
            if (!request.headers.has(requestIdHeaderName)) request.headers.set(requestIdHeaderName, request.requestId);
            return next(request);
        }
    };
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4amLW":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Name of the TLS Policy
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "tlsPolicyName", ()=>tlsPolicyName);
/**
 * Gets a pipeline policy that adds the client certificate to the HttpClient agent for authentication.
 */ parcelHelpers.export(exports, "tlsPolicy", ()=>tlsPolicy);
const tlsPolicyName = "tlsPolicy";
function tlsPolicy(tlsSettings) {
    return {
        name: tlsPolicyName,
        sendRequest: async (req, next)=>{
            // Users may define a request tlsSettings, honor those over the client level one
            if (!req.tlsSettings) req.tlsSettings = tlsSettings;
            return next(req);
        }
    };
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2kvXs":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "tracingPolicyName", ()=>tracingPolicyName);
/**
 * A simple policy to create OpenTelemetry Spans for each request made by the pipeline
 * that has SpanOptions with a parent.
 * Requests made without a parent Span will not be recorded.
 * @param options - Options to configure the telemetry logged by the tracing policy.
 */ parcelHelpers.export(exports, "tracingPolicy", ()=>tracingPolicy);
var _coreTracing = require("@azure/core-tracing");
var _constantsJs = require("../constants.js");
var _userAgentJs = require("../util/userAgent.js");
var _logJs = require("../log.js");
var _coreUtil = require("@azure/core-util");
var _restErrorJs = require("../restError.js");
var _sanitizerJs = require("../util/sanitizer.js");
const tracingPolicyName = "tracingPolicy";
function tracingPolicy(options = {}) {
    const userAgentPromise = (0, _userAgentJs.getUserAgentValue)(options.userAgentPrefix);
    const sanitizer = new (0, _sanitizerJs.Sanitizer)({
        additionalAllowedQueryParameters: options.additionalAllowedQueryParameters
    });
    const tracingClient = tryCreateTracingClient();
    return {
        name: tracingPolicyName,
        async sendRequest (request, next) {
            var _a, _b;
            if (!tracingClient || !((_a = request.tracingOptions) === null || _a === void 0 ? void 0 : _a.tracingContext)) return next(request);
            const userAgent = await userAgentPromise;
            const spanAttributes = {
                "http.url": sanitizer.sanitizeUrl(request.url),
                "http.method": request.method,
                "http.user_agent": userAgent,
                requestId: request.requestId
            };
            if (userAgent) spanAttributes["http.user_agent"] = userAgent;
            const { span, tracingContext } = (_b = tryCreateSpan(tracingClient, request, spanAttributes)) !== null && _b !== void 0 ? _b : {};
            if (!span || !tracingContext) return next(request);
            try {
                const response = await tracingClient.withContext(tracingContext, next, request);
                tryProcessResponse(span, response);
                return response;
            } catch (err) {
                tryProcessError(span, err);
                throw err;
            }
        }
    };
}
function tryCreateTracingClient() {
    try {
        return (0, _coreTracing.createTracingClient)({
            namespace: "",
            packageName: "@azure/core-rest-pipeline",
            packageVersion: (0, _constantsJs.SDK_VERSION)
        });
    } catch (e) {
        (0, _logJs.logger).warning(`Error when creating the TracingClient: ${(0, _coreUtil.getErrorMessage)(e)}`);
        return undefined;
    }
}
function tryCreateSpan(tracingClient, request, spanAttributes) {
    try {
        // As per spec, we do not need to differentiate between HTTP and HTTPS in span name.
        const { span, updatedOptions } = tracingClient.startSpan(`HTTP ${request.method}`, {
            tracingOptions: request.tracingOptions
        }, {
            spanKind: "client",
            spanAttributes
        });
        // If the span is not recording, don't do any more work.
        if (!span.isRecording()) {
            span.end();
            return undefined;
        }
        // set headers
        const headers = tracingClient.createRequestHeaders(updatedOptions.tracingOptions.tracingContext);
        for (const [key, value] of Object.entries(headers))request.headers.set(key, value);
        return {
            span,
            tracingContext: updatedOptions.tracingOptions.tracingContext
        };
    } catch (e) {
        (0, _logJs.logger).warning(`Skipping creating a tracing span due to an error: ${(0, _coreUtil.getErrorMessage)(e)}`);
        return undefined;
    }
}
function tryProcessError(span, error) {
    try {
        span.setStatus({
            status: "error",
            error: (0, _coreUtil.isError)(error) ? error : undefined
        });
        if ((0, _restErrorJs.isRestError)(error) && error.statusCode) span.setAttribute("http.status_code", error.statusCode);
        span.end();
    } catch (e) {
        (0, _logJs.logger).warning(`Skipping tracing span processing due to an error: ${(0, _coreUtil.getErrorMessage)(e)}`);
    }
}
function tryProcessResponse(span, response) {
    try {
        span.setAttribute("http.status_code", response.status);
        const serviceRequestId = response.headers.get("x-ms-request-id");
        if (serviceRequestId) span.setAttribute("serviceRequestId", serviceRequestId);
        span.setStatus({
            status: "success"
        });
        span.end();
    } catch (e) {
        (0, _logJs.logger).warning(`Skipping tracing span processing due to an error: ${(0, _coreUtil.getErrorMessage)(e)}`);
    }
}

},{"@azure/core-tracing":"fmgv7","../constants.js":"jZG4U","../util/userAgent.js":"5OVOJ","../log.js":"ajkUj","@azure/core-util":"b31OK","../restError.js":"4zR2D","../util/sanitizer.js":"eLdTc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fmgv7":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "useInstrumenter", ()=>(0, _instrumenterJs.useInstrumenter));
parcelHelpers.export(exports, "createTracingClient", ()=>(0, _tracingClientJs.createTracingClient));
var _instrumenterJs = require("./instrumenter.js");
var _tracingClientJs = require("./tracingClient.js");

},{"./instrumenter.js":"amHj2","./tracingClient.js":"daqnO","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"amHj2":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDefaultTracingSpan", ()=>createDefaultTracingSpan);
parcelHelpers.export(exports, "createDefaultInstrumenter", ()=>createDefaultInstrumenter);
/**
 * Extends the Azure SDK with support for a given instrumenter implementation.
 *
 * @param instrumenter - The instrumenter implementation to use.
 */ parcelHelpers.export(exports, "useInstrumenter", ()=>useInstrumenter);
/**
 * Gets the currently set instrumenter, a No-Op instrumenter by default.
 *
 * @returns The currently set instrumenter
 */ parcelHelpers.export(exports, "getInstrumenter", ()=>getInstrumenter);
var _tracingContextJs = require("./tracingContext.js");
var _stateJs = require("./state.js");
function createDefaultTracingSpan() {
    return {
        end: ()=>{
        // noop
        },
        isRecording: ()=>false,
        recordException: ()=>{
        // noop
        },
        setAttribute: ()=>{
        // noop
        },
        setStatus: ()=>{
        // noop
        }
    };
}
function createDefaultInstrumenter() {
    return {
        createRequestHeaders: ()=>{
            return {};
        },
        parseTraceparentHeader: ()=>{
            return undefined;
        },
        startSpan: (_name, spanOptions)=>{
            return {
                span: createDefaultTracingSpan(),
                tracingContext: (0, _tracingContextJs.createTracingContext)({
                    parentContext: spanOptions.tracingContext
                })
            };
        },
        withContext (_context, callback, ...callbackArgs) {
            return callback(...callbackArgs);
        }
    };
}
function useInstrumenter(instrumenter) {
    (0, _stateJs.state).instrumenterImplementation = instrumenter;
}
function getInstrumenter() {
    if (!(0, _stateJs.state).instrumenterImplementation) (0, _stateJs.state).instrumenterImplementation = createDefaultInstrumenter();
    return (0, _stateJs.state).instrumenterImplementation;
}

},{"./tracingContext.js":"8pfwk","./state.js":"hYFPh","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8pfwk":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/** @internal */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "knownContextKeys", ()=>knownContextKeys);
/**
 * Creates a new {@link TracingContext} with the given options.
 * @param options - A set of known keys that may be set on the context.
 * @returns A new {@link TracingContext} with the given options.
 *
 * @internal
 */ parcelHelpers.export(exports, "createTracingContext", ()=>createTracingContext);
/** @internal */ parcelHelpers.export(exports, "TracingContextImpl", ()=>TracingContextImpl);
const knownContextKeys = {
    span: Symbol.for("@azure/core-tracing span"),
    namespace: Symbol.for("@azure/core-tracing namespace")
};
function createTracingContext(options = {}) {
    let context = new TracingContextImpl(options.parentContext);
    if (options.span) context = context.setValue(knownContextKeys.span, options.span);
    if (options.namespace) context = context.setValue(knownContextKeys.namespace, options.namespace);
    return context;
}
class TracingContextImpl {
    constructor(initialContext){
        this._contextMap = initialContext instanceof TracingContextImpl ? new Map(initialContext._contextMap) : new Map();
    }
    setValue(key, value) {
        const newContext = new TracingContextImpl(this);
        newContext._contextMap.set(key, value);
        return newContext;
    }
    getValue(key) {
        return this._contextMap.get(key);
    }
    deleteValue(key) {
        const newContext = new TracingContextImpl(this);
        newContext._contextMap.delete(key);
        return newContext;
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hYFPh":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Browser-only implementation of the module's state. The browser esm variant will not load the commonjs state, so we do not need to share state between the two.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "state", ()=>state);
const state = {
    instrumenterImplementation: undefined
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"daqnO":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates a new tracing client.
 *
 * @param options - Options used to configure the tracing client.
 * @returns - An instance of {@link TracingClient}.
 */ parcelHelpers.export(exports, "createTracingClient", ()=>createTracingClient);
var _instrumenterJs = require("./instrumenter.js");
var _tracingContextJs = require("./tracingContext.js");
function createTracingClient(options) {
    const { namespace, packageName, packageVersion } = options;
    function startSpan(name, operationOptions, spanOptions) {
        var _a;
        const startSpanResult = (0, _instrumenterJs.getInstrumenter)().startSpan(name, Object.assign(Object.assign({}, spanOptions), {
            packageName: packageName,
            packageVersion: packageVersion,
            tracingContext: (_a = operationOptions === null || operationOptions === void 0 ? void 0 : operationOptions.tracingOptions) === null || _a === void 0 ? void 0 : _a.tracingContext
        }));
        let tracingContext = startSpanResult.tracingContext;
        const span = startSpanResult.span;
        if (!tracingContext.getValue((0, _tracingContextJs.knownContextKeys).namespace)) tracingContext = tracingContext.setValue((0, _tracingContextJs.knownContextKeys).namespace, namespace);
        span.setAttribute("az.namespace", tracingContext.getValue((0, _tracingContextJs.knownContextKeys).namespace));
        const updatedOptions = Object.assign({}, operationOptions, {
            tracingOptions: Object.assign(Object.assign({}, operationOptions === null || operationOptions === void 0 ? void 0 : operationOptions.tracingOptions), {
                tracingContext
            })
        });
        return {
            span,
            updatedOptions
        };
    }
    async function withSpan(name, operationOptions, callback, spanOptions) {
        const { span, updatedOptions } = startSpan(name, operationOptions, spanOptions);
        try {
            const result = await withContext(updatedOptions.tracingOptions.tracingContext, ()=>Promise.resolve(callback(updatedOptions, span)));
            span.setStatus({
                status: "success"
            });
            return result;
        } catch (err) {
            span.setStatus({
                status: "error",
                error: err
            });
            throw err;
        } finally{
            span.end();
        }
    }
    function withContext(context, callback, ...callbackArgs) {
        return (0, _instrumenterJs.getInstrumenter)().withContext(context, callback, ...callbackArgs);
    }
    /**
     * Parses a traceparent header value into a span identifier.
     *
     * @param traceparentHeader - The traceparent header to parse.
     * @returns An implementation-specific identifier for the span.
     */ function parseTraceparentHeader(traceparentHeader) {
        return (0, _instrumenterJs.getInstrumenter)().parseTraceparentHeader(traceparentHeader);
    }
    /**
     * Creates a set of request headers to propagate tracing information to a backend.
     *
     * @param tracingContext - The context containing the span to serialize.
     * @returns The set of headers to add to a request.
     */ function createRequestHeaders(tracingContext) {
        return (0, _instrumenterJs.getInstrumenter)().createRequestHeaders(tracingContext);
    }
    return {
        startSpan,
        withSpan,
        withContext,
        parseTraceparentHeader,
        createRequestHeaders
    };
}

},{"./instrumenter.js":"amHj2","./tracingContext.js":"8pfwk","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4zR2D":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A custom error type for failed pipeline requests.
 */ parcelHelpers.export(exports, "RestError", ()=>RestError);
/**
 * Typeguard for RestError
 * @param e - Something caught by a catch clause.
 */ parcelHelpers.export(exports, "isRestError", ()=>isRestError);
var _coreUtil = require("@azure/core-util");
var _inspectJs = require("./util/inspect.js");
var _sanitizerJs = require("./util/sanitizer.js");
const errorSanitizer = new (0, _sanitizerJs.Sanitizer)();
class RestError extends Error {
    constructor(message, options = {}){
        super(message);
        this.name = "RestError";
        this.code = options.code;
        this.statusCode = options.statusCode;
        this.request = options.request;
        this.response = options.response;
        Object.setPrototypeOf(this, RestError.prototype);
    }
    /**
     * Logging method for util.inspect in Node
     */ [(0, _inspectJs.custom)]() {
        return `RestError: ${this.message} \n ${errorSanitizer.sanitize(this)}`;
    }
}
/**
 * Something went wrong when making the request.
 * This means the actual request failed for some reason,
 * such as a DNS issue or the connection being lost.
 */ RestError.REQUEST_SEND_ERROR = "REQUEST_SEND_ERROR";
/**
 * This means that parsing the response from the server failed.
 * It may have been malformed.
 */ RestError.PARSE_ERROR = "PARSE_ERROR";
function isRestError(e) {
    if (e instanceof RestError) return true;
    return (0, _coreUtil.isError)(e) && e.name === "RestError";
}

},{"@azure/core-util":"b31OK","./util/inspect.js":"1SnxX","./util/sanitizer.js":"eLdTc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1SnxX":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _inspectCommonJs = require("./inspect.common.js");
parcelHelpers.exportAll(_inspectCommonJs, exports);

},{"./inspect.common.js":"jlGc4","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jlGc4":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "custom", ()=>custom);
const custom = {};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l9pN8":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Create the correct HttpClient for the current environment.
 */ parcelHelpers.export(exports, "createDefaultHttpClient", ()=>createDefaultHttpClient);
var _fetchHttpClientJs = require("./fetchHttpClient.js");
function createDefaultHttpClient() {
    return (0, _fetchHttpClientJs.createFetchHttpClient)();
}

},{"./fetchHttpClient.js":"6k7ka","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6k7ka":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Create a new HttpClient instance for the browser environment.
 * @internal
 */ parcelHelpers.export(exports, "createFetchHttpClient", ()=>createFetchHttpClient);
var _abortController = require("@azure/abort-controller");
var _restErrorJs = require("./restError.js");
var _httpHeadersJs = require("./httpHeaders.js");
var _typeGuardsJs = require("./util/typeGuards.js");
/**
 * Checks if the body is a Blob or Blob-like
 */ function isBlob(body) {
    // File objects count as a type of Blob, so we want to use instanceof explicitly
    return (typeof Blob === "function" || typeof Blob === "object") && body instanceof Blob;
}
/**
 * A HttpClient implementation that uses window.fetch to send HTTP requests.
 * @internal
 */ class FetchHttpClient {
    /**
     * Makes a request over an underlying transport layer and returns the response.
     * @param request - The request to be made.
     */ async sendRequest(request) {
        const url = new URL(request.url);
        const isInsecure = url.protocol !== "https:";
        if (isInsecure && !request.allowInsecureConnection) throw new Error(`Cannot connect to ${request.url} while allowInsecureConnection is false.`);
        if (request.proxySettings) throw new Error("HTTP proxy is not supported in browser environment");
        try {
            return await makeRequest(request);
        } catch (e) {
            throw getError(e, request);
        }
    }
}
/**
 * Sends a request
 */ async function makeRequest(request) {
    const { abortController, abortControllerCleanup } = setupAbortSignal(request);
    try {
        const headers = buildFetchHeaders(request.headers);
        const { streaming, body: requestBody } = buildRequestBody(request);
        const requestInit = Object.assign(Object.assign({
            body: requestBody,
            method: request.method,
            headers: headers,
            signal: abortController.signal
        }, "credentials" in Request.prototype ? {
            credentials: request.withCredentials ? "include" : "same-origin"
        } : {}), "cache" in Request.prototype ? {
            cache: "no-store"
        } : {});
        // According to https://fetch.spec.whatwg.org/#fetch-method,
        // init.duplex must be set when body is a ReadableStream object.
        // currently "half" is the only valid value.
        if (streaming) requestInit.duplex = "half";
        /**
         * Developers of the future:
         * Do not set redirect: "manual" as part
         * of request options.
         * It will not work as you expect.
         */ const response = await fetch(request.url, requestInit);
        // If we're uploading a blob, we need to fire the progress event manually
        if (isBlob(request.body) && request.onUploadProgress) request.onUploadProgress({
            loadedBytes: request.body.size
        });
        return buildPipelineResponse(response, request, abortControllerCleanup);
    } catch (e) {
        abortControllerCleanup === null || abortControllerCleanup === void 0 || abortControllerCleanup();
        throw e;
    }
}
/**
 * Creates a pipeline response from a Fetch response;
 */ async function buildPipelineResponse(httpResponse, request, abortControllerCleanup) {
    var _a, _b;
    const headers = buildPipelineHeaders(httpResponse);
    const response = {
        request,
        headers,
        status: httpResponse.status
    };
    const bodyStream = (0, _typeGuardsJs.isWebReadableStream)(httpResponse.body) ? buildBodyStream(httpResponse.body, {
        onProgress: request.onDownloadProgress,
        onEnd: abortControllerCleanup
    }) : httpResponse.body;
    if (// Value of POSITIVE_INFINITY in streamResponseStatusCodes is considered as any status code
    ((_a = request.streamResponseStatusCodes) === null || _a === void 0 ? void 0 : _a.has(Number.POSITIVE_INFINITY)) || ((_b = request.streamResponseStatusCodes) === null || _b === void 0 ? void 0 : _b.has(response.status))) {
        if (request.enableBrowserStreams) response.browserStreamBody = bodyStream !== null && bodyStream !== void 0 ? bodyStream : undefined;
        else {
            const responseStream = new Response(bodyStream);
            response.blobBody = responseStream.blob();
            abortControllerCleanup === null || abortControllerCleanup === void 0 || abortControllerCleanup();
        }
    } else {
        const responseStream = new Response(bodyStream);
        response.bodyAsText = await responseStream.text();
        abortControllerCleanup === null || abortControllerCleanup === void 0 || abortControllerCleanup();
    }
    return response;
}
function setupAbortSignal(request) {
    const abortController = new AbortController();
    // Cleanup function
    let abortControllerCleanup;
    /**
     * Attach an abort listener to the request
     */ let abortListener;
    if (request.abortSignal) {
        if (request.abortSignal.aborted) throw new (0, _abortController.AbortError)("The operation was aborted.");
        abortListener = (event)=>{
            if (event.type === "abort") abortController.abort();
        };
        request.abortSignal.addEventListener("abort", abortListener);
        abortControllerCleanup = ()=>{
            var _a;
            if (abortListener) (_a = request.abortSignal) === null || _a === void 0 || _a.removeEventListener("abort", abortListener);
        };
    }
    // If a timeout was passed, call the abort signal once the time elapses
    if (request.timeout > 0) setTimeout(()=>{
        abortController.abort();
    }, request.timeout);
    return {
        abortController,
        abortControllerCleanup
    };
}
/**
 * Gets the specific error
 */ // eslint-disable-next-line @azure/azure-sdk/ts-use-interface-parameters
function getError(e, request) {
    var _a;
    if (e && (e === null || e === void 0 ? void 0 : e.name) === "AbortError") return e;
    else return new (0, _restErrorJs.RestError)(`Error sending request: ${e.message}`, {
        code: (_a = e === null || e === void 0 ? void 0 : e.code) !== null && _a !== void 0 ? _a : (0, _restErrorJs.RestError).REQUEST_SEND_ERROR,
        request
    });
}
/**
 * Converts PipelineRequest headers to Fetch headers
 */ function buildFetchHeaders(pipelineHeaders) {
    const headers = new Headers();
    for (const [name, value] of pipelineHeaders)headers.append(name, value);
    return headers;
}
function buildPipelineHeaders(httpResponse) {
    const responseHeaders = (0, _httpHeadersJs.createHttpHeaders)();
    for (const [name, value] of httpResponse.headers)responseHeaders.set(name, value);
    return responseHeaders;
}
function buildRequestBody(request) {
    const body = typeof request.body === "function" ? request.body() : request.body;
    if ((0, _typeGuardsJs.isNodeReadableStream)(body)) throw new Error("Node streams are not supported in browser environment.");
    return (0, _typeGuardsJs.isWebReadableStream)(body) ? {
        streaming: true,
        body: buildBodyStream(body, {
            onProgress: request.onUploadProgress
        })
    } : {
        streaming: false,
        body
    };
}
/**
 * Reads the request/response original stream and stream it through a new
 * ReadableStream, this is done to be able to report progress in a way that
 * all modern browsers support. TransformStreams would be an alternative,
 * however they are not yet supported by all browsers i.e Firefox
 */ function buildBodyStream(readableStream, options = {}) {
    let loadedBytes = 0;
    const { onProgress, onEnd } = options;
    // If the current browser supports pipeThrough we use a TransformStream
    // to report progress
    if (isTransformStreamSupported(readableStream)) return readableStream.pipeThrough(new TransformStream({
        transform (chunk, controller) {
            if (chunk === null) {
                controller.terminate();
                return;
            }
            controller.enqueue(chunk);
            loadedBytes += chunk.length;
            if (onProgress) onProgress({
                loadedBytes
            });
        },
        flush () {
            onEnd === null || onEnd === void 0 || onEnd();
        }
    }));
    else {
        // If we can't use transform streams, wrap the original stream in a new readable stream
        // and use pull to enqueue each chunk and report progress.
        const reader = readableStream.getReader();
        return new ReadableStream({
            async pull (controller) {
                var _a;
                const { done, value } = await reader.read();
                // When no more data needs to be consumed, break the reading
                if (done || !value) {
                    onEnd === null || onEnd === void 0 || onEnd();
                    // Close the stream
                    controller.close();
                    reader.releaseLock();
                    return;
                }
                loadedBytes += (_a = value === null || value === void 0 ? void 0 : value.length) !== null && _a !== void 0 ? _a : 0;
                // Enqueue the next data chunk into our target stream
                controller.enqueue(value);
                if (onProgress) onProgress({
                    loadedBytes
                });
            },
            cancel (reason) {
                onEnd === null || onEnd === void 0 || onEnd();
                return reader.cancel(reason);
            }
        });
    }
}
function createFetchHttpClient() {
    return new FetchHttpClient();
}
function isTransformStreamSupported(readableStream) {
    return readableStream.pipeThrough !== undefined && self.TransformStream !== undefined;
}

},{"@azure/abort-controller":"58LhO","./restError.js":"4zR2D","./httpHeaders.js":"6kO5I","./util/typeGuards.js":"74uwK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5jPfp":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates a new pipeline request with the given options.
 * This method is to allow for the easy setting of default values and not required.
 * @param options - The options to create the request with.
 */ parcelHelpers.export(exports, "createPipelineRequest", ()=>createPipelineRequest);
var _httpHeadersJs = require("./httpHeaders.js");
var _coreUtil = require("@azure/core-util");
class PipelineRequestImpl {
    constructor(options){
        var _a, _b, _c, _d, _e, _f, _g;
        this.url = options.url;
        this.body = options.body;
        this.headers = (_a = options.headers) !== null && _a !== void 0 ? _a : (0, _httpHeadersJs.createHttpHeaders)();
        this.method = (_b = options.method) !== null && _b !== void 0 ? _b : "GET";
        this.timeout = (_c = options.timeout) !== null && _c !== void 0 ? _c : 0;
        this.multipartBody = options.multipartBody;
        this.formData = options.formData;
        this.disableKeepAlive = (_d = options.disableKeepAlive) !== null && _d !== void 0 ? _d : false;
        this.proxySettings = options.proxySettings;
        this.streamResponseStatusCodes = options.streamResponseStatusCodes;
        this.withCredentials = (_e = options.withCredentials) !== null && _e !== void 0 ? _e : false;
        this.abortSignal = options.abortSignal;
        this.tracingOptions = options.tracingOptions;
        this.onUploadProgress = options.onUploadProgress;
        this.onDownloadProgress = options.onDownloadProgress;
        this.requestId = options.requestId || (0, _coreUtil.randomUUID)();
        this.allowInsecureConnection = (_f = options.allowInsecureConnection) !== null && _f !== void 0 ? _f : false;
        this.enableBrowserStreams = (_g = options.enableBrowserStreams) !== null && _g !== void 0 ? _g : false;
    }
}
function createPipelineRequest(options) {
    return new PipelineRequestImpl(options);
}

},{"./httpHeaders.js":"6kO5I","@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"72bbW":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "exponentialRetryPolicyName", ()=>exponentialRetryPolicyName);
/**
 * A policy that attempts to retry requests while introducing an exponentially increasing delay.
 * @param options - Options that configure retry logic.
 */ parcelHelpers.export(exports, "exponentialRetryPolicy", ()=>exponentialRetryPolicy);
var _exponentialRetryStrategyJs = require("../retryStrategies/exponentialRetryStrategy.js");
var _retryPolicyJs = require("./retryPolicy.js");
var _constantsJs = require("../constants.js");
const exponentialRetryPolicyName = "exponentialRetryPolicy";
function exponentialRetryPolicy(options = {}) {
    var _a;
    return (0, _retryPolicyJs.retryPolicy)([
        (0, _exponentialRetryStrategyJs.exponentialRetryStrategy)(Object.assign(Object.assign({}, options), {
            ignoreSystemErrors: true
        }))
    ], {
        maxRetries: (_a = options.maxRetries) !== null && _a !== void 0 ? _a : (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT)
    });
}

},{"../retryStrategies/exponentialRetryStrategy.js":"8AL5c","./retryPolicy.js":"jxxY0","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"loJXt":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "systemErrorRetryPolicyName", ()=>systemErrorRetryPolicyName);
/**
 * A retry policy that specifically seeks to handle errors in the
 * underlying transport layer (e.g. DNS lookup failures) rather than
 * retryable error codes from the server itself.
 * @param options - Options that customize the policy.
 */ parcelHelpers.export(exports, "systemErrorRetryPolicy", ()=>systemErrorRetryPolicy);
var _exponentialRetryStrategyJs = require("../retryStrategies/exponentialRetryStrategy.js");
var _retryPolicyJs = require("./retryPolicy.js");
var _constantsJs = require("../constants.js");
const systemErrorRetryPolicyName = "systemErrorRetryPolicy";
function systemErrorRetryPolicy(options = {}) {
    var _a;
    return {
        name: systemErrorRetryPolicyName,
        sendRequest: (0, _retryPolicyJs.retryPolicy)([
            (0, _exponentialRetryStrategyJs.exponentialRetryStrategy)(Object.assign(Object.assign({}, options), {
                ignoreHttpStatusCodes: true
            }))
        ], {
            maxRetries: (_a = options.maxRetries) !== null && _a !== void 0 ? _a : (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT)
        }).sendRequest
    };
}

},{"../retryStrategies/exponentialRetryStrategy.js":"8AL5c","./retryPolicy.js":"jxxY0","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ar39k":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "throttlingRetryPolicyName", ()=>throttlingRetryPolicyName);
/**
 * A policy that retries when the server sends a 429 response with a Retry-After header.
 *
 * To learn more, please refer to
 * https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-request-limits,
 * https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits and
 * https://docs.microsoft.com/en-us/azure/virtual-machines/troubleshooting/troubleshooting-throttling-errors
 *
 * @param options - Options that configure retry logic.
 */ parcelHelpers.export(exports, "throttlingRetryPolicy", ()=>throttlingRetryPolicy);
var _throttlingRetryStrategyJs = require("../retryStrategies/throttlingRetryStrategy.js");
var _retryPolicyJs = require("./retryPolicy.js");
var _constantsJs = require("../constants.js");
const throttlingRetryPolicyName = "throttlingRetryPolicy";
function throttlingRetryPolicy(options = {}) {
    var _a;
    return {
        name: throttlingRetryPolicyName,
        sendRequest: (0, _retryPolicyJs.retryPolicy)([
            (0, _throttlingRetryStrategyJs.throttlingRetryStrategy)()
        ], {
            maxRetries: (_a = options.maxRetries) !== null && _a !== void 0 ? _a : (0, _constantsJs.DEFAULT_RETRY_POLICY_COUNT)
        }).sendRequest
    };
}

},{"../retryStrategies/throttlingRetryStrategy.js":"g1val","./retryPolicy.js":"jxxY0","../constants.js":"jZG4U","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2U14w":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "bearerTokenAuthenticationPolicyName", ()=>bearerTokenAuthenticationPolicyName);
/**
 * A policy that can request a token from a TokenCredential implementation and
 * then apply it to the Authorization header of a request as a Bearer token.
 */ parcelHelpers.export(exports, "bearerTokenAuthenticationPolicy", ()=>bearerTokenAuthenticationPolicy);
var _tokenCyclerJs = require("../util/tokenCycler.js");
var _logJs = require("../log.js");
const bearerTokenAuthenticationPolicyName = "bearerTokenAuthenticationPolicy";
/**
 * Default authorize request handler
 */ async function defaultAuthorizeRequest(options) {
    const { scopes, getAccessToken, request } = options;
    const getTokenOptions = {
        abortSignal: request.abortSignal,
        tracingOptions: request.tracingOptions
    };
    const accessToken = await getAccessToken(scopes, getTokenOptions);
    if (accessToken) options.request.headers.set("Authorization", `Bearer ${accessToken.token}`);
}
/**
 * We will retrieve the challenge only if the response status code was 401,
 * and if the response contained the header "WWW-Authenticate" with a non-empty value.
 */ function getChallenge(response) {
    const challenge = response.headers.get("WWW-Authenticate");
    if (response.status === 401 && challenge) return challenge;
    return;
}
function bearerTokenAuthenticationPolicy(options) {
    var _a;
    const { credential, scopes, challengeCallbacks } = options;
    const logger = options.logger || (0, _logJs.logger);
    const callbacks = Object.assign({
        authorizeRequest: (_a = challengeCallbacks === null || challengeCallbacks === void 0 ? void 0 : challengeCallbacks.authorizeRequest) !== null && _a !== void 0 ? _a : defaultAuthorizeRequest,
        authorizeRequestOnChallenge: challengeCallbacks === null || challengeCallbacks === void 0 ? void 0 : challengeCallbacks.authorizeRequestOnChallenge
    }, challengeCallbacks);
    // This function encapsulates the entire process of reliably retrieving the token
    // The options are left out of the public API until there's demand to configure this.
    // Remember to extend `BearerTokenAuthenticationPolicyOptions` with `TokenCyclerOptions`
    // in order to pass through the `options` object.
    const getAccessToken = credential ? (0, _tokenCyclerJs.createTokenCycler)(credential /* , options */ ) : ()=>Promise.resolve(null);
    return {
        name: bearerTokenAuthenticationPolicyName,
        /**
         * If there's no challenge parameter:
         * - It will try to retrieve the token using the cache, or the credential's getToken.
         * - Then it will try the next policy with or without the retrieved token.
         *
         * It uses the challenge parameters to:
         * - Skip a first attempt to get the token from the credential if there's no cached token,
         *   since it expects the token to be retrievable only after the challenge.
         * - Prepare the outgoing request if the `prepareRequest` method has been provided.
         * - Send an initial request to receive the challenge if it fails.
         * - Process a challenge if the response contains it.
         * - Retrieve a token with the challenge information, then re-send the request.
         */ async sendRequest (request, next) {
            if (!request.url.toLowerCase().startsWith("https://")) throw new Error("Bearer token authentication is not permitted for non-TLS protected (non-https) URLs.");
            await callbacks.authorizeRequest({
                scopes: Array.isArray(scopes) ? scopes : [
                    scopes
                ],
                request,
                getAccessToken,
                logger
            });
            let response;
            let error;
            try {
                response = await next(request);
            } catch (err) {
                error = err;
                response = err.response;
            }
            if (callbacks.authorizeRequestOnChallenge && (response === null || response === void 0 ? void 0 : response.status) === 401 && getChallenge(response)) {
                // processes challenge
                const shouldSendRequest = await callbacks.authorizeRequestOnChallenge({
                    scopes: Array.isArray(scopes) ? scopes : [
                        scopes
                    ],
                    request,
                    response,
                    getAccessToken,
                    logger
                });
                if (shouldSendRequest) return next(request);
            }
            if (error) throw error;
            else return response;
        }
    };
}

},{"../util/tokenCycler.js":"2et2q","../log.js":"ajkUj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2et2q":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "DEFAULT_CYCLER_OPTIONS", ()=>DEFAULT_CYCLER_OPTIONS);
/**
 * Creates a token cycler from a credential, scopes, and optional settings.
 *
 * A token cycler represents a way to reliably retrieve a valid access token
 * from a TokenCredential. It will handle initializing the token, refreshing it
 * when it nears expiration, and synchronizes refresh attempts to avoid
 * concurrency hazards.
 *
 * @param credential - the underlying TokenCredential that provides the access
 * token
 * @param tokenCyclerOptions - optionally override default settings for the cycler
 *
 * @returns - a function that reliably produces a valid access token
 */ parcelHelpers.export(exports, "createTokenCycler", ()=>createTokenCycler);
var _helpersJs = require("./helpers.js");
const DEFAULT_CYCLER_OPTIONS = {
    forcedRefreshWindowInMs: 1000,
    retryIntervalInMs: 3000,
    refreshWindowInMs: 120000
};
/**
 * Converts an an unreliable access token getter (which may resolve with null)
 * into an AccessTokenGetter by retrying the unreliable getter in a regular
 * interval.
 *
 * @param getAccessToken - A function that produces a promise of an access token that may fail by returning null.
 * @param retryIntervalInMs - The time (in milliseconds) to wait between retry attempts.
 * @param refreshTimeout - The timestamp after which the refresh attempt will fail, throwing an exception.
 * @returns - A promise that, if it resolves, will resolve with an access token.
 */ async function beginRefresh(getAccessToken, retryIntervalInMs, refreshTimeout) {
    // This wrapper handles exceptions gracefully as long as we haven't exceeded
    // the timeout.
    async function tryGetAccessToken() {
        if (Date.now() < refreshTimeout) try {
            return await getAccessToken();
        } catch (_a) {
            return null;
        }
        else {
            const finalToken = await getAccessToken();
            // Timeout is up, so throw if it's still null
            if (finalToken === null) throw new Error("Failed to refresh access token.");
            return finalToken;
        }
    }
    let token = await tryGetAccessToken();
    while(token === null){
        await (0, _helpersJs.delay)(retryIntervalInMs);
        token = await tryGetAccessToken();
    }
    return token;
}
function createTokenCycler(credential, tokenCyclerOptions) {
    let refreshWorker = null;
    let token = null;
    let tenantId;
    const options = Object.assign(Object.assign({}, DEFAULT_CYCLER_OPTIONS), tokenCyclerOptions);
    /**
     * This little holder defines several predicates that we use to construct
     * the rules of refreshing the token.
     */ const cycler = {
        /**
         * Produces true if a refresh job is currently in progress.
         */ get isRefreshing () {
            return refreshWorker !== null;
        },
        /**
         * Produces true if the cycler SHOULD refresh (we are within the refresh
         * window and not already refreshing)
         */ get shouldRefresh () {
            var _a;
            return !cycler.isRefreshing && ((_a = token === null || token === void 0 ? void 0 : token.expiresOnTimestamp) !== null && _a !== void 0 ? _a : 0) - options.refreshWindowInMs < Date.now();
        },
        /**
         * Produces true if the cycler MUST refresh (null or nearly-expired
         * token).
         */ get mustRefresh () {
            return token === null || token.expiresOnTimestamp - options.forcedRefreshWindowInMs < Date.now();
        }
    };
    /**
     * Starts a refresh job or returns the existing job if one is already
     * running.
     */ function refresh(scopes, getTokenOptions) {
        var _a;
        if (!cycler.isRefreshing) {
            // We bind `scopes` here to avoid passing it around a lot
            const tryGetAccessToken = ()=>credential.getToken(scopes, getTokenOptions);
            // Take advantage of promise chaining to insert an assignment to `token`
            // before the refresh can be considered done.
            refreshWorker = beginRefresh(tryGetAccessToken, options.retryIntervalInMs, // If we don't have a token, then we should timeout immediately
            (_a = token === null || token === void 0 ? void 0 : token.expiresOnTimestamp) !== null && _a !== void 0 ? _a : Date.now()).then((_token)=>{
                refreshWorker = null;
                token = _token;
                tenantId = getTokenOptions.tenantId;
                return token;
            }).catch((reason)=>{
                // We also should reset the refresher if we enter a failed state.  All
                // existing awaiters will throw, but subsequent requests will start a
                // new retry chain.
                refreshWorker = null;
                token = null;
                tenantId = undefined;
                throw reason;
            });
        }
        return refreshWorker;
    }
    return async (scopes, tokenOptions)=>{
        //
        // Simple rules:
        // - If we MUST refresh, then return the refresh task, blocking
        //   the pipeline until a token is available.
        // - If we SHOULD refresh, then run refresh but don't return it
        //   (we can still use the cached token).
        // - Return the token, since it's fine if we didn't return in
        //   step 1.
        //
        const hasClaimChallenge = Boolean(tokenOptions.claims);
        const tenantIdChanged = tenantId !== tokenOptions.tenantId;
        if (hasClaimChallenge) // If we've received a claim, we know the existing token isn't valid
        // We want to clear it so that that refresh worker won't use the old expiration time as a timeout
        token = null;
        // If the tenantId passed in token options is different to the one we have
        // Or if we are in claim challenge and the token was rejected and a new access token need to be issued, we need to
        // refresh the token with the new tenantId or token.
        const mustRefresh = tenantIdChanged || hasClaimChallenge || cycler.mustRefresh;
        if (mustRefresh) return refresh(scopes, tokenOptions);
        if (cycler.shouldRefresh) refresh(scopes, tokenOptions);
        return token;
    };
}

},{"./helpers.js":"hgA7h","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gSxn5":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The programmatic identifier of the ndJsonPolicy.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ndJsonPolicyName", ()=>ndJsonPolicyName);
/**
 * ndJsonPolicy is a policy used to control keep alive settings for every request.
 */ parcelHelpers.export(exports, "ndJsonPolicy", ()=>ndJsonPolicy);
const ndJsonPolicyName = "ndJsonPolicy";
function ndJsonPolicy() {
    return {
        name: ndJsonPolicyName,
        async sendRequest (request, next) {
            // There currently isn't a good way to bypass the serializer
            if (typeof request.body === "string" && request.body.startsWith("[")) {
                const body = JSON.parse(request.body);
                if (Array.isArray(body)) request.body = body.map((item)=>JSON.stringify(item) + "\n").join("");
            }
            return next(request);
        }
    };
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aG7O2":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "auxiliaryAuthenticationHeaderPolicyName", ()=>auxiliaryAuthenticationHeaderPolicyName);
/**
 * A policy for external tokens to `x-ms-authorization-auxiliary` header.
 * This header will be used when creating a cross-tenant application we may need to handle authentication requests
 * for resources that are in different tenants.
 * You could see [ARM docs](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/authenticate-multi-tenant) for a rundown of how this feature works
 */ parcelHelpers.export(exports, "auxiliaryAuthenticationHeaderPolicy", ()=>auxiliaryAuthenticationHeaderPolicy);
var _tokenCyclerJs = require("../util/tokenCycler.js");
var _logJs = require("../log.js");
const auxiliaryAuthenticationHeaderPolicyName = "auxiliaryAuthenticationHeaderPolicy";
const AUTHORIZATION_AUXILIARY_HEADER = "x-ms-authorization-auxiliary";
async function sendAuthorizeRequest(options) {
    var _a, _b;
    const { scopes, getAccessToken, request } = options;
    const getTokenOptions = {
        abortSignal: request.abortSignal,
        tracingOptions: request.tracingOptions
    };
    return (_b = (_a = await getAccessToken(scopes, getTokenOptions)) === null || _a === void 0 ? void 0 : _a.token) !== null && _b !== void 0 ? _b : "";
}
function auxiliaryAuthenticationHeaderPolicy(options) {
    const { credentials, scopes } = options;
    const logger = options.logger || (0, _logJs.logger);
    const tokenCyclerMap = new WeakMap();
    return {
        name: auxiliaryAuthenticationHeaderPolicyName,
        async sendRequest (request, next) {
            if (!request.url.toLowerCase().startsWith("https://")) throw new Error("Bearer token authentication for auxiliary header is not permitted for non-TLS protected (non-https) URLs.");
            if (!credentials || credentials.length === 0) {
                logger.info(`${auxiliaryAuthenticationHeaderPolicyName} header will not be set due to empty credentials.`);
                return next(request);
            }
            const tokenPromises = [];
            for (const credential of credentials){
                let getAccessToken = tokenCyclerMap.get(credential);
                if (!getAccessToken) {
                    getAccessToken = (0, _tokenCyclerJs.createTokenCycler)(credential);
                    tokenCyclerMap.set(credential, getAccessToken);
                }
                tokenPromises.push(sendAuthorizeRequest({
                    scopes: Array.isArray(scopes) ? scopes : [
                        scopes
                    ],
                    request,
                    getAccessToken,
                    logger
                }));
            }
            const auxiliaryTokens = (await Promise.all(tokenPromises)).filter((token)=>Boolean(token));
            if (auxiliaryTokens.length === 0) {
                logger.warning(`None of the auxiliary tokens are valid. ${AUTHORIZATION_AUXILIARY_HEADER} header will not be set.`);
                return next(request);
            }
            request.headers.set(AUTHORIZATION_AUXILIARY_HEADER, auxiliaryTokens.map((token)=>`Bearer ${token}`).join(", "));
            return next(request);
        }
    };
}

},{"../util/tokenCycler.js":"2et2q","../log.js":"ajkUj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5lLVn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A BlobServiceClient represents a Client to the Azure Storage Blob service allowing you
 * to manipulate blob containers.
 */ parcelHelpers.export(exports, "BlobServiceClient", ()=>BlobServiceClient);
var _tslib = require("tslib");
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var _coreAuth = require("@azure/core-auth");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreUtil = require("@azure/core-util");
var _pipeline = require("./Pipeline");
var _containerClient = require("./ContainerClient");
var _utilsCommon = require("./utils/utils.common");
var _storageSharedKeyCredential = require("./credentials/StorageSharedKeyCredential");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _tracing = require("./utils/tracing");
var _blobBatchClient = require("./BlobBatchClient");
var _storageClient = require("./StorageClient");
var _accountSASPermissions = require("./sas/AccountSASPermissions");
var _accountSASSignatureValues = require("./sas/AccountSASSignatureValues");
var _accountSASServices = require("./sas/AccountSASServices");
class BlobServiceClient extends (0, _storageClient.StorageClient) {
    /**
     *
     * Creates an instance of BlobServiceClient from connection string.
     *
     * @param connectionString - Account connection string or a SAS connection string of an Azure storage account.
     *                                  [ Note - Account connection string can only be used in NODE.JS runtime. ]
     *                                  Account connection string example -
     *                                  `DefaultEndpointsProtocol=https;AccountName=myaccount;AccountKey=accountKey;EndpointSuffix=core.windows.net`
     *                                  SAS connection string example -
     *                                  `BlobEndpoint=https://myaccount.blob.core.windows.net/;QueueEndpoint=https://myaccount.queue.core.windows.net/;FileEndpoint=https://myaccount.file.core.windows.net/;TableEndpoint=https://myaccount.table.core.windows.net/;SharedAccessSignature=sasString`
     * @param options - Optional. Options to configure the HTTP pipeline.
     */ static fromConnectionString(connectionString, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options) {
        options = options || {};
        const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(connectionString);
        if (extractedCreds.kind === "AccountConnString") {
            if (0, _coreUtil.isNode) {
                const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                const pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                return new BlobServiceClient(extractedCreds.url, pipeline);
            } else throw new Error("Account connection string is only supported in Node.js environment");
        } else if (extractedCreds.kind === "SASConnString") {
            const pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            return new BlobServiceClient(extractedCreds.url + "?" + extractedCreds.accountSas, pipeline);
        } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
    }
    constructor(url, credentialOrPipeline, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        let pipeline;
        if ((0, _pipeline.isPipelineLike)(credentialOrPipeline)) pipeline = credentialOrPipeline;
        else if ((0, _coreUtil.isNode) && credentialOrPipeline instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipeline instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipeline)) pipeline = (0, _pipeline.newPipeline)(credentialOrPipeline, options);
        else // The second parameter is undefined. Use anonymous credential
        pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        super(url, pipeline);
        this.serviceContext = this.storageClientContext.service;
    }
    /**
     * Creates a {@link ContainerClient} object
     *
     * @param containerName - A container name
     * @returns A new ContainerClient object for the given container name.
     *
     * Example usage:
     *
     * ```js
     * const containerClient = blobServiceClient.getContainerClient("<container name>");
     * ```
     */ getContainerClient(containerName) {
        return new (0, _containerClient.ContainerClient)((0, _utilsCommon.appendToURLPath)(this.url, encodeURIComponent(containerName)), this.pipeline);
    }
    /**
     * Create a Blob container. @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     *
     * @param containerName - Name of the container to create.
     * @param options - Options to configure Container Create operation.
     * @returns Container creation response and the corresponding container client.
     */ async createContainer(containerName, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-createContainer", options, async (updatedOptions)=>{
            const containerClient = this.getContainerClient(containerName);
            const containerCreateResponse = await containerClient.create(updatedOptions);
            return {
                containerClient,
                containerCreateResponse
            };
        });
    }
    /**
     * Deletes a Blob container.
     *
     * @param containerName - Name of the container to delete.
     * @param options - Options to configure Container Delete operation.
     * @returns Container deletion response.
     */ async deleteContainer(containerName, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-deleteContainer", options, async (updatedOptions)=>{
            const containerClient = this.getContainerClient(containerName);
            return containerClient.delete(updatedOptions);
        });
    }
    /**
     * Restore a previously deleted Blob container.
     * This API is only functional if Container Soft Delete is enabled for the storage account associated with the container.
     *
     * @param deletedContainerName - Name of the previously deleted container.
     * @param deletedContainerVersion - Version of the previously deleted container, used to uniquely identify the deleted container.
     * @param options - Options to configure Container Restore operation.
     * @returns Container deletion response.
     */ async undeleteContainer(deletedContainerName, deletedContainerVersion, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-undeleteContainer", options, async (updatedOptions)=>{
            const containerClient = this.getContainerClient(options.destinationContainerName || deletedContainerName);
            // Hack to access a protected member.
            const containerContext = containerClient["storageClientContext"].container;
            const containerUndeleteResponse = (0, _utilsCommon.assertResponse)(await containerContext.restore({
                deletedContainerName,
                deletedContainerVersion,
                tracingOptions: updatedOptions.tracingOptions
            }));
            return {
                containerClient,
                containerUndeleteResponse
            };
        });
    }
    /**
     * Rename an existing Blob Container.
     *
     * @param sourceContainerName - The name of the source container.
     * @param destinationContainerName - The new name of the container.
     * @param options - Options to configure Container Rename operation.
     */ /* eslint-disable-next-line @typescript-eslint/ban-ts-comment */ // @ts-ignore Need to hide this interface for now. Make it public and turn on the live tests for it when the service is ready.
    async renameContainer(sourceContainerName, destinationContainerName, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-renameContainer", options, async (updatedOptions)=>{
            var _a;
            const containerClient = this.getContainerClient(destinationContainerName);
            // Hack to access a protected member.
            const containerContext = containerClient["storageClientContext"].container;
            const containerRenameResponse = (0, _utilsCommon.assertResponse)(await containerContext.rename(sourceContainerName, Object.assign(Object.assign({}, updatedOptions), {
                sourceLeaseId: (_a = options.sourceCondition) === null || _a === void 0 ? void 0 : _a.leaseId
            })));
            return {
                containerClient,
                containerRenameResponse
            };
        });
    }
    /**
     * Gets the properties of a storage accounts Blob service, including properties
     * for Storage Analytics and CORS (Cross-Origin Resource Sharing) rules.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-service-properties
     *
     * @param options - Options to the Service Get Properties operation.
     * @returns Response data for the Service Get Properties operation.
     */ async getProperties(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-getProperties", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.serviceContext.getProperties({
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets properties for a storage accounts Blob service endpoint, including properties
     * for Storage Analytics, CORS (Cross-Origin Resource Sharing) rules and soft delete settings.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-service-properties
     *
     * @param properties -
     * @param options - Options to the Service Set Properties operation.
     * @returns Response data for the Service Set Properties operation.
     */ async setProperties(properties, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-setProperties", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.serviceContext.setProperties(properties, {
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Retrieves statistics related to replication for the Blob service. It is only
     * available on the secondary location endpoint when read-access geo-redundant
     * replication is enabled for the storage account.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-service-stats
     *
     * @param options - Options to the Service Get Statistics operation.
     * @returns Response data for the Service Get Statistics operation.
     */ async getStatistics(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-getStatistics", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.serviceContext.getStatistics({
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * The Get Account Information operation returns the sku name and account kind
     * for the specified account.
     * The Get Account Information operation is available on service versions beginning
     * with version 2018-03-28.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-account-information
     *
     * @param options - Options to the Service Get Account Info operation.
     * @returns Response data for the Service Get Account Info operation.
     */ async getAccountInfo(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-getAccountInfo", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.serviceContext.getAccountInfo({
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Returns a list of the containers under the specified account.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/list-containers2
     *
     * @param marker - A string value that identifies the portion of
     *                        the list of containers to be returned with the next listing operation. The
     *                        operation returns the continuationToken value within the response body if the
     *                        listing operation did not return all containers remaining to be listed
     *                        with the current page. The continuationToken value can be used as the value for
     *                        the marker parameter in a subsequent call to request the next page of list
     *                        items. The marker value is opaque to the client.
     * @param options - Options to the Service List Container Segment operation.
     * @returns Response data for the Service List Container Segment operation.
     */ async listContainersSegment(marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-listContainersSegment", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.serviceContext.listContainersSegment(Object.assign(Object.assign({
                abortSignal: options.abortSignal,
                marker
            }, options), {
                include: typeof options.include === "string" ? [
                    options.include
                ] : options.include,
                tracingOptions: updatedOptions.tracingOptions
            })));
        });
    }
    /**
     * The Filter Blobs operation enables callers to list blobs across all containers whose tags
     * match a given search expression. Filter blobs searches across all containers within a
     * storage account but can be scoped within the expression to a single container.
     *
     * @param tagFilterSqlExpression - The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                        The given expression must evaluate to true for a blob to be returned in the results.
     *                                        The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                        however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the continuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The continuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to find blobs by tags.
     */ async findBlobsByTagsSegment(tagFilterSqlExpression, marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-findBlobsByTagsSegment", options, async (updatedOptions)=>{
            const response = (0, _utilsCommon.assertResponse)(await this.serviceContext.filterBlobs({
                abortSignal: options.abortSignal,
                where: tagFilterSqlExpression,
                marker,
                maxPageSize: options.maxPageSize,
                tracingOptions: updatedOptions.tracingOptions
            }));
            const wrappedResponse = Object.assign(Object.assign({}, response), {
                _response: response._response,
                blobs: response.blobs.map((blob)=>{
                    var _a;
                    let tagValue = "";
                    if (((_a = blob.tags) === null || _a === void 0 ? void 0 : _a.blobTagSet.length) === 1) tagValue = blob.tags.blobTagSet[0].value;
                    return Object.assign(Object.assign({}, blob), {
                        tags: (0, _utilsCommon.toTags)(blob.tags),
                        tagValue
                    });
                })
            });
            return wrappedResponse;
        });
    }
    /**
     * Returns an AsyncIterableIterator for ServiceFindBlobsByTagsSegmentResponse.
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the continuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The continuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to find blobs by tags.
     */ findBlobsByTagsSegments(tagFilterSqlExpression_1, marker_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* findBlobsByTagsSegments_1(tagFilterSqlExpression, marker, options = {}) {
            let response;
            if (!!marker || marker === undefined) do {
                response = yield (0, _tslib.__await)(this.findBlobsByTagsSegment(tagFilterSqlExpression, marker, options));
                response.blobs = response.blobs || [];
                marker = response.continuationToken;
                yield yield (0, _tslib.__await)(response);
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator for blobs.
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param options - Options to findBlobsByTagsItems.
     */ findBlobsByTagsItems(tagFilterSqlExpression_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* findBlobsByTagsItems_1(tagFilterSqlExpression, options = {}) {
            var _a, e_1, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.findBlobsByTagsSegments(tagFilterSqlExpression, marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const segment = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)(segment.blobs))));
                }
            } catch (e_1_1) {
                e_1 = {
                    error: e_1_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_1) throw e_1.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to find all blobs with specified tag
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the blobs in pages.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-service-properties
     *
     * Example using `for await` syntax:
     *
     * ```js
     * let i = 1;
     * for await (const blob of blobServiceClient.findBlobsByTags("tagkey='tagvalue'")) {
     *   console.log(`Blob ${i++}: ${container.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * const iter = blobServiceClient.findBlobsByTags("tagkey='tagvalue'");
     * let blobItem = await iter.next();
     * while (!blobItem.done) {
     *   console.log(`Blob ${i++}: ${blobItem.value.name}`);
     *   blobItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of blobServiceClient.findBlobsByTags("tagkey='tagvalue'").byPage({ maxPageSize: 20 })) {
     *   if (response.blobs) {
     *     for (const blob of response.blobs) {
     *       console.log(`Blob ${i++}: ${blob.name}`);
     *     }
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = blobServiceClient.findBlobsByTags("tagkey='tagvalue'").byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 blob names
     * if (response.blobs) {
     *   for (const blob of response.blobs) {
     *     console.log(`Blob ${i++}: ${blob.name}`);
     *   }
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     * // Passing next marker as continuationToken
     * iterator = blobServiceClient
     *   .findBlobsByTags("tagkey='tagvalue'")
     *   .byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints blob names
     * if (response.blobs) {
     *   for (const blob of response.blobs) {
     *      console.log(`Blob ${i++}: ${blob.name}`);
     *   }
     * }
     * ```
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param options - Options to find blobs by tags.
     */ findBlobsByTags(tagFilterSqlExpression, options = {}) {
        // AsyncIterableIterator to iterate over blobs
        const listSegmentOptions = Object.assign({}, options);
        const iter = this.findBlobsByTagsItems(tagFilterSqlExpression, listSegmentOptions);
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.findBlobsByTagsSegments(tagFilterSqlExpression, settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, listSegmentOptions));
            }
        };
    }
    /**
     * Returns an AsyncIterableIterator for ServiceListContainersSegmentResponses
     *
     * @param marker - A string value that identifies the portion of
     *                        the list of containers to be returned with the next listing operation. The
     *                        operation returns the continuationToken value within the response body if the
     *                        listing operation did not return all containers remaining to be listed
     *                        with the current page. The continuationToken value can be used as the value for
     *                        the marker parameter in a subsequent call to request the next page of list
     *                        items. The marker value is opaque to the client.
     * @param options - Options to list containers operation.
     */ listSegments(marker_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listSegments_1(marker, options = {}) {
            let listContainersSegmentResponse;
            if (!!marker || marker === undefined) do {
                listContainersSegmentResponse = yield (0, _tslib.__await)(this.listContainersSegment(marker, options));
                listContainersSegmentResponse.containerItems = listContainersSegmentResponse.containerItems || [];
                marker = listContainersSegmentResponse.continuationToken;
                yield yield (0, _tslib.__await)((yield (0, _tslib.__await)(listContainersSegmentResponse)));
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator for Container Items
     *
     * @param options - Options to list containers operation.
     */ listItems() {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listItems_1(options = {}) {
            var _a, e_2, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.listSegments(marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const segment = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)(segment.containerItems))));
                }
            } catch (e_2_1) {
                e_2 = {
                    error: e_2_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_2) throw e_2.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to list all the containers
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the containers in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * let i = 1;
     * for await (const container of blobServiceClient.listContainers()) {
     *   console.log(`Container ${i++}: ${container.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * const iter = blobServiceClient.listContainers();
     * let containerItem = await iter.next();
     * while (!containerItem.done) {
     *   console.log(`Container ${i++}: ${containerItem.value.name}`);
     *   containerItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of blobServiceClient.listContainers().byPage({ maxPageSize: 20 })) {
     *   if (response.containerItems) {
     *     for (const container of response.containerItems) {
     *       console.log(`Container ${i++}: ${container.name}`);
     *     }
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = blobServiceClient.listContainers().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 container names
     * if (response.containerItems) {
     *   for (const container of response.containerItems) {
     *     console.log(`Container ${i++}: ${container.name}`);
     *   }
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     * // Passing next marker as continuationToken
     * iterator = blobServiceClient
     *   .listContainers()
     *   .byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 container names
     * if (response.containerItems) {
     *   for (const container of response.containerItems) {
     *      console.log(`Container ${i++}: ${container.name}`);
     *   }
     * }
     * ```
     *
     * @param options - Options to list containers.
     * @returns An asyncIterableIterator that supports paging.
     */ listContainers(options = {}) {
        if (options.prefix === "") options.prefix = undefined;
        const include = [];
        if (options.includeDeleted) include.push("deleted");
        if (options.includeMetadata) include.push("metadata");
        if (options.includeSystem) include.push("system");
        // AsyncIterableIterator to iterate over containers
        const listSegmentOptions = Object.assign(Object.assign({}, options), include.length > 0 ? {
            include
        } : {});
        const iter = this.listItems(listSegmentOptions);
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.listSegments(settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, listSegmentOptions));
            }
        };
    }
    /**
     * ONLY AVAILABLE WHEN USING BEARER TOKEN AUTHENTICATION (TokenCredential).
     *
     * Retrieves a user delegation key for the Blob service. This is only a valid operation when using
     * bearer token authentication.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-user-delegation-key
     *
     * @param startsOn -      The start time for the user delegation SAS. Must be within 7 days of the current time
     * @param expiresOn -     The end time for the user delegation SAS. Must be within 7 days of the current time
     */ async getUserDelegationKey(startsOn, expiresOn, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobServiceClient-getUserDelegationKey", options, async (updatedOptions)=>{
            const response = (0, _utilsCommon.assertResponse)(await this.serviceContext.getUserDelegationKey({
                startsOn: (0, _utilsCommon.truncatedISO8061Date)(startsOn, false),
                expiresOn: (0, _utilsCommon.truncatedISO8061Date)(expiresOn, false)
            }, {
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
            const userDelegationKey = {
                signedObjectId: response.signedObjectId,
                signedTenantId: response.signedTenantId,
                signedStartsOn: new Date(response.signedStartsOn),
                signedExpiresOn: new Date(response.signedExpiresOn),
                signedService: response.signedService,
                signedVersion: response.signedVersion,
                value: response.value
            };
            const res = Object.assign({
                _response: response._response,
                requestId: response.requestId,
                clientRequestId: response.clientRequestId,
                version: response.version,
                date: response.date,
                errorCode: response.errorCode
            }, userDelegationKey);
            return res;
        });
    }
    /**
     * Creates a BlobBatchClient object to conduct batch operations.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch
     *
     * @returns A new BlobBatchClient object for this service.
     */ getBlobBatchClient() {
        return new (0, _blobBatchClient.BlobBatchClient)(this.url, this.pipeline);
    }
    /**
     * Only available for BlobServiceClient constructed with a shared key credential.
     *
     * Generates a Blob account Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas
     *
     * @param expiresOn - Optional. The time at which the shared access signature becomes invalid. Default to an hour later if not provided.
     * @param permissions - Specifies the list of permissions to be associated with the SAS.
     * @param resourceTypes - Specifies the resource types associated with the shared access signature.
     * @param options - Optional parameters.
     * @returns An account SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */ generateAccountSasUrl(expiresOn, permissions = (0, _accountSASPermissions.AccountSASPermissions).parse("r"), resourceTypes = "sco", options = {}) {
        if (!(this.credential instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential))) throw RangeError("Can only generate the account SAS when the client is initialized with a shared key credential");
        if (expiresOn === undefined) {
            const now = new Date();
            expiresOn = new Date(now.getTime() + 3600000);
        }
        const sas = (0, _accountSASSignatureValues.generateAccountSASQueryParameters)(Object.assign({
            permissions,
            expiresOn,
            resourceTypes,
            services: (0, _accountSASServices.AccountSASServices).parse("b").toString()
        }, options), this.credential).toString();
        return (0, _utilsCommon.appendToURLQuery)(this.url, sas);
    }
}

},{"tslib":"lRdW5","@azure/core-auth":"2xRAB","@azure/core-rest-pipeline":"d0mqv","@azure/core-util":"b31OK","./Pipeline":"bsozg","./ContainerClient":"45MBz","./utils/utils.common":"2SR3M","./credentials/StorageSharedKeyCredential":"jUFIX","./credentials/AnonymousCredential":"f0sOe","./utils/tracing":"m0KjB","./BlobBatchClient":"iF02i","./StorageClient":"gO9Kx","./sas/AccountSASPermissions":"8tbmf","./sas/AccountSASSignatureValues":"d00sP","./sas/AccountSASServices":"7HHJy","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lRdW5":[function(require,module,exports) {
/******************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */ /* global Reflect, Promise, SuppressedError, Symbol */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "__extends", ()=>__extends);
parcelHelpers.export(exports, "__assign", ()=>__assign);
parcelHelpers.export(exports, "__rest", ()=>__rest);
parcelHelpers.export(exports, "__decorate", ()=>__decorate);
parcelHelpers.export(exports, "__param", ()=>__param);
parcelHelpers.export(exports, "__esDecorate", ()=>__esDecorate);
parcelHelpers.export(exports, "__runInitializers", ()=>__runInitializers);
parcelHelpers.export(exports, "__propKey", ()=>__propKey);
parcelHelpers.export(exports, "__setFunctionName", ()=>__setFunctionName);
parcelHelpers.export(exports, "__metadata", ()=>__metadata);
parcelHelpers.export(exports, "__awaiter", ()=>__awaiter);
parcelHelpers.export(exports, "__generator", ()=>__generator);
parcelHelpers.export(exports, "__createBinding", ()=>__createBinding);
parcelHelpers.export(exports, "__exportStar", ()=>__exportStar);
parcelHelpers.export(exports, "__values", ()=>__values);
parcelHelpers.export(exports, "__read", ()=>__read);
/** @deprecated */ parcelHelpers.export(exports, "__spread", ()=>__spread);
/** @deprecated */ parcelHelpers.export(exports, "__spreadArrays", ()=>__spreadArrays);
parcelHelpers.export(exports, "__spreadArray", ()=>__spreadArray);
parcelHelpers.export(exports, "__await", ()=>__await);
parcelHelpers.export(exports, "__asyncGenerator", ()=>__asyncGenerator);
parcelHelpers.export(exports, "__asyncDelegator", ()=>__asyncDelegator);
parcelHelpers.export(exports, "__asyncValues", ()=>__asyncValues);
parcelHelpers.export(exports, "__makeTemplateObject", ()=>__makeTemplateObject);
parcelHelpers.export(exports, "__importStar", ()=>__importStar);
parcelHelpers.export(exports, "__importDefault", ()=>__importDefault);
parcelHelpers.export(exports, "__classPrivateFieldGet", ()=>__classPrivateFieldGet);
parcelHelpers.export(exports, "__classPrivateFieldSet", ()=>__classPrivateFieldSet);
parcelHelpers.export(exports, "__classPrivateFieldIn", ()=>__classPrivateFieldIn);
parcelHelpers.export(exports, "__addDisposableResource", ()=>__addDisposableResource);
parcelHelpers.export(exports, "__disposeResources", ()=>__disposeResources);
var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d, b) {
        d.__proto__ = b;
    } || function(d, b) {
        for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var __assign = function() {
    __assign = Object.assign || function __assign(t) {
        for(var s, i = 1, n = arguments.length; i < n; i++){
            s = arguments[i];
            for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
function __rest(s, e) {
    var t = {};
    for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function") {
        for(var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++)if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];
    }
    return t;
}
function __decorate(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for(var i = decorators.length - 1; i >= 0; i--)if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
}
function __param(paramIndex, decorator) {
    return function(target, key) {
        decorator(target, key, paramIndex);
    };
}
function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {
    function accept(f) {
        if (f !== void 0 && typeof f !== "function") throw new TypeError("Function expected");
        return f;
    }
    var kind = contextIn.kind, key = kind === "getter" ? "get" : kind === "setter" ? "set" : "value";
    var target = !descriptorIn && ctor ? contextIn["static"] ? ctor : ctor.prototype : null;
    var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});
    var _, done = false;
    for(var i = decorators.length - 1; i >= 0; i--){
        var context = {};
        for(var p in contextIn)context[p] = p === "access" ? {} : contextIn[p];
        for(var p in contextIn.access)context.access[p] = contextIn.access[p];
        context.addInitializer = function(f) {
            if (done) throw new TypeError("Cannot add initializers after decoration has completed");
            extraInitializers.push(accept(f || null));
        };
        var result = (0, decorators[i])(kind === "accessor" ? {
            get: descriptor.get,
            set: descriptor.set
        } : descriptor[key], context);
        if (kind === "accessor") {
            if (result === void 0) continue;
            if (result === null || typeof result !== "object") throw new TypeError("Object expected");
            if (_ = accept(result.get)) descriptor.get = _;
            if (_ = accept(result.set)) descriptor.set = _;
            if (_ = accept(result.init)) initializers.unshift(_);
        } else if (_ = accept(result)) {
            if (kind === "field") initializers.unshift(_);
            else descriptor[key] = _;
        }
    }
    if (target) Object.defineProperty(target, contextIn.name, descriptor);
    done = true;
}
function __runInitializers(thisArg, initializers, value) {
    var useValue = arguments.length > 2;
    for(var i = 0; i < initializers.length; i++)value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);
    return useValue ? value : void 0;
}
function __propKey(x) {
    return typeof x === "symbol" ? x : "".concat(x);
}
function __setFunctionName(f, name, prefix) {
    if (typeof name === "symbol") name = name.description ? "[".concat(name.description, "]") : "";
    return Object.defineProperty(f, "name", {
        configurable: true,
        value: prefix ? "".concat(prefix, " ", name) : name
    });
}
function __metadata(metadataKey, metadataValue) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(metadataKey, metadataValue);
}
function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}
function __generator(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g;
    return g = {
        next: verb(0),
        "throw": verb(1),
        "return": verb(2)
    }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(g && (g = 0, op[0] && (_ = 0)), _)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
}
var __createBinding = Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) desc = {
        enumerable: true,
        get: function() {
            return m[k];
        }
    };
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
};
function __exportStar(m, o) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);
}
function __values(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function() {
            if (o && i >= o.length) o = void 0;
            return {
                value: o && o[i++],
                done: !o
            };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function __read(o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while((n === void 0 || n-- > 0) && !(r = i.next()).done)ar.push(r.value);
    } catch (error) {
        e = {
            error: error
        };
    } finally{
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        } finally{
            if (e) throw e.error;
        }
    }
    return ar;
}
function __spread() {
    for(var ar = [], i = 0; i < arguments.length; i++)ar = ar.concat(__read(arguments[i]));
    return ar;
}
function __spreadArrays() {
    for(var s = 0, i = 0, il = arguments.length; i < il; i++)s += arguments[i].length;
    for(var r = Array(s), k = 0, i = 0; i < il; i++)for(var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)r[k] = a[j];
    return r;
}
function __spreadArray(to, from, pack) {
    if (pack || arguments.length === 2) {
        for(var i = 0, l = from.length, ar; i < l; i++)if (ar || !(i in from)) {
            if (!ar) ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
        }
    }
    return to.concat(ar || Array.prototype.slice.call(from));
}
function __await(v) {
    return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = {}, verb("next"), verb("throw"), verb("return", awaitReturn), i[Symbol.asyncIterator] = function() {
        return this;
    }, i;
    function awaitReturn(f) {
        return function(v) {
            return Promise.resolve(v).then(f, reject);
        };
    }
    function verb(n, f) {
        if (g[n]) {
            i[n] = function(v) {
                return new Promise(function(a, b) {
                    q.push([
                        n,
                        v,
                        a,
                        b
                    ]) > 1 || resume(n, v);
                });
            };
            if (f) i[n] = f(i[n]);
        }
    }
    function resume(n, v) {
        try {
            step(g[n](v));
        } catch (e) {
            settle(q[0][3], e);
        }
    }
    function step(r) {
        r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
    }
    function fulfill(value) {
        resume("next", value);
    }
    function reject(value) {
        resume("throw", value);
    }
    function settle(f, v) {
        if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]);
    }
}
function __asyncDelegator(o) {
    var i, p;
    return i = {}, verb("next"), verb("throw", function(e) {
        throw e;
    }), verb("return"), i[Symbol.iterator] = function() {
        return this;
    }, i;
    function verb(n, f) {
        i[n] = o[n] ? function(v) {
            return (p = !p) ? {
                value: __await(o[n](v)),
                done: false
            } : f ? f(v) : v;
        } : f;
    }
}
function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i);
    function verb(n) {
        i[n] = o[n] && function(v) {
            return new Promise(function(resolve, reject) {
                v = o[n](v), settle(resolve, reject, v.done, v.value);
            });
        };
    }
    function settle(resolve, reject, d, v) {
        Promise.resolve(v).then(function(v) {
            resolve({
                value: v,
                done: d
            });
        }, reject);
    }
}
function __makeTemplateObject(cooked, raw) {
    if (Object.defineProperty) Object.defineProperty(cooked, "raw", {
        value: raw
    });
    else cooked.raw = raw;
    return cooked;
}
var __setModuleDefault = Object.create ? function(o, v) {
    Object.defineProperty(o, "default", {
        enumerable: true,
        value: v
    });
} : function(o, v) {
    o["default"] = v;
};
function __importStar(mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) {
        for(var k in mod)if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    }
    __setModuleDefault(result, mod);
    return result;
}
function __importDefault(mod) {
    return mod && mod.__esModule ? mod : {
        default: mod
    };
}
function __classPrivateFieldGet(receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}
function __classPrivateFieldSet(receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}
function __classPrivateFieldIn(state, receiver) {
    if (receiver === null || typeof receiver !== "object" && typeof receiver !== "function") throw new TypeError("Cannot use 'in' operator on non-object");
    return typeof state === "function" ? receiver === state : state.has(receiver);
}
function __addDisposableResource(env, value, async) {
    if (value !== null && value !== void 0) {
        if (typeof value !== "object" && typeof value !== "function") throw new TypeError("Object expected.");
        var dispose, inner;
        if (async) {
            if (!Symbol.asyncDispose) throw new TypeError("Symbol.asyncDispose is not defined.");
            dispose = value[Symbol.asyncDispose];
        }
        if (dispose === void 0) {
            if (!Symbol.dispose) throw new TypeError("Symbol.dispose is not defined.");
            dispose = value[Symbol.dispose];
            if (async) inner = dispose;
        }
        if (typeof dispose !== "function") throw new TypeError("Object not disposable.");
        if (inner) dispose = function() {
            try {
                inner.call(this);
            } catch (e) {
                return Promise.reject(e);
            }
        };
        env.stack.push({
            value: value,
            dispose: dispose,
            async: async
        });
    } else if (async) env.stack.push({
        async: true
    });
    return value;
}
var _SuppressedError = typeof SuppressedError === "function" ? SuppressedError : function(error, suppressed, message) {
    var e = new Error(message);
    return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
};
function __disposeResources(env) {
    function fail(e) {
        env.error = env.hasError ? new _SuppressedError(e, env.error, "An error was suppressed during disposal.") : e;
        env.hasError = true;
    }
    function next() {
        while(env.stack.length){
            var rec = env.stack.pop();
            try {
                var result = rec.dispose && rec.dispose.call(rec.value);
                if (rec.async) return Promise.resolve(result).then(next, function(e) {
                    fail(e);
                    return next();
                });
            } catch (e) {
                fail(e);
            }
        }
        if (env.hasError) throw env.error;
    }
    return next();
}
exports.default = {
    __extends: __extends,
    __assign: __assign,
    __rest: __rest,
    __decorate: __decorate,
    __param: __param,
    __metadata: __metadata,
    __awaiter: __awaiter,
    __generator: __generator,
    __createBinding: __createBinding,
    __exportStar: __exportStar,
    __values: __values,
    __read: __read,
    __spread: __spread,
    __spreadArrays: __spreadArrays,
    __spreadArray: __spreadArray,
    __await: __await,
    __asyncGenerator: __asyncGenerator,
    __asyncDelegator: __asyncDelegator,
    __asyncValues: __asyncValues,
    __makeTemplateObject: __makeTemplateObject,
    __importStar: __importStar,
    __importDefault: __importDefault,
    __classPrivateFieldGet: __classPrivateFieldGet,
    __classPrivateFieldSet: __classPrivateFieldSet,
    __classPrivateFieldIn: __classPrivateFieldIn,
    __addDisposableResource: __addDisposableResource,
    __disposeResources: __disposeResources
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2xRAB":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AzureKeyCredential", ()=>(0, _azureKeyCredentialJs.AzureKeyCredential));
parcelHelpers.export(exports, "isKeyCredential", ()=>(0, _keyCredentialJs.isKeyCredential));
parcelHelpers.export(exports, "AzureNamedKeyCredential", ()=>(0, _azureNamedKeyCredentialJs.AzureNamedKeyCredential));
parcelHelpers.export(exports, "isNamedKeyCredential", ()=>(0, _azureNamedKeyCredentialJs.isNamedKeyCredential));
parcelHelpers.export(exports, "AzureSASCredential", ()=>(0, _azureSASCredentialJs.AzureSASCredential));
parcelHelpers.export(exports, "isSASCredential", ()=>(0, _azureSASCredentialJs.isSASCredential));
parcelHelpers.export(exports, "isTokenCredential", ()=>(0, _tokenCredentialJs.isTokenCredential));
var _azureKeyCredentialJs = require("./azureKeyCredential.js");
var _keyCredentialJs = require("./keyCredential.js");
var _azureNamedKeyCredentialJs = require("./azureNamedKeyCredential.js");
var _azureSASCredentialJs = require("./azureSASCredential.js");
var _tokenCredentialJs = require("./tokenCredential.js");

},{"./azureKeyCredential.js":"7Gd5N","./keyCredential.js":"6QSYw","./azureNamedKeyCredential.js":"iJgBZ","./azureSASCredential.js":"cQXcC","./tokenCredential.js":"1ZQ0k","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7Gd5N":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * A static-key-based credential that supports updating
 * the underlying key value.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AzureKeyCredential", ()=>AzureKeyCredential);
class AzureKeyCredential {
    /**
     * The value of the key to be used in authentication
     */ get key() {
        return this._key;
    }
    /**
     * Create an instance of an AzureKeyCredential for use
     * with a service client.
     *
     * @param key - The initial value of the key to use in authentication
     */ constructor(key){
        if (!key) throw new Error("key must be a non-empty string");
        this._key = key;
    }
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newKey - The new key value to be used
     */ update(newKey) {
        this._key = newKey;
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6QSYw":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tests an object to determine whether it implements KeyCredential.
 *
 * @param credential - The assumed KeyCredential to be tested.
 */ parcelHelpers.export(exports, "isKeyCredential", ()=>isKeyCredential);
var _coreUtil = require("@azure/core-util");
function isKeyCredential(credential) {
    return (0, _coreUtil.isObjectWithProperties)(credential, [
        "key"
    ]) && typeof credential.key === "string";
}

},{"@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iJgBZ":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A static name/key-based credential that supports updating
 * the underlying name and key values.
 */ parcelHelpers.export(exports, "AzureNamedKeyCredential", ()=>AzureNamedKeyCredential);
/**
 * Tests an object to determine whether it implements NamedKeyCredential.
 *
 * @param credential - The assumed NamedKeyCredential to be tested.
 */ parcelHelpers.export(exports, "isNamedKeyCredential", ()=>isNamedKeyCredential);
var _coreUtil = require("@azure/core-util");
class AzureNamedKeyCredential {
    /**
     * The value of the key to be used in authentication.
     */ get key() {
        return this._key;
    }
    /**
     * The value of the name to be used in authentication.
     */ get name() {
        return this._name;
    }
    /**
     * Create an instance of an AzureNamedKeyCredential for use
     * with a service client.
     *
     * @param name - The initial value of the name to use in authentication.
     * @param key - The initial value of the key to use in authentication.
     */ constructor(name, key){
        if (!name || !key) throw new TypeError("name and key must be non-empty strings");
        this._name = name;
        this._key = key;
    }
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newName - The new name value to be used.
     * @param newKey - The new key value to be used.
     */ update(newName, newKey) {
        if (!newName || !newKey) throw new TypeError("newName and newKey must be non-empty strings");
        this._name = newName;
        this._key = newKey;
    }
}
function isNamedKeyCredential(credential) {
    return (0, _coreUtil.isObjectWithProperties)(credential, [
        "name",
        "key"
    ]) && typeof credential.key === "string" && typeof credential.name === "string";
}

},{"@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cQXcC":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A static-signature-based credential that supports updating
 * the underlying signature value.
 */ parcelHelpers.export(exports, "AzureSASCredential", ()=>AzureSASCredential);
/**
 * Tests an object to determine whether it implements SASCredential.
 *
 * @param credential - The assumed SASCredential to be tested.
 */ parcelHelpers.export(exports, "isSASCredential", ()=>isSASCredential);
var _coreUtil = require("@azure/core-util");
class AzureSASCredential {
    /**
     * The value of the shared access signature to be used in authentication
     */ get signature() {
        return this._signature;
    }
    /**
     * Create an instance of an AzureSASCredential for use
     * with a service client.
     *
     * @param signature - The initial value of the shared access signature to use in authentication
     */ constructor(signature){
        if (!signature) throw new Error("shared access signature must be a non-empty string");
        this._signature = signature;
    }
    /**
     * Change the value of the signature.
     *
     * Updates will take effect upon the next request after
     * updating the signature value.
     *
     * @param newSignature - The new shared access signature value to be used
     */ update(newSignature) {
        if (!newSignature) throw new Error("shared access signature must be a non-empty string");
        this._signature = newSignature;
    }
}
function isSASCredential(credential) {
    return (0, _coreUtil.isObjectWithProperties)(credential, [
        "signature"
    ]) && typeof credential.signature === "string";
}

},{"@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1ZQ0k":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Tests an object to determine whether it implements TokenCredential.
 *
 * @param credential - The assumed TokenCredential to be tested.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isTokenCredential", ()=>isTokenCredential);
function isTokenCredential(credential) {
    // Check for an object with a 'getToken' function and possibly with
    // a 'signRequest' function.  We do this check to make sure that
    // a ServiceClientCredentials implementor (like TokenClientCredentials
    // in ms-rest-nodeauth) doesn't get mistaken for a TokenCredential if
    // it doesn't actually implement TokenCredential also.
    const castCredential = credential;
    return castCredential && typeof castCredential.getToken === "function" && (castCredential.signRequest === undefined || castCredential.getToken.length > 0);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bsozg":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
// Export following interfaces and types for customers who want to implement their
// own RequestPolicy or HTTPClient
parcelHelpers.export(exports, "StorageOAuthScopes", ()=>(0, _constants.StorageOAuthScopes));
/**
 * A helper to decide if a given argument satisfies the Pipeline contract
 * @param pipeline - An argument that may be a Pipeline
 * @returns true when the argument satisfies the Pipeline contract
 */ parcelHelpers.export(exports, "isPipelineLike", ()=>isPipelineLike);
/**
 * A Pipeline class containing HTTP request policies.
 * You can create a default Pipeline by calling {@link newPipeline}.
 * Or you can create a Pipeline with your own policies by the constructor of Pipeline.
 *
 * Refer to {@link newPipeline} and provided policies before implementing your
 * customized Pipeline.
 */ parcelHelpers.export(exports, "Pipeline", ()=>Pipeline);
/**
 * Creates a new Pipeline object with Credential provided.
 *
 * @param credential -  Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
 * @param pipelineOptions - Optional. Options.
 * @returns A new Pipeline object.
 */ parcelHelpers.export(exports, "newPipeline", ()=>newPipeline);
parcelHelpers.export(exports, "getCoreClientOptions", ()=>getCoreClientOptions);
parcelHelpers.export(exports, "getCredentialFromPipeline", ()=>getCredentialFromPipeline);
var _tslib = require("tslib");
var _coreHttpCompat = require("@azure/core-http-compat");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreClient = require("@azure/core-client");
var _coreXml = require("@azure/core-xml");
var _coreAuth = require("@azure/core-auth");
var _log = require("./log");
var _storageRetryPolicyFactory = require("./StorageRetryPolicyFactory");
var _storageSharedKeyCredential = require("./credentials/StorageSharedKeyCredential");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _constants = require("./utils/constants");
var _cache = require("./utils/cache");
var _storageBrowserPolicyV2 = require("./policies/StorageBrowserPolicyV2");
var _storageRetryPolicyV2 = require("./policies/StorageRetryPolicyV2");
var _storageSharedKeyCredentialPolicyV2 = require("./policies/StorageSharedKeyCredentialPolicyV2");
var _storageBrowserPolicyFactory = require("./StorageBrowserPolicyFactory");
function isPipelineLike(pipeline) {
    if (!pipeline || typeof pipeline !== "object") return false;
    const castPipeline = pipeline;
    return Array.isArray(castPipeline.factories) && typeof castPipeline.options === "object" && typeof castPipeline.toServiceClientOptions === "function";
}
class Pipeline {
    /**
     * Creates an instance of Pipeline. Customize HTTPClient by implementing IHttpClient interface.
     *
     * @param factories -
     * @param options -
     */ constructor(factories, options = {}){
        this.factories = factories;
        this.options = options;
    }
    /**
     * Transfer Pipeline object to ServiceClientOptions object which is required by
     * ServiceClient constructor.
     *
     * @returns The ServiceClientOptions object from this Pipeline.
     */ toServiceClientOptions() {
        return {
            httpClient: this.options.httpClient,
            requestPolicyFactories: this.factories
        };
    }
}
function newPipeline(credential, pipelineOptions = {}) {
    if (!credential) credential = new (0, _anonymousCredential.AnonymousCredential)();
    const pipeline = new Pipeline([], pipelineOptions);
    pipeline._credential = credential;
    return pipeline;
}
function processDownlevelPipeline(pipeline) {
    const knownFactoryFunctions = [
        isAnonymousCredential,
        isStorageSharedKeyCredential,
        isCoreHttpBearerTokenFactory,
        isStorageBrowserPolicyFactory,
        isStorageRetryPolicyFactory,
        isStorageTelemetryPolicyFactory,
        isCoreHttpPolicyFactory
    ];
    if (pipeline.factories.length) {
        const novelFactories = pipeline.factories.filter((factory)=>{
            return !knownFactoryFunctions.some((knownFactory)=>knownFactory(factory));
        });
        if (novelFactories.length) {
            const hasInjector = novelFactories.some((factory)=>isInjectorPolicyFactory(factory));
            // if there are any left over, wrap in a requestPolicyFactoryPolicy
            return {
                wrappedPolicies: (0, _coreHttpCompat.createRequestPolicyFactoryPolicy)(novelFactories),
                afterRetry: hasInjector
            };
        }
    }
    return undefined;
}
function getCoreClientOptions(pipeline) {
    var _a;
    const _b = pipeline.options, { httpClient: v1Client } = _b, restOptions = (0, _tslib.__rest)(_b, [
        "httpClient"
    ]);
    let httpClient = pipeline._coreHttpClient;
    if (!httpClient) {
        httpClient = v1Client ? (0, _coreHttpCompat.convertHttpClient)(v1Client) : (0, _cache.getCachedDefaultHttpClient)();
        pipeline._coreHttpClient = httpClient;
    }
    let corePipeline = pipeline._corePipeline;
    if (!corePipeline) {
        const packageDetails = `azsdk-js-azure-storage-blob/${(0, _constants.SDK_VERSION)}`;
        const userAgentPrefix = restOptions.userAgentOptions && restOptions.userAgentOptions.userAgentPrefix ? `${restOptions.userAgentOptions.userAgentPrefix} ${packageDetails}` : `${packageDetails}`;
        corePipeline = (0, _coreClient.createClientPipeline)(Object.assign(Object.assign({}, restOptions), {
            loggingOptions: {
                additionalAllowedHeaderNames: (0, _constants.StorageBlobLoggingAllowedHeaderNames),
                additionalAllowedQueryParameters: (0, _constants.StorageBlobLoggingAllowedQueryParameters),
                logger: (0, _log.logger).info
            },
            userAgentOptions: {
                userAgentPrefix
            },
            serializationOptions: {
                stringifyXML: (0, _coreXml.stringifyXML),
                serializerOptions: {
                    xml: {
                        // Use customized XML char key of "#" so we can deserialize metadata
                        // with "_" key
                        xmlCharKey: "#"
                    }
                }
            },
            deserializationOptions: {
                parseXML: (0, _coreXml.parseXML),
                serializerOptions: {
                    xml: {
                        // Use customized XML char key of "#" so we can deserialize metadata
                        // with "_" key
                        xmlCharKey: "#"
                    }
                }
            }
        }));
        corePipeline.removePolicy({
            phase: "Retry"
        });
        corePipeline.removePolicy({
            name: (0, _coreRestPipeline.decompressResponsePolicyName)
        });
        corePipeline.addPolicy((0, _storageRetryPolicyV2.storageRetryPolicy)(restOptions.retryOptions), {
            phase: "Retry"
        });
        corePipeline.addPolicy((0, _storageBrowserPolicyV2.storageBrowserPolicy)());
        const downlevelResults = processDownlevelPipeline(pipeline);
        if (downlevelResults) corePipeline.addPolicy(downlevelResults.wrappedPolicies, downlevelResults.afterRetry ? {
            afterPhase: "Retry"
        } : undefined);
        const credential = getCredentialFromPipeline(pipeline);
        if ((0, _coreAuth.isTokenCredential)(credential)) corePipeline.addPolicy((0, _coreRestPipeline.bearerTokenAuthenticationPolicy)({
            credential,
            scopes: (_a = restOptions.audience) !== null && _a !== void 0 ? _a : (0, _constants.StorageOAuthScopes),
            challengeCallbacks: {
                authorizeRequestOnChallenge: (0, _coreClient.authorizeRequestOnTenantChallenge)
            }
        }), {
            phase: "Sign"
        });
        else if (credential instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential)) corePipeline.addPolicy((0, _storageSharedKeyCredentialPolicyV2.storageSharedKeyCredentialPolicy)({
            accountName: credential.accountName,
            accountKey: credential.accountKey
        }), {
            phase: "Sign"
        });
        pipeline._corePipeline = corePipeline;
    }
    return Object.assign(Object.assign({}, restOptions), {
        allowInsecureConnection: true,
        httpClient,
        pipeline: corePipeline
    });
}
function getCredentialFromPipeline(pipeline) {
    // see if we squirreled one away on the type itself
    if (pipeline._credential) return pipeline._credential;
    // if it came from another package, loop over the factories and look for one like before
    let credential = new (0, _anonymousCredential.AnonymousCredential)();
    for (const factory of pipeline.factories){
        if ((0, _coreAuth.isTokenCredential)(factory.credential)) // Only works if the factory has been attached a "credential" property.
        // We do that in newPipeline() when using TokenCredential.
        credential = factory.credential;
        else if (isStorageSharedKeyCredential(factory)) return factory;
    }
    return credential;
}
function isStorageSharedKeyCredential(factory) {
    if (factory instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential)) return true;
    return factory.constructor.name === "StorageSharedKeyCredential";
}
function isAnonymousCredential(factory) {
    if (factory instanceof (0, _anonymousCredential.AnonymousCredential)) return true;
    return factory.constructor.name === "AnonymousCredential";
}
function isCoreHttpBearerTokenFactory(factory) {
    return (0, _coreAuth.isTokenCredential)(factory.credential);
}
function isStorageBrowserPolicyFactory(factory) {
    if (factory instanceof (0, _storageBrowserPolicyFactory.StorageBrowserPolicyFactory)) return true;
    return factory.constructor.name === "StorageBrowserPolicyFactory";
}
function isStorageRetryPolicyFactory(factory) {
    if (factory instanceof (0, _storageRetryPolicyFactory.StorageRetryPolicyFactory)) return true;
    return factory.constructor.name === "StorageRetryPolicyFactory";
}
function isStorageTelemetryPolicyFactory(factory) {
    return factory.constructor.name === "TelemetryPolicyFactory";
}
function isInjectorPolicyFactory(factory) {
    return factory.constructor.name === "InjectorPolicyFactory";
}
function isCoreHttpPolicyFactory(factory) {
    const knownPolicies = [
        "GenerateClientRequestIdPolicy",
        "TracingPolicy",
        "LogPolicy",
        "ProxyPolicy",
        "DisableResponseDecompressionPolicy",
        "KeepAlivePolicy",
        "DeserializationPolicy"
    ];
    const mockHttpClient = {
        sendRequest: async (request)=>{
            return {
                request,
                headers: request.headers.clone(),
                status: 500
            };
        }
    };
    const mockRequestPolicyOptions = {
        log (_logLevel, _message) {
        /* do nothing */ },
        shouldLog (_logLevel) {
            return false;
        }
    };
    const policyInstance = factory.create(mockHttpClient, mockRequestPolicyOptions);
    const policyName = policyInstance.constructor.name;
    // bundlers sometimes add a custom suffix to the class name to make it unique
    return knownPolicies.some((knownPolicyName)=>{
        return policyName.startsWith(knownPolicyName);
    });
}

},{"tslib":"lRdW5","@azure/core-http-compat":"1I5Za","@azure/core-rest-pipeline":"d0mqv","@azure/core-client":"eVlwR","@azure/core-xml":"XDN0l","@azure/core-auth":"2xRAB","./log":"gc1Rl","./StorageRetryPolicyFactory":"ealHa","./credentials/StorageSharedKeyCredential":"jUFIX","./credentials/AnonymousCredential":"f0sOe","./utils/constants":"4gX5x","./utils/cache":"5SpI4","./policies/StorageBrowserPolicyV2":"bZYoE","./policies/StorageRetryPolicyV2":"iANjf","./policies/StorageSharedKeyCredentialPolicyV2":"lPMqJ","./StorageBrowserPolicyFactory":"lNMbH","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1I5Za":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * A Shim Library that provides compatibility between Core V1 & V2 Packages.
 *
 * @packageDocumentation
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ExtendedServiceClient", ()=>(0, _extendedClientJs.ExtendedServiceClient));
parcelHelpers.export(exports, "requestPolicyFactoryPolicyName", ()=>(0, _requestPolicyFactoryPolicyJs.requestPolicyFactoryPolicyName));
parcelHelpers.export(exports, "createRequestPolicyFactoryPolicy", ()=>(0, _requestPolicyFactoryPolicyJs.createRequestPolicyFactoryPolicy));
parcelHelpers.export(exports, "HttpPipelineLogLevel", ()=>(0, _requestPolicyFactoryPolicyJs.HttpPipelineLogLevel));
parcelHelpers.export(exports, "disableKeepAlivePolicyName", ()=>(0, _disableKeepAlivePolicyJs.disableKeepAlivePolicyName));
parcelHelpers.export(exports, "convertHttpClient", ()=>(0, _httpClientAdapterJs.convertHttpClient));
parcelHelpers.export(exports, "toHttpHeadersLike", ()=>(0, _utilJs.toHttpHeadersLike));
var _extendedClientJs = require("./extendedClient.js");
var _requestPolicyFactoryPolicyJs = require("./policies/requestPolicyFactoryPolicy.js");
var _disableKeepAlivePolicyJs = require("./policies/disableKeepAlivePolicy.js");
var _httpClientAdapterJs = require("./httpClientAdapter.js");
var _utilJs = require("./util.js");

},{"./extendedClient.js":"1uOuD","./policies/requestPolicyFactoryPolicy.js":"gfvZ1","./policies/disableKeepAlivePolicy.js":"gHe0g","./httpClientAdapter.js":"eMGtA","./util.js":"dhnfg","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1uOuD":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Client to provide compatability between core V1 & V2.
 */ parcelHelpers.export(exports, "ExtendedServiceClient", ()=>ExtendedServiceClient);
var _disableKeepAlivePolicyJs = require("./policies/disableKeepAlivePolicy.js");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreClient = require("@azure/core-client");
var _responseJs = require("./response.js");
class ExtendedServiceClient extends (0, _coreClient.ServiceClient) {
    constructor(options){
        var _a, _b;
        super(options);
        if (((_a = options.keepAliveOptions) === null || _a === void 0 ? void 0 : _a.enable) === false && !(0, _disableKeepAlivePolicyJs.pipelineContainsDisableKeepAlivePolicy)(this.pipeline)) this.pipeline.addPolicy((0, _disableKeepAlivePolicyJs.createDisableKeepAlivePolicy)());
        if (((_b = options.redirectOptions) === null || _b === void 0 ? void 0 : _b.handleRedirects) === false) this.pipeline.removePolicy({
            name: (0, _coreRestPipeline.redirectPolicyName)
        });
    }
    /**
     * Compatible send operation request function.
     *
     * @param operationArguments - Operation arguments
     * @param operationSpec - Operation Spec
     * @returns
     */ async sendOperationRequest(operationArguments, operationSpec) {
        var _a;
        const userProvidedCallBack = (_a = operationArguments === null || operationArguments === void 0 ? void 0 : operationArguments.options) === null || _a === void 0 ? void 0 : _a.onResponse;
        let lastResponse;
        function onResponse(rawResponse, flatResponse, error) {
            lastResponse = rawResponse;
            if (userProvidedCallBack) userProvidedCallBack(rawResponse, flatResponse, error);
        }
        operationArguments.options = Object.assign(Object.assign({}, operationArguments.options), {
            onResponse
        });
        const result = await super.sendOperationRequest(operationArguments, operationSpec);
        if (lastResponse) Object.defineProperty(result, "_response", {
            value: (0, _responseJs.toCompatResponse)(lastResponse)
        });
        return result;
    }
}

},{"./policies/disableKeepAlivePolicy.js":"gHe0g","@azure/core-rest-pipeline":"d0mqv","@azure/core-client":"eVlwR","./response.js":"bLzlA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gHe0g":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "disableKeepAlivePolicyName", ()=>disableKeepAlivePolicyName);
parcelHelpers.export(exports, "createDisableKeepAlivePolicy", ()=>createDisableKeepAlivePolicy);
/**
 * @internal
 */ parcelHelpers.export(exports, "pipelineContainsDisableKeepAlivePolicy", ()=>pipelineContainsDisableKeepAlivePolicy);
const disableKeepAlivePolicyName = "DisableKeepAlivePolicy";
function createDisableKeepAlivePolicy() {
    return {
        name: disableKeepAlivePolicyName,
        async sendRequest (request, next) {
            request.disableKeepAlive = true;
            return next(request);
        }
    };
}
function pipelineContainsDisableKeepAlivePolicy(pipeline) {
    return pipeline.getOrderedPolicies().some((policy)=>policy.name === disableKeepAlivePolicyName);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eVlwR":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createSerializer", ()=>(0, _serializerJs.createSerializer));
parcelHelpers.export(exports, "MapperTypeNames", ()=>(0, _serializerJs.MapperTypeNames));
parcelHelpers.export(exports, "ServiceClient", ()=>(0, _serviceClientJs.ServiceClient));
parcelHelpers.export(exports, "createClientPipeline", ()=>(0, _pipelineJs.createClientPipeline));
parcelHelpers.export(exports, "XML_ATTRKEY", ()=>(0, _interfacesJs.XML_ATTRKEY));
parcelHelpers.export(exports, "XML_CHARKEY", ()=>(0, _interfacesJs.XML_CHARKEY));
parcelHelpers.export(exports, "deserializationPolicy", ()=>(0, _deserializationPolicyJs.deserializationPolicy));
parcelHelpers.export(exports, "deserializationPolicyName", ()=>(0, _deserializationPolicyJs.deserializationPolicyName));
parcelHelpers.export(exports, "serializationPolicy", ()=>(0, _serializationPolicyJs.serializationPolicy));
parcelHelpers.export(exports, "serializationPolicyName", ()=>(0, _serializationPolicyJs.serializationPolicyName));
parcelHelpers.export(exports, "authorizeRequestOnClaimChallenge", ()=>(0, _authorizeRequestOnClaimChallengeJs.authorizeRequestOnClaimChallenge));
parcelHelpers.export(exports, "authorizeRequestOnTenantChallenge", ()=>(0, _authorizeRequestOnTenantChallengeJs.authorizeRequestOnTenantChallenge));
var _serializerJs = require("./serializer.js");
var _serviceClientJs = require("./serviceClient.js");
var _pipelineJs = require("./pipeline.js");
var _interfacesJs = require("./interfaces.js");
var _deserializationPolicyJs = require("./deserializationPolicy.js");
var _serializationPolicyJs = require("./serializationPolicy.js");
var _authorizeRequestOnClaimChallengeJs = require("./authorizeRequestOnClaimChallenge.js");
var _authorizeRequestOnTenantChallengeJs = require("./authorizeRequestOnTenantChallenge.js");

},{"./serializer.js":"j3nd8","./serviceClient.js":"271Ds","./pipeline.js":"ahtqz","./interfaces.js":"giOr3","./deserializationPolicy.js":"aQyHG","./serializationPolicy.js":"6OuRb","./authorizeRequestOnClaimChallenge.js":"i72A0","./authorizeRequestOnTenantChallenge.js":"jfY37","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j3nd8":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Method that creates and returns a Serializer.
 * @param modelMappers - Known models to map
 * @param isXML - If XML should be supported
 */ parcelHelpers.export(exports, "createSerializer", ()=>createSerializer);
parcelHelpers.export(exports, "MapperTypeNames", ()=>MapperTypeNames);
var _base64Js = require("./base64.js");
var _interfacesJs = require("./interfaces.js");
var _utilsJs = require("./utils.js");
class SerializerImpl {
    constructor(modelMappers = {}, isXML = false){
        this.modelMappers = modelMappers;
        this.isXML = isXML;
    }
    /**
     * @deprecated Removing the constraints validation on client side.
     */ validateConstraints(mapper, value, objectName) {
        const failValidation = (constraintName, constraintValue)=>{
            throw new Error(`"${objectName}" with value "${value}" should satisfy the constraint "${constraintName}": ${constraintValue}.`);
        };
        if (mapper.constraints && value !== undefined && value !== null) {
            const { ExclusiveMaximum, ExclusiveMinimum, InclusiveMaximum, InclusiveMinimum, MaxItems, MaxLength, MinItems, MinLength, MultipleOf, Pattern, UniqueItems } = mapper.constraints;
            if (ExclusiveMaximum !== undefined && value >= ExclusiveMaximum) failValidation("ExclusiveMaximum", ExclusiveMaximum);
            if (ExclusiveMinimum !== undefined && value <= ExclusiveMinimum) failValidation("ExclusiveMinimum", ExclusiveMinimum);
            if (InclusiveMaximum !== undefined && value > InclusiveMaximum) failValidation("InclusiveMaximum", InclusiveMaximum);
            if (InclusiveMinimum !== undefined && value < InclusiveMinimum) failValidation("InclusiveMinimum", InclusiveMinimum);
            if (MaxItems !== undefined && value.length > MaxItems) failValidation("MaxItems", MaxItems);
            if (MaxLength !== undefined && value.length > MaxLength) failValidation("MaxLength", MaxLength);
            if (MinItems !== undefined && value.length < MinItems) failValidation("MinItems", MinItems);
            if (MinLength !== undefined && value.length < MinLength) failValidation("MinLength", MinLength);
            if (MultipleOf !== undefined && value % MultipleOf !== 0) failValidation("MultipleOf", MultipleOf);
            if (Pattern) {
                const pattern = typeof Pattern === "string" ? new RegExp(Pattern) : Pattern;
                if (typeof value !== "string" || value.match(pattern) === null) failValidation("Pattern", Pattern);
            }
            if (UniqueItems && value.some((item, i, ar)=>ar.indexOf(item) !== i)) failValidation("UniqueItems", UniqueItems);
        }
    }
    /**
     * Serialize the given object based on its metadata defined in the mapper
     *
     * @param mapper - The mapper which defines the metadata of the serializable object
     *
     * @param object - A valid Javascript object to be serialized
     *
     * @param objectName - Name of the serialized object
     *
     * @param options - additional options to serialization
     *
     * @returns A valid serialized Javascript object
     */ serialize(mapper, object, objectName, options = {
        xml: {}
    }) {
        var _a, _b, _c;
        const updatedOptions = {
            xml: {
                rootName: (_a = options.xml.rootName) !== null && _a !== void 0 ? _a : "",
                includeRoot: (_b = options.xml.includeRoot) !== null && _b !== void 0 ? _b : false,
                xmlCharKey: (_c = options.xml.xmlCharKey) !== null && _c !== void 0 ? _c : (0, _interfacesJs.XML_CHARKEY)
            }
        };
        let payload = {};
        const mapperType = mapper.type.name;
        if (!objectName) objectName = mapper.serializedName;
        if (mapperType.match(/^Sequence$/i) !== null) payload = [];
        if (mapper.isConstant) object = mapper.defaultValue;
        // This table of allowed values should help explain
        // the mapper.required and mapper.nullable properties.
        // X means "neither undefined or null are allowed".
        //           || required
        //           || true      | false
        //  nullable || ==========================
        //      true || null      | undefined/null
        //     false || X         | undefined
        // undefined || X         | undefined/null
        const { required, nullable } = mapper;
        if (required && nullable && object === undefined) throw new Error(`${objectName} cannot be undefined.`);
        if (required && !nullable && (object === undefined || object === null)) throw new Error(`${objectName} cannot be null or undefined.`);
        if (!required && nullable === false && object === null) throw new Error(`${objectName} cannot be null.`);
        if (object === undefined || object === null) payload = object;
        else {
            if (mapperType.match(/^any$/i) !== null) payload = object;
            else if (mapperType.match(/^(Number|String|Boolean|Object|Stream|Uuid)$/i) !== null) payload = serializeBasicTypes(mapperType, objectName, object);
            else if (mapperType.match(/^Enum$/i) !== null) {
                const enumMapper = mapper;
                payload = serializeEnumType(objectName, enumMapper.type.allowedValues, object);
            } else if (mapperType.match(/^(Date|DateTime|TimeSpan|DateTimeRfc1123|UnixTime)$/i) !== null) payload = serializeDateTypes(mapperType, object, objectName);
            else if (mapperType.match(/^ByteArray$/i) !== null) payload = serializeByteArrayType(objectName, object);
            else if (mapperType.match(/^Base64Url$/i) !== null) payload = serializeBase64UrlType(objectName, object);
            else if (mapperType.match(/^Sequence$/i) !== null) payload = serializeSequenceType(this, mapper, object, objectName, Boolean(this.isXML), updatedOptions);
            else if (mapperType.match(/^Dictionary$/i) !== null) payload = serializeDictionaryType(this, mapper, object, objectName, Boolean(this.isXML), updatedOptions);
            else if (mapperType.match(/^Composite$/i) !== null) payload = serializeCompositeType(this, mapper, object, objectName, Boolean(this.isXML), updatedOptions);
        }
        return payload;
    }
    /**
     * Deserialize the given object based on its metadata defined in the mapper
     *
     * @param mapper - The mapper which defines the metadata of the serializable object
     *
     * @param responseBody - A valid Javascript entity to be deserialized
     *
     * @param objectName - Name of the deserialized object
     *
     * @param options - Controls behavior of XML parser and builder.
     *
     * @returns A valid deserialized Javascript object
     */ deserialize(mapper, responseBody, objectName, options = {
        xml: {}
    }) {
        var _a, _b, _c, _d;
        const updatedOptions = {
            xml: {
                rootName: (_a = options.xml.rootName) !== null && _a !== void 0 ? _a : "",
                includeRoot: (_b = options.xml.includeRoot) !== null && _b !== void 0 ? _b : false,
                xmlCharKey: (_c = options.xml.xmlCharKey) !== null && _c !== void 0 ? _c : (0, _interfacesJs.XML_CHARKEY)
            },
            ignoreUnknownProperties: (_d = options.ignoreUnknownProperties) !== null && _d !== void 0 ? _d : false
        };
        if (responseBody === undefined || responseBody === null) {
            if (this.isXML && mapper.type.name === "Sequence" && !mapper.xmlIsWrapped) // Edge case for empty XML non-wrapped lists. xml2js can't distinguish
            // between the list being empty versus being missing,
            // so let's do the more user-friendly thing and return an empty list.
            responseBody = [];
            // specifically check for undefined as default value can be a falsey value `0, "", false, null`
            if (mapper.defaultValue !== undefined) responseBody = mapper.defaultValue;
            return responseBody;
        }
        let payload;
        const mapperType = mapper.type.name;
        if (!objectName) objectName = mapper.serializedName;
        if (mapperType.match(/^Composite$/i) !== null) payload = deserializeCompositeType(this, mapper, responseBody, objectName, updatedOptions);
        else {
            if (this.isXML) {
                const xmlCharKey = updatedOptions.xml.xmlCharKey;
                /**
                 * If the mapper specifies this as a non-composite type value but the responseBody contains
                 * both header ("$" i.e., XML_ATTRKEY) and body ("#" i.e., XML_CHARKEY) properties,
                 * then just reduce the responseBody value to the body ("#" i.e., XML_CHARKEY) property.
                 */ if (responseBody[0, _interfacesJs.XML_ATTRKEY] !== undefined && responseBody[xmlCharKey] !== undefined) responseBody = responseBody[xmlCharKey];
            }
            if (mapperType.match(/^Number$/i) !== null) {
                payload = parseFloat(responseBody);
                if (isNaN(payload)) payload = responseBody;
            } else if (mapperType.match(/^Boolean$/i) !== null) {
                if (responseBody === "true") payload = true;
                else if (responseBody === "false") payload = false;
                else payload = responseBody;
            } else if (mapperType.match(/^(String|Enum|Object|Stream|Uuid|TimeSpan|any)$/i) !== null) payload = responseBody;
            else if (mapperType.match(/^(Date|DateTime|DateTimeRfc1123)$/i) !== null) payload = new Date(responseBody);
            else if (mapperType.match(/^UnixTime$/i) !== null) payload = unixTimeToDate(responseBody);
            else if (mapperType.match(/^ByteArray$/i) !== null) payload = _base64Js.decodeString(responseBody);
            else if (mapperType.match(/^Base64Url$/i) !== null) payload = base64UrlToByteArray(responseBody);
            else if (mapperType.match(/^Sequence$/i) !== null) payload = deserializeSequenceType(this, mapper, responseBody, objectName, updatedOptions);
            else if (mapperType.match(/^Dictionary$/i) !== null) payload = deserializeDictionaryType(this, mapper, responseBody, objectName, updatedOptions);
        }
        if (mapper.isConstant) payload = mapper.defaultValue;
        return payload;
    }
}
function createSerializer(modelMappers = {}, isXML = false) {
    return new SerializerImpl(modelMappers, isXML);
}
function trimEnd(str, ch) {
    let len = str.length;
    while(len - 1 >= 0 && str[len - 1] === ch)--len;
    return str.substr(0, len);
}
function bufferToBase64Url(buffer) {
    if (!buffer) return undefined;
    if (!(buffer instanceof Uint8Array)) throw new Error(`Please provide an input of type Uint8Array for converting to Base64Url.`);
    // Uint8Array to Base64.
    const str = _base64Js.encodeByteArray(buffer);
    // Base64 to Base64Url.
    return trimEnd(str, "=").replace(/\+/g, "-").replace(/\//g, "_");
}
function base64UrlToByteArray(str) {
    if (!str) return undefined;
    if (str && typeof str.valueOf() !== "string") throw new Error("Please provide an input of type string for converting to Uint8Array");
    // Base64Url to Base64.
    str = str.replace(/-/g, "+").replace(/_/g, "/");
    // Base64 to Uint8Array.
    return _base64Js.decodeString(str);
}
function splitSerializeName(prop) {
    const classes = [];
    let partialclass = "";
    if (prop) {
        const subwords = prop.split(".");
        for (const item of subwords)if (item.charAt(item.length - 1) === "\\") partialclass += item.substr(0, item.length - 1) + ".";
        else {
            partialclass += item;
            classes.push(partialclass);
            partialclass = "";
        }
    }
    return classes;
}
function dateToUnixTime(d) {
    if (!d) return undefined;
    if (typeof d.valueOf() === "string") d = new Date(d);
    return Math.floor(d.getTime() / 1000);
}
function unixTimeToDate(n) {
    if (!n) return undefined;
    return new Date(n * 1000);
}
function serializeBasicTypes(typeName, objectName, value) {
    if (value !== null && value !== undefined) {
        if (typeName.match(/^Number$/i) !== null) {
            if (typeof value !== "number") throw new Error(`${objectName} with value ${value} must be of type number.`);
        } else if (typeName.match(/^String$/i) !== null) {
            if (typeof value.valueOf() !== "string") throw new Error(`${objectName} with value "${value}" must be of type string.`);
        } else if (typeName.match(/^Uuid$/i) !== null) {
            if (!(typeof value.valueOf() === "string" && (0, _utilsJs.isValidUuid)(value))) throw new Error(`${objectName} with value "${value}" must be of type string and a valid uuid.`);
        } else if (typeName.match(/^Boolean$/i) !== null) {
            if (typeof value !== "boolean") throw new Error(`${objectName} with value ${value} must be of type boolean.`);
        } else if (typeName.match(/^Stream$/i) !== null) {
            const objectType = typeof value;
            if (objectType !== "string" && typeof value.pipe !== "function" && // NodeJS.ReadableStream
            typeof value.tee !== "function" && // browser ReadableStream
            !(value instanceof ArrayBuffer) && !ArrayBuffer.isView(value) && // File objects count as a type of Blob, so we want to use instanceof explicitly
            !((typeof Blob === "function" || typeof Blob === "object") && value instanceof Blob) && objectType !== "function") throw new Error(`${objectName} must be a string, Blob, ArrayBuffer, ArrayBufferView, ReadableStream, or () => ReadableStream.`);
        }
    }
    return value;
}
function serializeEnumType(objectName, allowedValues, value) {
    if (!allowedValues) throw new Error(`Please provide a set of allowedValues to validate ${objectName} as an Enum Type.`);
    const isPresent = allowedValues.some((item)=>{
        if (typeof item.valueOf() === "string") return item.toLowerCase() === value.toLowerCase();
        return item === value;
    });
    if (!isPresent) throw new Error(`${value} is not a valid value for ${objectName}. The valid values are: ${JSON.stringify(allowedValues)}.`);
    return value;
}
function serializeByteArrayType(objectName, value) {
    if (value !== undefined && value !== null) {
        if (!(value instanceof Uint8Array)) throw new Error(`${objectName} must be of type Uint8Array.`);
        value = _base64Js.encodeByteArray(value);
    }
    return value;
}
function serializeBase64UrlType(objectName, value) {
    if (value !== undefined && value !== null) {
        if (!(value instanceof Uint8Array)) throw new Error(`${objectName} must be of type Uint8Array.`);
        value = bufferToBase64Url(value);
    }
    return value;
}
function serializeDateTypes(typeName, value, objectName) {
    if (value !== undefined && value !== null) {
        if (typeName.match(/^Date$/i) !== null) {
            if (!(value instanceof Date || typeof value.valueOf() === "string" && !isNaN(Date.parse(value)))) throw new Error(`${objectName} must be an instanceof Date or a string in ISO8601 format.`);
            value = value instanceof Date ? value.toISOString().substring(0, 10) : new Date(value).toISOString().substring(0, 10);
        } else if (typeName.match(/^DateTime$/i) !== null) {
            if (!(value instanceof Date || typeof value.valueOf() === "string" && !isNaN(Date.parse(value)))) throw new Error(`${objectName} must be an instanceof Date or a string in ISO8601 format.`);
            value = value instanceof Date ? value.toISOString() : new Date(value).toISOString();
        } else if (typeName.match(/^DateTimeRfc1123$/i) !== null) {
            if (!(value instanceof Date || typeof value.valueOf() === "string" && !isNaN(Date.parse(value)))) throw new Error(`${objectName} must be an instanceof Date or a string in RFC-1123 format.`);
            value = value instanceof Date ? value.toUTCString() : new Date(value).toUTCString();
        } else if (typeName.match(/^UnixTime$/i) !== null) {
            if (!(value instanceof Date || typeof value.valueOf() === "string" && !isNaN(Date.parse(value)))) throw new Error(`${objectName} must be an instanceof Date or a string in RFC-1123/ISO8601 format ` + `for it to be serialized in UnixTime/Epoch format.`);
            value = dateToUnixTime(value);
        } else if (typeName.match(/^TimeSpan$/i) !== null) {
            if (!(0, _utilsJs.isDuration)(value)) throw new Error(`${objectName} must be a string in ISO 8601 format. Instead was "${value}".`);
        }
    }
    return value;
}
function serializeSequenceType(serializer, mapper, object, objectName, isXml, options) {
    var _a;
    if (!Array.isArray(object)) throw new Error(`${objectName} must be of type Array.`);
    let elementType = mapper.type.element;
    if (!elementType || typeof elementType !== "object") throw new Error(`element" metadata for an Array must be defined in the ` + `mapper and it must of type "object" in ${objectName}.`);
    // Quirk: Composite mappers referenced by `element` might
    // not have *all* properties declared (like uberParent),
    // so let's try to look up the full definition by name.
    if (elementType.type.name === "Composite" && elementType.type.className) elementType = (_a = serializer.modelMappers[elementType.type.className]) !== null && _a !== void 0 ? _a : elementType;
    const tempArray = [];
    for(let i = 0; i < object.length; i++){
        const serializedValue = serializer.serialize(elementType, object[i], objectName, options);
        if (isXml && elementType.xmlNamespace) {
            const xmlnsKey = elementType.xmlNamespacePrefix ? `xmlns:${elementType.xmlNamespacePrefix}` : "xmlns";
            if (elementType.type.name === "Composite") {
                tempArray[i] = Object.assign({}, serializedValue);
                tempArray[i][0, _interfacesJs.XML_ATTRKEY] = {
                    [xmlnsKey]: elementType.xmlNamespace
                };
            } else {
                tempArray[i] = {};
                tempArray[i][options.xml.xmlCharKey] = serializedValue;
                tempArray[i][0, _interfacesJs.XML_ATTRKEY] = {
                    [xmlnsKey]: elementType.xmlNamespace
                };
            }
        } else tempArray[i] = serializedValue;
    }
    return tempArray;
}
function serializeDictionaryType(serializer, mapper, object, objectName, isXml, options) {
    if (typeof object !== "object") throw new Error(`${objectName} must be of type object.`);
    const valueType = mapper.type.value;
    if (!valueType || typeof valueType !== "object") throw new Error(`"value" metadata for a Dictionary must be defined in the ` + `mapper and it must of type "object" in ${objectName}.`);
    const tempDictionary = {};
    for (const key of Object.keys(object)){
        const serializedValue = serializer.serialize(valueType, object[key], objectName, options);
        // If the element needs an XML namespace we need to add it within the $ property
        tempDictionary[key] = getXmlObjectValue(valueType, serializedValue, isXml, options);
    }
    // Add the namespace to the root element if needed
    if (isXml && mapper.xmlNamespace) {
        const xmlnsKey = mapper.xmlNamespacePrefix ? `xmlns:${mapper.xmlNamespacePrefix}` : "xmlns";
        const result = tempDictionary;
        result[0, _interfacesJs.XML_ATTRKEY] = {
            [xmlnsKey]: mapper.xmlNamespace
        };
        return result;
    }
    return tempDictionary;
}
/**
 * Resolves the additionalProperties property from a referenced mapper
 * @param serializer - the serializer containing the entire set of mappers
 * @param mapper - the composite mapper to resolve
 * @param objectName - name of the object being serialized
 */ function resolveAdditionalProperties(serializer, mapper, objectName) {
    const additionalProperties = mapper.type.additionalProperties;
    if (!additionalProperties && mapper.type.className) {
        const modelMapper = resolveReferencedMapper(serializer, mapper, objectName);
        return modelMapper === null || modelMapper === void 0 ? void 0 : modelMapper.type.additionalProperties;
    }
    return additionalProperties;
}
/**
 * Finds the mapper referenced by className
 * @param serializer - the serializer containing the entire set of mappers
 * @param mapper - the composite mapper to resolve
 * @param objectName - name of the object being serialized
 */ function resolveReferencedMapper(serializer, mapper, objectName) {
    const className = mapper.type.className;
    if (!className) throw new Error(`Class name for model "${objectName}" is not provided in the mapper "${JSON.stringify(mapper, undefined, 2)}".`);
    return serializer.modelMappers[className];
}
/**
 * Resolves a composite mapper's modelProperties.
 * @param serializer - the serializer containing the entire set of mappers
 * @param mapper - the composite mapper to resolve
 */ function resolveModelProperties(serializer, mapper, objectName) {
    let modelProps = mapper.type.modelProperties;
    if (!modelProps) {
        const modelMapper = resolveReferencedMapper(serializer, mapper, objectName);
        if (!modelMapper) throw new Error(`mapper() cannot be null or undefined for model "${mapper.type.className}".`);
        modelProps = modelMapper === null || modelMapper === void 0 ? void 0 : modelMapper.type.modelProperties;
        if (!modelProps) throw new Error(`modelProperties cannot be null or undefined in the ` + `mapper "${JSON.stringify(modelMapper)}" of type "${mapper.type.className}" for object "${objectName}".`);
    }
    return modelProps;
}
function serializeCompositeType(serializer, mapper, object, objectName, isXml, options) {
    if (getPolymorphicDiscriminatorRecursively(serializer, mapper)) mapper = getPolymorphicMapper(serializer, mapper, object, "clientName");
    if (object !== undefined && object !== null) {
        const payload = {};
        const modelProps = resolveModelProperties(serializer, mapper, objectName);
        for (const key of Object.keys(modelProps)){
            const propertyMapper = modelProps[key];
            if (propertyMapper.readOnly) continue;
            let propName;
            let parentObject = payload;
            if (serializer.isXML) {
                if (propertyMapper.xmlIsWrapped) propName = propertyMapper.xmlName;
                else propName = propertyMapper.xmlElementName || propertyMapper.xmlName;
            } else {
                const paths = splitSerializeName(propertyMapper.serializedName);
                propName = paths.pop();
                for (const pathName of paths){
                    const childObject = parentObject[pathName];
                    if ((childObject === undefined || childObject === null) && (object[key] !== undefined && object[key] !== null || propertyMapper.defaultValue !== undefined)) parentObject[pathName] = {};
                    parentObject = parentObject[pathName];
                }
            }
            if (parentObject !== undefined && parentObject !== null) {
                if (isXml && mapper.xmlNamespace) {
                    const xmlnsKey = mapper.xmlNamespacePrefix ? `xmlns:${mapper.xmlNamespacePrefix}` : "xmlns";
                    parentObject[0, _interfacesJs.XML_ATTRKEY] = Object.assign(Object.assign({}, parentObject[0, _interfacesJs.XML_ATTRKEY]), {
                        [xmlnsKey]: mapper.xmlNamespace
                    });
                }
                const propertyObjectName = propertyMapper.serializedName !== "" ? objectName + "." + propertyMapper.serializedName : objectName;
                let toSerialize = object[key];
                const polymorphicDiscriminator = getPolymorphicDiscriminatorRecursively(serializer, mapper);
                if (polymorphicDiscriminator && polymorphicDiscriminator.clientName === key && (toSerialize === undefined || toSerialize === null)) toSerialize = mapper.serializedName;
                const serializedValue = serializer.serialize(propertyMapper, toSerialize, propertyObjectName, options);
                if (serializedValue !== undefined && propName !== undefined && propName !== null) {
                    const value = getXmlObjectValue(propertyMapper, serializedValue, isXml, options);
                    if (isXml && propertyMapper.xmlIsAttribute) {
                        // XML_ATTRKEY, i.e., $ is the key attributes are kept under in xml2js.
                        // This keeps things simple while preventing name collision
                        // with names in user documents.
                        parentObject[0, _interfacesJs.XML_ATTRKEY] = parentObject[0, _interfacesJs.XML_ATTRKEY] || {};
                        parentObject[0, _interfacesJs.XML_ATTRKEY][propName] = serializedValue;
                    } else if (isXml && propertyMapper.xmlIsWrapped) parentObject[propName] = {
                        [propertyMapper.xmlElementName]: value
                    };
                    else parentObject[propName] = value;
                }
            }
        }
        const additionalPropertiesMapper = resolveAdditionalProperties(serializer, mapper, objectName);
        if (additionalPropertiesMapper) {
            const propNames = Object.keys(modelProps);
            for(const clientPropName in object){
                const isAdditionalProperty = propNames.every((pn)=>pn !== clientPropName);
                if (isAdditionalProperty) payload[clientPropName] = serializer.serialize(additionalPropertiesMapper, object[clientPropName], objectName + '["' + clientPropName + '"]', options);
            }
        }
        return payload;
    }
    return object;
}
function getXmlObjectValue(propertyMapper, serializedValue, isXml, options) {
    if (!isXml || !propertyMapper.xmlNamespace) return serializedValue;
    const xmlnsKey = propertyMapper.xmlNamespacePrefix ? `xmlns:${propertyMapper.xmlNamespacePrefix}` : "xmlns";
    const xmlNamespace = {
        [xmlnsKey]: propertyMapper.xmlNamespace
    };
    if ([
        "Composite"
    ].includes(propertyMapper.type.name)) {
        if (serializedValue[0, _interfacesJs.XML_ATTRKEY]) return serializedValue;
        else {
            const result = Object.assign({}, serializedValue);
            result[0, _interfacesJs.XML_ATTRKEY] = xmlNamespace;
            return result;
        }
    }
    const result = {};
    result[options.xml.xmlCharKey] = serializedValue;
    result[0, _interfacesJs.XML_ATTRKEY] = xmlNamespace;
    return result;
}
function isSpecialXmlProperty(propertyName, options) {
    return [
        (0, _interfacesJs.XML_ATTRKEY),
        options.xml.xmlCharKey
    ].includes(propertyName);
}
function deserializeCompositeType(serializer, mapper, responseBody, objectName, options) {
    var _a, _b;
    const xmlCharKey = (_a = options.xml.xmlCharKey) !== null && _a !== void 0 ? _a : (0, _interfacesJs.XML_CHARKEY);
    if (getPolymorphicDiscriminatorRecursively(serializer, mapper)) mapper = getPolymorphicMapper(serializer, mapper, responseBody, "serializedName");
    const modelProps = resolveModelProperties(serializer, mapper, objectName);
    let instance = {};
    const handledPropertyNames = [];
    for (const key of Object.keys(modelProps)){
        const propertyMapper = modelProps[key];
        const paths = splitSerializeName(modelProps[key].serializedName);
        handledPropertyNames.push(paths[0]);
        const { serializedName, xmlName, xmlElementName } = propertyMapper;
        let propertyObjectName = objectName;
        if (serializedName !== "" && serializedName !== undefined) propertyObjectName = objectName + "." + serializedName;
        const headerCollectionPrefix = propertyMapper.headerCollectionPrefix;
        if (headerCollectionPrefix) {
            const dictionary = {};
            for (const headerKey of Object.keys(responseBody)){
                if (headerKey.startsWith(headerCollectionPrefix)) dictionary[headerKey.substring(headerCollectionPrefix.length)] = serializer.deserialize(propertyMapper.type.value, responseBody[headerKey], propertyObjectName, options);
                handledPropertyNames.push(headerKey);
            }
            instance[key] = dictionary;
        } else if (serializer.isXML) {
            if (propertyMapper.xmlIsAttribute && responseBody[0, _interfacesJs.XML_ATTRKEY]) instance[key] = serializer.deserialize(propertyMapper, responseBody[0, _interfacesJs.XML_ATTRKEY][xmlName], propertyObjectName, options);
            else if (propertyMapper.xmlIsMsText) {
                if (responseBody[xmlCharKey] !== undefined) instance[key] = responseBody[xmlCharKey];
                else if (typeof responseBody === "string") // The special case where xml parser parses "<Name>content</Name>" into JSON of
                //   `{ name: "content"}` instead of `{ name: { "_": "content" }}`
                instance[key] = responseBody;
            } else {
                const propertyName = xmlElementName || xmlName || serializedName;
                if (propertyMapper.xmlIsWrapped) {
                    /* a list of <xmlElementName> wrapped by <xmlName>
                      For the xml example below
                        <Cors>
                          <CorsRule>...</CorsRule>
                          <CorsRule>...</CorsRule>
                        </Cors>
                      the responseBody has
                        {
                          Cors: {
                            CorsRule: [{...}, {...}]
                          }
                        }
                      xmlName is "Cors" and xmlElementName is"CorsRule".
                    */ const wrapped = responseBody[xmlName];
                    const elementList = (_b = wrapped === null || wrapped === void 0 ? void 0 : wrapped[xmlElementName]) !== null && _b !== void 0 ? _b : [];
                    instance[key] = serializer.deserialize(propertyMapper, elementList, propertyObjectName, options);
                    handledPropertyNames.push(xmlName);
                } else {
                    const property = responseBody[propertyName];
                    instance[key] = serializer.deserialize(propertyMapper, property, propertyObjectName, options);
                    handledPropertyNames.push(propertyName);
                }
            }
        } else {
            // deserialize the property if it is present in the provided responseBody instance
            let propertyInstance;
            let res = responseBody;
            // traversing the object step by step.
            let steps = 0;
            for (const item of paths){
                if (!res) break;
                steps++;
                res = res[item];
            }
            // only accept null when reaching the last position of object otherwise it would be undefined
            if (res === null && steps < paths.length) res = undefined;
            propertyInstance = res;
            const polymorphicDiscriminator = mapper.type.polymorphicDiscriminator;
            // checking that the model property name (key)(ex: "fishtype") and the
            // clientName of the polymorphicDiscriminator {metadata} (ex: "fishtype")
            // instead of the serializedName of the polymorphicDiscriminator (ex: "fish.type")
            // is a better approach. The generator is not consistent with escaping '\.' in the
            // serializedName of the property (ex: "fish\.type") that is marked as polymorphic discriminator
            // and the serializedName of the metadata polymorphicDiscriminator (ex: "fish.type"). However,
            // the clientName transformation of the polymorphicDiscriminator (ex: "fishtype") and
            // the transformation of model property name (ex: "fishtype") is done consistently.
            // Hence, it is a safer bet to rely on the clientName of the polymorphicDiscriminator.
            if (polymorphicDiscriminator && key === polymorphicDiscriminator.clientName && (propertyInstance === undefined || propertyInstance === null)) propertyInstance = mapper.serializedName;
            let serializedValue;
            // paging
            if (Array.isArray(responseBody[key]) && modelProps[key].serializedName === "") {
                propertyInstance = responseBody[key];
                const arrayInstance = serializer.deserialize(propertyMapper, propertyInstance, propertyObjectName, options);
                // Copy over any properties that have already been added into the instance, where they do
                // not exist on the newly de-serialized array
                for (const [k, v] of Object.entries(instance))if (!Object.prototype.hasOwnProperty.call(arrayInstance, k)) arrayInstance[k] = v;
                instance = arrayInstance;
            } else if (propertyInstance !== undefined || propertyMapper.defaultValue !== undefined) {
                serializedValue = serializer.deserialize(propertyMapper, propertyInstance, propertyObjectName, options);
                instance[key] = serializedValue;
            }
        }
    }
    const additionalPropertiesMapper = mapper.type.additionalProperties;
    if (additionalPropertiesMapper) {
        const isAdditionalProperty = (responsePropName)=>{
            for(const clientPropName in modelProps){
                const paths = splitSerializeName(modelProps[clientPropName].serializedName);
                if (paths[0] === responsePropName) return false;
            }
            return true;
        };
        for(const responsePropName in responseBody)if (isAdditionalProperty(responsePropName)) instance[responsePropName] = serializer.deserialize(additionalPropertiesMapper, responseBody[responsePropName], objectName + '["' + responsePropName + '"]', options);
    } else if (responseBody && !options.ignoreUnknownProperties) {
        for (const key of Object.keys(responseBody))if (instance[key] === undefined && !handledPropertyNames.includes(key) && !isSpecialXmlProperty(key, options)) instance[key] = responseBody[key];
    }
    return instance;
}
function deserializeDictionaryType(serializer, mapper, responseBody, objectName, options) {
    /* jshint validthis: true */ const value = mapper.type.value;
    if (!value || typeof value !== "object") throw new Error(`"value" metadata for a Dictionary must be defined in the ` + `mapper and it must of type "object" in ${objectName}`);
    if (responseBody) {
        const tempDictionary = {};
        for (const key of Object.keys(responseBody))tempDictionary[key] = serializer.deserialize(value, responseBody[key], objectName, options);
        return tempDictionary;
    }
    return responseBody;
}
function deserializeSequenceType(serializer, mapper, responseBody, objectName, options) {
    var _a;
    let element = mapper.type.element;
    if (!element || typeof element !== "object") throw new Error(`element" metadata for an Array must be defined in the ` + `mapper and it must of type "object" in ${objectName}`);
    if (responseBody) {
        if (!Array.isArray(responseBody)) // xml2js will interpret a single element array as just the element, so force it to be an array
        responseBody = [
            responseBody
        ];
        // Quirk: Composite mappers referenced by `element` might
        // not have *all* properties declared (like uberParent),
        // so let's try to look up the full definition by name.
        if (element.type.name === "Composite" && element.type.className) element = (_a = serializer.modelMappers[element.type.className]) !== null && _a !== void 0 ? _a : element;
        const tempArray = [];
        for(let i = 0; i < responseBody.length; i++)tempArray[i] = serializer.deserialize(element, responseBody[i], `${objectName}[${i}]`, options);
        return tempArray;
    }
    return responseBody;
}
function getIndexDiscriminator(discriminators, discriminatorValue, typeName) {
    const typeNamesToCheck = [
        typeName
    ];
    while(typeNamesToCheck.length){
        const currentName = typeNamesToCheck.shift();
        const indexDiscriminator = discriminatorValue === currentName ? discriminatorValue : currentName + "." + discriminatorValue;
        if (Object.prototype.hasOwnProperty.call(discriminators, indexDiscriminator)) return discriminators[indexDiscriminator];
        else {
            for (const [name, mapper] of Object.entries(discriminators))if (name.startsWith(currentName + ".") && mapper.type.uberParent === currentName && mapper.type.className) typeNamesToCheck.push(mapper.type.className);
        }
    }
    return undefined;
}
function getPolymorphicMapper(serializer, mapper, object, polymorphicPropertyName) {
    var _a;
    const polymorphicDiscriminator = getPolymorphicDiscriminatorRecursively(serializer, mapper);
    if (polymorphicDiscriminator) {
        let discriminatorName = polymorphicDiscriminator[polymorphicPropertyName];
        if (discriminatorName) {
            // The serializedName might have \\, which we just want to ignore
            if (polymorphicPropertyName === "serializedName") discriminatorName = discriminatorName.replace(/\\/gi, "");
            const discriminatorValue = object[discriminatorName];
            const typeName = (_a = mapper.type.uberParent) !== null && _a !== void 0 ? _a : mapper.type.className;
            if (typeof discriminatorValue === "string" && typeName) {
                const polymorphicMapper = getIndexDiscriminator(serializer.modelMappers.discriminators, discriminatorValue, typeName);
                if (polymorphicMapper) mapper = polymorphicMapper;
            }
        }
    }
    return mapper;
}
function getPolymorphicDiscriminatorRecursively(serializer, mapper) {
    return mapper.type.polymorphicDiscriminator || getPolymorphicDiscriminatorSafely(serializer, mapper.type.uberParent) || getPolymorphicDiscriminatorSafely(serializer, mapper.type.className);
}
function getPolymorphicDiscriminatorSafely(serializer, typeName) {
    return typeName && serializer.modelMappers[typeName] && serializer.modelMappers[typeName].type.polymorphicDiscriminator;
}
const MapperTypeNames = {
    Base64Url: "Base64Url",
    Boolean: "Boolean",
    ByteArray: "ByteArray",
    Composite: "Composite",
    Date: "Date",
    DateTime: "DateTime",
    DateTimeRfc1123: "DateTimeRfc1123",
    Dictionary: "Dictionary",
    Enum: "Enum",
    Number: "Number",
    Object: "Object",
    Sequence: "Sequence",
    String: "String",
    Stream: "Stream",
    TimeSpan: "TimeSpan",
    UnixTime: "UnixTime"
};

},{"./base64.js":"kcjsq","./interfaces.js":"giOr3","./utils.js":"geJiM","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kcjsq":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Encodes a string in base64 format.
 * @param value - the string to encode
 * @internal
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "encodeString", ()=>encodeString);
/**
 * Encodes a byte array in base64 format.
 * @param value - the Uint8Aray to encode
 * @internal
 */ parcelHelpers.export(exports, "encodeByteArray", ()=>encodeByteArray);
/**
 * Decodes a base64 string into a byte array.
 * @param value - the base64 string to decode
 * @internal
 */ parcelHelpers.export(exports, "decodeString", ()=>decodeString);
/**
 * Decodes a base64 string into a string.
 * @param value - the base64 string to decode
 * @internal
 */ parcelHelpers.export(exports, "decodeStringToString", ()=>decodeStringToString);
function encodeString(value) {
    return btoa(value);
}
function encodeByteArray(value) {
    let str = "";
    for(let i = 0; i < value.length; i++)str += String.fromCharCode(value[i]);
    return btoa(str);
}
function decodeString(value) {
    const byteString = atob(value);
    const arr = new Uint8Array(byteString.length);
    for(let i = 0; i < byteString.length; i++)arr[i] = byteString.charCodeAt(i);
    return arr;
}
function decodeStringToString(value) {
    return atob(value);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"giOr3":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Default key used to access the XML attributes.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "XML_ATTRKEY", ()=>XML_ATTRKEY);
parcelHelpers.export(exports, "XML_CHARKEY", ()=>XML_CHARKEY);
const XML_ATTRKEY = "$";
const XML_CHARKEY = "_";

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"geJiM":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * A type guard for a primitive response body.
 * @param value - Value to test
 *
 * @internal
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isPrimitiveBody", ()=>isPrimitiveBody);
/**
 * Returns true if the given string is in ISO 8601 format.
 * @param value - The value to be validated for ISO 8601 duration format.
 * @internal
 */ parcelHelpers.export(exports, "isDuration", ()=>isDuration);
/**
 * Returns true if the provided uuid is valid.
 *
 * @param uuid - The uuid that needs to be validated.
 *
 * @internal
 */ parcelHelpers.export(exports, "isValidUuid", ()=>isValidUuid);
/**
 * Take a `FullOperationResponse` and turn it into a flat
 * response object to hand back to the consumer.
 * @param fullResponse - The processed response from the operation request
 * @param responseSpec - The response map from the OperationSpec
 *
 * @internal
 */ parcelHelpers.export(exports, "flattenResponse", ()=>flattenResponse);
function isPrimitiveBody(value, mapperTypeName) {
    return mapperTypeName !== "Composite" && mapperTypeName !== "Dictionary" && (typeof value === "string" || typeof value === "number" || typeof value === "boolean" || (mapperTypeName === null || mapperTypeName === void 0 ? void 0 : mapperTypeName.match(/^(Date|DateTime|DateTimeRfc1123|UnixTime|ByteArray|Base64Url)$/i)) !== null || value === undefined || value === null);
}
const validateISODuration = /^(-|\+)?P(?:([-+]?[0-9,.]*)Y)?(?:([-+]?[0-9,.]*)M)?(?:([-+]?[0-9,.]*)W)?(?:([-+]?[0-9,.]*)D)?(?:T(?:([-+]?[0-9,.]*)H)?(?:([-+]?[0-9,.]*)M)?(?:([-+]?[0-9,.]*)S)?)?$/;
function isDuration(value) {
    return validateISODuration.test(value);
}
const validUuidRegex = /^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$/i;
function isValidUuid(uuid) {
    return validUuidRegex.test(uuid);
}
/**
 * Maps the response as follows:
 * - wraps the response body if needed (typically if its type is primitive).
 * - returns null if the combination of the headers and the body is empty.
 * - otherwise, returns the combination of the headers and the body.
 *
 * @param responseObject - a representation of the parsed response
 * @returns the response that will be returned to the user which can be null and/or wrapped
 *
 * @internal
 */ function handleNullableResponseAndWrappableBody(responseObject) {
    const combinedHeadersAndBody = Object.assign(Object.assign({}, responseObject.headers), responseObject.body);
    if (responseObject.hasNullableType && Object.getOwnPropertyNames(combinedHeadersAndBody).length === 0) return responseObject.shouldWrapBody ? {
        body: null
    } : null;
    else return responseObject.shouldWrapBody ? Object.assign(Object.assign({}, responseObject.headers), {
        body: responseObject.body
    }) : combinedHeadersAndBody;
}
function flattenResponse(fullResponse, responseSpec) {
    var _a, _b;
    const parsedHeaders = fullResponse.parsedHeaders;
    // head methods never have a body, but we return a boolean set to body property
    // to indicate presence/absence of the resource
    if (fullResponse.request.method === "HEAD") return Object.assign(Object.assign({}, parsedHeaders), {
        body: fullResponse.parsedBody
    });
    const bodyMapper = responseSpec && responseSpec.bodyMapper;
    const isNullable = Boolean(bodyMapper === null || bodyMapper === void 0 ? void 0 : bodyMapper.nullable);
    const expectedBodyTypeName = bodyMapper === null || bodyMapper === void 0 ? void 0 : bodyMapper.type.name;
    /** If the body is asked for, we look at the expected body type to handle it */ if (expectedBodyTypeName === "Stream") return Object.assign(Object.assign({}, parsedHeaders), {
        blobBody: fullResponse.blobBody,
        readableStreamBody: fullResponse.readableStreamBody
    });
    const modelProperties = expectedBodyTypeName === "Composite" && bodyMapper.type.modelProperties || {};
    const isPageableResponse = Object.keys(modelProperties).some((k)=>modelProperties[k].serializedName === "");
    if (expectedBodyTypeName === "Sequence" || isPageableResponse) {
        const arrayResponse = (_a = fullResponse.parsedBody) !== null && _a !== void 0 ? _a : [];
        for (const key of Object.keys(modelProperties))if (modelProperties[key].serializedName) arrayResponse[key] = (_b = fullResponse.parsedBody) === null || _b === void 0 ? void 0 : _b[key];
        if (parsedHeaders) for (const key of Object.keys(parsedHeaders))arrayResponse[key] = parsedHeaders[key];
        return isNullable && !fullResponse.parsedBody && !parsedHeaders && Object.getOwnPropertyNames(modelProperties).length === 0 ? null : arrayResponse;
    }
    return handleNullableResponseAndWrappableBody({
        body: fullResponse.parsedBody,
        headers: parsedHeaders,
        hasNullableType: isNullable,
        shouldWrapBody: isPrimitiveBody(fullResponse.parsedBody, expectedBodyTypeName)
    });
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"271Ds":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Initializes a new instance of the ServiceClient.
 */ parcelHelpers.export(exports, "ServiceClient", ()=>ServiceClient);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _pipelineJs = require("./pipeline.js");
var _utilsJs = require("./utils.js");
var _httpClientCacheJs = require("./httpClientCache.js");
var _operationHelpersJs = require("./operationHelpers.js");
var _urlHelpersJs = require("./urlHelpers.js");
var _interfaceHelpersJs = require("./interfaceHelpers.js");
var _logJs = require("./log.js");
class ServiceClient {
    /**
     * The ServiceClient constructor
     * @param credential - The credentials used for authentication with the service.
     * @param options - The service client options that govern the behavior of the client.
     */ constructor(options = {}){
        var _a, _b;
        this._requestContentType = options.requestContentType;
        this._endpoint = (_a = options.endpoint) !== null && _a !== void 0 ? _a : options.baseUri;
        if (options.baseUri) (0, _logJs.logger).warning("The baseUri option for SDK Clients has been deprecated, please use endpoint instead.");
        this._allowInsecureConnection = options.allowInsecureConnection;
        this._httpClient = options.httpClient || (0, _httpClientCacheJs.getCachedDefaultHttpClient)();
        this.pipeline = options.pipeline || createDefaultPipeline(options);
        if ((_b = options.additionalPolicies) === null || _b === void 0 ? void 0 : _b.length) for (const { policy, position } of options.additionalPolicies){
            // Sign happens after Retry and is commonly needed to occur
            // before policies that intercept post-retry.
            const afterPhase = position === "perRetry" ? "Sign" : undefined;
            this.pipeline.addPolicy(policy, {
                afterPhase
            });
        }
    }
    /**
     * Send the provided httpRequest.
     */ async sendRequest(request) {
        return this.pipeline.sendRequest(this._httpClient, request);
    }
    /**
     * Send an HTTP request that is populated using the provided OperationSpec.
     * @typeParam T - The typed result of the request, based on the OperationSpec.
     * @param operationArguments - The arguments that the HTTP request's templated values will be populated from.
     * @param operationSpec - The OperationSpec to use to populate the httpRequest.
     */ async sendOperationRequest(operationArguments, operationSpec) {
        const endpoint = operationSpec.baseUrl || this._endpoint;
        if (!endpoint) throw new Error("If operationSpec.baseUrl is not specified, then the ServiceClient must have a endpoint string property that contains the base URL to use.");
        // Templatized URLs sometimes reference properties on the ServiceClient child class,
        // so we have to pass `this` below in order to search these properties if they're
        // not part of OperationArguments
        const url = (0, _urlHelpersJs.getRequestUrl)(endpoint, operationSpec, operationArguments, this);
        const request = (0, _coreRestPipeline.createPipelineRequest)({
            url
        });
        request.method = operationSpec.httpMethod;
        const operationInfo = (0, _operationHelpersJs.getOperationRequestInfo)(request);
        operationInfo.operationSpec = operationSpec;
        operationInfo.operationArguments = operationArguments;
        const contentType = operationSpec.contentType || this._requestContentType;
        if (contentType && operationSpec.requestBody) request.headers.set("Content-Type", contentType);
        const options = operationArguments.options;
        if (options) {
            const requestOptions = options.requestOptions;
            if (requestOptions) {
                if (requestOptions.timeout) request.timeout = requestOptions.timeout;
                if (requestOptions.onUploadProgress) request.onUploadProgress = requestOptions.onUploadProgress;
                if (requestOptions.onDownloadProgress) request.onDownloadProgress = requestOptions.onDownloadProgress;
                if (requestOptions.shouldDeserialize !== undefined) operationInfo.shouldDeserialize = requestOptions.shouldDeserialize;
                if (requestOptions.allowInsecureConnection) request.allowInsecureConnection = true;
            }
            if (options.abortSignal) request.abortSignal = options.abortSignal;
            if (options.tracingOptions) request.tracingOptions = options.tracingOptions;
        }
        if (this._allowInsecureConnection) request.allowInsecureConnection = true;
        if (request.streamResponseStatusCodes === undefined) request.streamResponseStatusCodes = (0, _interfaceHelpersJs.getStreamingResponseStatusCodes)(operationSpec);
        try {
            const rawResponse = await this.sendRequest(request);
            const flatResponse = (0, _utilsJs.flattenResponse)(rawResponse, operationSpec.responses[rawResponse.status]);
            if (options === null || options === void 0 ? void 0 : options.onResponse) options.onResponse(rawResponse, flatResponse);
            return flatResponse;
        } catch (error) {
            if (typeof error === "object" && (error === null || error === void 0 ? void 0 : error.response)) {
                const rawResponse = error.response;
                const flatResponse = (0, _utilsJs.flattenResponse)(rawResponse, operationSpec.responses[error.statusCode] || operationSpec.responses["default"]);
                error.details = flatResponse;
                if (options === null || options === void 0 ? void 0 : options.onResponse) options.onResponse(rawResponse, flatResponse, error);
            }
            throw error;
        }
    }
}
function createDefaultPipeline(options) {
    const credentialScopes = getCredentialScopes(options);
    const credentialOptions = options.credential && credentialScopes ? {
        credentialScopes,
        credential: options.credential
    } : undefined;
    return (0, _pipelineJs.createClientPipeline)(Object.assign(Object.assign({}, options), {
        credentialOptions
    }));
}
function getCredentialScopes(options) {
    if (options.credentialScopes) return options.credentialScopes;
    if (options.endpoint) return `${options.endpoint}/.default`;
    if (options.baseUri) return `${options.baseUri}/.default`;
    if (options.credential && !options.credentialScopes) throw new Error(`When using credentials, the ServiceClientOptions must contain either a endpoint or a credentialScopes. Unable to create a bearerTokenAuthenticationPolicy`);
    return undefined;
}

},{"@azure/core-rest-pipeline":"d0mqv","./pipeline.js":"ahtqz","./utils.js":"geJiM","./httpClientCache.js":"c4KzD","./operationHelpers.js":"5lrBI","./urlHelpers.js":"chOgR","./interfaceHelpers.js":"d2zaE","./log.js":"82Mlw","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ahtqz":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates a new Pipeline for use with a Service Client.
 * Adds in deserializationPolicy by default.
 * Also adds in bearerTokenAuthenticationPolicy if passed a TokenCredential.
 * @param options - Options to customize the created pipeline.
 */ parcelHelpers.export(exports, "createClientPipeline", ()=>createClientPipeline);
var _deserializationPolicyJs = require("./deserializationPolicy.js");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _serializationPolicyJs = require("./serializationPolicy.js");
function createClientPipeline(options = {}) {
    const pipeline = (0, _coreRestPipeline.createPipelineFromOptions)(options !== null && options !== void 0 ? options : {});
    if (options.credentialOptions) pipeline.addPolicy((0, _coreRestPipeline.bearerTokenAuthenticationPolicy)({
        credential: options.credentialOptions.credential,
        scopes: options.credentialOptions.credentialScopes
    }));
    pipeline.addPolicy((0, _serializationPolicyJs.serializationPolicy)(options.serializationOptions), {
        phase: "Serialize"
    });
    pipeline.addPolicy((0, _deserializationPolicyJs.deserializationPolicy)(options.deserializationOptions), {
        phase: "Deserialize"
    });
    return pipeline;
}

},{"./deserializationPolicy.js":"aQyHG","@azure/core-rest-pipeline":"d0mqv","./serializationPolicy.js":"6OuRb","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aQyHG":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deserializationPolicyName", ()=>deserializationPolicyName);
/**
 * This policy handles parsing out responses according to OperationSpecs on the request.
 */ parcelHelpers.export(exports, "deserializationPolicy", ()=>deserializationPolicy);
var _interfacesJs = require("./interfaces.js");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _serializerJs = require("./serializer.js");
var _operationHelpersJs = require("./operationHelpers.js");
const defaultJsonContentTypes = [
    "application/json",
    "text/json"
];
const defaultXmlContentTypes = [
    "application/xml",
    "application/atom+xml"
];
const deserializationPolicyName = "deserializationPolicy";
function deserializationPolicy(options = {}) {
    var _a, _b, _c, _d, _e, _f, _g;
    const jsonContentTypes = (_b = (_a = options.expectedContentTypes) === null || _a === void 0 ? void 0 : _a.json) !== null && _b !== void 0 ? _b : defaultJsonContentTypes;
    const xmlContentTypes = (_d = (_c = options.expectedContentTypes) === null || _c === void 0 ? void 0 : _c.xml) !== null && _d !== void 0 ? _d : defaultXmlContentTypes;
    const parseXML = options.parseXML;
    const serializerOptions = options.serializerOptions;
    const updatedOptions = {
        xml: {
            rootName: (_e = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.rootName) !== null && _e !== void 0 ? _e : "",
            includeRoot: (_f = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.includeRoot) !== null && _f !== void 0 ? _f : false,
            xmlCharKey: (_g = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.xmlCharKey) !== null && _g !== void 0 ? _g : (0, _interfacesJs.XML_CHARKEY)
        }
    };
    return {
        name: deserializationPolicyName,
        async sendRequest (request, next) {
            const response = await next(request);
            return deserializeResponseBody(jsonContentTypes, xmlContentTypes, response, updatedOptions, parseXML);
        }
    };
}
function getOperationResponseMap(parsedResponse) {
    let result;
    const request = parsedResponse.request;
    const operationInfo = (0, _operationHelpersJs.getOperationRequestInfo)(request);
    const operationSpec = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationSpec;
    if (operationSpec) {
        if (!(operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationResponseGetter)) result = operationSpec.responses[parsedResponse.status];
        else result = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationResponseGetter(operationSpec, parsedResponse);
    }
    return result;
}
function shouldDeserializeResponse(parsedResponse) {
    const request = parsedResponse.request;
    const operationInfo = (0, _operationHelpersJs.getOperationRequestInfo)(request);
    const shouldDeserialize = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.shouldDeserialize;
    let result;
    if (shouldDeserialize === undefined) result = true;
    else if (typeof shouldDeserialize === "boolean") result = shouldDeserialize;
    else result = shouldDeserialize(parsedResponse);
    return result;
}
async function deserializeResponseBody(jsonContentTypes, xmlContentTypes, response, options, parseXML) {
    const parsedResponse = await parse(jsonContentTypes, xmlContentTypes, response, options, parseXML);
    if (!shouldDeserializeResponse(parsedResponse)) return parsedResponse;
    const operationInfo = (0, _operationHelpersJs.getOperationRequestInfo)(parsedResponse.request);
    const operationSpec = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationSpec;
    if (!operationSpec || !operationSpec.responses) return parsedResponse;
    const responseSpec = getOperationResponseMap(parsedResponse);
    const { error, shouldReturnResponse } = handleErrorResponse(parsedResponse, operationSpec, responseSpec, options);
    if (error) throw error;
    else if (shouldReturnResponse) return parsedResponse;
    // An operation response spec does exist for current status code, so
    // use it to deserialize the response.
    if (responseSpec) {
        if (responseSpec.bodyMapper) {
            let valueToDeserialize = parsedResponse.parsedBody;
            if (operationSpec.isXML && responseSpec.bodyMapper.type.name === (0, _serializerJs.MapperTypeNames).Sequence) valueToDeserialize = typeof valueToDeserialize === "object" ? valueToDeserialize[responseSpec.bodyMapper.xmlElementName] : [];
            try {
                parsedResponse.parsedBody = operationSpec.serializer.deserialize(responseSpec.bodyMapper, valueToDeserialize, "operationRes.parsedBody", options);
            } catch (deserializeError) {
                const restError = new (0, _coreRestPipeline.RestError)(`Error ${deserializeError} occurred in deserializing the responseBody - ${parsedResponse.bodyAsText}`, {
                    statusCode: parsedResponse.status,
                    request: parsedResponse.request,
                    response: parsedResponse
                });
                throw restError;
            }
        } else if (operationSpec.httpMethod === "HEAD") // head methods never have a body, but we return a boolean to indicate presence/absence of the resource
        parsedResponse.parsedBody = response.status >= 200 && response.status < 300;
        if (responseSpec.headersMapper) parsedResponse.parsedHeaders = operationSpec.serializer.deserialize(responseSpec.headersMapper, parsedResponse.headers.toJSON(), "operationRes.parsedHeaders", {
            xml: {},
            ignoreUnknownProperties: true
        });
    }
    return parsedResponse;
}
function isOperationSpecEmpty(operationSpec) {
    const expectedStatusCodes = Object.keys(operationSpec.responses);
    return expectedStatusCodes.length === 0 || expectedStatusCodes.length === 1 && expectedStatusCodes[0] === "default";
}
function handleErrorResponse(parsedResponse, operationSpec, responseSpec, options) {
    var _a;
    const isSuccessByStatus = 200 <= parsedResponse.status && parsedResponse.status < 300;
    const isExpectedStatusCode = isOperationSpecEmpty(operationSpec) ? isSuccessByStatus : !!responseSpec;
    if (isExpectedStatusCode) {
        if (responseSpec) {
            if (!responseSpec.isError) return {
                error: null,
                shouldReturnResponse: false
            };
        } else return {
            error: null,
            shouldReturnResponse: false
        };
    }
    const errorResponseSpec = responseSpec !== null && responseSpec !== void 0 ? responseSpec : operationSpec.responses.default;
    const initialErrorMessage = ((_a = parsedResponse.request.streamResponseStatusCodes) === null || _a === void 0 ? void 0 : _a.has(parsedResponse.status)) ? `Unexpected status code: ${parsedResponse.status}` : parsedResponse.bodyAsText;
    const error = new (0, _coreRestPipeline.RestError)(initialErrorMessage, {
        statusCode: parsedResponse.status,
        request: parsedResponse.request,
        response: parsedResponse
    });
    // If the item failed but there's no error spec or default spec to deserialize the error,
    // we should fail so we just throw the parsed response
    if (!errorResponseSpec) throw error;
    const defaultBodyMapper = errorResponseSpec.bodyMapper;
    const defaultHeadersMapper = errorResponseSpec.headersMapper;
    try {
        // If error response has a body, try to deserialize it using default body mapper.
        // Then try to extract error code & message from it
        if (parsedResponse.parsedBody) {
            const parsedBody = parsedResponse.parsedBody;
            let deserializedError;
            if (defaultBodyMapper) {
                let valueToDeserialize = parsedBody;
                if (operationSpec.isXML && defaultBodyMapper.type.name === (0, _serializerJs.MapperTypeNames).Sequence) {
                    valueToDeserialize = [];
                    const elementName = defaultBodyMapper.xmlElementName;
                    if (typeof parsedBody === "object" && elementName) valueToDeserialize = parsedBody[elementName];
                }
                deserializedError = operationSpec.serializer.deserialize(defaultBodyMapper, valueToDeserialize, "error.response.parsedBody", options);
            }
            const internalError = parsedBody.error || deserializedError || parsedBody;
            error.code = internalError.code;
            if (internalError.message) error.message = internalError.message;
            if (defaultBodyMapper) error.response.parsedBody = deserializedError;
        }
        // If error response has headers, try to deserialize it using default header mapper
        if (parsedResponse.headers && defaultHeadersMapper) error.response.parsedHeaders = operationSpec.serializer.deserialize(defaultHeadersMapper, parsedResponse.headers.toJSON(), "operationRes.parsedHeaders");
    } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody - "${parsedResponse.bodyAsText}" for the default response.`;
    }
    return {
        error,
        shouldReturnResponse: false
    };
}
async function parse(jsonContentTypes, xmlContentTypes, operationResponse, opts, parseXML) {
    var _a;
    if (!((_a = operationResponse.request.streamResponseStatusCodes) === null || _a === void 0 ? void 0 : _a.has(operationResponse.status)) && operationResponse.bodyAsText) {
        const text = operationResponse.bodyAsText;
        const contentType = operationResponse.headers.get("Content-Type") || "";
        const contentComponents = !contentType ? [] : contentType.split(";").map((component)=>component.toLowerCase());
        try {
            if (contentComponents.length === 0 || contentComponents.some((component)=>jsonContentTypes.indexOf(component) !== -1)) {
                operationResponse.parsedBody = JSON.parse(text);
                return operationResponse;
            } else if (contentComponents.some((component)=>xmlContentTypes.indexOf(component) !== -1)) {
                if (!parseXML) throw new Error("Parsing XML not supported.");
                const body = await parseXML(text, opts.xml);
                operationResponse.parsedBody = body;
                return operationResponse;
            }
        } catch (err) {
            const msg = `Error "${err}" occurred while parsing the response body - ${operationResponse.bodyAsText}.`;
            const errCode = err.code || (0, _coreRestPipeline.RestError).PARSE_ERROR;
            const e = new (0, _coreRestPipeline.RestError)(msg, {
                code: errCode,
                statusCode: operationResponse.status,
                request: operationResponse.request,
                response: operationResponse
            });
            throw e;
        }
    }
    return operationResponse;
}

},{"./interfaces.js":"giOr3","@azure/core-rest-pipeline":"d0mqv","./serializer.js":"j3nd8","./operationHelpers.js":"5lrBI","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5lrBI":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @internal
 * Retrieves the value to use for a given operation argument
 * @param operationArguments - The arguments passed from the generated client
 * @param parameter - The parameter description
 * @param fallbackObject - If something isn't found in the arguments bag, look here.
 *  Generally used to look at the service client properties.
 */ parcelHelpers.export(exports, "getOperationArgumentValueFromParameter", ()=>getOperationArgumentValueFromParameter);
parcelHelpers.export(exports, "getOperationRequestInfo", ()=>getOperationRequestInfo);
var _stateJs = require("./state.js");
function getOperationArgumentValueFromParameter(operationArguments, parameter, fallbackObject) {
    let parameterPath = parameter.parameterPath;
    const parameterMapper = parameter.mapper;
    let value;
    if (typeof parameterPath === "string") parameterPath = [
        parameterPath
    ];
    if (Array.isArray(parameterPath)) {
        if (parameterPath.length > 0) {
            if (parameterMapper.isConstant) value = parameterMapper.defaultValue;
            else {
                let propertySearchResult = getPropertyFromParameterPath(operationArguments, parameterPath);
                if (!propertySearchResult.propertyFound && fallbackObject) propertySearchResult = getPropertyFromParameterPath(fallbackObject, parameterPath);
                let useDefaultValue = false;
                if (!propertySearchResult.propertyFound) useDefaultValue = parameterMapper.required || parameterPath[0] === "options" && parameterPath.length === 2;
                value = useDefaultValue ? parameterMapper.defaultValue : propertySearchResult.propertyValue;
            }
        }
    } else {
        if (parameterMapper.required) value = {};
        for(const propertyName in parameterPath){
            const propertyMapper = parameterMapper.type.modelProperties[propertyName];
            const propertyPath = parameterPath[propertyName];
            const propertyValue = getOperationArgumentValueFromParameter(operationArguments, {
                parameterPath: propertyPath,
                mapper: propertyMapper
            }, fallbackObject);
            if (propertyValue !== undefined) {
                if (!value) value = {};
                value[propertyName] = propertyValue;
            }
        }
    }
    return value;
}
function getPropertyFromParameterPath(parent, parameterPath) {
    const result = {
        propertyFound: false
    };
    let i = 0;
    for(; i < parameterPath.length; ++i){
        const parameterPathPart = parameterPath[i];
        // Make sure to check inherited properties too, so don't use hasOwnProperty().
        if (parent && parameterPathPart in parent) parent = parent[parameterPathPart];
        else break;
    }
    if (i === parameterPath.length) {
        result.propertyValue = parent;
        result.propertyFound = true;
    }
    return result;
}
const originalRequestSymbol = Symbol.for("@azure/core-client original request");
function hasOriginalRequest(request) {
    return originalRequestSymbol in request;
}
function getOperationRequestInfo(request) {
    if (hasOriginalRequest(request)) return getOperationRequestInfo(request[originalRequestSymbol]);
    let info = (0, _stateJs.state).operationRequestMap.get(request);
    if (!info) {
        info = {};
        (0, _stateJs.state).operationRequestMap.set(request, info);
    }
    return info;
}

},{"./state.js":"jEMv9","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jEMv9":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Browser-only implementation of the module's state. The browser esm variant will not load the commonjs state, so we do not need to share state between the two.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "state", ()=>state);
const state = {
    operationRequestMap: new WeakMap()
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6OuRb":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "serializationPolicyName", ()=>serializationPolicyName);
/**
 * This policy handles assembling the request body and headers using
 * an OperationSpec and OperationArguments on the request.
 */ parcelHelpers.export(exports, "serializationPolicy", ()=>serializationPolicy);
/**
 * @internal
 */ parcelHelpers.export(exports, "serializeHeaders", ()=>serializeHeaders);
/**
 * @internal
 */ parcelHelpers.export(exports, "serializeRequestBody", ()=>serializeRequestBody);
var _interfacesJs = require("./interfaces.js");
var _operationHelpersJs = require("./operationHelpers.js");
var _serializerJs = require("./serializer.js");
var _interfaceHelpersJs = require("./interfaceHelpers.js");
const serializationPolicyName = "serializationPolicy";
function serializationPolicy(options = {}) {
    const stringifyXML = options.stringifyXML;
    return {
        name: serializationPolicyName,
        async sendRequest (request, next) {
            const operationInfo = (0, _operationHelpersJs.getOperationRequestInfo)(request);
            const operationSpec = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationSpec;
            const operationArguments = operationInfo === null || operationInfo === void 0 ? void 0 : operationInfo.operationArguments;
            if (operationSpec && operationArguments) {
                serializeHeaders(request, operationArguments, operationSpec);
                serializeRequestBody(request, operationArguments, operationSpec, stringifyXML);
            }
            return next(request);
        }
    };
}
function serializeHeaders(request, operationArguments, operationSpec) {
    var _a, _b;
    if (operationSpec.headerParameters) for (const headerParameter of operationSpec.headerParameters){
        let headerValue = (0, _operationHelpersJs.getOperationArgumentValueFromParameter)(operationArguments, headerParameter);
        if (headerValue !== null && headerValue !== undefined || headerParameter.mapper.required) {
            headerValue = operationSpec.serializer.serialize(headerParameter.mapper, headerValue, (0, _interfaceHelpersJs.getPathStringFromParameter)(headerParameter));
            const headerCollectionPrefix = headerParameter.mapper.headerCollectionPrefix;
            if (headerCollectionPrefix) for (const key of Object.keys(headerValue))request.headers.set(headerCollectionPrefix + key, headerValue[key]);
            else request.headers.set(headerParameter.mapper.serializedName || (0, _interfaceHelpersJs.getPathStringFromParameter)(headerParameter), headerValue);
        }
    }
    const customHeaders = (_b = (_a = operationArguments.options) === null || _a === void 0 ? void 0 : _a.requestOptions) === null || _b === void 0 ? void 0 : _b.customHeaders;
    if (customHeaders) for (const customHeaderName of Object.keys(customHeaders))request.headers.set(customHeaderName, customHeaders[customHeaderName]);
}
function serializeRequestBody(request, operationArguments, operationSpec, stringifyXML = function() {
    throw new Error("XML serialization unsupported!");
}) {
    var _a, _b, _c, _d, _e;
    const serializerOptions = (_a = operationArguments.options) === null || _a === void 0 ? void 0 : _a.serializerOptions;
    const updatedOptions = {
        xml: {
            rootName: (_b = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.rootName) !== null && _b !== void 0 ? _b : "",
            includeRoot: (_c = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.includeRoot) !== null && _c !== void 0 ? _c : false,
            xmlCharKey: (_d = serializerOptions === null || serializerOptions === void 0 ? void 0 : serializerOptions.xml.xmlCharKey) !== null && _d !== void 0 ? _d : (0, _interfacesJs.XML_CHARKEY)
        }
    };
    const xmlCharKey = updatedOptions.xml.xmlCharKey;
    if (operationSpec.requestBody && operationSpec.requestBody.mapper) {
        request.body = (0, _operationHelpersJs.getOperationArgumentValueFromParameter)(operationArguments, operationSpec.requestBody);
        const bodyMapper = operationSpec.requestBody.mapper;
        const { required, serializedName, xmlName, xmlElementName, xmlNamespace, xmlNamespacePrefix, nullable } = bodyMapper;
        const typeName = bodyMapper.type.name;
        try {
            if (request.body !== undefined && request.body !== null || nullable && request.body === null || required) {
                const requestBodyParameterPathString = (0, _interfaceHelpersJs.getPathStringFromParameter)(operationSpec.requestBody);
                request.body = operationSpec.serializer.serialize(bodyMapper, request.body, requestBodyParameterPathString, updatedOptions);
                const isStream = typeName === (0, _serializerJs.MapperTypeNames).Stream;
                if (operationSpec.isXML) {
                    const xmlnsKey = xmlNamespacePrefix ? `xmlns:${xmlNamespacePrefix}` : "xmlns";
                    const value = getXmlValueWithNamespace(xmlNamespace, xmlnsKey, typeName, request.body, updatedOptions);
                    if (typeName === (0, _serializerJs.MapperTypeNames).Sequence) request.body = stringifyXML(prepareXMLRootList(value, xmlElementName || xmlName || serializedName, xmlnsKey, xmlNamespace), {
                        rootName: xmlName || serializedName,
                        xmlCharKey
                    });
                    else if (!isStream) request.body = stringifyXML(value, {
                        rootName: xmlName || serializedName,
                        xmlCharKey
                    });
                } else if (typeName === (0, _serializerJs.MapperTypeNames).String && (((_e = operationSpec.contentType) === null || _e === void 0 ? void 0 : _e.match("text/plain")) || operationSpec.mediaType === "text")) // the String serializer has validated that request body is a string
                // so just send the string.
                return;
                else if (!isStream) request.body = JSON.stringify(request.body);
            }
        } catch (error) {
            throw new Error(`Error "${error.message}" occurred in serializing the payload - ${JSON.stringify(serializedName, undefined, "  ")}.`);
        }
    } else if (operationSpec.formDataParameters && operationSpec.formDataParameters.length > 0) {
        request.formData = {};
        for (const formDataParameter of operationSpec.formDataParameters){
            const formDataParameterValue = (0, _operationHelpersJs.getOperationArgumentValueFromParameter)(operationArguments, formDataParameter);
            if (formDataParameterValue !== undefined && formDataParameterValue !== null) {
                const formDataParameterPropertyName = formDataParameter.mapper.serializedName || (0, _interfaceHelpersJs.getPathStringFromParameter)(formDataParameter);
                request.formData[formDataParameterPropertyName] = operationSpec.serializer.serialize(formDataParameter.mapper, formDataParameterValue, (0, _interfaceHelpersJs.getPathStringFromParameter)(formDataParameter), updatedOptions);
            }
        }
    }
}
/**
 * Adds an xml namespace to the xml serialized object if needed, otherwise it just returns the value itself
 */ function getXmlValueWithNamespace(xmlNamespace, xmlnsKey, typeName, serializedValue, options) {
    // Composite and Sequence schemas already got their root namespace set during serialization
    // We just need to add xmlns to the other schema types
    if (xmlNamespace && ![
        "Composite",
        "Sequence",
        "Dictionary"
    ].includes(typeName)) {
        const result = {};
        result[options.xml.xmlCharKey] = serializedValue;
        result[0, _interfacesJs.XML_ATTRKEY] = {
            [xmlnsKey]: xmlNamespace
        };
        return result;
    }
    return serializedValue;
}
function prepareXMLRootList(obj, elementName, xmlNamespaceKey, xmlNamespace) {
    if (!Array.isArray(obj)) obj = [
        obj
    ];
    if (!xmlNamespaceKey || !xmlNamespace) return {
        [elementName]: obj
    };
    const result = {
        [elementName]: obj
    };
    result[0, _interfacesJs.XML_ATTRKEY] = {
        [xmlNamespaceKey]: xmlNamespace
    };
    return result;
}

},{"./interfaces.js":"giOr3","./operationHelpers.js":"5lrBI","./serializer.js":"j3nd8","./interfaceHelpers.js":"d2zaE","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d2zaE":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Gets the list of status codes for streaming responses.
 * @internal
 */ parcelHelpers.export(exports, "getStreamingResponseStatusCodes", ()=>getStreamingResponseStatusCodes);
/**
 * Get the path to this parameter's value as a dotted string (a.b.c).
 * @param parameter - The parameter to get the path string for.
 * @returns The path to this parameter's value as a dotted string.
 * @internal
 */ parcelHelpers.export(exports, "getPathStringFromParameter", ()=>getPathStringFromParameter);
var _serializerJs = require("./serializer.js");
function getStreamingResponseStatusCodes(operationSpec) {
    const result = new Set();
    for(const statusCode in operationSpec.responses){
        const operationResponse = operationSpec.responses[statusCode];
        if (operationResponse.bodyMapper && operationResponse.bodyMapper.type.name === (0, _serializerJs.MapperTypeNames).Stream) result.add(Number(statusCode));
    }
    return result;
}
function getPathStringFromParameter(parameter) {
    const { parameterPath, mapper } = parameter;
    let result;
    if (typeof parameterPath === "string") result = parameterPath;
    else if (Array.isArray(parameterPath)) result = parameterPath.join(".");
    else result = mapper.serializedName;
    return result;
}

},{"./serializer.js":"j3nd8","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c4KzD":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getCachedDefaultHttpClient", ()=>getCachedDefaultHttpClient);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
let cachedHttpClient;
function getCachedDefaultHttpClient() {
    if (!cachedHttpClient) cachedHttpClient = (0, _coreRestPipeline.createDefaultHttpClient)();
    return cachedHttpClient;
}

},{"@azure/core-rest-pipeline":"d0mqv","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"chOgR":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getRequestUrl", ()=>getRequestUrl);
/** @internal */ parcelHelpers.export(exports, "appendQueryParams", ()=>appendQueryParams);
var _operationHelpersJs = require("./operationHelpers.js");
var _interfaceHelpersJs = require("./interfaceHelpers.js");
const CollectionFormatToDelimiterMap = {
    CSV: ",",
    SSV: " ",
    Multi: "Multi",
    TSV: "	",
    Pipes: "|"
};
function getRequestUrl(baseUri, operationSpec, operationArguments, fallbackObject) {
    const urlReplacements = calculateUrlReplacements(operationSpec, operationArguments, fallbackObject);
    let isAbsolutePath = false;
    let requestUrl = replaceAll(baseUri, urlReplacements);
    if (operationSpec.path) {
        let path = replaceAll(operationSpec.path, urlReplacements);
        // QUIRK: sometimes we get a path component like /{nextLink}
        // which may be a fully formed URL with a leading /. In that case, we should
        // remove the leading /
        if (operationSpec.path === "/{nextLink}" && path.startsWith("/")) path = path.substring(1);
        // QUIRK: sometimes we get a path component like {nextLink}
        // which may be a fully formed URL. In that case, we should
        // ignore the baseUri.
        if (isAbsoluteUrl(path)) {
            requestUrl = path;
            isAbsolutePath = true;
        } else requestUrl = appendPath(requestUrl, path);
    }
    const { queryParams, sequenceParams } = calculateQueryParameters(operationSpec, operationArguments, fallbackObject);
    /**
     * Notice that this call sets the `noOverwrite` parameter to true if the `requestUrl`
     * is an absolute path. This ensures that existing query parameter values in `requestUrl`
     * do not get overwritten. On the other hand when `requestUrl` is not absolute path, it
     * is still being built so there is nothing to overwrite.
     */ requestUrl = appendQueryParams(requestUrl, queryParams, sequenceParams, isAbsolutePath);
    return requestUrl;
}
function replaceAll(input, replacements) {
    let result = input;
    for (const [searchValue, replaceValue] of replacements)result = result.split(searchValue).join(replaceValue);
    return result;
}
function calculateUrlReplacements(operationSpec, operationArguments, fallbackObject) {
    var _a;
    const result = new Map();
    if ((_a = operationSpec.urlParameters) === null || _a === void 0 ? void 0 : _a.length) for (const urlParameter of operationSpec.urlParameters){
        let urlParameterValue = (0, _operationHelpersJs.getOperationArgumentValueFromParameter)(operationArguments, urlParameter, fallbackObject);
        const parameterPathString = (0, _interfaceHelpersJs.getPathStringFromParameter)(urlParameter);
        urlParameterValue = operationSpec.serializer.serialize(urlParameter.mapper, urlParameterValue, parameterPathString);
        if (!urlParameter.skipEncoding) urlParameterValue = encodeURIComponent(urlParameterValue);
        result.set(`{${urlParameter.mapper.serializedName || parameterPathString}}`, urlParameterValue);
    }
    return result;
}
function isAbsoluteUrl(url) {
    return url.includes("://");
}
function appendPath(url, pathToAppend) {
    if (!pathToAppend) return url;
    const parsedUrl = new URL(url);
    let newPath = parsedUrl.pathname;
    if (!newPath.endsWith("/")) newPath = `${newPath}/`;
    if (pathToAppend.startsWith("/")) pathToAppend = pathToAppend.substring(1);
    const searchStart = pathToAppend.indexOf("?");
    if (searchStart !== -1) {
        const path = pathToAppend.substring(0, searchStart);
        const search = pathToAppend.substring(searchStart + 1);
        newPath = newPath + path;
        if (search) parsedUrl.search = parsedUrl.search ? `${parsedUrl.search}&${search}` : search;
    } else newPath = newPath + pathToAppend;
    parsedUrl.pathname = newPath;
    return parsedUrl.toString();
}
function calculateQueryParameters(operationSpec, operationArguments, fallbackObject) {
    var _a;
    const result = new Map();
    const sequenceParams = new Set();
    if ((_a = operationSpec.queryParameters) === null || _a === void 0 ? void 0 : _a.length) for (const queryParameter of operationSpec.queryParameters){
        if (queryParameter.mapper.type.name === "Sequence" && queryParameter.mapper.serializedName) sequenceParams.add(queryParameter.mapper.serializedName);
        let queryParameterValue = (0, _operationHelpersJs.getOperationArgumentValueFromParameter)(operationArguments, queryParameter, fallbackObject);
        if (queryParameterValue !== undefined && queryParameterValue !== null || queryParameter.mapper.required) {
            queryParameterValue = operationSpec.serializer.serialize(queryParameter.mapper, queryParameterValue, (0, _interfaceHelpersJs.getPathStringFromParameter)(queryParameter));
            const delimiter = queryParameter.collectionFormat ? CollectionFormatToDelimiterMap[queryParameter.collectionFormat] : "";
            if (Array.isArray(queryParameterValue)) // replace null and undefined
            queryParameterValue = queryParameterValue.map((item)=>{
                if (item === null || item === undefined) return "";
                return item;
            });
            if (queryParameter.collectionFormat === "Multi" && queryParameterValue.length === 0) continue;
            else if (Array.isArray(queryParameterValue) && (queryParameter.collectionFormat === "SSV" || queryParameter.collectionFormat === "TSV")) queryParameterValue = queryParameterValue.join(delimiter);
            if (!queryParameter.skipEncoding) {
                if (Array.isArray(queryParameterValue)) queryParameterValue = queryParameterValue.map((item)=>{
                    return encodeURIComponent(item);
                });
                else queryParameterValue = encodeURIComponent(queryParameterValue);
            }
            // Join pipes and CSV *after* encoding, or the server will be upset.
            if (Array.isArray(queryParameterValue) && (queryParameter.collectionFormat === "CSV" || queryParameter.collectionFormat === "Pipes")) queryParameterValue = queryParameterValue.join(delimiter);
            result.set(queryParameter.mapper.serializedName || (0, _interfaceHelpersJs.getPathStringFromParameter)(queryParameter), queryParameterValue);
        }
    }
    return {
        queryParams: result,
        sequenceParams
    };
}
function simpleParseQueryParams(queryString) {
    const result = new Map();
    if (!queryString || queryString[0] !== "?") return result;
    // remove the leading ?
    queryString = queryString.slice(1);
    const pairs = queryString.split("&");
    for (const pair of pairs){
        const [name, value] = pair.split("=", 2);
        const existingValue = result.get(name);
        if (existingValue) {
            if (Array.isArray(existingValue)) existingValue.push(value);
            else result.set(name, [
                existingValue,
                value
            ]);
        } else result.set(name, value);
    }
    return result;
}
function appendQueryParams(url, queryParams, sequenceParams, noOverwrite = false) {
    if (queryParams.size === 0) return url;
    const parsedUrl = new URL(url);
    // QUIRK: parsedUrl.searchParams will have their name/value pairs decoded, which
    // can change their meaning to the server, such as in the case of a SAS signature.
    // To avoid accidentally un-encoding a query param, we parse the key/values ourselves
    const combinedParams = simpleParseQueryParams(parsedUrl.search);
    for (const [name, value] of queryParams){
        const existingValue = combinedParams.get(name);
        if (Array.isArray(existingValue)) {
            if (Array.isArray(value)) {
                existingValue.push(...value);
                const valueSet = new Set(existingValue);
                combinedParams.set(name, Array.from(valueSet));
            } else existingValue.push(value);
        } else if (existingValue) {
            if (Array.isArray(value)) value.unshift(existingValue);
            else if (sequenceParams.has(name)) combinedParams.set(name, [
                existingValue,
                value
            ]);
            if (!noOverwrite) combinedParams.set(name, value);
        } else combinedParams.set(name, value);
    }
    const searchPieces = [];
    for (const [name, value] of combinedParams){
        if (typeof value === "string") searchPieces.push(`${name}=${value}`);
        else if (Array.isArray(value)) // QUIRK: If we get an array of values, include multiple key/value pairs
        for (const subValue of value)searchPieces.push(`${name}=${subValue}`);
        else searchPieces.push(`${name}=${value}`);
    }
    // QUIRK: we have to set search manually as searchParams will encode comma when it shouldn't.
    parsedUrl.search = searchPieces.length ? `?${searchPieces.join("&")}` : "";
    return parsedUrl.toString();
}

},{"./operationHelpers.js":"5lrBI","./interfaceHelpers.js":"d2zaE","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"82Mlw":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "logger", ()=>logger);
var _logger = require("@azure/logger");
const logger = (0, _logger.createClientLogger)("core-client");

},{"@azure/logger":"cnBke","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"i72A0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Converts: `Bearer a="b", c="d", Bearer d="e", f="g"`.
 * Into: `[ { a: 'b', c: 'd' }, { d: 'e', f: 'g' } ]`.
 *
 * @internal
 */ parcelHelpers.export(exports, "parseCAEChallenge", ()=>parseCAEChallenge);
/**
 * This function can be used as a callback for the `bearerTokenAuthenticationPolicy` of `@azure/core-rest-pipeline`, to support CAE challenges:
 * [Continuous Access Evaluation](https://docs.microsoft.com/azure/active-directory/conditional-access/concept-continuous-access-evaluation).
 *
 * Call the `bearerTokenAuthenticationPolicy` with the following options:
 *
 * ```ts
 * import { bearerTokenAuthenticationPolicy } from "@azure/core-rest-pipeline";
 * import { authorizeRequestOnClaimChallenge } from "@azure/core-client";
 *
 * const bearerTokenAuthenticationPolicy = bearerTokenAuthenticationPolicy({
 *   authorizeRequestOnChallenge: authorizeRequestOnClaimChallenge
 * });
 * ```
 *
 * Once provided, the `bearerTokenAuthenticationPolicy` policy will internally handle Continuous Access Evaluation (CAE) challenges.
 * When it can't complete a challenge it will return the 401 (unauthorized) response from ARM.
 *
 * Example challenge with claims:
 *
 * ```
 * Bearer authorization_uri="https://login.windows-ppe.net/", error="invalid_token",
 * error_description="User session has been revoked",
 * claims="eyJhY2Nlc3NfdG9rZW4iOnsibmJmIjp7ImVzc2VudGlhbCI6dHJ1ZSwgInZhbHVlIjoiMTYwMzc0MjgwMCJ9fX0="
 * ```
 */ parcelHelpers.export(exports, "authorizeRequestOnClaimChallenge", ()=>authorizeRequestOnClaimChallenge);
var _logJs = require("./log.js");
var _base64Js = require("./base64.js");
function parseCAEChallenge(challenges) {
    const bearerChallenges = `, ${challenges.trim()}`.split(", Bearer ").filter((x)=>x);
    return bearerChallenges.map((challenge)=>{
        const challengeParts = `${challenge.trim()}, `.split('", ').filter((x)=>x);
        const keyValuePairs = challengeParts.map((keyValue)=>(([key, value])=>({
                    [key]: value
                }))(keyValue.trim().split('="')));
        // Key-value pairs to plain object:
        return keyValuePairs.reduce((a, b)=>Object.assign(Object.assign({}, a), b), {});
    });
}
async function authorizeRequestOnClaimChallenge(onChallengeOptions) {
    const { scopes, response } = onChallengeOptions;
    const logger = onChallengeOptions.logger || (0, _logJs.logger);
    const challenge = response.headers.get("WWW-Authenticate");
    if (!challenge) {
        logger.info(`The WWW-Authenticate header was missing. Failed to perform the Continuous Access Evaluation authentication flow.`);
        return false;
    }
    const challenges = parseCAEChallenge(challenge) || [];
    const parsedChallenge = challenges.find((x)=>x.claims);
    if (!parsedChallenge) {
        logger.info(`The WWW-Authenticate header was missing the necessary "claims" to perform the Continuous Access Evaluation authentication flow.`);
        return false;
    }
    const accessToken = await onChallengeOptions.getAccessToken(parsedChallenge.scope ? [
        parsedChallenge.scope
    ] : scopes, {
        claims: (0, _base64Js.decodeStringToString)(parsedChallenge.claims)
    });
    if (!accessToken) return false;
    onChallengeOptions.request.headers.set("Authorization", `Bearer ${accessToken.token}`);
    return true;
}

},{"./log.js":"82Mlw","./base64.js":"kcjsq","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jfY37":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * A set of constants used internally when processing requests.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "authorizeRequestOnTenantChallenge", ()=>authorizeRequestOnTenantChallenge);
const Constants = {
    DefaultScope: "/.default",
    /**
     * Defines constants for use with HTTP headers.
     */ HeaderConstants: {
        /**
         * The Authorization header.
         */ AUTHORIZATION: "authorization"
    }
};
function isUuid(text) {
    return /^[0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12}$/.test(text);
}
const authorizeRequestOnTenantChallenge = async (challengeOptions)=>{
    const requestOptions = requestToOptions(challengeOptions.request);
    const challenge = getChallenge(challengeOptions.response);
    if (challenge) {
        const challengeInfo = parseChallenge(challenge);
        const challengeScopes = buildScopes(challengeOptions, challengeInfo);
        const tenantId = extractTenantId(challengeInfo);
        if (!tenantId) return false;
        const accessToken = await challengeOptions.getAccessToken(challengeScopes, Object.assign(Object.assign({}, requestOptions), {
            tenantId
        }));
        if (!accessToken) return false;
        challengeOptions.request.headers.set(Constants.HeaderConstants.AUTHORIZATION, `Bearer ${accessToken.token}`);
        return true;
    }
    return false;
};
/**
 * Extracts the tenant id from the challenge information
 * The tenant id is contained in the authorization_uri as the first
 * path part.
 */ function extractTenantId(challengeInfo) {
    const parsedAuthUri = new URL(challengeInfo.authorization_uri);
    const pathSegments = parsedAuthUri.pathname.split("/");
    const tenantId = pathSegments[1];
    if (tenantId && isUuid(tenantId)) return tenantId;
    return undefined;
}
/**
 * Builds the authentication scopes based on the information that comes in the
 * challenge information. Scopes url is present in the resource_id, if it is empty
 * we keep using the original scopes.
 */ function buildScopes(challengeOptions, challengeInfo) {
    if (!challengeInfo.resource_id) return challengeOptions.scopes;
    const challengeScopes = new URL(challengeInfo.resource_id);
    challengeScopes.pathname = Constants.DefaultScope;
    let scope = challengeScopes.toString();
    if (scope === "https://disk.azure.com/.default") // the extra slash is required by the service
    scope = "https://disk.azure.com//.default";
    return [
        scope
    ];
}
/**
 * We will retrieve the challenge only if the response status code was 401,
 * and if the response contained the header "WWW-Authenticate" with a non-empty value.
 */ function getChallenge(response) {
    const challenge = response.headers.get("WWW-Authenticate");
    if (response.status === 401 && challenge) return challenge;
    return;
}
/**
 * Converts: `Bearer a="b" c="d"`.
 * Into: `[ { a: 'b', c: 'd' }]`.
 *
 * @internal
 */ function parseChallenge(challenge) {
    const bearerChallenge = challenge.slice(7);
    const challengeParts = `${bearerChallenge.trim()} `.split(" ").filter((x)=>x);
    const keyValuePairs = challengeParts.map((keyValue)=>(([key, value])=>({
                [key]: value
            }))(keyValue.trim().split("=")));
    // Key-value pairs to plain object:
    return keyValuePairs.reduce((a, b)=>Object.assign(Object.assign({}, a), b), {});
}
/**
 * Extracts the options form a Pipeline Request for later re-use
 */ function requestToOptions(request) {
    return {
        abortSignal: request.abortSignal,
        requestOptions: {
            timeout: request.timeout
        },
        tracingOptions: request.tracingOptions
    };
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bLzlA":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A helper to convert response objects from the new pipeline back to the old one.
 * @param response - A response object from core-client.
 * @returns A response compatible with `HttpOperationResponse` from core-http.
 */ parcelHelpers.export(exports, "toCompatResponse", ()=>toCompatResponse);
/**
 * A helper to convert back to a PipelineResponse
 * @param compatResponse - A response compatible with `HttpOperationResponse` from core-http.
 */ parcelHelpers.export(exports, "toPipelineResponse", ()=>toPipelineResponse);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _utilJs = require("./util.js");
const originalResponse = Symbol("Original FullOperationResponse");
function toCompatResponse(response, options) {
    let request = (0, _utilJs.toWebResourceLike)(response.request);
    let headers = (0, _utilJs.toHttpHeadersLike)(response.headers);
    if (options === null || options === void 0 ? void 0 : options.createProxy) return new Proxy(response, {
        get (target, prop, receiver) {
            if (prop === "headers") return headers;
            else if (prop === "request") return request;
            else if (prop === originalResponse) return response;
            return Reflect.get(target, prop, receiver);
        },
        set (target, prop, value, receiver) {
            if (prop === "headers") headers = value;
            else if (prop === "request") request = value;
            return Reflect.set(target, prop, value, receiver);
        }
    });
    else return Object.assign(Object.assign({}, response), {
        request,
        headers
    });
}
function toPipelineResponse(compatResponse) {
    const extendedCompatResponse = compatResponse;
    const response = extendedCompatResponse[originalResponse];
    const headers = (0, _coreRestPipeline.createHttpHeaders)(compatResponse.headers.toJson({
        preserveCase: true
    }));
    if (response) {
        response.headers = headers;
        return response;
    } else return Object.assign(Object.assign({}, compatResponse), {
        headers,
        request: (0, _utilJs.toPipelineRequest)(compatResponse.request)
    });
}

},{"@azure/core-rest-pipeline":"d0mqv","./util.js":"dhnfg","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dhnfg":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "toPipelineRequest", ()=>toPipelineRequest);
parcelHelpers.export(exports, "toWebResourceLike", ()=>toWebResourceLike);
/**
 * Converts HttpHeaders from core-rest-pipeline to look like
 * HttpHeaders from core-http.
 * @param headers - HttpHeaders from core-rest-pipeline
 * @returns HttpHeaders as they looked in core-http
 */ parcelHelpers.export(exports, "toHttpHeadersLike", ()=>toHttpHeadersLike);
/**
 * A collection of HTTP header key/value pairs.
 */ parcelHelpers.export(exports, "HttpHeaders", ()=>HttpHeaders);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
// We use a custom symbol to cache a reference to the original request without
// exposing it on the public interface.
const originalRequestSymbol = Symbol("Original PipelineRequest");
// Symbol.for() will return the same symbol if it's already been created
// This particular one is used in core-client to handle the case of when a request is
// cloned but we need to retrieve the OperationSpec and OperationArguments from the
// original request.
const originalClientRequestSymbol = Symbol.for("@azure/core-client original request");
function toPipelineRequest(webResource, options = {}) {
    const compatWebResource = webResource;
    const request = compatWebResource[originalRequestSymbol];
    const headers = (0, _coreRestPipeline.createHttpHeaders)(webResource.headers.toJson({
        preserveCase: true
    }));
    if (request) {
        request.headers = headers;
        return request;
    } else {
        const newRequest = (0, _coreRestPipeline.createPipelineRequest)({
            url: webResource.url,
            method: webResource.method,
            headers,
            withCredentials: webResource.withCredentials,
            timeout: webResource.timeout,
            requestId: webResource.requestId,
            abortSignal: webResource.abortSignal,
            body: webResource.body,
            formData: webResource.formData,
            disableKeepAlive: !!webResource.keepAlive,
            onDownloadProgress: webResource.onDownloadProgress,
            onUploadProgress: webResource.onUploadProgress,
            proxySettings: webResource.proxySettings,
            streamResponseStatusCodes: webResource.streamResponseStatusCodes
        });
        if (options.originalRequest) newRequest[originalClientRequestSymbol] = options.originalRequest;
        return newRequest;
    }
}
function toWebResourceLike(request, options) {
    var _a;
    const originalRequest = (_a = options === null || options === void 0 ? void 0 : options.originalRequest) !== null && _a !== void 0 ? _a : request;
    const webResource = {
        url: request.url,
        method: request.method,
        headers: toHttpHeadersLike(request.headers),
        withCredentials: request.withCredentials,
        timeout: request.timeout,
        requestId: request.headers.get("x-ms-client-request-id") || request.requestId,
        abortSignal: request.abortSignal,
        body: request.body,
        formData: request.formData,
        keepAlive: !!request.disableKeepAlive,
        onDownloadProgress: request.onDownloadProgress,
        onUploadProgress: request.onUploadProgress,
        proxySettings: request.proxySettings,
        streamResponseStatusCodes: request.streamResponseStatusCodes,
        clone () {
            throw new Error("Cannot clone a non-proxied WebResourceLike");
        },
        prepare () {
            throw new Error("WebResourceLike.prepare() is not supported by @azure/core-http-compat");
        },
        validateRequestProperties () {
        /** do nothing */ }
    };
    if (options === null || options === void 0 ? void 0 : options.createProxy) return new Proxy(webResource, {
        get (target, prop, receiver) {
            if (prop === originalRequestSymbol) return request;
            else if (prop === "clone") return ()=>{
                return toWebResourceLike(toPipelineRequest(webResource, {
                    originalRequest
                }), {
                    createProxy: true,
                    originalRequest
                });
            };
            return Reflect.get(target, prop, receiver);
        },
        set (target, prop, value, receiver) {
            if (prop === "keepAlive") request.disableKeepAlive = !value;
            const passThroughProps = [
                "url",
                "method",
                "withCredentials",
                "timeout",
                "requestId",
                "abortSignal",
                "body",
                "formData",
                "onDownloadProgress",
                "onUploadProgress",
                "proxySettings",
                "streamResponseStatusCodes"
            ];
            if (typeof prop === "string" && passThroughProps.includes(prop)) request[prop] = value;
            return Reflect.set(target, prop, value, receiver);
        }
    });
    else return webResource;
}
function toHttpHeadersLike(headers) {
    return new HttpHeaders(headers.toJSON({
        preserveCase: true
    }));
}
/**
 * A collection of HttpHeaders that can be sent with a HTTP request.
 */ function getHeaderKey(headerName) {
    return headerName.toLowerCase();
}
class HttpHeaders {
    constructor(rawHeaders){
        this._headersMap = {};
        if (rawHeaders) for(const headerName in rawHeaders)this.set(headerName, rawHeaders[headerName]);
    }
    /**
     * Set a header in this collection with the provided name and value. The name is
     * case-insensitive.
     * @param headerName - The name of the header to set. This value is case-insensitive.
     * @param headerValue - The value of the header to set.
     */ set(headerName, headerValue) {
        this._headersMap[getHeaderKey(headerName)] = {
            name: headerName,
            value: headerValue.toString()
        };
    }
    /**
     * Get the header value for the provided header name, or undefined if no header exists in this
     * collection with the provided name.
     * @param headerName - The name of the header.
     */ get(headerName) {
        const header = this._headersMap[getHeaderKey(headerName)];
        return !header ? undefined : header.value;
    }
    /**
     * Get whether or not this header collection contains a header entry for the provided header name.
     */ contains(headerName) {
        return !!this._headersMap[getHeaderKey(headerName)];
    }
    /**
     * Remove the header with the provided headerName. Return whether or not the header existed and
     * was removed.
     * @param headerName - The name of the header to remove.
     */ remove(headerName) {
        const result = this.contains(headerName);
        delete this._headersMap[getHeaderKey(headerName)];
        return result;
    }
    /**
     * Get the headers that are contained this collection as an object.
     */ rawHeaders() {
        return this.toJson({
            preserveCase: true
        });
    }
    /**
     * Get the headers that are contained in this collection as an array.
     */ headersArray() {
        const headers = [];
        for(const headerKey in this._headersMap)headers.push(this._headersMap[headerKey]);
        return headers;
    }
    /**
     * Get the header names that are contained in this collection.
     */ headerNames() {
        const headerNames = [];
        const headers = this.headersArray();
        for(let i = 0; i < headers.length; ++i)headerNames.push(headers[i].name);
        return headerNames;
    }
    /**
     * Get the header values that are contained in this collection.
     */ headerValues() {
        const headerValues = [];
        const headers = this.headersArray();
        for(let i = 0; i < headers.length; ++i)headerValues.push(headers[i].value);
        return headerValues;
    }
    /**
     * Get the JSON object representation of this HTTP header collection.
     */ toJson(options = {}) {
        const result = {};
        if (options.preserveCase) for(const headerKey in this._headersMap){
            const header = this._headersMap[headerKey];
            result[header.name] = header.value;
        }
        else for(const headerKey in this._headersMap){
            const header = this._headersMap[headerKey];
            result[getHeaderKey(header.name)] = header.value;
        }
        return result;
    }
    /**
     * Get the string representation of this HTTP header collection.
     */ toString() {
        return JSON.stringify(this.toJson({
            preserveCase: true
        }));
    }
    /**
     * Create a deep clone/copy of this HttpHeaders collection.
     */ clone() {
        const resultPreservingCasing = {};
        for(const headerKey in this._headersMap){
            const header = this._headersMap[headerKey];
            resultPreservingCasing[header.name] = header.value;
        }
        return new HttpHeaders(resultPreservingCasing);
    }
}

},{"@azure/core-rest-pipeline":"d0mqv","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gfvZ1":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "HttpPipelineLogLevel", ()=>HttpPipelineLogLevel);
parcelHelpers.export(exports, "requestPolicyFactoryPolicyName", ()=>requestPolicyFactoryPolicyName);
/**
 * A policy that wraps policies written for core-http.
 * @param factories - An array of `RequestPolicyFactory` objects from a core-http pipeline
 */ parcelHelpers.export(exports, "createRequestPolicyFactoryPolicy", ()=>createRequestPolicyFactoryPolicy);
var _utilJs = require("../util.js");
var _responseJs = require("../response.js");
var HttpPipelineLogLevel;
(function(HttpPipelineLogLevel) {
    HttpPipelineLogLevel[HttpPipelineLogLevel["ERROR"] = 1] = "ERROR";
    HttpPipelineLogLevel[HttpPipelineLogLevel["INFO"] = 3] = "INFO";
    HttpPipelineLogLevel[HttpPipelineLogLevel["OFF"] = 0] = "OFF";
    HttpPipelineLogLevel[HttpPipelineLogLevel["WARNING"] = 2] = "WARNING";
})(HttpPipelineLogLevel || (HttpPipelineLogLevel = {}));
const mockRequestPolicyOptions = {
    log (_logLevel, _message) {
    /* do nothing */ },
    shouldLog (_logLevel) {
        return false;
    }
};
const requestPolicyFactoryPolicyName = "RequestPolicyFactoryPolicy";
function createRequestPolicyFactoryPolicy(factories) {
    const orderedFactories = factories.slice().reverse();
    return {
        name: requestPolicyFactoryPolicyName,
        async sendRequest (request, next) {
            let httpPipeline = {
                async sendRequest (httpRequest) {
                    const response = await next((0, _utilJs.toPipelineRequest)(httpRequest));
                    return (0, _responseJs.toCompatResponse)(response, {
                        createProxy: true
                    });
                }
            };
            for (const factory of orderedFactories)httpPipeline = factory.create(httpPipeline, mockRequestPolicyOptions);
            const webResourceLike = (0, _utilJs.toWebResourceLike)(request, {
                createProxy: true
            });
            const response = await httpPipeline.sendRequest(webResourceLike);
            return (0, _responseJs.toPipelineResponse)(response);
        }
    };
}

},{"../util.js":"dhnfg","../response.js":"bLzlA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eMGtA":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Converts a RequestPolicy based HttpClient to a PipelineRequest based HttpClient.
 * @param requestPolicyClient - A HttpClient compatible with core-http
 * @returns A HttpClient compatible with core-rest-pipeline
 */ parcelHelpers.export(exports, "convertHttpClient", ()=>convertHttpClient);
var _responseJs = require("./response.js");
var _utilJs = require("./util.js");
function convertHttpClient(requestPolicyClient) {
    return {
        sendRequest: async (request)=>{
            const response = await requestPolicyClient.sendRequest((0, _utilJs.toWebResourceLike)(request, {
                createProxy: true
            }));
            return (0, _responseJs.toPipelineResponse)(response);
        }
    };
}

},{"./response.js":"bLzlA","./util.js":"dhnfg","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"XDN0l":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "stringifyXML", ()=>(0, _xmlJs.stringifyXML));
parcelHelpers.export(exports, "parseXML", ()=>(0, _xmlJs.parseXML));
parcelHelpers.export(exports, "XML_ATTRKEY", ()=>(0, _xmlCommonJs.XML_ATTRKEY));
parcelHelpers.export(exports, "XML_CHARKEY", ()=>(0, _xmlCommonJs.XML_CHARKEY));
var _xmlJs = require("./xml.js");
var _xmlCommonJs = require("./xml.common.js");

},{"./xml.js":"cHWhP","./xml.common.js":"4fdme","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cHWhP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/// <reference lib="dom"/>
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "parseXML", ()=>parseXML);
parcelHelpers.export(exports, "stringifyXML", ()=>stringifyXML);
var _xmlCommonJs = require("./xml.common.js");
if (!document || !DOMParser || !Node || !XMLSerializer) throw new Error(`This library depends on the following DOM objects: ["document", "DOMParser", "Node", "XMLSerializer"] to parse XML, but some of these are undefined. You may provide a polyfill to make these globally available in order to support your environment. For more information, please refer to https://aka.ms/azsdk/js/web-workers. `);
// Policy to make our code Trusted Types compliant at running time.
//   https://github.com/w3c/webappsec-trusted-types
// We are calling DOMParser.parseFromString() to parse XML payload from Azure services.
// The parsed DOM object is not exposed to outside. Scripts are disabled when parsing
// according to the spec.  There are no HTML/XSS security concerns on the usage of
// parseFromString() here.
let ttPolicy;
try {
    if (typeof self.trustedTypes !== "undefined") ttPolicy = self.trustedTypes.createPolicy("@azure/core-xml#xml.browser", {
        createHTML: (s)=>s
    });
} catch (e) {
    console.warn('Could not create trusted types policy "@azure/core-xml#xml.browser"');
}
const doc = document.implementation.createDocument(null, null, null);
const parser = new DOMParser();
function parseXML(str, opts = {}) {
    var _a, _b, _c, _d, _e, _f;
    try {
        const updatedOptions = {
            rootName: (_a = opts.rootName) !== null && _a !== void 0 ? _a : "",
            includeRoot: (_b = opts.includeRoot) !== null && _b !== void 0 ? _b : false,
            xmlCharKey: (_c = opts.xmlCharKey) !== null && _c !== void 0 ? _c : (0, _xmlCommonJs.XML_CHARKEY),
            cdataPropName: (_d = opts.cdataPropName) !== null && _d !== void 0 ? _d : "__cdata",
            stopNodes: (_e = opts.stopNodes) !== null && _e !== void 0 ? _e : []
        };
        const dom = parser.parseFromString((_f = ttPolicy === null || ttPolicy === void 0 ? void 0 : ttPolicy.createHTML(str)) !== null && _f !== void 0 ? _f : str, "application/xml");
        throwIfError(dom);
        let obj;
        if (updatedOptions.includeRoot) obj = domToObject(dom, updatedOptions);
        else obj = domToObject(dom.childNodes[0], updatedOptions);
        return Promise.resolve(obj);
    } catch (err) {
        return Promise.reject(err);
    }
}
let errorNS;
function getErrorNamespace() {
    var _a, _b;
    if (errorNS === undefined) try {
        const invalidXML = (_a = ttPolicy === null || ttPolicy === void 0 ? void 0 : ttPolicy.createHTML("INVALID")) !== null && _a !== void 0 ? _a : "INVALID";
        errorNS = (_b = parser.parseFromString(invalidXML, "text/xml").getElementsByTagName("parsererror")[0].namespaceURI) !== null && _b !== void 0 ? _b : "";
    } catch (ignored) {
        // Most browsers will return a document containing <parsererror>, but IE will throw.
        errorNS = "";
    }
    return errorNS;
}
function throwIfError(dom) {
    const parserErrors = dom.getElementsByTagName("parsererror");
    if (parserErrors.length > 0 && getErrorNamespace()) for(let i = 0; i < parserErrors.length; i++){
        if (parserErrors[i].namespaceURI === errorNS) throw new Error(parserErrors[i].innerHTML);
    }
}
function isElement(node) {
    return !!node.attributes;
}
/**
 * Get the Element-typed version of the provided Node if the provided node is an element with
 * attributes. If it isn't, then undefined is returned.
 */ function asElementWithAttributes(node) {
    return isElement(node) && node.hasAttributes() ? node : undefined;
}
function domToObject(node, options) {
    var _a;
    let result = {};
    const childNodeCount = node.childNodes.length;
    const firstChildNode = node.childNodes[0];
    const onlyChildTextValue = firstChildNode && childNodeCount === 1 && firstChildNode.nodeType === Node.TEXT_NODE && firstChildNode.nodeValue || undefined;
    const elementWithAttributes = asElementWithAttributes(node);
    if (elementWithAttributes) {
        result[0, _xmlCommonJs.XML_ATTRKEY] = {};
        for(let i = 0; i < elementWithAttributes.attributes.length; i++){
            const attr = elementWithAttributes.attributes[i];
            result[0, _xmlCommonJs.XML_ATTRKEY][attr.nodeName] = attr.nodeValue;
        }
        if (onlyChildTextValue) result[options.xmlCharKey] = onlyChildTextValue;
    } else if (childNodeCount === 0) result = "";
    else if (onlyChildTextValue) result = onlyChildTextValue;
    if (!onlyChildTextValue) for(let i = 0; i < childNodeCount; i++){
        const child = node.childNodes[i];
        // Check if CData
        if ((child === null || child === void 0 ? void 0 : child.nodeType) === Node.CDATA_SECTION_NODE) // Already in the CDATA
        result = child.textContent;
        else if (((_a = child === null || child === void 0 ? void 0 : child.firstChild) === null || _a === void 0 ? void 0 : _a.nodeType) === Node.CDATA_SECTION_NODE) // Look if child is CDATA
        result[child.nodeName] = child.textContent;
        else if (child.nodeType !== Node.TEXT_NODE) {
            // Ignore leading/trailing whitespace nodes
            const childObject = domToObject(child, options);
            if (!result[child.nodeName]) result[child.nodeName] = childObject;
            else if (Array.isArray(result[child.nodeName])) result[child.nodeName].push(childObject);
            else result[child.nodeName] = [
                result[child.nodeName],
                childObject
            ];
        }
    }
    return result;
}
const serializer = new XMLSerializer();
function stringifyXML(content, opts = {}) {
    var _a, _b, _c, _d, _e;
    const updatedOptions = {
        rootName: (_a = opts.rootName) !== null && _a !== void 0 ? _a : "root",
        includeRoot: (_b = opts.includeRoot) !== null && _b !== void 0 ? _b : false,
        xmlCharKey: (_c = opts.xmlCharKey) !== null && _c !== void 0 ? _c : (0, _xmlCommonJs.XML_CHARKEY),
        cdataPropName: (_d = opts.cdataPropName) !== null && _d !== void 0 ? _d : "__cdata",
        stopNodes: (_e = opts.stopNodes) !== null && _e !== void 0 ? _e : []
    };
    const dom = buildNode(content, updatedOptions.rootName, updatedOptions)[0];
    return '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>' + serializer.serializeToString(dom);
}
function buildAttributes(attrs) {
    const result = [];
    for (const key of Object.keys(attrs)){
        const attr = doc.createAttribute(key);
        attr.value = attrs[key].toString();
        result.push(attr);
    }
    return result;
}
function buildNode(obj, elementName, options) {
    if (obj === undefined || obj === null || typeof obj === "string" || typeof obj === "number" || typeof obj === "boolean") {
        const elem = doc.createElement(elementName);
        elem.textContent = obj === undefined || obj === null ? "" : obj.toString();
        return [
            elem
        ];
    } else if (Array.isArray(obj)) {
        const result = [];
        for (const arrayElem of obj)for (const child of buildNode(arrayElem, elementName, options))result.push(child);
        return result;
    } else if (typeof obj === "object") {
        const elem = doc.createElement(elementName);
        for (const key of Object.keys(obj)){
            if (key === (0, _xmlCommonJs.XML_ATTRKEY)) for (const attr of buildAttributes(obj[key]))elem.attributes.setNamedItem(attr);
            else if (key === options.xmlCharKey) elem.textContent = obj[key].toString();
            else if (key === options.cdataPropName) {
                const cdataElement = doc.createCDATASection(obj[key].toString());
                elem.appendChild(cdataElement);
            } else for (const child of buildNode(obj[key], key, options))elem.appendChild(child);
        }
        return [
            elem
        ];
    } else throw new Error(`Illegal value passed to buildObject: ${obj}`);
}

},{"./xml.common.js":"4fdme","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4fdme":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Default key used to access the XML attributes.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "XML_ATTRKEY", ()=>XML_ATTRKEY);
parcelHelpers.export(exports, "XML_CHARKEY", ()=>XML_CHARKEY);
const XML_ATTRKEY = "$";
const XML_CHARKEY = "_";

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gc1Rl":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "logger", ()=>logger);
var _logger = require("@azure/logger");
const logger = (0, _logger.createClientLogger)("storage-blob");

},{"@azure/logger":"cnBke","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ealHa":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "StorageRetryPolicyType", ()=>(0, _storageRetryPolicy.StorageRetryPolicyType));
parcelHelpers.export(exports, "StorageRetryPolicy", ()=>(0, _storageRetryPolicy.StorageRetryPolicy));
/**
 * StorageRetryPolicyFactory is a factory class helping generating {@link StorageRetryPolicy} objects.
 */ parcelHelpers.export(exports, "StorageRetryPolicyFactory", ()=>StorageRetryPolicyFactory);
var _storageRetryPolicy = require("./policies/StorageRetryPolicy");
class StorageRetryPolicyFactory {
    /**
     * Creates an instance of StorageRetryPolicyFactory.
     * @param retryOptions -
     */ constructor(retryOptions){
        this.retryOptions = retryOptions;
    }
    /**
     * Creates a StorageRetryPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */ create(nextPolicy, options) {
        return new (0, _storageRetryPolicy.StorageRetryPolicy)(nextPolicy, options, this.retryOptions);
    }
}

},{"./policies/StorageRetryPolicy":"4j5T8","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4j5T8":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A factory method used to generated a RetryPolicy factory.
 *
 * @param retryOptions -
 */ parcelHelpers.export(exports, "NewRetryPolicyFactory", ()=>NewRetryPolicyFactory);
parcelHelpers.export(exports, "StorageRetryPolicyType", ()=>StorageRetryPolicyType);
/**
 * Retry policy with exponential retry and linear retry implemented.
 */ parcelHelpers.export(exports, "StorageRetryPolicy", ()=>StorageRetryPolicy);
var _abortController = require("@azure/abort-controller");
var _requestPolicy = require("./RequestPolicy");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
var _log = require("../log");
function NewRetryPolicyFactory(retryOptions) {
    return {
        create: (nextPolicy, options)=>{
            return new StorageRetryPolicy(nextPolicy, options, retryOptions);
        }
    };
}
var StorageRetryPolicyType;
(function(StorageRetryPolicyType) {
    /**
     * Exponential retry. Retry time delay grows exponentially.
     */ StorageRetryPolicyType[StorageRetryPolicyType["EXPONENTIAL"] = 0] = "EXPONENTIAL";
    /**
     * Linear retry. Retry time delay grows linearly.
     */ StorageRetryPolicyType[StorageRetryPolicyType["FIXED"] = 1] = "FIXED";
})(StorageRetryPolicyType || (StorageRetryPolicyType = {}));
// Default values of StorageRetryOptions
const DEFAULT_RETRY_OPTIONS = {
    maxRetryDelayInMs: 120000,
    maxTries: 4,
    retryDelayInMs: 4000,
    retryPolicyType: StorageRetryPolicyType.EXPONENTIAL,
    secondaryHost: "",
    tryTimeoutInMs: undefined
};
const RETRY_ABORT_ERROR = new (0, _abortController.AbortError)("The operation was aborted.");
class StorageRetryPolicy extends (0, _requestPolicy.BaseRequestPolicy) {
    /**
     * Creates an instance of RetryPolicy.
     *
     * @param nextPolicy -
     * @param options -
     * @param retryOptions -
     */ constructor(nextPolicy, options, retryOptions = DEFAULT_RETRY_OPTIONS){
        super(nextPolicy, options);
        // Initialize retry options
        this.retryOptions = {
            retryPolicyType: retryOptions.retryPolicyType ? retryOptions.retryPolicyType : DEFAULT_RETRY_OPTIONS.retryPolicyType,
            maxTries: retryOptions.maxTries && retryOptions.maxTries >= 1 ? Math.floor(retryOptions.maxTries) : DEFAULT_RETRY_OPTIONS.maxTries,
            tryTimeoutInMs: retryOptions.tryTimeoutInMs && retryOptions.tryTimeoutInMs >= 0 ? retryOptions.tryTimeoutInMs : DEFAULT_RETRY_OPTIONS.tryTimeoutInMs,
            retryDelayInMs: retryOptions.retryDelayInMs && retryOptions.retryDelayInMs >= 0 ? Math.min(retryOptions.retryDelayInMs, retryOptions.maxRetryDelayInMs ? retryOptions.maxRetryDelayInMs : DEFAULT_RETRY_OPTIONS.maxRetryDelayInMs) : DEFAULT_RETRY_OPTIONS.retryDelayInMs,
            maxRetryDelayInMs: retryOptions.maxRetryDelayInMs && retryOptions.maxRetryDelayInMs >= 0 ? retryOptions.maxRetryDelayInMs : DEFAULT_RETRY_OPTIONS.maxRetryDelayInMs,
            secondaryHost: retryOptions.secondaryHost ? retryOptions.secondaryHost : DEFAULT_RETRY_OPTIONS.secondaryHost
        };
    }
    /**
     * Sends request.
     *
     * @param request -
     */ async sendRequest(request) {
        return this.attemptSendRequest(request, false, 1);
    }
    /**
     * Decide and perform next retry. Won't mutate request parameter.
     *
     * @param request -
     * @param secondaryHas404 -  If attempt was against the secondary & it returned a StatusNotFound (404), then
     *                                   the resource was not found. This may be due to replication delay. So, in this
     *                                   case, we'll never try the secondary again for this operation.
     * @param attempt -           How many retries has been attempted to performed, starting from 1, which includes
     *                                   the attempt will be performed by this method call.
     */ async attemptSendRequest(request, secondaryHas404, attempt) {
        const newRequest = request.clone();
        const isPrimaryRetry = secondaryHas404 || !this.retryOptions.secondaryHost || !(request.method === "GET" || request.method === "HEAD" || request.method === "OPTIONS") || attempt % 2 === 1;
        if (!isPrimaryRetry) newRequest.url = (0, _utilsCommon.setURLHost)(newRequest.url, this.retryOptions.secondaryHost);
        // Set the server-side timeout query parameter "timeout=[seconds]"
        if (this.retryOptions.tryTimeoutInMs) newRequest.url = (0, _utilsCommon.setURLParameter)(newRequest.url, (0, _constants.URLConstants).Parameters.TIMEOUT, Math.floor(this.retryOptions.tryTimeoutInMs / 1000).toString());
        let response;
        try {
            (0, _log.logger).info(`RetryPolicy: =====> Try=${attempt} ${isPrimaryRetry ? "Primary" : "Secondary"}`);
            response = await this._nextPolicy.sendRequest(newRequest);
            if (!this.shouldRetry(isPrimaryRetry, attempt, response)) return response;
            secondaryHas404 = secondaryHas404 || !isPrimaryRetry && response.status === 404;
        } catch (err) {
            (0, _log.logger).error(`RetryPolicy: Caught error, message: ${err.message}, code: ${err.code}`);
            if (!this.shouldRetry(isPrimaryRetry, attempt, response, err)) throw err;
        }
        await this.delay(isPrimaryRetry, attempt, request.abortSignal);
        return this.attemptSendRequest(request, secondaryHas404, ++attempt);
    }
    /**
     * Decide whether to retry according to last HTTP response and retry counters.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param response -
     * @param err -
     */ shouldRetry(isPrimaryRetry, attempt, response, err) {
        if (attempt >= this.retryOptions.maxTries) {
            (0, _log.logger).info(`RetryPolicy: Attempt(s) ${attempt} >= maxTries ${this.retryOptions.maxTries}, no further try.`);
            return false;
        }
        // Handle network failures, you may need to customize the list when you implement
        // your own http client
        const retriableErrors = [
            "ETIMEDOUT",
            "ESOCKETTIMEDOUT",
            "ECONNREFUSED",
            "ECONNRESET",
            "ENOENT",
            "ENOTFOUND",
            "TIMEOUT",
            "EPIPE",
            "REQUEST_SEND_ERROR"
        ];
        if (err) {
            for (const retriableError of retriableErrors)if (err.name.toUpperCase().includes(retriableError) || err.message.toUpperCase().includes(retriableError) || err.code && err.code.toString().toUpperCase() === retriableError) {
                (0, _log.logger).info(`RetryPolicy: Network error ${retriableError} found, will retry.`);
                return true;
            }
        }
        // If attempt was against the secondary & it returned a StatusNotFound (404), then
        // the resource was not found. This may be due to replication delay. So, in this
        // case, we'll never try the secondary again for this operation.
        if (response || err) {
            const statusCode = response ? response.status : err ? err.statusCode : 0;
            if (!isPrimaryRetry && statusCode === 404) {
                (0, _log.logger).info(`RetryPolicy: Secondary access with 404, will retry.`);
                return true;
            }
            // Server internal error or server timeout
            if (statusCode === 503 || statusCode === 500) {
                (0, _log.logger).info(`RetryPolicy: Will retry for status code ${statusCode}.`);
                return true;
            }
        }
        if ((err === null || err === void 0 ? void 0 : err.code) === "PARSE_ERROR" && (err === null || err === void 0 ? void 0 : err.message.startsWith(`Error "Error: Unclosed root tag`))) {
            (0, _log.logger).info("RetryPolicy: Incomplete XML response likely due to service timeout, will retry.");
            return true;
        }
        return false;
    }
    /**
     * Delay a calculated time between retries.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param abortSignal -
     */ async delay(isPrimaryRetry, attempt, abortSignal) {
        let delayTimeInMs = 0;
        if (isPrimaryRetry) switch(this.retryOptions.retryPolicyType){
            case StorageRetryPolicyType.EXPONENTIAL:
                delayTimeInMs = Math.min((Math.pow(2, attempt - 1) - 1) * this.retryOptions.retryDelayInMs, this.retryOptions.maxRetryDelayInMs);
                break;
            case StorageRetryPolicyType.FIXED:
                delayTimeInMs = this.retryOptions.retryDelayInMs;
                break;
        }
        else delayTimeInMs = Math.random() * 1000;
        (0, _log.logger).info(`RetryPolicy: Delay for ${delayTimeInMs}ms`);
        return (0, _utilsCommon.delay)(delayTimeInMs, abortSignal, RETRY_ABORT_ERROR);
    }
}

},{"@azure/abort-controller":"6HB9r","./RequestPolicy":"9jet0","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","../log":"gc1Rl","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6HB9r":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
// Changes to Aborter
// * Rename Aborter to AbortSignal
// * Remove withValue and getValue - async context should be solved differently/wholistically, not tied to cancellation
// * Remove withTimeout, it's moved to the controller
// * AbortSignal constructor no longer takes a parent. Cancellation graphs are created from the controller.
// Potential changes to align with DOM Spec
// * dispatchEvent on Signal
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbortController", ()=>(0, _abortController.AbortController));
parcelHelpers.export(exports, "AbortError", ()=>(0, _abortController.AbortError));
parcelHelpers.export(exports, "AbortSignal", ()=>(0, _abortSignal.AbortSignal));
var _abortController = require("./AbortController");
var _abortSignal = require("./AbortSignal");

},{"./AbortController":"fBDhi","./AbortSignal":false,"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fBDhi":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * This error is thrown when an asynchronous operation has been aborted.
 * Check for this error by testing the `name` that the name property of the
 * error matches `"AbortError"`.
 *
 * @example
 * ```ts
 * const controller = new AbortController();
 * controller.abort();
 * try {
 *   doAsyncWork(controller.signal)
 * } catch (e) {
 *   if (e.name === 'AbortError') {
 *     // handle abort error here.
 *   }
 * }
 * ```
 */ parcelHelpers.export(exports, "AbortError", ()=>AbortError);
/**
 * An AbortController provides an AbortSignal and the associated controls to signal
 * that an asynchronous operation should be aborted.
 *
 * @example
 * Abort an operation when another event fires
 * ```ts
 * const controller = new AbortController();
 * const signal = controller.signal;
 * doAsyncWork(signal);
 * button.addEventListener('click', () => controller.abort());
 * ```
 *
 * @example
 * Share aborter cross multiple operations in 30s
 * ```ts
 * // Upload the same data to 2 different data centers at the same time,
 * // abort another when any of them is finished
 * const controller = AbortController.withTimeout(30 * 1000);
 * doAsyncWork(controller.signal).then(controller.abort);
 * doAsyncWork(controller.signal).then(controller.abort);
 *```
 *
 * @example
 * Cascaded aborting
 * ```ts
 * // All operations can't take more than 30 seconds
 * const aborter = Aborter.timeout(30 * 1000);
 *
 * // Following 2 operations can't take more than 25 seconds
 * await doAsyncWork(aborter.withTimeout(25 * 1000));
 * await doAsyncWork(aborter.withTimeout(25 * 1000));
 * ```
 */ parcelHelpers.export(exports, "AbortController", ()=>AbortController);
var _abortSignal = require("./AbortSignal");
class AbortError extends Error {
    constructor(message){
        super(message);
        this.name = "AbortError";
    }
}
class AbortController {
    // eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
    constructor(parentSignals){
        this._signal = new (0, _abortSignal.AbortSignal)();
        if (!parentSignals) return;
        // coerce parentSignals into an array
        if (!Array.isArray(parentSignals)) // eslint-disable-next-line prefer-rest-params
        parentSignals = arguments;
        for (const parentSignal of parentSignals)// if the parent signal has already had abort() called,
        // then call abort on this signal as well.
        if (parentSignal.aborted) this.abort();
        else // when the parent signal aborts, this signal should as well.
        parentSignal.addEventListener("abort", ()=>{
            this.abort();
        });
    }
    /**
     * The AbortSignal associated with this controller that will signal aborted
     * when the abort method is called on this controller.
     *
     * @readonly
     */ get signal() {
        return this._signal;
    }
    /**
     * Signal that any operations passed this controller's associated abort signal
     * to cancel any remaining work and throw an `AbortError`.
     */ abort() {
        (0, _abortSignal.abortSignal)(this._signal);
    }
    /**
     * Creates a new AbortSignal instance that will abort after the provided ms.
     * @param ms - Elapsed time in milliseconds to trigger an abort.
     */ static timeout(ms) {
        const signal = new (0, _abortSignal.AbortSignal)();
        const timer = setTimeout((0, _abortSignal.abortSignal), ms, signal);
        // Prevent the active Timer from keeping the Node.js event loop active.
        if (typeof timer.unref === "function") timer.unref();
        return signal;
    }
}

},{"./AbortSignal":"bM4Ui","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bM4Ui":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/// <reference path="../shims-public.d.ts" />
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * An aborter instance implements AbortSignal interface, can abort HTTP requests.
 *
 * - Call AbortSignal.none to create a new AbortSignal instance that cannot be cancelled.
 * Use `AbortSignal.none` when you are required to pass a cancellation token but the operation
 * cannot or will not ever be cancelled.
 *
 * @example
 * Abort without timeout
 * ```ts
 * await doAsyncWork(AbortSignal.none);
 * ```
 */ parcelHelpers.export(exports, "AbortSignal", ()=>AbortSignal);
/**
 * Helper to trigger an abort event immediately, the onabort and all abort event listeners will be triggered.
 * Will try to trigger abort event for all linked AbortSignal nodes.
 *
 * - If there is a timeout, the timer will be cancelled.
 * - If aborted is true, nothing will happen.
 *
 * @internal
 */ // eslint-disable-next-line @azure/azure-sdk/ts-use-interface-parameters
parcelHelpers.export(exports, "abortSignal", ()=>abortSignal);
const listenersMap = new WeakMap();
const abortedMap = new WeakMap();
class AbortSignal {
    constructor(){
        /**
         * onabort event listener.
         */ this.onabort = null;
        listenersMap.set(this, []);
        abortedMap.set(this, false);
    }
    /**
     * Status of whether aborted or not.
     *
     * @readonly
     */ get aborted() {
        if (!abortedMap.has(this)) throw new TypeError("Expected `this` to be an instance of AbortSignal.");
        return abortedMap.get(this);
    }
    /**
     * Creates a new AbortSignal instance that will never be aborted.
     *
     * @readonly
     */ static get none() {
        return new AbortSignal();
    }
    /**
     * Added new "abort" event listener, only support "abort" event.
     *
     * @param _type - Only support "abort" event
     * @param listener - The listener to be added
     */ addEventListener(// tslint:disable-next-line:variable-name
    _type, listener) {
        if (!listenersMap.has(this)) throw new TypeError("Expected `this` to be an instance of AbortSignal.");
        const listeners = listenersMap.get(this);
        listeners.push(listener);
    }
    /**
     * Remove "abort" event listener, only support "abort" event.
     *
     * @param _type - Only support "abort" event
     * @param listener - The listener to be removed
     */ removeEventListener(// tslint:disable-next-line:variable-name
    _type, listener) {
        if (!listenersMap.has(this)) throw new TypeError("Expected `this` to be an instance of AbortSignal.");
        const listeners = listenersMap.get(this);
        const index = listeners.indexOf(listener);
        if (index > -1) listeners.splice(index, 1);
    }
    /**
     * Dispatches a synthetic event to the AbortSignal.
     */ dispatchEvent(_event) {
        throw new Error("This is a stub dispatchEvent implementation that should not be used.  It only exists for type-checking purposes.");
    }
}
function abortSignal(signal) {
    if (signal.aborted) return;
    if (signal.onabort) signal.onabort.call(signal);
    const listeners = listenersMap.get(signal);
    if (listeners) // Create a copy of listeners so mutations to the array
    // (e.g. via removeListener calls) don't affect the listeners
    // we invoke.
    listeners.slice().forEach((listener)=>{
        listener.call(signal, {
            type: "abort"
        });
    });
    abortedMap.set(signal, true);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9jet0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The base class from which all request policies derive.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BaseRequestPolicy", ()=>BaseRequestPolicy);
class BaseRequestPolicy {
    /**
     * The main method to implement that manipulates a request/response.
     */ constructor(/**
     * The next policy in the pipeline. Each policy is responsible for executing the next one if the request is to continue through the pipeline.
     */ _nextPolicy, /**
     * The options that can be passed to a given request policy.
     */ _options){
        this._nextPolicy = _nextPolicy;
        this._options = _options;
    }
    /**
     * Get whether or not a log with the provided log level should be logged.
     * @param logLevel - The log level of the log that will be logged.
     * @returns Whether or not a log with the provided log level should be logged.
     */ shouldLog(logLevel) {
        return this._options.shouldLog(logLevel);
    }
    /**
     * Attempt to log the provided message to the provided logger. If no logger was provided or if
     * the log level does not meat the logger's threshold, then nothing will be logged.
     * @param logLevel - The log level of this log.
     * @param message - The message of this log.
     */ log(logLevel, message) {
        this._options.log(logLevel, message);
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4gX5x":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "SDK_VERSION", ()=>SDK_VERSION);
parcelHelpers.export(exports, "SERVICE_VERSION", ()=>SERVICE_VERSION);
parcelHelpers.export(exports, "BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES", ()=>BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES);
parcelHelpers.export(exports, "BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES", ()=>BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES);
parcelHelpers.export(exports, "BLOCK_BLOB_MAX_BLOCKS", ()=>BLOCK_BLOB_MAX_BLOCKS);
parcelHelpers.export(exports, "DEFAULT_BLOCK_BUFFER_SIZE_BYTES", ()=>DEFAULT_BLOCK_BUFFER_SIZE_BYTES);
parcelHelpers.export(exports, "DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES", ()=>DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES);
parcelHelpers.export(exports, "DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS", ()=>DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS);
parcelHelpers.export(exports, "REQUEST_TIMEOUT", ()=>REQUEST_TIMEOUT);
parcelHelpers.export(exports, "StorageOAuthScopes", ()=>StorageOAuthScopes);
parcelHelpers.export(exports, "URLConstants", ()=>URLConstants);
parcelHelpers.export(exports, "HTTPURLConnection", ()=>HTTPURLConnection);
parcelHelpers.export(exports, "HeaderConstants", ()=>HeaderConstants);
parcelHelpers.export(exports, "ETagNone", ()=>ETagNone);
parcelHelpers.export(exports, "ETagAny", ()=>ETagAny);
parcelHelpers.export(exports, "SIZE_1_MB", ()=>SIZE_1_MB);
parcelHelpers.export(exports, "BATCH_MAX_REQUEST", ()=>BATCH_MAX_REQUEST);
parcelHelpers.export(exports, "BATCH_MAX_PAYLOAD_IN_BYTES", ()=>BATCH_MAX_PAYLOAD_IN_BYTES);
parcelHelpers.export(exports, "HTTP_LINE_ENDING", ()=>HTTP_LINE_ENDING);
parcelHelpers.export(exports, "HTTP_VERSION_1_1", ()=>HTTP_VERSION_1_1);
parcelHelpers.export(exports, "EncryptionAlgorithmAES25", ()=>EncryptionAlgorithmAES25);
parcelHelpers.export(exports, "DevelopmentConnectionString", ()=>DevelopmentConnectionString);
parcelHelpers.export(exports, "StorageBlobLoggingAllowedHeaderNames", ()=>StorageBlobLoggingAllowedHeaderNames);
parcelHelpers.export(exports, "StorageBlobLoggingAllowedQueryParameters", ()=>StorageBlobLoggingAllowedQueryParameters);
parcelHelpers.export(exports, "BlobUsesCustomerSpecifiedEncryptionMsg", ()=>BlobUsesCustomerSpecifiedEncryptionMsg);
parcelHelpers.export(exports, "BlobDoesNotUseCustomerSpecifiedEncryption", ()=>BlobDoesNotUseCustomerSpecifiedEncryption);
parcelHelpers.export(exports, "PathStylePorts", ()=>PathStylePorts);
const SDK_VERSION = "12.23.0";
const SERVICE_VERSION = "2024-05-04";
const BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES = 268435456; // 256MB
const BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES = 4194304000; // 4000MB
const BLOCK_BLOB_MAX_BLOCKS = 50000;
const DEFAULT_BLOCK_BUFFER_SIZE_BYTES = 8388608; // 8MB
const DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES = 4194304; // 4MB
const DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS = 5;
const REQUEST_TIMEOUT = 100000; // In ms
const StorageOAuthScopes = "https://storage.azure.com/.default";
const URLConstants = {
    Parameters: {
        FORCE_BROWSER_NO_CACHE: "_",
        SIGNATURE: "sig",
        SNAPSHOT: "snapshot",
        VERSIONID: "versionid",
        TIMEOUT: "timeout"
    }
};
const HTTPURLConnection = {
    HTTP_ACCEPTED: 202,
    HTTP_CONFLICT: 409,
    HTTP_NOT_FOUND: 404,
    HTTP_PRECON_FAILED: 412,
    HTTP_RANGE_NOT_SATISFIABLE: 416
};
const HeaderConstants = {
    AUTHORIZATION: "Authorization",
    AUTHORIZATION_SCHEME: "Bearer",
    CONTENT_ENCODING: "Content-Encoding",
    CONTENT_ID: "Content-ID",
    CONTENT_LANGUAGE: "Content-Language",
    CONTENT_LENGTH: "Content-Length",
    CONTENT_MD5: "Content-Md5",
    CONTENT_TRANSFER_ENCODING: "Content-Transfer-Encoding",
    CONTENT_TYPE: "Content-Type",
    COOKIE: "Cookie",
    DATE: "date",
    IF_MATCH: "if-match",
    IF_MODIFIED_SINCE: "if-modified-since",
    IF_NONE_MATCH: "if-none-match",
    IF_UNMODIFIED_SINCE: "if-unmodified-since",
    PREFIX_FOR_STORAGE: "x-ms-",
    RANGE: "Range",
    USER_AGENT: "User-Agent",
    X_MS_CLIENT_REQUEST_ID: "x-ms-client-request-id",
    X_MS_COPY_SOURCE: "x-ms-copy-source",
    X_MS_DATE: "x-ms-date",
    X_MS_ERROR_CODE: "x-ms-error-code",
    X_MS_VERSION: "x-ms-version"
};
const ETagNone = "";
const ETagAny = "*";
const SIZE_1_MB = 1048576;
const BATCH_MAX_REQUEST = 256;
const BATCH_MAX_PAYLOAD_IN_BYTES = 4 * SIZE_1_MB;
const HTTP_LINE_ENDING = "\r\n";
const HTTP_VERSION_1_1 = "HTTP/1.1";
const EncryptionAlgorithmAES25 = "AES256";
const DevelopmentConnectionString = `DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;`;
const StorageBlobLoggingAllowedHeaderNames = [
    "Access-Control-Allow-Origin",
    "Cache-Control",
    "Content-Length",
    "Content-Type",
    "Date",
    "Request-Id",
    "traceparent",
    "Transfer-Encoding",
    "User-Agent",
    "x-ms-client-request-id",
    "x-ms-date",
    "x-ms-error-code",
    "x-ms-request-id",
    "x-ms-return-client-request-id",
    "x-ms-version",
    "Accept-Ranges",
    "Content-Disposition",
    "Content-Encoding",
    "Content-Language",
    "Content-MD5",
    "Content-Range",
    "ETag",
    "Last-Modified",
    "Server",
    "Vary",
    "x-ms-content-crc64",
    "x-ms-copy-action",
    "x-ms-copy-completion-time",
    "x-ms-copy-id",
    "x-ms-copy-progress",
    "x-ms-copy-status",
    "x-ms-has-immutability-policy",
    "x-ms-has-legal-hold",
    "x-ms-lease-state",
    "x-ms-lease-status",
    "x-ms-range",
    "x-ms-request-server-encrypted",
    "x-ms-server-encrypted",
    "x-ms-snapshot",
    "x-ms-source-range",
    "If-Match",
    "If-Modified-Since",
    "If-None-Match",
    "If-Unmodified-Since",
    "x-ms-access-tier",
    "x-ms-access-tier-change-time",
    "x-ms-access-tier-inferred",
    "x-ms-account-kind",
    "x-ms-archive-status",
    "x-ms-blob-append-offset",
    "x-ms-blob-cache-control",
    "x-ms-blob-committed-block-count",
    "x-ms-blob-condition-appendpos",
    "x-ms-blob-condition-maxsize",
    "x-ms-blob-content-disposition",
    "x-ms-blob-content-encoding",
    "x-ms-blob-content-language",
    "x-ms-blob-content-length",
    "x-ms-blob-content-md5",
    "x-ms-blob-content-type",
    "x-ms-blob-public-access",
    "x-ms-blob-sequence-number",
    "x-ms-blob-type",
    "x-ms-copy-destination-snapshot",
    "x-ms-creation-time",
    "x-ms-default-encryption-scope",
    "x-ms-delete-snapshots",
    "x-ms-delete-type-permanent",
    "x-ms-deny-encryption-scope-override",
    "x-ms-encryption-algorithm",
    "x-ms-if-sequence-number-eq",
    "x-ms-if-sequence-number-le",
    "x-ms-if-sequence-number-lt",
    "x-ms-incremental-copy",
    "x-ms-lease-action",
    "x-ms-lease-break-period",
    "x-ms-lease-duration",
    "x-ms-lease-id",
    "x-ms-lease-time",
    "x-ms-page-write",
    "x-ms-proposed-lease-id",
    "x-ms-range-get-content-md5",
    "x-ms-rehydrate-priority",
    "x-ms-sequence-number-action",
    "x-ms-sku-name",
    "x-ms-source-content-md5",
    "x-ms-source-if-match",
    "x-ms-source-if-modified-since",
    "x-ms-source-if-none-match",
    "x-ms-source-if-unmodified-since",
    "x-ms-tag-count",
    "x-ms-encryption-key-sha256",
    "x-ms-if-tags",
    "x-ms-source-if-tags"
];
const StorageBlobLoggingAllowedQueryParameters = [
    "comp",
    "maxresults",
    "rscc",
    "rscd",
    "rsce",
    "rscl",
    "rsct",
    "se",
    "si",
    "sip",
    "sp",
    "spr",
    "sr",
    "srt",
    "ss",
    "st",
    "sv",
    "include",
    "marker",
    "prefix",
    "copyid",
    "restype",
    "blockid",
    "blocklisttype",
    "delimiter",
    "prevsnapshot",
    "ske",
    "skoid",
    "sks",
    "skt",
    "sktid",
    "skv",
    "snapshot"
];
const BlobUsesCustomerSpecifiedEncryptionMsg = "BlobUsesCustomerSpecifiedEncryption";
const BlobDoesNotUseCustomerSpecifiedEncryption = "BlobDoesNotUseCustomerSpecifiedEncryption";
const PathStylePorts = [
    "10000",
    "10001",
    "10002",
    "10003",
    "10004",
    "10100",
    "10101",
    "10102",
    "10103",
    "10104",
    "11000",
    "11001",
    "11002",
    "11003",
    "11004",
    "11100",
    "11101",
    "11102",
    "11103",
    "11104"
];

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2SR3M":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Reserved URL characters must be properly escaped for Storage services like Blob or File.
 *
 * ## URL encode and escape strategy for JS SDKs
 *
 * When customers pass a URL string into XxxClient classes constructor, the URL string may already be URL encoded or not.
 * But before sending to Azure Storage server, the URL must be encoded. However, it's hard for a SDK to guess whether the URL
 * string has been encoded or not. We have 2 potential strategies, and chose strategy two for the XxxClient constructors.
 *
 * ### Strategy One: Assume the customer URL string is not encoded, and always encode URL string in SDK.
 *
 * This is what legacy V2 SDK does, simple and works for most of the cases.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b:",
 *   SDK will encode it to "http://account.blob.core.windows.net/con/b%3A" and send to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%3A",
 *   SDK will encode it to "http://account.blob.core.windows.net/con/b%253A" and send to server. A blob named "b%3A" will be created.
 *
 * But this strategy will make it not possible to create a blob with "?" in it's name. Because when customer URL string is
 * "http://account.blob.core.windows.net/con/blob?name", the "?name" will be treated as URL paramter instead of blob name.
 * If customer URL string is "http://account.blob.core.windows.net/con/blob%3Fname", a blob named "blob%3Fname" will be created.
 * V2 SDK doesn't have this issue because it doesn't allow customer pass in a full URL, it accepts a separate blob name and encodeURIComponent for it.
 * We cannot accept a SDK cannot create a blob name with "?". So we implement strategy two:
 *
 * ### Strategy Two: SDK doesn't assume the URL has been encoded or not. It will just escape the special characters.
 *
 * This is what V10 Blob Go SDK does. It accepts a URL type in Go, and call url.EscapedPath() to escape the special chars unescaped.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b:",
 *   SDK will escape ":" like "http://account.blob.core.windows.net/con/b%3A" and send to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%3A",
 *   There is no special characters, so send "http://account.blob.core.windows.net/con/b%3A" to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%253A",
 *   There is no special characters, so send "http://account.blob.core.windows.net/con/b%253A" to server. A blob named "b%3A" will be created.
 *
 * This strategy gives us flexibility to create with any special characters. But "%" will be treated as a special characters, if the URL string
 * is not encoded, there shouldn't a "%" in the URL string, otherwise the URL is not a valid URL.
 * If customer needs to create a blob with "%" in it's blob name, use "%25" instead of "%". Just like above 3rd sample.
 * And following URL strings are invalid:
 * - "http://account.blob.core.windows.net/con/b%"
 * - "http://account.blob.core.windows.net/con/b%2"
 * - "http://account.blob.core.windows.net/con/b%G"
 *
 * Another special character is "?", use "%2F" to represent a blob name with "?" in a URL string.
 *
 * ### Strategy for containerName, blobName or other specific XXXName parameters in methods such as `containerClient.getBlobClient(blobName)`
 *
 * We will apply strategy one, and call encodeURIComponent for these parameters like blobName. Because what customers passes in is a plain name instead of a URL.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-shares--directories--files--and-metadata
 *
 * @param url -
 */ parcelHelpers.export(exports, "escapeURLPath", ()=>escapeURLPath);
parcelHelpers.export(exports, "getValueInConnString", ()=>getValueInConnString);
/**
 * Extracts the parts of an Azure Storage account connection string.
 *
 * @param connectionString - Connection string.
 * @returns String key value pairs of the storage account's url and credentials.
 */ parcelHelpers.export(exports, "extractConnectionStringParts", ()=>extractConnectionStringParts);
/**
 * Append a string to URL path. Will remove duplicated "/" in front of the string
 * when URL path ends with a "/".
 *
 * @param url - Source URL string
 * @param name - String to be appended to URL
 * @returns An updated URL string
 */ parcelHelpers.export(exports, "appendToURLPath", ()=>appendToURLPath);
/**
 * Set URL parameter name and value. If name exists in URL parameters, old value
 * will be replaced by name key. If not provide value, the parameter will be deleted.
 *
 * @param url - Source URL string
 * @param name - Parameter name
 * @param value - Parameter value
 * @returns An updated URL string
 */ parcelHelpers.export(exports, "setURLParameter", ()=>setURLParameter);
/**
 * Get URL parameter by name.
 *
 * @param url -
 * @param name -
 */ parcelHelpers.export(exports, "getURLParameter", ()=>getURLParameter);
/**
 * Set URL host.
 *
 * @param url - Source URL string
 * @param host - New host string
 * @returns An updated URL string
 */ parcelHelpers.export(exports, "setURLHost", ()=>setURLHost);
/**
 * Get URL path from an URL string.
 *
 * @param url - Source URL string
 */ parcelHelpers.export(exports, "getURLPath", ()=>getURLPath);
/**
 * Get URL scheme from an URL string.
 *
 * @param url - Source URL string
 */ parcelHelpers.export(exports, "getURLScheme", ()=>getURLScheme);
/**
 * Get URL path and query from an URL string.
 *
 * @param url - Source URL string
 */ parcelHelpers.export(exports, "getURLPathAndQuery", ()=>getURLPathAndQuery);
/**
 * Get URL query key value pairs from an URL string.
 *
 * @param url -
 */ parcelHelpers.export(exports, "getURLQueries", ()=>getURLQueries);
/**
 * Append a string to URL query.
 *
 * @param url - Source URL string.
 * @param queryParts - String to be appended to the URL query.
 * @returns An updated URL string.
 */ parcelHelpers.export(exports, "appendToURLQuery", ()=>appendToURLQuery);
/**
 * Rounds a date off to seconds.
 *
 * @param date -
 * @param withMilliseconds - If true, YYYY-MM-DDThh:mm:ss.fffffffZ will be returned;
 *                                          If false, YYYY-MM-DDThh:mm:ssZ will be returned.
 * @returns Date string in ISO8061 format, with or without 7 milliseconds component
 */ parcelHelpers.export(exports, "truncatedISO8061Date", ()=>truncatedISO8061Date);
/**
 * Base64 encode.
 *
 * @param content -
 */ parcelHelpers.export(exports, "base64encode", ()=>base64encode);
/**
 * Base64 decode.
 *
 * @param encodedString -
 */ parcelHelpers.export(exports, "base64decode", ()=>base64decode);
/**
 * Generate a 64 bytes base64 block ID string.
 *
 * @param blockIndex -
 */ parcelHelpers.export(exports, "generateBlockID", ()=>generateBlockID);
/**
 * Delay specified time interval.
 *
 * @param timeInMs -
 * @param aborter -
 * @param abortError -
 */ parcelHelpers.export(exports, "delay", ()=>delay);
/**
 * String.prototype.padStart()
 *
 * @param currentString -
 * @param targetLength -
 * @param padString -
 */ parcelHelpers.export(exports, "padStart", ()=>padStart);
parcelHelpers.export(exports, "sanitizeURL", ()=>sanitizeURL);
parcelHelpers.export(exports, "sanitizeHeaders", ()=>sanitizeHeaders);
/**
 * If two strings are equal when compared case insensitive.
 *
 * @param str1 -
 * @param str2 -
 */ parcelHelpers.export(exports, "iEqual", ()=>iEqual);
/**
 * Extracts account name from the url
 * @param url - url to extract the account name from
 * @returns with the account name
 */ parcelHelpers.export(exports, "getAccountNameFromUrl", ()=>getAccountNameFromUrl);
parcelHelpers.export(exports, "isIpEndpointStyle", ()=>isIpEndpointStyle);
/**
 * Convert Tags to encoded string.
 *
 * @param tags -
 */ parcelHelpers.export(exports, "toBlobTagsString", ()=>toBlobTagsString);
/**
 * Convert Tags type to BlobTags.
 *
 * @param tags -
 */ parcelHelpers.export(exports, "toBlobTags", ()=>toBlobTags);
/**
 * Covert BlobTags to Tags type.
 *
 * @param tags -
 */ parcelHelpers.export(exports, "toTags", ()=>toTags);
/**
 * Convert BlobQueryTextConfiguration to QuerySerialization type.
 *
 * @param textConfiguration -
 */ parcelHelpers.export(exports, "toQuerySerialization", ()=>toQuerySerialization);
parcelHelpers.export(exports, "parseObjectReplicationRecord", ()=>parseObjectReplicationRecord);
/**
 * Attach a TokenCredential to an object.
 *
 * @param thing -
 * @param credential -
 */ parcelHelpers.export(exports, "attachCredential", ()=>attachCredential);
parcelHelpers.export(exports, "httpAuthorizationToString", ()=>httpAuthorizationToString);
parcelHelpers.export(exports, "BlobNameToString", ()=>BlobNameToString);
parcelHelpers.export(exports, "ConvertInternalResponseOfListBlobFlat", ()=>ConvertInternalResponseOfListBlobFlat);
parcelHelpers.export(exports, "ConvertInternalResponseOfListBlobHierarchy", ()=>ConvertInternalResponseOfListBlobHierarchy);
parcelHelpers.export(exports, "ExtractPageRangeInfoItems", ()=>ExtractPageRangeInfoItems);
/**
 * Escape the blobName but keep path separator ('/').
 */ parcelHelpers.export(exports, "EscapePath", ()=>EscapePath);
/**
 * A typesafe helper for ensuring that a given response object has
 * the original _response attached.
 * @param response - A response object from calling a client operation
 * @returns The same object, but with known _response property
 */ parcelHelpers.export(exports, "assertResponse", ()=>assertResponse);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreUtil = require("@azure/core-util");
var _constants = require("./constants");
var Buffer = require("dcca5190e76c2bf4").Buffer;
function escapeURLPath(url) {
    const urlParsed = new URL(url);
    let path = urlParsed.pathname;
    path = path || "/";
    path = escape(path);
    urlParsed.pathname = path;
    return urlParsed.toString();
}
function getProxyUriFromDevConnString(connectionString) {
    // Development Connection String
    // https://docs.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string#connect-to-the-emulator-account-using-the-well-known-account-name-and-key
    let proxyUri = "";
    if (connectionString.search("DevelopmentStorageProxyUri=") !== -1) {
        // CONNECTION_STRING=UseDevelopmentStorage=true;DevelopmentStorageProxyUri=http://myProxyUri
        const matchCredentials = connectionString.split(";");
        for (const element of matchCredentials)if (element.trim().startsWith("DevelopmentStorageProxyUri=")) proxyUri = element.trim().match("DevelopmentStorageProxyUri=(.*)")[1];
    }
    return proxyUri;
}
function getValueInConnString(connectionString, argument) {
    const elements = connectionString.split(";");
    for (const element of elements){
        if (element.trim().startsWith(argument)) return element.trim().match(argument + "=(.*)")[1];
    }
    return "";
}
function extractConnectionStringParts(connectionString) {
    let proxyUri = "";
    if (connectionString.startsWith("UseDevelopmentStorage=true")) {
        // Development connection string
        proxyUri = getProxyUriFromDevConnString(connectionString);
        connectionString = (0, _constants.DevelopmentConnectionString);
    }
    // Matching BlobEndpoint in the Account connection string
    let blobEndpoint = getValueInConnString(connectionString, "BlobEndpoint");
    // Slicing off '/' at the end if exists
    // (The methods that use `extractConnectionStringParts` expect the url to not have `/` at the end)
    blobEndpoint = blobEndpoint.endsWith("/") ? blobEndpoint.slice(0, -1) : blobEndpoint;
    if (connectionString.search("DefaultEndpointsProtocol=") !== -1 && connectionString.search("AccountKey=") !== -1) {
        // Account connection string
        let defaultEndpointsProtocol = "";
        let accountName = "";
        let accountKey = Buffer.from("accountKey", "base64");
        let endpointSuffix = "";
        // Get account name and key
        accountName = getValueInConnString(connectionString, "AccountName");
        accountKey = Buffer.from(getValueInConnString(connectionString, "AccountKey"), "base64");
        if (!blobEndpoint) {
            // BlobEndpoint is not present in the Account connection string
            // Can be obtained from `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`
            defaultEndpointsProtocol = getValueInConnString(connectionString, "DefaultEndpointsProtocol");
            const protocol = defaultEndpointsProtocol.toLowerCase();
            if (protocol !== "https" && protocol !== "http") throw new Error("Invalid DefaultEndpointsProtocol in the provided Connection String. Expecting 'https' or 'http'");
            endpointSuffix = getValueInConnString(connectionString, "EndpointSuffix");
            if (!endpointSuffix) throw new Error("Invalid EndpointSuffix in the provided Connection String");
            blobEndpoint = `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`;
        }
        if (!accountName) throw new Error("Invalid AccountName in the provided Connection String");
        else if (accountKey.length === 0) throw new Error("Invalid AccountKey in the provided Connection String");
        return {
            kind: "AccountConnString",
            url: blobEndpoint,
            accountName,
            accountKey,
            proxyUri
        };
    } else {
        // SAS connection string
        let accountSas = getValueInConnString(connectionString, "SharedAccessSignature");
        let accountName = getValueInConnString(connectionString, "AccountName");
        // if accountName is empty, try to read it from BlobEndpoint
        if (!accountName) accountName = getAccountNameFromUrl(blobEndpoint);
        if (!blobEndpoint) throw new Error("Invalid BlobEndpoint in the provided SAS Connection String");
        else if (!accountSas) throw new Error("Invalid SharedAccessSignature in the provided SAS Connection String");
        // client constructors assume accountSas does *not* start with ?
        if (accountSas.startsWith("?")) accountSas = accountSas.substring(1);
        return {
            kind: "SASConnString",
            url: blobEndpoint,
            accountName,
            accountSas
        };
    }
}
/**
 * Internal escape method implemented Strategy Two mentioned in escapeURL() description.
 *
 * @param text -
 */ function escape(text) {
    return encodeURIComponent(text).replace(/%2F/g, "/") // Don't escape for "/"
    .replace(/'/g, "%27") // Escape for "'"
    .replace(/\+/g, "%20").replace(/%25/g, "%"); // Revert encoded "%"
}
function appendToURLPath(url, name) {
    const urlParsed = new URL(url);
    let path = urlParsed.pathname;
    path = path ? path.endsWith("/") ? `${path}${name}` : `${path}/${name}` : name;
    urlParsed.pathname = path;
    return urlParsed.toString();
}
function setURLParameter(url, name, value) {
    const urlParsed = new URL(url);
    const encodedName = encodeURIComponent(name);
    const encodedValue = value ? encodeURIComponent(value) : undefined;
    // mutating searchParams will change the encoding, so we have to do this ourselves
    const searchString = urlParsed.search === "" ? "?" : urlParsed.search;
    const searchPieces = [];
    for (const pair of searchString.slice(1).split("&"))if (pair) {
        const [key] = pair.split("=", 2);
        if (key !== encodedName) searchPieces.push(pair);
    }
    if (encodedValue) searchPieces.push(`${encodedName}=${encodedValue}`);
    urlParsed.search = searchPieces.length ? `?${searchPieces.join("&")}` : "";
    return urlParsed.toString();
}
function getURLParameter(url, name) {
    var _a;
    const urlParsed = new URL(url);
    return (_a = urlParsed.searchParams.get(name)) !== null && _a !== void 0 ? _a : undefined;
}
function setURLHost(url, host) {
    const urlParsed = new URL(url);
    urlParsed.hostname = host;
    return urlParsed.toString();
}
function getURLPath(url) {
    try {
        const urlParsed = new URL(url);
        return urlParsed.pathname;
    } catch (e) {
        return undefined;
    }
}
function getURLScheme(url) {
    try {
        const urlParsed = new URL(url);
        return urlParsed.protocol.endsWith(":") ? urlParsed.protocol.slice(0, -1) : urlParsed.protocol;
    } catch (e) {
        return undefined;
    }
}
function getURLPathAndQuery(url) {
    const urlParsed = new URL(url);
    const pathString = urlParsed.pathname;
    if (!pathString) throw new RangeError("Invalid url without valid path.");
    let queryString = urlParsed.search || "";
    queryString = queryString.trim();
    if (queryString !== "") queryString = queryString.startsWith("?") ? queryString : `?${queryString}`; // Ensure query string start with '?'
    return `${pathString}${queryString}`;
}
function getURLQueries(url) {
    let queryString = new URL(url).search;
    if (!queryString) return {};
    queryString = queryString.trim();
    queryString = queryString.startsWith("?") ? queryString.substring(1) : queryString;
    let querySubStrings = queryString.split("&");
    querySubStrings = querySubStrings.filter((value)=>{
        const indexOfEqual = value.indexOf("=");
        const lastIndexOfEqual = value.lastIndexOf("=");
        return indexOfEqual > 0 && indexOfEqual === lastIndexOfEqual && lastIndexOfEqual < value.length - 1;
    });
    const queries = {};
    for (const querySubString of querySubStrings){
        const splitResults = querySubString.split("=");
        const key = splitResults[0];
        const value = splitResults[1];
        queries[key] = value;
    }
    return queries;
}
function appendToURLQuery(url, queryParts) {
    const urlParsed = new URL(url);
    let query = urlParsed.search;
    if (query) query += "&" + queryParts;
    else query = queryParts;
    urlParsed.search = query;
    return urlParsed.toString();
}
function truncatedISO8061Date(date, withMilliseconds = true) {
    // Date.toISOString() will return like "2018-10-29T06:34:36.139Z"
    const dateString = date.toISOString();
    return withMilliseconds ? dateString.substring(0, dateString.length - 1) + "0000" + "Z" : dateString.substring(0, dateString.length - 5) + "Z";
}
function base64encode(content) {
    return !(0, _coreUtil.isNode) ? btoa(content) : Buffer.from(content).toString("base64");
}
function base64decode(encodedString) {
    return !(0, _coreUtil.isNode) ? atob(encodedString) : Buffer.from(encodedString, "base64").toString();
}
function generateBlockID(blockIDPrefix, blockIndex) {
    // To generate a 64 bytes base64 string, source string should be 48
    const maxSourceStringLength = 48;
    // A blob can have a maximum of 100,000 uncommitted blocks at any given time
    const maxBlockIndexLength = 6;
    const maxAllowedBlockIDPrefixLength = maxSourceStringLength - maxBlockIndexLength;
    if (blockIDPrefix.length > maxAllowedBlockIDPrefixLength) blockIDPrefix = blockIDPrefix.slice(0, maxAllowedBlockIDPrefixLength);
    const res = blockIDPrefix + padStart(blockIndex.toString(), maxSourceStringLength - blockIDPrefix.length, "0");
    return base64encode(res);
}
async function delay(timeInMs, aborter, abortError) {
    return new Promise((resolve, reject)=>{
        /* eslint-disable-next-line prefer-const */ let timeout;
        const abortHandler = ()=>{
            if (timeout !== undefined) clearTimeout(timeout);
            reject(abortError);
        };
        const resolveHandler = ()=>{
            if (aborter !== undefined) aborter.removeEventListener("abort", abortHandler);
            resolve();
        };
        timeout = setTimeout(resolveHandler, timeInMs);
        if (aborter !== undefined) aborter.addEventListener("abort", abortHandler);
    });
}
function padStart(currentString, targetLength, padString = " ") {
    // @ts-expect-error: TS doesn't know this code needs to run downlevel sometimes
    if (String.prototype.padStart) return currentString.padStart(targetLength, padString);
    padString = padString || " ";
    if (currentString.length > targetLength) return currentString;
    else {
        targetLength = targetLength - currentString.length;
        if (targetLength > padString.length) padString += padString.repeat(targetLength / padString.length);
        return padString.slice(0, targetLength) + currentString;
    }
}
function sanitizeURL(url) {
    let safeURL = url;
    if (getURLParameter(safeURL, (0, _constants.URLConstants).Parameters.SIGNATURE)) safeURL = setURLParameter(safeURL, (0, _constants.URLConstants).Parameters.SIGNATURE, "*****");
    return safeURL;
}
function sanitizeHeaders(originalHeader) {
    const headers = (0, _coreRestPipeline.createHttpHeaders)();
    for (const [name, value] of originalHeader){
        if (name.toLowerCase() === (0, _constants.HeaderConstants).AUTHORIZATION.toLowerCase()) headers.set(name, "*****");
        else if (name.toLowerCase() === (0, _constants.HeaderConstants).X_MS_COPY_SOURCE) headers.set(name, sanitizeURL(value));
        else headers.set(name, value);
    }
    return headers;
}
function iEqual(str1, str2) {
    return str1.toLocaleLowerCase() === str2.toLocaleLowerCase();
}
function getAccountNameFromUrl(url) {
    const parsedUrl = new URL(url);
    let accountName;
    try {
        if (parsedUrl.hostname.split(".")[1] === "blob") // `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`;
        accountName = parsedUrl.hostname.split(".")[0];
        else if (isIpEndpointStyle(parsedUrl)) // IPv4/IPv6 address hosts... Example - http://192.0.0.10:10001/devstoreaccount1/
        // Single word domain without a [dot] in the endpoint... Example - http://localhost:10001/devstoreaccount1/
        // .getPath() -> /devstoreaccount1/
        accountName = parsedUrl.pathname.split("/")[1];
        else // Custom domain case: "https://customdomain.com/containername/blob".
        accountName = "";
        return accountName;
    } catch (error) {
        throw new Error("Unable to extract accountName with provided information.");
    }
}
function isIpEndpointStyle(parsedUrl) {
    const host = parsedUrl.host;
    // Case 1: Ipv6, use a broad regex to find out candidates whose host contains two ':'.
    // Case 2: localhost(:port) or host.docker.internal, use broad regex to match port part.
    // Case 3: Ipv4, use broad regex which just check if host contains Ipv4.
    // For valid host please refer to https://man7.org/linux/man-pages/man7/hostname.7.html.
    return /^.*:.*:.*$|^(localhost|host.docker.internal)(:[0-9]+)?$|^(\d|[1-9]\d|1\d\d|2[0-4]\d|25[0-5])(\.(\d|[1-9]\d|1\d\d|2[0-4]\d|25[0-5])){3}(:[0-9]+)?$/.test(host) || Boolean(parsedUrl.port) && (0, _constants.PathStylePorts).includes(parsedUrl.port);
}
function toBlobTagsString(tags) {
    if (tags === undefined) return undefined;
    const tagPairs = [];
    for(const key in tags)if (Object.prototype.hasOwnProperty.call(tags, key)) {
        const value = tags[key];
        tagPairs.push(`${encodeURIComponent(key)}=${encodeURIComponent(value)}`);
    }
    return tagPairs.join("&");
}
function toBlobTags(tags) {
    if (tags === undefined) return undefined;
    const res = {
        blobTagSet: []
    };
    for(const key in tags)if (Object.prototype.hasOwnProperty.call(tags, key)) {
        const value = tags[key];
        res.blobTagSet.push({
            key,
            value
        });
    }
    return res;
}
function toTags(tags) {
    if (tags === undefined) return undefined;
    const res = {};
    for (const blobTag of tags.blobTagSet)res[blobTag.key] = blobTag.value;
    return res;
}
function toQuerySerialization(textConfiguration) {
    if (textConfiguration === undefined) return undefined;
    switch(textConfiguration.kind){
        case "csv":
            return {
                format: {
                    type: "delimited",
                    delimitedTextConfiguration: {
                        columnSeparator: textConfiguration.columnSeparator || ",",
                        fieldQuote: textConfiguration.fieldQuote || "",
                        recordSeparator: textConfiguration.recordSeparator,
                        escapeChar: textConfiguration.escapeCharacter || "",
                        headersPresent: textConfiguration.hasHeaders || false
                    }
                }
            };
        case "json":
            return {
                format: {
                    type: "json",
                    jsonTextConfiguration: {
                        recordSeparator: textConfiguration.recordSeparator
                    }
                }
            };
        case "arrow":
            return {
                format: {
                    type: "arrow",
                    arrowConfiguration: {
                        schema: textConfiguration.schema
                    }
                }
            };
        case "parquet":
            return {
                format: {
                    type: "parquet"
                }
            };
        default:
            throw Error("Invalid BlobQueryTextConfiguration.");
    }
}
function parseObjectReplicationRecord(objectReplicationRecord) {
    if (!objectReplicationRecord) return undefined;
    if ("policy-id" in objectReplicationRecord) // If the dictionary contains a key with policy id, we are not required to do any parsing since
    // the policy id should already be stored in the ObjectReplicationDestinationPolicyId.
    return undefined;
    const orProperties = [];
    for(const key in objectReplicationRecord){
        const ids = key.split("_");
        const policyPrefix = "or-";
        if (ids[0].startsWith(policyPrefix)) ids[0] = ids[0].substring(policyPrefix.length);
        const rule = {
            ruleId: ids[1],
            replicationStatus: objectReplicationRecord[key]
        };
        const policyIndex = orProperties.findIndex((policy)=>policy.policyId === ids[0]);
        if (policyIndex > -1) orProperties[policyIndex].rules.push(rule);
        else orProperties.push({
            policyId: ids[0],
            rules: [
                rule
            ]
        });
    }
    return orProperties;
}
function attachCredential(thing, credential) {
    thing.credential = credential;
    return thing;
}
function httpAuthorizationToString(httpAuthorization) {
    return httpAuthorization ? httpAuthorization.scheme + " " + httpAuthorization.value : undefined;
}
function BlobNameToString(name) {
    if (name.encoded) return decodeURIComponent(name.content);
    else return name.content;
}
function ConvertInternalResponseOfListBlobFlat(internalResponse) {
    return Object.assign(Object.assign({}, internalResponse), {
        segment: {
            blobItems: internalResponse.segment.blobItems.map((blobItemInteral)=>{
                const blobItem = Object.assign(Object.assign({}, blobItemInteral), {
                    name: BlobNameToString(blobItemInteral.name)
                });
                return blobItem;
            })
        }
    });
}
function ConvertInternalResponseOfListBlobHierarchy(internalResponse) {
    var _a;
    return Object.assign(Object.assign({}, internalResponse), {
        segment: {
            blobPrefixes: (_a = internalResponse.segment.blobPrefixes) === null || _a === void 0 ? void 0 : _a.map((blobPrefixInternal)=>{
                const blobPrefix = Object.assign(Object.assign({}, blobPrefixInternal), {
                    name: BlobNameToString(blobPrefixInternal.name)
                });
                return blobPrefix;
            }),
            blobItems: internalResponse.segment.blobItems.map((blobItemInteral)=>{
                const blobItem = Object.assign(Object.assign({}, blobItemInteral), {
                    name: BlobNameToString(blobItemInteral.name)
                });
                return blobItem;
            })
        }
    });
}
function* ExtractPageRangeInfoItems(getPageRangesSegment) {
    let pageRange = [];
    let clearRange = [];
    if (getPageRangesSegment.pageRange) pageRange = getPageRangesSegment.pageRange;
    if (getPageRangesSegment.clearRange) clearRange = getPageRangesSegment.clearRange;
    let pageRangeIndex = 0;
    let clearRangeIndex = 0;
    while(pageRangeIndex < pageRange.length && clearRangeIndex < clearRange.length)if (pageRange[pageRangeIndex].start < clearRange[clearRangeIndex].start) {
        yield {
            start: pageRange[pageRangeIndex].start,
            end: pageRange[pageRangeIndex].end,
            isClear: false
        };
        ++pageRangeIndex;
    } else {
        yield {
            start: clearRange[clearRangeIndex].start,
            end: clearRange[clearRangeIndex].end,
            isClear: true
        };
        ++clearRangeIndex;
    }
    for(; pageRangeIndex < pageRange.length; ++pageRangeIndex)yield {
        start: pageRange[pageRangeIndex].start,
        end: pageRange[pageRangeIndex].end,
        isClear: false
    };
    for(; clearRangeIndex < clearRange.length; ++clearRangeIndex)yield {
        start: clearRange[clearRangeIndex].start,
        end: clearRange[clearRangeIndex].end,
        isClear: true
    };
}
function EscapePath(blobName) {
    const split = blobName.split("/");
    for(let i = 0; i < split.length; i++)split[i] = encodeURIComponent(split[i]);
    return split.join("/");
}
function assertResponse(response) {
    if (`_response` in response) return response;
    throw new TypeError(`Unexpected response object ${response}`);
}

},{"dcca5190e76c2bf4":"fCgem","@azure/core-rest-pipeline":"d0mqv","@azure/core-util":"b31OK","./constants":"4gX5x","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fCgem":[function(require,module,exports) {
/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */ /* eslint-disable no-proto */ "use strict";
const base64 = require("9c62938f1dccc73c");
const ieee754 = require("aceacb6a4531a9d2");
const customInspectSymbol = typeof Symbol === "function" && typeof Symbol["for"] === "function" // eslint-disable-line dot-notation
 ? Symbol["for"]("nodejs.util.inspect.custom") // eslint-disable-line dot-notation
 : null;
exports.Buffer = Buffer;
exports.SlowBuffer = SlowBuffer;
exports.INSPECT_MAX_BYTES = 50;
const K_MAX_LENGTH = 0x7fffffff;
exports.kMaxLength = K_MAX_LENGTH;
/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
 *               implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * We report that the browser does not support typed arrays if the are not subclassable
 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
 * for __proto__ and has a buggy typed array implementation.
 */ Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport();
if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== "undefined" && typeof console.error === "function") console.error("This browser lacks typed array (Uint8Array) support which is required by `buffer` v5.x. Use `buffer` v4.x if you require old browser support.");
function typedArraySupport() {
    // Can typed array instances can be augmented?
    try {
        const arr = new Uint8Array(1);
        const proto = {
            foo: function() {
                return 42;
            }
        };
        Object.setPrototypeOf(proto, Uint8Array.prototype);
        Object.setPrototypeOf(arr, proto);
        return arr.foo() === 42;
    } catch (e) {
        return false;
    }
}
Object.defineProperty(Buffer.prototype, "parent", {
    enumerable: true,
    get: function() {
        if (!Buffer.isBuffer(this)) return undefined;
        return this.buffer;
    }
});
Object.defineProperty(Buffer.prototype, "offset", {
    enumerable: true,
    get: function() {
        if (!Buffer.isBuffer(this)) return undefined;
        return this.byteOffset;
    }
});
function createBuffer(length) {
    if (length > K_MAX_LENGTH) throw new RangeError('The value "' + length + '" is invalid for option "size"');
    // Return an augmented `Uint8Array` instance
    const buf = new Uint8Array(length);
    Object.setPrototypeOf(buf, Buffer.prototype);
    return buf;
}
/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */ function Buffer(arg, encodingOrOffset, length) {
    // Common case.
    if (typeof arg === "number") {
        if (typeof encodingOrOffset === "string") throw new TypeError('The "string" argument must be of type string. Received type number');
        return allocUnsafe(arg);
    }
    return from(arg, encodingOrOffset, length);
}
Buffer.poolSize = 8192 // not used by this implementation
;
function from(value, encodingOrOffset, length) {
    if (typeof value === "string") return fromString(value, encodingOrOffset);
    if (ArrayBuffer.isView(value)) return fromArrayView(value);
    if (value == null) throw new TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type " + typeof value);
    if (isInstance(value, ArrayBuffer) || value && isInstance(value.buffer, ArrayBuffer)) return fromArrayBuffer(value, encodingOrOffset, length);
    if (typeof SharedArrayBuffer !== "undefined" && (isInstance(value, SharedArrayBuffer) || value && isInstance(value.buffer, SharedArrayBuffer))) return fromArrayBuffer(value, encodingOrOffset, length);
    if (typeof value === "number") throw new TypeError('The "value" argument must not be of type number. Received type number');
    const valueOf = value.valueOf && value.valueOf();
    if (valueOf != null && valueOf !== value) return Buffer.from(valueOf, encodingOrOffset, length);
    const b = fromObject(value);
    if (b) return b;
    if (typeof Symbol !== "undefined" && Symbol.toPrimitive != null && typeof value[Symbol.toPrimitive] === "function") return Buffer.from(value[Symbol.toPrimitive]("string"), encodingOrOffset, length);
    throw new TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type " + typeof value);
}
/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/ Buffer.from = function(value, encodingOrOffset, length) {
    return from(value, encodingOrOffset, length);
};
// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
// https://github.com/feross/buffer/pull/148
Object.setPrototypeOf(Buffer.prototype, Uint8Array.prototype);
Object.setPrototypeOf(Buffer, Uint8Array);
function assertSize(size) {
    if (typeof size !== "number") throw new TypeError('"size" argument must be of type number');
    else if (size < 0) throw new RangeError('The value "' + size + '" is invalid for option "size"');
}
function alloc(size, fill, encoding) {
    assertSize(size);
    if (size <= 0) return createBuffer(size);
    if (fill !== undefined) // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpreted as a start offset.
    return typeof encoding === "string" ? createBuffer(size).fill(fill, encoding) : createBuffer(size).fill(fill);
    return createBuffer(size);
}
/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/ Buffer.alloc = function(size, fill, encoding) {
    return alloc(size, fill, encoding);
};
function allocUnsafe(size) {
    assertSize(size);
    return createBuffer(size < 0 ? 0 : checked(size) | 0);
}
/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */ Buffer.allocUnsafe = function(size) {
    return allocUnsafe(size);
};
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */ Buffer.allocUnsafeSlow = function(size) {
    return allocUnsafe(size);
};
function fromString(string, encoding) {
    if (typeof encoding !== "string" || encoding === "") encoding = "utf8";
    if (!Buffer.isEncoding(encoding)) throw new TypeError("Unknown encoding: " + encoding);
    const length = byteLength(string, encoding) | 0;
    let buf = createBuffer(length);
    const actual = buf.write(string, encoding);
    if (actual !== length) // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    buf = buf.slice(0, actual);
    return buf;
}
function fromArrayLike(array) {
    const length = array.length < 0 ? 0 : checked(array.length) | 0;
    const buf = createBuffer(length);
    for(let i = 0; i < length; i += 1)buf[i] = array[i] & 255;
    return buf;
}
function fromArrayView(arrayView) {
    if (isInstance(arrayView, Uint8Array)) {
        const copy = new Uint8Array(arrayView);
        return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength);
    }
    return fromArrayLike(arrayView);
}
function fromArrayBuffer(array, byteOffset, length) {
    if (byteOffset < 0 || array.byteLength < byteOffset) throw new RangeError('"offset" is outside of buffer bounds');
    if (array.byteLength < byteOffset + (length || 0)) throw new RangeError('"length" is outside of buffer bounds');
    let buf;
    if (byteOffset === undefined && length === undefined) buf = new Uint8Array(array);
    else if (length === undefined) buf = new Uint8Array(array, byteOffset);
    else buf = new Uint8Array(array, byteOffset, length);
    // Return an augmented `Uint8Array` instance
    Object.setPrototypeOf(buf, Buffer.prototype);
    return buf;
}
function fromObject(obj) {
    if (Buffer.isBuffer(obj)) {
        const len = checked(obj.length) | 0;
        const buf = createBuffer(len);
        if (buf.length === 0) return buf;
        obj.copy(buf, 0, 0, len);
        return buf;
    }
    if (obj.length !== undefined) {
        if (typeof obj.length !== "number" || numberIsNaN(obj.length)) return createBuffer(0);
        return fromArrayLike(obj);
    }
    if (obj.type === "Buffer" && Array.isArray(obj.data)) return fromArrayLike(obj.data);
}
function checked(length) {
    // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
    // length is NaN (which is otherwise coerced to zero.)
    if (length >= K_MAX_LENGTH) throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x" + K_MAX_LENGTH.toString(16) + " bytes");
    return length | 0;
}
function SlowBuffer(length) {
    if (+length != length) length = 0;
    return Buffer.alloc(+length);
}
Buffer.isBuffer = function isBuffer(b) {
    return b != null && b._isBuffer === true && b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
    ;
};
Buffer.compare = function compare(a, b) {
    if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength);
    if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength);
    if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) throw new TypeError('The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array');
    if (a === b) return 0;
    let x = a.length;
    let y = b.length;
    for(let i = 0, len = Math.min(x, y); i < len; ++i)if (a[i] !== b[i]) {
        x = a[i];
        y = b[i];
        break;
    }
    if (x < y) return -1;
    if (y < x) return 1;
    return 0;
};
Buffer.isEncoding = function isEncoding(encoding) {
    switch(String(encoding).toLowerCase()){
        case "hex":
        case "utf8":
        case "utf-8":
        case "ascii":
        case "latin1":
        case "binary":
        case "base64":
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
            return true;
        default:
            return false;
    }
};
Buffer.concat = function concat(list, length) {
    if (!Array.isArray(list)) throw new TypeError('"list" argument must be an Array of Buffers');
    if (list.length === 0) return Buffer.alloc(0);
    let i;
    if (length === undefined) {
        length = 0;
        for(i = 0; i < list.length; ++i)length += list[i].length;
    }
    const buffer = Buffer.allocUnsafe(length);
    let pos = 0;
    for(i = 0; i < list.length; ++i){
        let buf = list[i];
        if (isInstance(buf, Uint8Array)) {
            if (pos + buf.length > buffer.length) {
                if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf);
                buf.copy(buffer, pos);
            } else Uint8Array.prototype.set.call(buffer, buf, pos);
        } else if (!Buffer.isBuffer(buf)) throw new TypeError('"list" argument must be an Array of Buffers');
        else buf.copy(buffer, pos);
        pos += buf.length;
    }
    return buffer;
};
function byteLength(string, encoding) {
    if (Buffer.isBuffer(string)) return string.length;
    if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) return string.byteLength;
    if (typeof string !== "string") throw new TypeError('The "string" argument must be one of type string, Buffer, or ArrayBuffer. Received type ' + typeof string);
    const len = string.length;
    const mustMatch = arguments.length > 2 && arguments[2] === true;
    if (!mustMatch && len === 0) return 0;
    // Use a for loop to avoid recursion
    let loweredCase = false;
    for(;;)switch(encoding){
        case "ascii":
        case "latin1":
        case "binary":
            return len;
        case "utf8":
        case "utf-8":
            return utf8ToBytes(string).length;
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
            return len * 2;
        case "hex":
            return len >>> 1;
        case "base64":
            return base64ToBytes(string).length;
        default:
            if (loweredCase) return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
            ;
            encoding = ("" + encoding).toLowerCase();
            loweredCase = true;
    }
}
Buffer.byteLength = byteLength;
function slowToString(encoding, start, end) {
    let loweredCase = false;
    // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
    // property of a typed array.
    // This behaves neither like String nor Uint8Array in that we set start/end
    // to their upper/lower bounds if the value passed is out of range.
    // undefined is handled specially as per ECMA-262 6th Edition,
    // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
    if (start === undefined || start < 0) start = 0;
    // Return early if start > this.length. Done here to prevent potential uint32
    // coercion fail below.
    if (start > this.length) return "";
    if (end === undefined || end > this.length) end = this.length;
    if (end <= 0) return "";
    // Force coercion to uint32. This will also coerce falsey/NaN values to 0.
    end >>>= 0;
    start >>>= 0;
    if (end <= start) return "";
    if (!encoding) encoding = "utf8";
    while(true)switch(encoding){
        case "hex":
            return hexSlice(this, start, end);
        case "utf8":
        case "utf-8":
            return utf8Slice(this, start, end);
        case "ascii":
            return asciiSlice(this, start, end);
        case "latin1":
        case "binary":
            return latin1Slice(this, start, end);
        case "base64":
            return base64Slice(this, start, end);
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
            return utf16leSlice(this, start, end);
        default:
            if (loweredCase) throw new TypeError("Unknown encoding: " + encoding);
            encoding = (encoding + "").toLowerCase();
            loweredCase = true;
    }
}
// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
// reliably in a browserify context because there could be multiple different
// copies of the 'buffer' package in use. This method works even for Buffer
// instances that were created from another copy of the `buffer` package.
// See: https://github.com/feross/buffer/issues/154
Buffer.prototype._isBuffer = true;
function swap(b, n, m) {
    const i = b[n];
    b[n] = b[m];
    b[m] = i;
}
Buffer.prototype.swap16 = function swap16() {
    const len = this.length;
    if (len % 2 !== 0) throw new RangeError("Buffer size must be a multiple of 16-bits");
    for(let i = 0; i < len; i += 2)swap(this, i, i + 1);
    return this;
};
Buffer.prototype.swap32 = function swap32() {
    const len = this.length;
    if (len % 4 !== 0) throw new RangeError("Buffer size must be a multiple of 32-bits");
    for(let i = 0; i < len; i += 4){
        swap(this, i, i + 3);
        swap(this, i + 1, i + 2);
    }
    return this;
};
Buffer.prototype.swap64 = function swap64() {
    const len = this.length;
    if (len % 8 !== 0) throw new RangeError("Buffer size must be a multiple of 64-bits");
    for(let i = 0; i < len; i += 8){
        swap(this, i, i + 7);
        swap(this, i + 1, i + 6);
        swap(this, i + 2, i + 5);
        swap(this, i + 3, i + 4);
    }
    return this;
};
Buffer.prototype.toString = function toString() {
    const length = this.length;
    if (length === 0) return "";
    if (arguments.length === 0) return utf8Slice(this, 0, length);
    return slowToString.apply(this, arguments);
};
Buffer.prototype.toLocaleString = Buffer.prototype.toString;
Buffer.prototype.equals = function equals(b) {
    if (!Buffer.isBuffer(b)) throw new TypeError("Argument must be a Buffer");
    if (this === b) return true;
    return Buffer.compare(this, b) === 0;
};
Buffer.prototype.inspect = function inspect() {
    let str = "";
    const max = exports.INSPECT_MAX_BYTES;
    str = this.toString("hex", 0, max).replace(/(.{2})/g, "$1 ").trim();
    if (this.length > max) str += " ... ";
    return "<Buffer " + str + ">";
};
if (customInspectSymbol) Buffer.prototype[customInspectSymbol] = Buffer.prototype.inspect;
Buffer.prototype.compare = function compare(target, start, end, thisStart, thisEnd) {
    if (isInstance(target, Uint8Array)) target = Buffer.from(target, target.offset, target.byteLength);
    if (!Buffer.isBuffer(target)) throw new TypeError('The "target" argument must be one of type Buffer or Uint8Array. Received type ' + typeof target);
    if (start === undefined) start = 0;
    if (end === undefined) end = target ? target.length : 0;
    if (thisStart === undefined) thisStart = 0;
    if (thisEnd === undefined) thisEnd = this.length;
    if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) throw new RangeError("out of range index");
    if (thisStart >= thisEnd && start >= end) return 0;
    if (thisStart >= thisEnd) return -1;
    if (start >= end) return 1;
    start >>>= 0;
    end >>>= 0;
    thisStart >>>= 0;
    thisEnd >>>= 0;
    if (this === target) return 0;
    let x = thisEnd - thisStart;
    let y = end - start;
    const len = Math.min(x, y);
    const thisCopy = this.slice(thisStart, thisEnd);
    const targetCopy = target.slice(start, end);
    for(let i = 0; i < len; ++i)if (thisCopy[i] !== targetCopy[i]) {
        x = thisCopy[i];
        y = targetCopy[i];
        break;
    }
    if (x < y) return -1;
    if (y < x) return 1;
    return 0;
};
// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf(buffer, val, byteOffset, encoding, dir) {
    // Empty buffer means no match
    if (buffer.length === 0) return -1;
    // Normalize byteOffset
    if (typeof byteOffset === "string") {
        encoding = byteOffset;
        byteOffset = 0;
    } else if (byteOffset > 0x7fffffff) byteOffset = 0x7fffffff;
    else if (byteOffset < -2147483648) byteOffset = -2147483648;
    byteOffset = +byteOffset // Coerce to Number.
    ;
    if (numberIsNaN(byteOffset)) // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : buffer.length - 1;
    // Normalize byteOffset: negative offsets start from the end of the buffer
    if (byteOffset < 0) byteOffset = buffer.length + byteOffset;
    if (byteOffset >= buffer.length) {
        if (dir) return -1;
        else byteOffset = buffer.length - 1;
    } else if (byteOffset < 0) {
        if (dir) byteOffset = 0;
        else return -1;
    }
    // Normalize val
    if (typeof val === "string") val = Buffer.from(val, encoding);
    // Finally, search either indexOf (if dir is true) or lastIndexOf
    if (Buffer.isBuffer(val)) {
        // Special case: looking for empty string/buffer always fails
        if (val.length === 0) return -1;
        return arrayIndexOf(buffer, val, byteOffset, encoding, dir);
    } else if (typeof val === "number") {
        val = val & 0xFF // Search for a byte value [0-255]
        ;
        if (typeof Uint8Array.prototype.indexOf === "function") {
            if (dir) return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset);
            else return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset);
        }
        return arrayIndexOf(buffer, [
            val
        ], byteOffset, encoding, dir);
    }
    throw new TypeError("val must be string, number or Buffer");
}
function arrayIndexOf(arr, val, byteOffset, encoding, dir) {
    let indexSize = 1;
    let arrLength = arr.length;
    let valLength = val.length;
    if (encoding !== undefined) {
        encoding = String(encoding).toLowerCase();
        if (encoding === "ucs2" || encoding === "ucs-2" || encoding === "utf16le" || encoding === "utf-16le") {
            if (arr.length < 2 || val.length < 2) return -1;
            indexSize = 2;
            arrLength /= 2;
            valLength /= 2;
            byteOffset /= 2;
        }
    }
    function read(buf, i) {
        if (indexSize === 1) return buf[i];
        else return buf.readUInt16BE(i * indexSize);
    }
    let i;
    if (dir) {
        let foundIndex = -1;
        for(i = byteOffset; i < arrLength; i++)if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
            if (foundIndex === -1) foundIndex = i;
            if (i - foundIndex + 1 === valLength) return foundIndex * indexSize;
        } else {
            if (foundIndex !== -1) i -= i - foundIndex;
            foundIndex = -1;
        }
    } else {
        if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength;
        for(i = byteOffset; i >= 0; i--){
            let found = true;
            for(let j = 0; j < valLength; j++)if (read(arr, i + j) !== read(val, j)) {
                found = false;
                break;
            }
            if (found) return i;
        }
    }
    return -1;
}
Buffer.prototype.includes = function includes(val, byteOffset, encoding) {
    return this.indexOf(val, byteOffset, encoding) !== -1;
};
Buffer.prototype.indexOf = function indexOf(val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, true);
};
Buffer.prototype.lastIndexOf = function lastIndexOf(val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, false);
};
function hexWrite(buf, string, offset, length) {
    offset = Number(offset) || 0;
    const remaining = buf.length - offset;
    if (!length) length = remaining;
    else {
        length = Number(length);
        if (length > remaining) length = remaining;
    }
    const strLen = string.length;
    if (length > strLen / 2) length = strLen / 2;
    let i;
    for(i = 0; i < length; ++i){
        const parsed = parseInt(string.substr(i * 2, 2), 16);
        if (numberIsNaN(parsed)) return i;
        buf[offset + i] = parsed;
    }
    return i;
}
function utf8Write(buf, string, offset, length) {
    return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length);
}
function asciiWrite(buf, string, offset, length) {
    return blitBuffer(asciiToBytes(string), buf, offset, length);
}
function base64Write(buf, string, offset, length) {
    return blitBuffer(base64ToBytes(string), buf, offset, length);
}
function ucs2Write(buf, string, offset, length) {
    return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length);
}
Buffer.prototype.write = function write(string, offset, length, encoding) {
    // Buffer#write(string)
    if (offset === undefined) {
        encoding = "utf8";
        length = this.length;
        offset = 0;
    // Buffer#write(string, encoding)
    } else if (length === undefined && typeof offset === "string") {
        encoding = offset;
        length = this.length;
        offset = 0;
    // Buffer#write(string, offset[, length][, encoding])
    } else if (isFinite(offset)) {
        offset = offset >>> 0;
        if (isFinite(length)) {
            length = length >>> 0;
            if (encoding === undefined) encoding = "utf8";
        } else {
            encoding = length;
            length = undefined;
        }
    } else throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");
    const remaining = this.length - offset;
    if (length === undefined || length > remaining) length = remaining;
    if (string.length > 0 && (length < 0 || offset < 0) || offset > this.length) throw new RangeError("Attempt to write outside buffer bounds");
    if (!encoding) encoding = "utf8";
    let loweredCase = false;
    for(;;)switch(encoding){
        case "hex":
            return hexWrite(this, string, offset, length);
        case "utf8":
        case "utf-8":
            return utf8Write(this, string, offset, length);
        case "ascii":
        case "latin1":
        case "binary":
            return asciiWrite(this, string, offset, length);
        case "base64":
            // Warning: maxLength not taken into account in base64Write
            return base64Write(this, string, offset, length);
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
            return ucs2Write(this, string, offset, length);
        default:
            if (loweredCase) throw new TypeError("Unknown encoding: " + encoding);
            encoding = ("" + encoding).toLowerCase();
            loweredCase = true;
    }
};
Buffer.prototype.toJSON = function toJSON() {
    return {
        type: "Buffer",
        data: Array.prototype.slice.call(this._arr || this, 0)
    };
};
function base64Slice(buf, start, end) {
    if (start === 0 && end === buf.length) return base64.fromByteArray(buf);
    else return base64.fromByteArray(buf.slice(start, end));
}
function utf8Slice(buf, start, end) {
    end = Math.min(buf.length, end);
    const res = [];
    let i = start;
    while(i < end){
        const firstByte = buf[i];
        let codePoint = null;
        let bytesPerSequence = firstByte > 0xEF ? 4 : firstByte > 0xDF ? 3 : firstByte > 0xBF ? 2 : 1;
        if (i + bytesPerSequence <= end) {
            let secondByte, thirdByte, fourthByte, tempCodePoint;
            switch(bytesPerSequence){
                case 1:
                    if (firstByte < 0x80) codePoint = firstByte;
                    break;
                case 2:
                    secondByte = buf[i + 1];
                    if ((secondByte & 0xC0) === 0x80) {
                        tempCodePoint = (firstByte & 0x1F) << 0x6 | secondByte & 0x3F;
                        if (tempCodePoint > 0x7F) codePoint = tempCodePoint;
                    }
                    break;
                case 3:
                    secondByte = buf[i + 1];
                    thirdByte = buf[i + 2];
                    if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
                        tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | thirdByte & 0x3F;
                        if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) codePoint = tempCodePoint;
                    }
                    break;
                case 4:
                    secondByte = buf[i + 1];
                    thirdByte = buf[i + 2];
                    fourthByte = buf[i + 3];
                    if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
                        tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | fourthByte & 0x3F;
                        if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) codePoint = tempCodePoint;
                    }
            }
        }
        if (codePoint === null) {
            // we did not generate a valid codePoint so insert a
            // replacement char (U+FFFD) and advance only 1 byte
            codePoint = 0xFFFD;
            bytesPerSequence = 1;
        } else if (codePoint > 0xFFFF) {
            // encode to utf16 (surrogate pair dance)
            codePoint -= 0x10000;
            res.push(codePoint >>> 10 & 0x3FF | 0xD800);
            codePoint = 0xDC00 | codePoint & 0x3FF;
        }
        res.push(codePoint);
        i += bytesPerSequence;
    }
    return decodeCodePointsArray(res);
}
// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
const MAX_ARGUMENTS_LENGTH = 0x1000;
function decodeCodePointsArray(codePoints) {
    const len = codePoints.length;
    if (len <= MAX_ARGUMENTS_LENGTH) return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
    ;
    // Decode in chunks to avoid "call stack size exceeded".
    let res = "";
    let i = 0;
    while(i < len)res += String.fromCharCode.apply(String, codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH));
    return res;
}
function asciiSlice(buf, start, end) {
    let ret = "";
    end = Math.min(buf.length, end);
    for(let i = start; i < end; ++i)ret += String.fromCharCode(buf[i] & 0x7F);
    return ret;
}
function latin1Slice(buf, start, end) {
    let ret = "";
    end = Math.min(buf.length, end);
    for(let i = start; i < end; ++i)ret += String.fromCharCode(buf[i]);
    return ret;
}
function hexSlice(buf, start, end) {
    const len = buf.length;
    if (!start || start < 0) start = 0;
    if (!end || end < 0 || end > len) end = len;
    let out = "";
    for(let i = start; i < end; ++i)out += hexSliceLookupTable[buf[i]];
    return out;
}
function utf16leSlice(buf, start, end) {
    const bytes = buf.slice(start, end);
    let res = "";
    // If bytes.length is odd, the last 8 bits must be ignored (same as node.js)
    for(let i = 0; i < bytes.length - 1; i += 2)res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256);
    return res;
}
Buffer.prototype.slice = function slice(start, end) {
    const len = this.length;
    start = ~~start;
    end = end === undefined ? len : ~~end;
    if (start < 0) {
        start += len;
        if (start < 0) start = 0;
    } else if (start > len) start = len;
    if (end < 0) {
        end += len;
        if (end < 0) end = 0;
    } else if (end > len) end = len;
    if (end < start) end = start;
    const newBuf = this.subarray(start, end);
    // Return an augmented `Uint8Array` instance
    Object.setPrototypeOf(newBuf, Buffer.prototype);
    return newBuf;
};
/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */ function checkOffset(offset, ext, length) {
    if (offset % 1 !== 0 || offset < 0) throw new RangeError("offset is not uint");
    if (offset + ext > length) throw new RangeError("Trying to access beyond buffer length");
}
Buffer.prototype.readUintLE = Buffer.prototype.readUIntLE = function readUIntLE(offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);
    let val = this[offset];
    let mul = 1;
    let i = 0;
    while(++i < byteLength && (mul *= 0x100))val += this[offset + i] * mul;
    return val;
};
Buffer.prototype.readUintBE = Buffer.prototype.readUIntBE = function readUIntBE(offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);
    let val = this[offset + --byteLength];
    let mul = 1;
    while(byteLength > 0 && (mul *= 0x100))val += this[offset + --byteLength] * mul;
    return val;
};
Buffer.prototype.readUint8 = Buffer.prototype.readUInt8 = function readUInt8(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 1, this.length);
    return this[offset];
};
Buffer.prototype.readUint16LE = Buffer.prototype.readUInt16LE = function readUInt16LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    return this[offset] | this[offset + 1] << 8;
};
Buffer.prototype.readUint16BE = Buffer.prototype.readUInt16BE = function readUInt16BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    return this[offset] << 8 | this[offset + 1];
};
Buffer.prototype.readUint32LE = Buffer.prototype.readUInt32LE = function readUInt32LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return (this[offset] | this[offset + 1] << 8 | this[offset + 2] << 16) + this[offset + 3] * 0x1000000;
};
Buffer.prototype.readUint32BE = Buffer.prototype.readUInt32BE = function readUInt32BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return this[offset] * 0x1000000 + (this[offset + 1] << 16 | this[offset + 2] << 8 | this[offset + 3]);
};
Buffer.prototype.readBigUInt64LE = defineBigIntMethod(function readBigUInt64LE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) boundsError(offset, this.length - 8);
    const lo = first + this[++offset] * 256 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 24;
    const hi = this[++offset] + this[++offset] * 256 + this[++offset] * 2 ** 16 + last * 2 ** 24;
    return BigInt(lo) + (BigInt(hi) << BigInt(32));
});
Buffer.prototype.readBigUInt64BE = defineBigIntMethod(function readBigUInt64BE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) boundsError(offset, this.length - 8);
    const hi = first * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 256 + this[++offset];
    const lo = this[++offset] * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 256 + last;
    return (BigInt(hi) << BigInt(32)) + BigInt(lo);
});
Buffer.prototype.readIntLE = function readIntLE(offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);
    let val = this[offset];
    let mul = 1;
    let i = 0;
    while(++i < byteLength && (mul *= 0x100))val += this[offset + i] * mul;
    mul *= 0x80;
    if (val >= mul) val -= Math.pow(2, 8 * byteLength);
    return val;
};
Buffer.prototype.readIntBE = function readIntBE(offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);
    let i = byteLength;
    let mul = 1;
    let val = this[offset + --i];
    while(i > 0 && (mul *= 0x100))val += this[offset + --i] * mul;
    mul *= 0x80;
    if (val >= mul) val -= Math.pow(2, 8 * byteLength);
    return val;
};
Buffer.prototype.readInt8 = function readInt8(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 1, this.length);
    if (!(this[offset] & 0x80)) return this[offset];
    return (0xff - this[offset] + 1) * -1;
};
Buffer.prototype.readInt16LE = function readInt16LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    const val = this[offset] | this[offset + 1] << 8;
    return val & 0x8000 ? val | 0xFFFF0000 : val;
};
Buffer.prototype.readInt16BE = function readInt16BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    const val = this[offset + 1] | this[offset] << 8;
    return val & 0x8000 ? val | 0xFFFF0000 : val;
};
Buffer.prototype.readInt32LE = function readInt32LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return this[offset] | this[offset + 1] << 8 | this[offset + 2] << 16 | this[offset + 3] << 24;
};
Buffer.prototype.readInt32BE = function readInt32BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return this[offset] << 24 | this[offset + 1] << 16 | this[offset + 2] << 8 | this[offset + 3];
};
Buffer.prototype.readBigInt64LE = defineBigIntMethod(function readBigInt64LE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) boundsError(offset, this.length - 8);
    const val = this[offset + 4] + this[offset + 5] * 256 + this[offset + 6] * 2 ** 16 + (last << 24 // Overflow
    );
    return (BigInt(val) << BigInt(32)) + BigInt(first + this[++offset] * 256 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 24);
});
Buffer.prototype.readBigInt64BE = defineBigIntMethod(function readBigInt64BE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) boundsError(offset, this.length - 8);
    const val = (first << 24) + // Overflow
    this[++offset] * 2 ** 16 + this[++offset] * 256 + this[++offset];
    return (BigInt(val) << BigInt(32)) + BigInt(this[++offset] * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 256 + last);
});
Buffer.prototype.readFloatLE = function readFloatLE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return ieee754.read(this, offset, true, 23, 4);
};
Buffer.prototype.readFloatBE = function readFloatBE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return ieee754.read(this, offset, false, 23, 4);
};
Buffer.prototype.readDoubleLE = function readDoubleLE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 8, this.length);
    return ieee754.read(this, offset, true, 52, 8);
};
Buffer.prototype.readDoubleBE = function readDoubleBE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 8, this.length);
    return ieee754.read(this, offset, false, 52, 8);
};
function checkInt(buf, value, offset, ext, max, min) {
    if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance');
    if (value > max || value < min) throw new RangeError('"value" argument is out of bounds');
    if (offset + ext > buf.length) throw new RangeError("Index out of range");
}
Buffer.prototype.writeUintLE = Buffer.prototype.writeUIntLE = function writeUIntLE(value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) {
        const maxBytes = Math.pow(2, 8 * byteLength) - 1;
        checkInt(this, value, offset, byteLength, maxBytes, 0);
    }
    let mul = 1;
    let i = 0;
    this[offset] = value & 0xFF;
    while(++i < byteLength && (mul *= 0x100))this[offset + i] = value / mul & 0xFF;
    return offset + byteLength;
};
Buffer.prototype.writeUintBE = Buffer.prototype.writeUIntBE = function writeUIntBE(value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) {
        const maxBytes = Math.pow(2, 8 * byteLength) - 1;
        checkInt(this, value, offset, byteLength, maxBytes, 0);
    }
    let i = byteLength - 1;
    let mul = 1;
    this[offset + i] = value & 0xFF;
    while(--i >= 0 && (mul *= 0x100))this[offset + i] = value / mul & 0xFF;
    return offset + byteLength;
};
Buffer.prototype.writeUint8 = Buffer.prototype.writeUInt8 = function writeUInt8(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0);
    this[offset] = value & 0xff;
    return offset + 1;
};
Buffer.prototype.writeUint16LE = Buffer.prototype.writeUInt16LE = function writeUInt16LE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
    this[offset] = value & 0xff;
    this[offset + 1] = value >>> 8;
    return offset + 2;
};
Buffer.prototype.writeUint16BE = Buffer.prototype.writeUInt16BE = function writeUInt16BE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
    this[offset] = value >>> 8;
    this[offset + 1] = value & 0xff;
    return offset + 2;
};
Buffer.prototype.writeUint32LE = Buffer.prototype.writeUInt32LE = function writeUInt32LE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
    this[offset + 3] = value >>> 24;
    this[offset + 2] = value >>> 16;
    this[offset + 1] = value >>> 8;
    this[offset] = value & 0xff;
    return offset + 4;
};
Buffer.prototype.writeUint32BE = Buffer.prototype.writeUInt32BE = function writeUInt32BE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
    this[offset] = value >>> 24;
    this[offset + 1] = value >>> 16;
    this[offset + 2] = value >>> 8;
    this[offset + 3] = value & 0xff;
    return offset + 4;
};
function wrtBigUInt64LE(buf, value, offset, min, max) {
    checkIntBI(value, min, max, buf, offset, 7);
    let lo = Number(value & BigInt(0xffffffff));
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    return offset;
}
function wrtBigUInt64BE(buf, value, offset, min, max) {
    checkIntBI(value, min, max, buf, offset, 7);
    let lo = Number(value & BigInt(0xffffffff));
    buf[offset + 7] = lo;
    lo = lo >> 8;
    buf[offset + 6] = lo;
    lo = lo >> 8;
    buf[offset + 5] = lo;
    lo = lo >> 8;
    buf[offset + 4] = lo;
    let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
    buf[offset + 3] = hi;
    hi = hi >> 8;
    buf[offset + 2] = hi;
    hi = hi >> 8;
    buf[offset + 1] = hi;
    hi = hi >> 8;
    buf[offset] = hi;
    return offset + 8;
}
Buffer.prototype.writeBigUInt64LE = defineBigIntMethod(function writeBigUInt64LE(value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt("0xffffffffffffffff"));
});
Buffer.prototype.writeBigUInt64BE = defineBigIntMethod(function writeBigUInt64BE(value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt("0xffffffffffffffff"));
});
Buffer.prototype.writeIntLE = function writeIntLE(value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
        const limit = Math.pow(2, 8 * byteLength - 1);
        checkInt(this, value, offset, byteLength, limit - 1, -limit);
    }
    let i = 0;
    let mul = 1;
    let sub = 0;
    this[offset] = value & 0xFF;
    while(++i < byteLength && (mul *= 0x100)){
        if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) sub = 1;
        this[offset + i] = (value / mul >> 0) - sub & 0xFF;
    }
    return offset + byteLength;
};
Buffer.prototype.writeIntBE = function writeIntBE(value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
        const limit = Math.pow(2, 8 * byteLength - 1);
        checkInt(this, value, offset, byteLength, limit - 1, -limit);
    }
    let i = byteLength - 1;
    let mul = 1;
    let sub = 0;
    this[offset + i] = value & 0xFF;
    while(--i >= 0 && (mul *= 0x100)){
        if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) sub = 1;
        this[offset + i] = (value / mul >> 0) - sub & 0xFF;
    }
    return offset + byteLength;
};
Buffer.prototype.writeInt8 = function writeInt8(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -128);
    if (value < 0) value = 0xff + value + 1;
    this[offset] = value & 0xff;
    return offset + 1;
};
Buffer.prototype.writeInt16LE = function writeInt16LE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -32768);
    this[offset] = value & 0xff;
    this[offset + 1] = value >>> 8;
    return offset + 2;
};
Buffer.prototype.writeInt16BE = function writeInt16BE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -32768);
    this[offset] = value >>> 8;
    this[offset + 1] = value & 0xff;
    return offset + 2;
};
Buffer.prototype.writeInt32LE = function writeInt32LE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -2147483648);
    this[offset] = value & 0xff;
    this[offset + 1] = value >>> 8;
    this[offset + 2] = value >>> 16;
    this[offset + 3] = value >>> 24;
    return offset + 4;
};
Buffer.prototype.writeInt32BE = function writeInt32BE(value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -2147483648);
    if (value < 0) value = 0xffffffff + value + 1;
    this[offset] = value >>> 24;
    this[offset + 1] = value >>> 16;
    this[offset + 2] = value >>> 8;
    this[offset + 3] = value & 0xff;
    return offset + 4;
};
Buffer.prototype.writeBigInt64LE = defineBigIntMethod(function writeBigInt64LE(value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"));
});
Buffer.prototype.writeBigInt64BE = defineBigIntMethod(function writeBigInt64BE(value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"));
});
function checkIEEE754(buf, value, offset, ext, max, min) {
    if (offset + ext > buf.length) throw new RangeError("Index out of range");
    if (offset < 0) throw new RangeError("Index out of range");
}
function writeFloat(buf, value, offset, littleEndian, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -340282346638528860000000000000000000000);
    ieee754.write(buf, value, offset, littleEndian, 23, 4);
    return offset + 4;
}
Buffer.prototype.writeFloatLE = function writeFloatLE(value, offset, noAssert) {
    return writeFloat(this, value, offset, true, noAssert);
};
Buffer.prototype.writeFloatBE = function writeFloatBE(value, offset, noAssert) {
    return writeFloat(this, value, offset, false, noAssert);
};
function writeDouble(buf, value, offset, littleEndian, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000);
    ieee754.write(buf, value, offset, littleEndian, 52, 8);
    return offset + 8;
}
Buffer.prototype.writeDoubleLE = function writeDoubleLE(value, offset, noAssert) {
    return writeDouble(this, value, offset, true, noAssert);
};
Buffer.prototype.writeDoubleBE = function writeDoubleBE(value, offset, noAssert) {
    return writeDouble(this, value, offset, false, noAssert);
};
// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy(target, targetStart, start, end) {
    if (!Buffer.isBuffer(target)) throw new TypeError("argument should be a Buffer");
    if (!start) start = 0;
    if (!end && end !== 0) end = this.length;
    if (targetStart >= target.length) targetStart = target.length;
    if (!targetStart) targetStart = 0;
    if (end > 0 && end < start) end = start;
    // Copy 0 bytes; we're done
    if (end === start) return 0;
    if (target.length === 0 || this.length === 0) return 0;
    // Fatal error conditions
    if (targetStart < 0) throw new RangeError("targetStart out of bounds");
    if (start < 0 || start >= this.length) throw new RangeError("Index out of range");
    if (end < 0) throw new RangeError("sourceEnd out of bounds");
    // Are we oob?
    if (end > this.length) end = this.length;
    if (target.length - targetStart < end - start) end = target.length - targetStart + start;
    const len = end - start;
    if (this === target && typeof Uint8Array.prototype.copyWithin === "function") // Use built-in when available, missing from IE11
    this.copyWithin(targetStart, start, end);
    else Uint8Array.prototype.set.call(target, this.subarray(start, end), targetStart);
    return len;
};
// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill(val, start, end, encoding) {
    // Handle string cases:
    if (typeof val === "string") {
        if (typeof start === "string") {
            encoding = start;
            start = 0;
            end = this.length;
        } else if (typeof end === "string") {
            encoding = end;
            end = this.length;
        }
        if (encoding !== undefined && typeof encoding !== "string") throw new TypeError("encoding must be a string");
        if (typeof encoding === "string" && !Buffer.isEncoding(encoding)) throw new TypeError("Unknown encoding: " + encoding);
        if (val.length === 1) {
            const code = val.charCodeAt(0);
            if (encoding === "utf8" && code < 128 || encoding === "latin1") // Fast path: If `val` fits into a single byte, use that numeric value.
            val = code;
        }
    } else if (typeof val === "number") val = val & 255;
    else if (typeof val === "boolean") val = Number(val);
    // Invalid ranges are not set to a default, so can range check early.
    if (start < 0 || this.length < start || this.length < end) throw new RangeError("Out of range index");
    if (end <= start) return this;
    start = start >>> 0;
    end = end === undefined ? this.length : end >>> 0;
    if (!val) val = 0;
    let i;
    if (typeof val === "number") for(i = start; i < end; ++i)this[i] = val;
    else {
        const bytes = Buffer.isBuffer(val) ? val : Buffer.from(val, encoding);
        const len = bytes.length;
        if (len === 0) throw new TypeError('The value "' + val + '" is invalid for argument "value"');
        for(i = 0; i < end - start; ++i)this[i + start] = bytes[i % len];
    }
    return this;
};
// CUSTOM ERRORS
// =============
// Simplified versions from Node, changed for Buffer-only usage
const errors = {};
function E(sym, getMessage, Base) {
    errors[sym] = class NodeError extends Base {
        constructor(){
            super();
            Object.defineProperty(this, "message", {
                value: getMessage.apply(this, arguments),
                writable: true,
                configurable: true
            });
            // Add the error code to the name to include it in the stack trace.
            this.name = `${this.name} [${sym}]`;
            // Access the stack to generate the error message including the error code
            // from the name.
            this.stack // eslint-disable-line no-unused-expressions
            ;
            // Reset the name to the actual name.
            delete this.name;
        }
        get code() {
            return sym;
        }
        set code(value) {
            Object.defineProperty(this, "code", {
                configurable: true,
                enumerable: true,
                value,
                writable: true
            });
        }
        toString() {
            return `${this.name} [${sym}]: ${this.message}`;
        }
    };
}
E("ERR_BUFFER_OUT_OF_BOUNDS", function(name) {
    if (name) return `${name} is outside of buffer bounds`;
    return "Attempt to access memory outside buffer bounds";
}, RangeError);
E("ERR_INVALID_ARG_TYPE", function(name, actual) {
    return `The "${name}" argument must be of type number. Received type ${typeof actual}`;
}, TypeError);
E("ERR_OUT_OF_RANGE", function(str, range, input) {
    let msg = `The value of "${str}" is out of range.`;
    let received = input;
    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) received = addNumericalSeparator(String(input));
    else if (typeof input === "bigint") {
        received = String(input);
        if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) received = addNumericalSeparator(received);
        received += "n";
    }
    msg += ` It must be ${range}. Received ${received}`;
    return msg;
}, RangeError);
function addNumericalSeparator(val) {
    let res = "";
    let i = val.length;
    const start = val[0] === "-" ? 1 : 0;
    for(; i >= start + 4; i -= 3)res = `_${val.slice(i - 3, i)}${res}`;
    return `${val.slice(0, i)}${res}`;
}
// CHECK FUNCTIONS
// ===============
function checkBounds(buf, offset, byteLength) {
    validateNumber(offset, "offset");
    if (buf[offset] === undefined || buf[offset + byteLength] === undefined) boundsError(offset, buf.length - (byteLength + 1));
}
function checkIntBI(value, min, max, buf, offset, byteLength) {
    if (value > max || value < min) {
        const n = typeof min === "bigint" ? "n" : "";
        let range;
        if (byteLength > 3) {
            if (min === 0 || min === BigInt(0)) range = `>= 0${n} and < 2${n} ** ${(byteLength + 1) * 8}${n}`;
            else range = `>= -(2${n} ** ${(byteLength + 1) * 8 - 1}${n}) and < 2 ** ` + `${(byteLength + 1) * 8 - 1}${n}`;
        } else range = `>= ${min}${n} and <= ${max}${n}`;
        throw new errors.ERR_OUT_OF_RANGE("value", range, value);
    }
    checkBounds(buf, offset, byteLength);
}
function validateNumber(value, name) {
    if (typeof value !== "number") throw new errors.ERR_INVALID_ARG_TYPE(name, "number", value);
}
function boundsError(value, length, type) {
    if (Math.floor(value) !== value) {
        validateNumber(value, type);
        throw new errors.ERR_OUT_OF_RANGE(type || "offset", "an integer", value);
    }
    if (length < 0) throw new errors.ERR_BUFFER_OUT_OF_BOUNDS();
    throw new errors.ERR_OUT_OF_RANGE(type || "offset", `>= ${type ? 1 : 0} and <= ${length}`, value);
}
// HELPER FUNCTIONS
// ================
const INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g;
function base64clean(str) {
    // Node takes equal signs as end of the Base64 encoding
    str = str.split("=")[0];
    // Node strips out invalid characters like \n and \t from the string, base64-js does not
    str = str.trim().replace(INVALID_BASE64_RE, "");
    // Node converts strings with length < 2 to ''
    if (str.length < 2) return "";
    // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
    while(str.length % 4 !== 0)str = str + "=";
    return str;
}
function utf8ToBytes(string, units) {
    units = units || Infinity;
    let codePoint;
    const length = string.length;
    let leadSurrogate = null;
    const bytes = [];
    for(let i = 0; i < length; ++i){
        codePoint = string.charCodeAt(i);
        // is surrogate component
        if (codePoint > 0xD7FF && codePoint < 0xE000) {
            // last char was a lead
            if (!leadSurrogate) {
                // no lead yet
                if (codePoint > 0xDBFF) {
                    // unexpected trail
                    if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
                    continue;
                } else if (i + 1 === length) {
                    // unpaired lead
                    if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
                    continue;
                }
                // valid lead
                leadSurrogate = codePoint;
                continue;
            }
            // 2 leads in a row
            if (codePoint < 0xDC00) {
                if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
                leadSurrogate = codePoint;
                continue;
            }
            // valid surrogate pair
            codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000;
        } else if (leadSurrogate) // valid bmp char, but last char was a lead
        {
            if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
        }
        leadSurrogate = null;
        // encode utf8
        if (codePoint < 0x80) {
            if ((units -= 1) < 0) break;
            bytes.push(codePoint);
        } else if (codePoint < 0x800) {
            if ((units -= 2) < 0) break;
            bytes.push(codePoint >> 0x6 | 0xC0, codePoint & 0x3F | 0x80);
        } else if (codePoint < 0x10000) {
            if ((units -= 3) < 0) break;
            bytes.push(codePoint >> 0xC | 0xE0, codePoint >> 0x6 & 0x3F | 0x80, codePoint & 0x3F | 0x80);
        } else if (codePoint < 0x110000) {
            if ((units -= 4) < 0) break;
            bytes.push(codePoint >> 0x12 | 0xF0, codePoint >> 0xC & 0x3F | 0x80, codePoint >> 0x6 & 0x3F | 0x80, codePoint & 0x3F | 0x80);
        } else throw new Error("Invalid code point");
    }
    return bytes;
}
function asciiToBytes(str) {
    const byteArray = [];
    for(let i = 0; i < str.length; ++i)// Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF);
    return byteArray;
}
function utf16leToBytes(str, units) {
    let c, hi, lo;
    const byteArray = [];
    for(let i = 0; i < str.length; ++i){
        if ((units -= 2) < 0) break;
        c = str.charCodeAt(i);
        hi = c >> 8;
        lo = c % 256;
        byteArray.push(lo);
        byteArray.push(hi);
    }
    return byteArray;
}
function base64ToBytes(str) {
    return base64.toByteArray(base64clean(str));
}
function blitBuffer(src, dst, offset, length) {
    let i;
    for(i = 0; i < length; ++i){
        if (i + offset >= dst.length || i >= src.length) break;
        dst[i + offset] = src[i];
    }
    return i;
}
// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
// the `instanceof` check but they should be treated as of that type.
// See: https://github.com/feross/buffer/issues/166
function isInstance(obj, type) {
    return obj instanceof type || obj != null && obj.constructor != null && obj.constructor.name != null && obj.constructor.name === type.name;
}
function numberIsNaN(obj) {
    // For IE11 support
    return obj !== obj // eslint-disable-line no-self-compare
    ;
}
// Create lookup table for `toString('hex')`
// See: https://github.com/feross/buffer/issues/219
const hexSliceLookupTable = function() {
    const alphabet = "0123456789abcdef";
    const table = new Array(256);
    for(let i = 0; i < 16; ++i){
        const i16 = i * 16;
        for(let j = 0; j < 16; ++j)table[i16 + j] = alphabet[i] + alphabet[j];
    }
    return table;
}();
// Return not function with Error if BigInt not supported
function defineBigIntMethod(fn) {
    return typeof BigInt === "undefined" ? BufferBigIntNotDefined : fn;
}
function BufferBigIntNotDefined() {
    throw new Error("BigInt not supported");
}

},{"9c62938f1dccc73c":"eIiSV","aceacb6a4531a9d2":"cO95r"}],"eIiSV":[function(require,module,exports) {
"use strict";
exports.byteLength = byteLength;
exports.toByteArray = toByteArray;
exports.fromByteArray = fromByteArray;
var lookup = [];
var revLookup = [];
var Arr = typeof Uint8Array !== "undefined" ? Uint8Array : Array;
var code = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
for(var i = 0, len = code.length; i < len; ++i){
    lookup[i] = code[i];
    revLookup[code.charCodeAt(i)] = i;
}
// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup["-".charCodeAt(0)] = 62;
revLookup["_".charCodeAt(0)] = 63;
function getLens(b64) {
    var len = b64.length;
    if (len % 4 > 0) throw new Error("Invalid string. Length must be a multiple of 4");
    // Trim off extra bytes after placeholder bytes are found
    // See: https://github.com/beatgammit/base64-js/issues/42
    var validLen = b64.indexOf("=");
    if (validLen === -1) validLen = len;
    var placeHoldersLen = validLen === len ? 0 : 4 - validLen % 4;
    return [
        validLen,
        placeHoldersLen
    ];
}
// base64 is 4/3 + up to two characters of the original data
function byteLength(b64) {
    var lens = getLens(b64);
    var validLen = lens[0];
    var placeHoldersLen = lens[1];
    return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
}
function _byteLength(b64, validLen, placeHoldersLen) {
    return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
}
function toByteArray(b64) {
    var tmp;
    var lens = getLens(b64);
    var validLen = lens[0];
    var placeHoldersLen = lens[1];
    var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen));
    var curByte = 0;
    // if there are placeholders, only get up to the last complete 4 chars
    var len = placeHoldersLen > 0 ? validLen - 4 : validLen;
    var i;
    for(i = 0; i < len; i += 4){
        tmp = revLookup[b64.charCodeAt(i)] << 18 | revLookup[b64.charCodeAt(i + 1)] << 12 | revLookup[b64.charCodeAt(i + 2)] << 6 | revLookup[b64.charCodeAt(i + 3)];
        arr[curByte++] = tmp >> 16 & 0xFF;
        arr[curByte++] = tmp >> 8 & 0xFF;
        arr[curByte++] = tmp & 0xFF;
    }
    if (placeHoldersLen === 2) {
        tmp = revLookup[b64.charCodeAt(i)] << 2 | revLookup[b64.charCodeAt(i + 1)] >> 4;
        arr[curByte++] = tmp & 0xFF;
    }
    if (placeHoldersLen === 1) {
        tmp = revLookup[b64.charCodeAt(i)] << 10 | revLookup[b64.charCodeAt(i + 1)] << 4 | revLookup[b64.charCodeAt(i + 2)] >> 2;
        arr[curByte++] = tmp >> 8 & 0xFF;
        arr[curByte++] = tmp & 0xFF;
    }
    return arr;
}
function tripletToBase64(num) {
    return lookup[num >> 18 & 0x3F] + lookup[num >> 12 & 0x3F] + lookup[num >> 6 & 0x3F] + lookup[num & 0x3F];
}
function encodeChunk(uint8, start, end) {
    var tmp;
    var output = [];
    for(var i = start; i < end; i += 3){
        tmp = (uint8[i] << 16 & 0xFF0000) + (uint8[i + 1] << 8 & 0xFF00) + (uint8[i + 2] & 0xFF);
        output.push(tripletToBase64(tmp));
    }
    return output.join("");
}
function fromByteArray(uint8) {
    var tmp;
    var len = uint8.length;
    var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
    ;
    var parts = [];
    var maxChunkLength = 16383 // must be multiple of 3
    ;
    // go through the array every three bytes, we'll deal with trailing stuff later
    for(var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength)parts.push(encodeChunk(uint8, i, i + maxChunkLength > len2 ? len2 : i + maxChunkLength));
    // pad the end with zeros, but make sure to not forget the extra bytes
    if (extraBytes === 1) {
        tmp = uint8[len - 1];
        parts.push(lookup[tmp >> 2] + lookup[tmp << 4 & 0x3F] + "==");
    } else if (extraBytes === 2) {
        tmp = (uint8[len - 2] << 8) + uint8[len - 1];
        parts.push(lookup[tmp >> 10] + lookup[tmp >> 4 & 0x3F] + lookup[tmp << 2 & 0x3F] + "=");
    }
    return parts.join("");
}

},{}],"cO95r":[function(require,module,exports) {
/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */ exports.read = function(buffer, offset, isLE, mLen, nBytes) {
    var e, m;
    var eLen = nBytes * 8 - mLen - 1;
    var eMax = (1 << eLen) - 1;
    var eBias = eMax >> 1;
    var nBits = -7;
    var i = isLE ? nBytes - 1 : 0;
    var d = isLE ? -1 : 1;
    var s = buffer[offset + i];
    i += d;
    e = s & (1 << -nBits) - 1;
    s >>= -nBits;
    nBits += eLen;
    for(; nBits > 0; e = e * 256 + buffer[offset + i], i += d, nBits -= 8);
    m = e & (1 << -nBits) - 1;
    e >>= -nBits;
    nBits += mLen;
    for(; nBits > 0; m = m * 256 + buffer[offset + i], i += d, nBits -= 8);
    if (e === 0) e = 1 - eBias;
    else if (e === eMax) return m ? NaN : (s ? -1 : 1) * Infinity;
    else {
        m = m + Math.pow(2, mLen);
        e = e - eBias;
    }
    return (s ? -1 : 1) * m * Math.pow(2, e - mLen);
};
exports.write = function(buffer, value, offset, isLE, mLen, nBytes) {
    var e, m, c;
    var eLen = nBytes * 8 - mLen - 1;
    var eMax = (1 << eLen) - 1;
    var eBias = eMax >> 1;
    var rt = mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0;
    var i = isLE ? 0 : nBytes - 1;
    var d = isLE ? 1 : -1;
    var s = value < 0 || value === 0 && 1 / value < 0 ? 1 : 0;
    value = Math.abs(value);
    if (isNaN(value) || value === Infinity) {
        m = isNaN(value) ? 1 : 0;
        e = eMax;
    } else {
        e = Math.floor(Math.log(value) / Math.LN2);
        if (value * (c = Math.pow(2, -e)) < 1) {
            e--;
            c *= 2;
        }
        if (e + eBias >= 1) value += rt / c;
        else value += rt * Math.pow(2, 1 - eBias);
        if (value * c >= 2) {
            e++;
            c /= 2;
        }
        if (e + eBias >= eMax) {
            m = 0;
            e = eMax;
        } else if (e + eBias >= 1) {
            m = (value * c - 1) * Math.pow(2, mLen);
            e = e + eBias;
        } else {
            m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen);
            e = 0;
        }
    }
    for(; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8);
    e = e << mLen | m;
    eLen += mLen;
    for(; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8);
    buffer[offset + i - d] |= s * 128;
};

},{}],"jUFIX":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "StorageSharedKeyCredential", ()=>StorageSharedKeyCredential);
class StorageSharedKeyCredential {
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f0sOe":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AnonymousCredential provides a credentialPolicyCreator member used to create
 * AnonymousCredentialPolicy objects. AnonymousCredentialPolicy is used with
 * HTTP(S) requests that read public resources or for use with Shared Access
 * Signatures (SAS).
 */ parcelHelpers.export(exports, "AnonymousCredential", ()=>AnonymousCredential);
var _anonymousCredentialPolicy = require("../policies/AnonymousCredentialPolicy");
var _credential = require("./Credential");
class AnonymousCredential extends (0, _credential.Credential) {
    /**
     * Creates an {@link AnonymousCredentialPolicy} object.
     *
     * @param nextPolicy -
     * @param options -
     */ create(nextPolicy, options) {
        return new (0, _anonymousCredentialPolicy.AnonymousCredentialPolicy)(nextPolicy, options);
    }
}

},{"../policies/AnonymousCredentialPolicy":"kNMa0","./Credential":"1Ib4y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kNMa0":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AnonymousCredentialPolicy is used with HTTP(S) requests that read public resources
 * or for use with Shared Access Signatures (SAS).
 */ parcelHelpers.export(exports, "AnonymousCredentialPolicy", ()=>AnonymousCredentialPolicy);
var _credentialPolicy = require("./CredentialPolicy");
class AnonymousCredentialPolicy extends (0, _credentialPolicy.CredentialPolicy) {
    /**
     * Creates an instance of AnonymousCredentialPolicy.
     * @param nextPolicy -
     * @param options -
     */ // The base class has a protected constructor. Adding a public one to enable constructing of this class.
    /* eslint-disable-next-line @typescript-eslint/no-useless-constructor*/ constructor(nextPolicy, options){
        super(nextPolicy, options);
    }
}

},{"./CredentialPolicy":"eiIAi","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eiIAi":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Credential policy used to sign HTTP(S) requests before sending. This is an
 * abstract class.
 */ parcelHelpers.export(exports, "CredentialPolicy", ()=>CredentialPolicy);
var _requestPolicy = require("./RequestPolicy");
class CredentialPolicy extends (0, _requestPolicy.BaseRequestPolicy) {
    /**
     * Sends out request.
     *
     * @param request -
     */ sendRequest(request) {
        return this._nextPolicy.sendRequest(this.signRequest(request));
    }
    /**
     * Child classes must implement this method with request signing. This method
     * will be executed in {@link sendRequest}.
     *
     * @param request -
     */ signRequest(request) {
        // Child classes must override this method with request signing. This method
        // will be executed in sendRequest().
        return request;
    }
}

},{"./RequestPolicy":"9jet0","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1Ib4y":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Credential is an abstract class for Azure Storage HTTP requests signing. This
 * class will host an credentialPolicyCreator factory which generates CredentialPolicy.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Credential", ()=>Credential);
class Credential {
    /**
     * Creates a RequestPolicy object.
     *
     * @param _nextPolicy -
     * @param _options -
     */ create(_nextPolicy, _options) {
        throw new Error("Method should be implemented in children classes.");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5SpI4":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getCachedDefaultHttpClient", ()=>getCachedDefaultHttpClient);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
let _defaultHttpClient;
function getCachedDefaultHttpClient() {
    if (!_defaultHttpClient) _defaultHttpClient = (0, _coreRestPipeline.createDefaultHttpClient)();
    return _defaultHttpClient;
}

},{"@azure/core-rest-pipeline":"d0mqv","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bZYoE":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "storageBrowserPolicyName", ()=>storageBrowserPolicyName);
/**
 * storageBrowserPolicy is a policy used to prevent browsers from caching requests
 * and to remove cookies and explicit content-length headers.
 */ parcelHelpers.export(exports, "storageBrowserPolicy", ()=>storageBrowserPolicy);
var _coreUtil = require("@azure/core-util");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
const storageBrowserPolicyName = "storageBrowserPolicy";
function storageBrowserPolicy() {
    return {
        name: storageBrowserPolicyName,
        async sendRequest (request, next) {
            if (0, _coreUtil.isNode) return next(request);
            if (request.method === "GET" || request.method === "HEAD") request.url = (0, _utilsCommon.setURLParameter)(request.url, (0, _constants.URLConstants).Parameters.FORCE_BROWSER_NO_CACHE, new Date().getTime().toString());
            request.headers.delete((0, _constants.HeaderConstants).COOKIE);
            // According to XHR standards, content-length should be fully controlled by browsers
            request.headers.delete((0, _constants.HeaderConstants).CONTENT_LENGTH);
            return next(request);
        }
    };
}

},{"@azure/core-util":"b31OK","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iANjf":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "storageRetryPolicyName", ()=>storageRetryPolicyName);
parcelHelpers.export(exports, "StorageRetryPolicyType", ()=>StorageRetryPolicyType);
/**
 * Retry policy with exponential retry and linear retry implemented.
 */ parcelHelpers.export(exports, "storageRetryPolicy", ()=>storageRetryPolicy);
var _abortController = require("@azure/abort-controller");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreUtil = require("@azure/core-util");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
var _log = require("../log");
const storageRetryPolicyName = "storageRetryPolicy";
var StorageRetryPolicyType;
(function(StorageRetryPolicyType) {
    /**
     * Exponential retry. Retry time delay grows exponentially.
     */ StorageRetryPolicyType[StorageRetryPolicyType["EXPONENTIAL"] = 0] = "EXPONENTIAL";
    /**
     * Linear retry. Retry time delay grows linearly.
     */ StorageRetryPolicyType[StorageRetryPolicyType["FIXED"] = 1] = "FIXED";
})(StorageRetryPolicyType || (StorageRetryPolicyType = {}));
// Default values of StorageRetryOptions
const DEFAULT_RETRY_OPTIONS = {
    maxRetryDelayInMs: 120000,
    maxTries: 4,
    retryDelayInMs: 4000,
    retryPolicyType: StorageRetryPolicyType.EXPONENTIAL,
    secondaryHost: "",
    tryTimeoutInMs: undefined
};
const retriableErrors = [
    "ETIMEDOUT",
    "ESOCKETTIMEDOUT",
    "ECONNREFUSED",
    "ECONNRESET",
    "ENOENT",
    "ENOTFOUND",
    "TIMEOUT",
    "EPIPE",
    "REQUEST_SEND_ERROR"
];
const RETRY_ABORT_ERROR = new (0, _abortController.AbortError)("The operation was aborted.");
function storageRetryPolicy(options = {}) {
    var _a, _b, _c, _d, _e, _f;
    const retryPolicyType = (_a = options.retryPolicyType) !== null && _a !== void 0 ? _a : DEFAULT_RETRY_OPTIONS.retryPolicyType;
    const maxTries = (_b = options.maxTries) !== null && _b !== void 0 ? _b : DEFAULT_RETRY_OPTIONS.maxTries;
    const retryDelayInMs = (_c = options.retryDelayInMs) !== null && _c !== void 0 ? _c : DEFAULT_RETRY_OPTIONS.retryDelayInMs;
    const maxRetryDelayInMs = (_d = options.maxRetryDelayInMs) !== null && _d !== void 0 ? _d : DEFAULT_RETRY_OPTIONS.maxRetryDelayInMs;
    const secondaryHost = (_e = options.secondaryHost) !== null && _e !== void 0 ? _e : DEFAULT_RETRY_OPTIONS.secondaryHost;
    const tryTimeoutInMs = (_f = options.tryTimeoutInMs) !== null && _f !== void 0 ? _f : DEFAULT_RETRY_OPTIONS.tryTimeoutInMs;
    function shouldRetry({ isPrimaryRetry, attempt, response, error }) {
        var _a, _b;
        if (attempt >= maxTries) {
            (0, _log.logger).info(`RetryPolicy: Attempt(s) ${attempt} >= maxTries ${maxTries}, no further try.`);
            return false;
        }
        if (error) {
            for (const retriableError of retriableErrors)if (error.name.toUpperCase().includes(retriableError) || error.message.toUpperCase().includes(retriableError) || error.code && error.code.toString().toUpperCase() === retriableError) {
                (0, _log.logger).info(`RetryPolicy: Network error ${retriableError} found, will retry.`);
                return true;
            }
            if ((error === null || error === void 0 ? void 0 : error.code) === "PARSE_ERROR" && (error === null || error === void 0 ? void 0 : error.message.startsWith(`Error "Error: Unclosed root tag`))) {
                (0, _log.logger).info("RetryPolicy: Incomplete XML response likely due to service timeout, will retry.");
                return true;
            }
        }
        // If attempt was against the secondary & it returned a StatusNotFound (404), then
        // the resource was not found. This may be due to replication delay. So, in this
        // case, we'll never try the secondary again for this operation.
        if (response || error) {
            const statusCode = (_b = (_a = response === null || response === void 0 ? void 0 : response.status) !== null && _a !== void 0 ? _a : error === null || error === void 0 ? void 0 : error.statusCode) !== null && _b !== void 0 ? _b : 0;
            if (!isPrimaryRetry && statusCode === 404) {
                (0, _log.logger).info(`RetryPolicy: Secondary access with 404, will retry.`);
                return true;
            }
            // Server internal error or server timeout
            if (statusCode === 503 || statusCode === 500) {
                (0, _log.logger).info(`RetryPolicy: Will retry for status code ${statusCode}.`);
                return true;
            }
        }
        return false;
    }
    function calculateDelay(isPrimaryRetry, attempt) {
        let delayTimeInMs = 0;
        if (isPrimaryRetry) switch(retryPolicyType){
            case StorageRetryPolicyType.EXPONENTIAL:
                delayTimeInMs = Math.min((Math.pow(2, attempt - 1) - 1) * retryDelayInMs, maxRetryDelayInMs);
                break;
            case StorageRetryPolicyType.FIXED:
                delayTimeInMs = retryDelayInMs;
                break;
        }
        else delayTimeInMs = Math.random() * 1000;
        (0, _log.logger).info(`RetryPolicy: Delay for ${delayTimeInMs}ms`);
        return delayTimeInMs;
    }
    return {
        name: storageRetryPolicyName,
        async sendRequest (request, next) {
            // Set the server-side timeout query parameter "timeout=[seconds]"
            if (tryTimeoutInMs) request.url = (0, _utilsCommon.setURLParameter)(request.url, (0, _constants.URLConstants).Parameters.TIMEOUT, String(Math.floor(tryTimeoutInMs / 1000)));
            const primaryUrl = request.url;
            const secondaryUrl = secondaryHost ? (0, _utilsCommon.setURLHost)(request.url, secondaryHost) : undefined;
            let secondaryHas404 = false;
            let attempt = 1;
            let retryAgain = true;
            let response;
            let error;
            while(retryAgain){
                const isPrimaryRetry = secondaryHas404 || !secondaryUrl || ![
                    "GET",
                    "HEAD",
                    "OPTIONS"
                ].includes(request.method) || attempt % 2 === 1;
                request.url = isPrimaryRetry ? primaryUrl : secondaryUrl;
                response = undefined;
                error = undefined;
                try {
                    (0, _log.logger).info(`RetryPolicy: =====> Try=${attempt} ${isPrimaryRetry ? "Primary" : "Secondary"}`);
                    response = await next(request);
                    secondaryHas404 = secondaryHas404 || !isPrimaryRetry && response.status === 404;
                } catch (e) {
                    if ((0, _coreRestPipeline.isRestError)(e)) {
                        (0, _log.logger).error(`RetryPolicy: Caught error, message: ${e.message}, code: ${e.code}`);
                        error = e;
                    } else {
                        (0, _log.logger).error(`RetryPolicy: Caught error, message: ${(0, _coreUtil.getErrorMessage)(e)}`);
                        throw e;
                    }
                }
                retryAgain = shouldRetry({
                    isPrimaryRetry,
                    attempt,
                    response,
                    error
                });
                if (retryAgain) await (0, _utilsCommon.delay)(calculateDelay(isPrimaryRetry, attempt), request.abortSignal, RETRY_ABORT_ERROR);
                attempt++;
            }
            if (response) return response;
            throw error !== null && error !== void 0 ? error : new (0, _coreRestPipeline.RestError)("RetryPolicy failed without known error.");
        }
    };
}

},{"@azure/abort-controller":"6HB9r","@azure/core-rest-pipeline":"d0mqv","@azure/core-util":"b31OK","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","../log":"gc1Rl","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lPMqJ":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The programmatic identifier of the storageSharedKeyCredentialPolicy.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "storageSharedKeyCredentialPolicyName", ()=>storageSharedKeyCredentialPolicyName);
/**
 * storageSharedKeyCredentialPolicy handles signing requests using storage account keys.
 */ parcelHelpers.export(exports, "storageSharedKeyCredentialPolicy", ()=>storageSharedKeyCredentialPolicy);
const storageSharedKeyCredentialPolicyName = "storageSharedKeyCredentialPolicy";
function storageSharedKeyCredentialPolicy(_options) {
    return {
        name: storageSharedKeyCredentialPolicyName,
        async sendRequest (request, next) {
            return next(request);
        }
    };
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lNMbH":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "StorageBrowserPolicy", ()=>(0, _storageBrowserPolicy.StorageBrowserPolicy));
/**
 * StorageBrowserPolicyFactory is a factory class helping generating StorageBrowserPolicy objects.
 */ parcelHelpers.export(exports, "StorageBrowserPolicyFactory", ()=>StorageBrowserPolicyFactory);
var _storageBrowserPolicy = require("./policies/StorageBrowserPolicy");
class StorageBrowserPolicyFactory {
    /**
     * Creates a StorageBrowserPolicyFactory object.
     *
     * @param nextPolicy -
     * @param options -
     */ create(nextPolicy, options) {
        return new (0, _storageBrowserPolicy.StorageBrowserPolicy)(nextPolicy, options);
    }
}

},{"./policies/StorageBrowserPolicy":"9E0kg","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9E0kg":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * StorageBrowserPolicy will handle differences between Node.js and browser runtime, including:
 *
 * 1. Browsers cache GET/HEAD requests by adding conditional headers such as 'IF_MODIFIED_SINCE'.
 * StorageBrowserPolicy is a policy used to add a timestamp query to GET/HEAD request URL
 * thus avoid the browser cache.
 *
 * 2. Remove cookie header for security
 *
 * 3. Remove content-length header to avoid browsers warning
 */ parcelHelpers.export(exports, "StorageBrowserPolicy", ()=>StorageBrowserPolicy);
var _requestPolicy = require("./RequestPolicy");
var _coreUtil = require("@azure/core-util");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
class StorageBrowserPolicy extends (0, _requestPolicy.BaseRequestPolicy) {
    /**
     * Creates an instance of StorageBrowserPolicy.
     * @param nextPolicy -
     * @param options -
     */ // The base class has a protected constructor. Adding a public one to enable constructing of this class.
    /* eslint-disable-next-line @typescript-eslint/no-useless-constructor*/ constructor(nextPolicy, options){
        super(nextPolicy, options);
    }
    /**
     * Sends out request.
     *
     * @param request -
     */ async sendRequest(request) {
        if (0, _coreUtil.isNode) return this._nextPolicy.sendRequest(request);
        if (request.method.toUpperCase() === "GET" || request.method.toUpperCase() === "HEAD") request.url = (0, _utilsCommon.setURLParameter)(request.url, (0, _constants.URLConstants).Parameters.FORCE_BROWSER_NO_CACHE, new Date().getTime().toString());
        request.headers.remove((0, _constants.HeaderConstants).COOKIE);
        // According to XHR standards, content-length should be fully controlled by browsers
        request.headers.remove((0, _constants.HeaderConstants).CONTENT_LENGTH);
        return this._nextPolicy.sendRequest(request);
    }
}

},{"./RequestPolicy":"9jet0","@azure/core-util":"b31OK","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"45MBz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A ContainerClient represents a URL to the Azure Storage container allowing you to manipulate its blobs.
 */ parcelHelpers.export(exports, "ContainerClient", ()=>ContainerClient);
var _tslib = require("tslib");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreUtil = require("@azure/core-util");
var _coreAuth = require("@azure/core-auth");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _storageSharedKeyCredential = require("./credentials/StorageSharedKeyCredential");
var _pipeline = require("./Pipeline");
var _storageClient = require("./StorageClient");
var _tracing = require("./utils/tracing");
var _utilsCommon = require("./utils/utils.common");
var _blobSASSignatureValues = require("./sas/BlobSASSignatureValues");
var _blobLeaseClient = require("./BlobLeaseClient");
var _clients = require("./Clients");
var _blobBatchClient = require("./BlobBatchClient");
class ContainerClient extends (0, _storageClient.StorageClient) {
    /**
     * The name of the container.
     */ get containerName() {
        return this._containerName;
    }
    constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        let pipeline;
        let url;
        options = options || {};
        if ((0, _pipeline.isPipelineLike)(credentialOrPipelineOrContainerName)) {
            // (url: string, pipeline: Pipeline)
            url = urlOrConnectionString;
            pipeline = credentialOrPipelineOrContainerName;
        } else if ((0, _coreUtil.isNode) && credentialOrPipelineOrContainerName instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipelineOrContainerName instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipelineOrContainerName)) {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            url = urlOrConnectionString;
            pipeline = (0, _pipeline.newPipeline)(credentialOrPipelineOrContainerName, options);
        } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== "string") {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            // The second parameter is undefined. Use anonymous credential.
            url = urlOrConnectionString;
            pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === "string") {
            // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)
            const containerName = credentialOrPipelineOrContainerName;
            const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(urlOrConnectionString);
            if (extractedCreds.kind === "AccountConnString") {
                if (0, _coreUtil.isNode) {
                    const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                    url = (0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName));
                    if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                    pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                } else throw new Error("Account connection string is only supported in Node.js environment");
            } else if (extractedCreds.kind === "SASConnString") {
                url = (0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)) + "?" + extractedCreds.accountSas;
                pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        } else throw new Error("Expecting non-empty strings for containerName parameter");
        super(url, pipeline);
        this._containerName = this.getContainerNameFromUrl();
        this.containerContext = this.storageClientContext.container;
    }
    /**
     * Creates a new container under the specified account. If the container with
     * the same name already exists, the operation fails.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     * Naming rules: @see https://learn.microsoft.com/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata
     *
     * @param options - Options to Container Create operation.
     *
     *
     * Example usage:
     *
     * ```js
     * const containerClient = blobServiceClient.getContainerClient("<container name>");
     * const createContainerResponse = await containerClient.create();
     * console.log("Container was created successfully", createContainerResponse.requestId);
     * ```
     */ async create(options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-create", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.containerContext.create(updatedOptions));
        });
    }
    /**
     * Creates a new container under the specified account. If the container with
     * the same name already exists, it is not changed.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     * Naming rules: @see https://learn.microsoft.com/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata
     *
     * @param options -
     */ async createIfNotExists(options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-createIfNotExists", options, async (updatedOptions)=>{
            var _a, _b;
            try {
                const res = await this.create(updatedOptions);
                return Object.assign(Object.assign({
                    succeeded: true
                }, res), {
                    _response: res._response
                });
            } catch (e) {
                if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "ContainerAlreadyExists") return Object.assign(Object.assign({
                    succeeded: false
                }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {
                    _response: e.response
                });
                else throw e;
            }
        });
    }
    /**
     * Returns true if the Azure container resource represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing container might be deleted by other clients or
     * applications. Vice versa new containers with the same name might be added by other clients or
     * applications after this function completes.
     *
     * @param options -
     */ async exists(options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-exists", options, async (updatedOptions)=>{
            try {
                await this.getProperties({
                    abortSignal: options.abortSignal,
                    tracingOptions: updatedOptions.tracingOptions
                });
                return true;
            } catch (e) {
                if (e.statusCode === 404) return false;
                throw e;
            }
        });
    }
    /**
     * Creates a {@link BlobClient}
     *
     * @param blobName - A blob name
     * @returns A new BlobClient object for the given blob name.
     */ getBlobClient(blobName) {
        return new (0, _clients.BlobClient)((0, _utilsCommon.appendToURLPath)(this.url, (0, _utilsCommon.EscapePath)(blobName)), this.pipeline);
    }
    /**
     * Creates an {@link AppendBlobClient}
     *
     * @param blobName - An append blob name
     */ getAppendBlobClient(blobName) {
        return new (0, _clients.AppendBlobClient)((0, _utilsCommon.appendToURLPath)(this.url, (0, _utilsCommon.EscapePath)(blobName)), this.pipeline);
    }
    /**
     * Creates a {@link BlockBlobClient}
     *
     * @param blobName - A block blob name
     *
     *
     * Example usage:
     *
     * ```js
     * const content = "Hello world!";
     *
     * const blockBlobClient = containerClient.getBlockBlobClient("<blob name>");
     * const uploadBlobResponse = await blockBlobClient.upload(content, content.length);
     * ```
     */ getBlockBlobClient(blobName) {
        return new (0, _clients.BlockBlobClient)((0, _utilsCommon.appendToURLPath)(this.url, (0, _utilsCommon.EscapePath)(blobName)), this.pipeline);
    }
    /**
     * Creates a {@link PageBlobClient}
     *
     * @param blobName - A page blob name
     */ getPageBlobClient(blobName) {
        return new (0, _clients.PageBlobClient)((0, _utilsCommon.appendToURLPath)(this.url, (0, _utilsCommon.EscapePath)(blobName)), this.pipeline);
    }
    /**
     * Returns all user-defined metadata and system properties for the specified
     * container. The data returned does not include the container's list of blobs.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-properties
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the `listContainers` method of {@link BlobServiceClient} using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @param options - Options to Container Get Properties operation.
     */ async getProperties(options = {}) {
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("ContainerClient-getProperties", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.containerContext.getProperties(Object.assign(Object.assign({
                abortSignal: options.abortSignal
            }, options.conditions), {
                tracingOptions: updatedOptions.tracingOptions
            })));
        });
    }
    /**
     * Marks the specified container for deletion. The container and any blobs
     * contained within it are later deleted during garbage collection.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options - Options to Container Delete operation.
     */ async delete(options = {}) {
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("ContainerClient-delete", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.containerContext.delete({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: options.conditions,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Marks the specified container for deletion if it exists. The container and any blobs
     * contained within it are later deleted during garbage collection.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options - Options to Container Delete operation.
     */ async deleteIfExists(options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-deleteIfExists", options, async (updatedOptions)=>{
            var _a, _b;
            try {
                const res = await this.delete(updatedOptions);
                return Object.assign(Object.assign({
                    succeeded: true
                }, res), {
                    _response: res._response
                });
            } catch (e) {
                if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "ContainerNotFound") return Object.assign(Object.assign({
                    succeeded: false
                }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {
                    _response: e.response
                });
                throw e;
            }
        });
    }
    /**
     * Sets one or more user-defined name-value pairs for the specified container.
     *
     * If no option provided, or no metadata defined in the parameter, the container
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-metadata
     *
     * @param metadata - Replace existing metadata with this value.
     *                            If no value provided the existing metadata will be removed.
     * @param options - Options to Container Set Metadata operation.
     */ async setMetadata(metadata, options = {}) {
        if (!options.conditions) options.conditions = {};
        if (options.conditions.ifUnmodifiedSince) throw new RangeError("the IfUnmodifiedSince must have their default values because they are ignored by the blob service");
        return (0, _tracing.tracingClient).withSpan("ContainerClient-setMetadata", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.containerContext.setMetadata({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                metadata,
                modifiedAccessConditions: options.conditions,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Gets the permissions for the specified container. The permissions indicate
     * whether container data may be accessed publicly.
     *
     * WARNING: JavaScript Date will potentially lose precision when parsing startsOn and expiresOn strings.
     * For example, new Date("2018-12-31T03:44:23.8827891Z").toISOString() will get "2018-12-31T03:44:23.882Z".
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-acl
     *
     * @param options - Options to Container Get Access Policy operation.
     */ async getAccessPolicy(options = {}) {
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("ContainerClient-getAccessPolicy", options, async (updatedOptions)=>{
            const response = (0, _utilsCommon.assertResponse)(await this.containerContext.getAccessPolicy({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                tracingOptions: updatedOptions.tracingOptions
            }));
            const res = {
                _response: response._response,
                blobPublicAccess: response.blobPublicAccess,
                date: response.date,
                etag: response.etag,
                errorCode: response.errorCode,
                lastModified: response.lastModified,
                requestId: response.requestId,
                clientRequestId: response.clientRequestId,
                signedIdentifiers: [],
                version: response.version
            };
            for (const identifier of response){
                let accessPolicy = undefined;
                if (identifier.accessPolicy) {
                    accessPolicy = {
                        permissions: identifier.accessPolicy.permissions
                    };
                    if (identifier.accessPolicy.expiresOn) accessPolicy.expiresOn = new Date(identifier.accessPolicy.expiresOn);
                    if (identifier.accessPolicy.startsOn) accessPolicy.startsOn = new Date(identifier.accessPolicy.startsOn);
                }
                res.signedIdentifiers.push({
                    accessPolicy,
                    id: identifier.id
                });
            }
            return res;
        });
    }
    /**
     * Sets the permissions for the specified container. The permissions indicate
     * whether blobs in a container may be accessed publicly.
     *
     * When you set permissions for a container, the existing permissions are replaced.
     * If no access or containerAcl provided, the existing container ACL will be
     * removed.
     *
     * When you establish a stored access policy on a container, it may take up to 30 seconds to take effect.
     * During this interval, a shared access signature that is associated with the stored access policy will
     * fail with status code 403 (Forbidden), until the access policy becomes active.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-acl
     *
     * @param access - The level of public access to data in the container.
     * @param containerAcl - Array of elements each having a unique Id and details of the access policy.
     * @param options - Options to Container Set Access Policy operation.
     */ async setAccessPolicy(access, containerAcl, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("ContainerClient-setAccessPolicy", options, async (updatedOptions)=>{
            const acl = [];
            for (const identifier of containerAcl || [])acl.push({
                accessPolicy: {
                    expiresOn: identifier.accessPolicy.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(identifier.accessPolicy.expiresOn) : "",
                    permissions: identifier.accessPolicy.permissions,
                    startsOn: identifier.accessPolicy.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(identifier.accessPolicy.startsOn) : ""
                },
                id: identifier.id
            });
            return (0, _utilsCommon.assertResponse)(await this.containerContext.setAccessPolicy({
                abortSignal: options.abortSignal,
                access,
                containerAcl: acl,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: options.conditions,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Get a {@link BlobLeaseClient} that manages leases on the container.
     *
     * @param proposeLeaseId - Initial proposed lease Id.
     * @returns A new BlobLeaseClient object for managing leases on the container.
     */ getBlobLeaseClient(proposeLeaseId) {
        return new (0, _blobLeaseClient.BlobLeaseClient)(this, proposeLeaseId);
    }
    /**
     * Creates a new block blob, or updates the content of an existing block blob.
     *
     * Updating an existing block blob overwrites any existing metadata on the blob.
     * Partial updates are not supported; the content of the existing blob is
     * overwritten with the new content. To perform a partial update of a block blob's,
     * use {@link BlockBlobClient.stageBlock} and {@link BlockBlobClient.commitBlockList}.
     *
     * This is a non-parallel uploading method, please use {@link BlockBlobClient.uploadFile},
     * {@link BlockBlobClient.uploadStream} or {@link BlockBlobClient.uploadBrowserData} for better
     * performance with concurrency uploading.
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param blobName - Name of the block blob to create or update.
     * @param body - Blob, string, ArrayBuffer, ArrayBufferView or a function
     *                               which returns a new Readable stream whose offset is from data source beginning.
     * @param contentLength - Length of body in bytes. Use Buffer.byteLength() to calculate body length for a
     *                               string including non non-Base64/Hex-encoded characters.
     * @param options - Options to configure the Block Blob Upload operation.
     * @returns Block Blob upload response data and the corresponding BlockBlobClient instance.
     */ async uploadBlockBlob(blobName, body, contentLength, options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-uploadBlockBlob", options, async (updatedOptions)=>{
            const blockBlobClient = this.getBlockBlobClient(blobName);
            const response = await blockBlobClient.upload(body, contentLength, updatedOptions);
            return {
                blockBlobClient,
                response
            };
        });
    }
    /**
     * Marks the specified blob or snapshot for deletion. The blob is later deleted
     * during garbage collection. Note that in order to delete a blob, you must delete
     * all of its snapshots. You can delete both at the same time with the Delete
     * Blob operation.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-blob
     *
     * @param blobName -
     * @param options - Options to Blob Delete operation.
     * @returns Block blob deletion response data.
     */ async deleteBlob(blobName, options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-deleteBlob", options, async (updatedOptions)=>{
            let blobClient = this.getBlobClient(blobName);
            if (options.versionId) blobClient = blobClient.withVersion(options.versionId);
            return blobClient.delete(updatedOptions);
        });
    }
    /**
     * listBlobFlatSegment returns a single segment of blobs starting from the
     * specified Marker. Use an empty Marker to start enumeration from the beginning.
     * After getting a segment, process it, and then call listBlobsFlatSegment again
     * (passing the the previously-returned Marker) to get the next segment.
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param marker - A string value that identifies the portion of the list to be returned with the next list operation.
     * @param options - Options to Container List Blob Flat Segment operation.
     */ async listBlobFlatSegment(marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-listBlobFlatSegment", options, async (updatedOptions)=>{
            const response = (0, _utilsCommon.assertResponse)(await this.containerContext.listBlobFlatSegment(Object.assign(Object.assign({
                marker
            }, options), {
                tracingOptions: updatedOptions.tracingOptions
            })));
            const wrappedResponse = Object.assign(Object.assign({}, response), {
                _response: Object.assign(Object.assign({}, response._response), {
                    parsedBody: (0, _utilsCommon.ConvertInternalResponseOfListBlobFlat)(response._response.parsedBody)
                }),
                segment: Object.assign(Object.assign({}, response.segment), {
                    blobItems: response.segment.blobItems.map((blobItemInternal)=>{
                        const blobItem = Object.assign(Object.assign({}, blobItemInternal), {
                            name: (0, _utilsCommon.BlobNameToString)(blobItemInternal.name),
                            tags: (0, _utilsCommon.toTags)(blobItemInternal.blobTags),
                            objectReplicationSourceProperties: (0, _utilsCommon.parseObjectReplicationRecord)(blobItemInternal.objectReplicationMetadata)
                        });
                        return blobItem;
                    })
                })
            });
            return wrappedResponse;
        });
    }
    /**
     * listBlobHierarchySegment returns a single segment of blobs starting from
     * the specified Marker. Use an empty Marker to start enumeration from the
     * beginning. After getting a segment, process it, and then call listBlobsHierarchicalSegment
     * again (passing the the previously-returned Marker) to get the next segment.
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param delimiter - The character or string used to define the virtual hierarchy
     * @param marker - A string value that identifies the portion of the list to be returned with the next list operation.
     * @param options - Options to Container List Blob Hierarchy Segment operation.
     */ async listBlobHierarchySegment(delimiter, marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-listBlobHierarchySegment", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this.containerContext.listBlobHierarchySegment(delimiter, Object.assign(Object.assign({
                marker
            }, options), {
                tracingOptions: updatedOptions.tracingOptions
            })));
            const wrappedResponse = Object.assign(Object.assign({}, response), {
                _response: Object.assign(Object.assign({}, response._response), {
                    parsedBody: (0, _utilsCommon.ConvertInternalResponseOfListBlobHierarchy)(response._response.parsedBody)
                }),
                segment: Object.assign(Object.assign({}, response.segment), {
                    blobItems: response.segment.blobItems.map((blobItemInternal)=>{
                        const blobItem = Object.assign(Object.assign({}, blobItemInternal), {
                            name: (0, _utilsCommon.BlobNameToString)(blobItemInternal.name),
                            tags: (0, _utilsCommon.toTags)(blobItemInternal.blobTags),
                            objectReplicationSourceProperties: (0, _utilsCommon.parseObjectReplicationRecord)(blobItemInternal.objectReplicationMetadata)
                        });
                        return blobItem;
                    }),
                    blobPrefixes: (_a = response.segment.blobPrefixes) === null || _a === void 0 ? void 0 : _a.map((blobPrefixInternal)=>{
                        const blobPrefix = Object.assign(Object.assign({}, blobPrefixInternal), {
                            name: (0, _utilsCommon.BlobNameToString)(blobPrefixInternal.name)
                        });
                        return blobPrefix;
                    })
                })
            });
            return wrappedResponse;
        });
    }
    /**
     * Returns an AsyncIterableIterator for ContainerListBlobFlatSegmentResponse
     *
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the ContinuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The ContinuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to list blobs operation.
     */ listSegments(marker_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listSegments_1(marker, options = {}) {
            let listBlobsFlatSegmentResponse;
            if (!!marker || marker === undefined) do {
                listBlobsFlatSegmentResponse = yield (0, _tslib.__await)(this.listBlobFlatSegment(marker, options));
                marker = listBlobsFlatSegmentResponse.continuationToken;
                yield yield (0, _tslib.__await)((yield (0, _tslib.__await)(listBlobsFlatSegmentResponse)));
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator of {@link BlobItem} objects
     *
     * @param options - Options to list blobs operation.
     */ listItems() {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listItems_1(options = {}) {
            var _a, e_1, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.listSegments(marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const listBlobsFlatSegmentResponse = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)(listBlobsFlatSegmentResponse.segment.blobItems))));
                }
            } catch (e_1_1) {
                e_1 = {
                    error: e_1_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_1) throw e_1.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to list all the blobs
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the blobs in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the containerClient before you run these snippets,
     * // Can be obtained from `blobServiceClient.getContainerClient("<your-container-name>");`
     * let i = 1;
     * for await (const blob of containerClient.listBlobsFlat()) {
     *   console.log(`Blob ${i++}: ${blob.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = containerClient.listBlobsFlat();
     * let blobItem = await iter.next();
     * while (!blobItem.done) {
     *   console.log(`Blob ${i++}: ${blobItem.value.name}`);
     *   blobItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of containerClient.listBlobsFlat().byPage({ maxPageSize: 20 })) {
     *   for (const blob of response.segment.blobItems) {
     *     console.log(`Blob ${i++}: ${blob.name}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = containerClient.listBlobsFlat().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 blob names
     * for (const blob of response.segment.blobItems) {
     *   console.log(`Blob ${i++}: ${blob.name}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = containerClient.listBlobsFlat().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 blob names
     * for (const blob of response.segment.blobItems) {
     *   console.log(`Blob ${i++}: ${blob.name}`);
     * }
     * ```
     *
     * @param options - Options to list blobs.
     * @returns An asyncIterableIterator that supports paging.
     */ listBlobsFlat(options = {}) {
        const include = [];
        if (options.includeCopy) include.push("copy");
        if (options.includeDeleted) include.push("deleted");
        if (options.includeMetadata) include.push("metadata");
        if (options.includeSnapshots) include.push("snapshots");
        if (options.includeVersions) include.push("versions");
        if (options.includeUncommitedBlobs) include.push("uncommittedblobs");
        if (options.includeTags) include.push("tags");
        if (options.includeDeletedWithVersions) include.push("deletedwithversions");
        if (options.includeImmutabilityPolicy) include.push("immutabilitypolicy");
        if (options.includeLegalHold) include.push("legalhold");
        if (options.prefix === "") options.prefix = undefined;
        const updatedOptions = Object.assign(Object.assign({}, options), include.length > 0 ? {
            include: include
        } : {});
        // AsyncIterableIterator to iterate over blobs
        const iter = this.listItems(updatedOptions);
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.listSegments(settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, updatedOptions));
            }
        };
    }
    /**
     * Returns an AsyncIterableIterator for ContainerListBlobHierarchySegmentResponse
     *
     * @param delimiter - The character or string used to define the virtual hierarchy
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the ContinuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The ContinuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to list blobs operation.
     */ listHierarchySegments(delimiter_1, marker_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listHierarchySegments_1(delimiter, marker, options = {}) {
            let listBlobsHierarchySegmentResponse;
            if (!!marker || marker === undefined) do {
                listBlobsHierarchySegmentResponse = yield (0, _tslib.__await)(this.listBlobHierarchySegment(delimiter, marker, options));
                marker = listBlobsHierarchySegmentResponse.continuationToken;
                yield yield (0, _tslib.__await)((yield (0, _tslib.__await)(listBlobsHierarchySegmentResponse)));
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator for {@link BlobPrefix} and {@link BlobItem} objects.
     *
     * @param delimiter - The character or string used to define the virtual hierarchy
     * @param options - Options to list blobs operation.
     */ listItemsByHierarchy(delimiter_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listItemsByHierarchy_1(delimiter, options = {}) {
            var _a, e_2, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.listHierarchySegments(delimiter, marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const listBlobsHierarchySegmentResponse = _c;
                    const segment = listBlobsHierarchySegmentResponse.segment;
                    if (segment.blobPrefixes) for (const prefix of segment.blobPrefixes)yield yield (0, _tslib.__await)(Object.assign({
                        kind: "prefix"
                    }, prefix));
                    for (const blob of segment.blobItems)yield yield (0, _tslib.__await)(Object.assign({
                        kind: "blob"
                    }, blob));
                }
            } catch (e_2_1) {
                e_2 = {
                    error: e_2_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_2) throw e_2.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to list all the blobs by hierarchy.
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the blobs by hierarchy in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * for await (const item of containerClient.listBlobsByHierarchy("/")) {
     *   if (item.kind === "prefix") {
     *     console.log(`\tBlobPrefix: ${item.name}`);
     *   } else {
     *     console.log(`\tBlobItem: name - ${item.name}`);
     *   }
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let iter = containerClient.listBlobsByHierarchy("/", { prefix: "prefix1/" });
     * let entity = await iter.next();
     * while (!entity.done) {
     *   let item = entity.value;
     *   if (item.kind === "prefix") {
     *     console.log(`\tBlobPrefix: ${item.name}`);
     *   } else {
     *     console.log(`\tBlobItem: name - ${item.name}`);
     *   }
     *   entity = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * console.log("Listing blobs by hierarchy by page");
     * for await (const response of containerClient.listBlobsByHierarchy("/").byPage()) {
     *   const segment = response.segment;
     *   if (segment.blobPrefixes) {
     *     for (const prefix of segment.blobPrefixes) {
     *       console.log(`\tBlobPrefix: ${prefix.name}`);
     *     }
     *   }
     *   for (const blob of response.segment.blobItems) {
     *     console.log(`\tBlobItem: name - ${blob.name}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a max page size:
     *
     * ```js
     * console.log("Listing blobs by hierarchy by page, specifying a prefix and a max page size");
     *
     * let i = 1;
     * for await (const response of containerClient
     *   .listBlobsByHierarchy("/", { prefix: "prefix2/sub1/" })
     *   .byPage({ maxPageSize: 2 })) {
     *   console.log(`Page ${i++}`);
     *   const segment = response.segment;
     *
     *   if (segment.blobPrefixes) {
     *     for (const prefix of segment.blobPrefixes) {
     *       console.log(`\tBlobPrefix: ${prefix.name}`);
     *     }
     *   }
     *
     *   for (const blob of response.segment.blobItems) {
     *     console.log(`\tBlobItem: name - ${blob.name}`);
     *   }
     * }
     * ```
     *
     * @param delimiter - The character or string used to define the virtual hierarchy
     * @param options - Options to list blobs operation.
     */ listBlobsByHierarchy(delimiter, options = {}) {
        if (delimiter === "") throw new RangeError("delimiter should contain one or more characters");
        const include = [];
        if (options.includeCopy) include.push("copy");
        if (options.includeDeleted) include.push("deleted");
        if (options.includeMetadata) include.push("metadata");
        if (options.includeSnapshots) include.push("snapshots");
        if (options.includeVersions) include.push("versions");
        if (options.includeUncommitedBlobs) include.push("uncommittedblobs");
        if (options.includeTags) include.push("tags");
        if (options.includeDeletedWithVersions) include.push("deletedwithversions");
        if (options.includeImmutabilityPolicy) include.push("immutabilitypolicy");
        if (options.includeLegalHold) include.push("legalhold");
        if (options.prefix === "") options.prefix = undefined;
        const updatedOptions = Object.assign(Object.assign({}, options), include.length > 0 ? {
            include: include
        } : {});
        // AsyncIterableIterator to iterate over blob prefixes and blobs
        const iter = this.listItemsByHierarchy(delimiter, updatedOptions);
        return {
            /**
             * The next method, part of the iteration protocol
             */ async next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.listHierarchySegments(delimiter, settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, updatedOptions));
            }
        };
    }
    /**
     * The Filter Blobs operation enables callers to list blobs in the container whose tags
     * match a given search expression.
     *
     * @param tagFilterSqlExpression - The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                        The given expression must evaluate to true for a blob to be returned in the results.
     *                                        The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                        however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the continuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The continuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to find blobs by tags.
     */ async findBlobsByTagsSegment(tagFilterSqlExpression, marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("ContainerClient-findBlobsByTagsSegment", options, async (updatedOptions)=>{
            const response = (0, _utilsCommon.assertResponse)(await this.containerContext.filterBlobs({
                abortSignal: options.abortSignal,
                where: tagFilterSqlExpression,
                marker,
                maxPageSize: options.maxPageSize,
                tracingOptions: updatedOptions.tracingOptions
            }));
            const wrappedResponse = Object.assign(Object.assign({}, response), {
                _response: response._response,
                blobs: response.blobs.map((blob)=>{
                    var _a;
                    let tagValue = "";
                    if (((_a = blob.tags) === null || _a === void 0 ? void 0 : _a.blobTagSet.length) === 1) tagValue = blob.tags.blobTagSet[0].value;
                    return Object.assign(Object.assign({}, blob), {
                        tags: (0, _utilsCommon.toTags)(blob.tags),
                        tagValue
                    });
                })
            });
            return wrappedResponse;
        });
    }
    /**
     * Returns an AsyncIterableIterator for ContainerFindBlobsByTagsSegmentResponse.
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param marker - A string value that identifies the portion of
     *                          the list of blobs to be returned with the next listing operation. The
     *                          operation returns the continuationToken value within the response body if the
     *                          listing operation did not return all blobs remaining to be listed
     *                          with the current page. The continuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of list
     *                          items. The marker value is opaque to the client.
     * @param options - Options to find blobs by tags.
     */ findBlobsByTagsSegments(tagFilterSqlExpression_1, marker_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* findBlobsByTagsSegments_1(tagFilterSqlExpression, marker, options = {}) {
            let response;
            if (!!marker || marker === undefined) do {
                response = yield (0, _tslib.__await)(this.findBlobsByTagsSegment(tagFilterSqlExpression, marker, options));
                response.blobs = response.blobs || [];
                marker = response.continuationToken;
                yield yield (0, _tslib.__await)(response);
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator for blobs.
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param options - Options to findBlobsByTagsItems.
     */ findBlobsByTagsItems(tagFilterSqlExpression_1) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* findBlobsByTagsItems_1(tagFilterSqlExpression, options = {}) {
            var _a, e_3, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.findBlobsByTagsSegments(tagFilterSqlExpression, marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const segment = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)(segment.blobs))));
                }
            } catch (e_3_1) {
                e_3 = {
                    error: e_3_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_3) throw e_3.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to find all blobs with specified tag
     * under the specified container.
     *
     * .byPage() returns an async iterable iterator to list the blobs in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * let i = 1;
     * for await (const blob of containerClient.findBlobsByTags("tagkey='tagvalue'")) {
     *   console.log(`Blob ${i++}: ${blob.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * const iter = containerClient.findBlobsByTags("tagkey='tagvalue'");
     * let blobItem = await iter.next();
     * while (!blobItem.done) {
     *   console.log(`Blob ${i++}: ${blobItem.value.name}`);
     *   blobItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of containerClient.findBlobsByTags("tagkey='tagvalue'").byPage({ maxPageSize: 20 })) {
     *   if (response.blobs) {
     *     for (const blob of response.blobs) {
     *       console.log(`Blob ${i++}: ${blob.name}`);
     *     }
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = containerClient.findBlobsByTags("tagkey='tagvalue'").byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 blob names
     * if (response.blobs) {
     *   for (const blob of response.blobs) {
     *     console.log(`Blob ${i++}: ${blob.name}`);
     *   }
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     * // Passing next marker as continuationToken
     * iterator = containerClient
     *   .findBlobsByTags("tagkey='tagvalue'")
     *   .byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints blob names
     * if (response.blobs) {
     *   for (const blob of response.blobs) {
     *      console.log(`Blob ${i++}: ${blob.name}`);
     *   }
     * }
     * ```
     *
     * @param tagFilterSqlExpression -  The where parameter enables the caller to query blobs whose tags match a given expression.
     *                                         The given expression must evaluate to true for a blob to be returned in the results.
     *                                         The[OData - ABNF] filter syntax rule defines the formal grammar for the value of the where query parameter;
     *                                         however, only a subset of the OData filter syntax is supported in the Blob service.
     * @param options - Options to find blobs by tags.
     */ findBlobsByTags(tagFilterSqlExpression, options = {}) {
        // AsyncIterableIterator to iterate over blobs
        const listSegmentOptions = Object.assign({}, options);
        const iter = this.findBlobsByTagsItems(tagFilterSqlExpression, listSegmentOptions);
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.findBlobsByTagsSegments(tagFilterSqlExpression, settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, listSegmentOptions));
            }
        };
    }
    getContainerNameFromUrl() {
        let containerName;
        try {
            //  URL may look like the following
            // "https://myaccount.blob.core.windows.net/mycontainer?sasString";
            // "https://myaccount.blob.core.windows.net/mycontainer";
            // IPv4/IPv6 address hosts, Endpoints - `http://127.0.0.1:10000/devstoreaccount1/containername`
            // http://localhost:10001/devstoreaccount1/containername
            const parsedUrl = new URL(this.url);
            if (parsedUrl.hostname.split(".")[1] === "blob") // "https://myaccount.blob.core.windows.net/containername".
            // "https://customdomain.com/containername".
            // .getPath() -> /containername
            containerName = parsedUrl.pathname.split("/")[1];
            else if ((0, _utilsCommon.isIpEndpointStyle)(parsedUrl)) // IPv4/IPv6 address hosts... Example - http://192.0.0.10:10001/devstoreaccount1/containername
            // Single word domain without a [dot] in the endpoint... Example - http://localhost:10001/devstoreaccount1/containername
            // .getPath() -> /devstoreaccount1/containername
            containerName = parsedUrl.pathname.split("/")[2];
            else // "https://customdomain.com/containername".
            // .getPath() -> /containername
            containerName = parsedUrl.pathname.split("/")[1];
            // decode the encoded containerName - to get all the special characters that might be present in it
            containerName = decodeURIComponent(containerName);
            if (!containerName) throw new Error("Provided containerName is invalid.");
            return containerName;
        } catch (error) {
            throw new Error("Unable to extract containerName with provided information.");
        }
    }
    /**
     * Only available for ContainerClient constructed with a shared key credential.
     *
     * Generates a Blob Container Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */ generateSasUrl(options) {
        return new Promise((resolve)=>{
            if (!(this.credential instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential))) throw new RangeError("Can only generate the SAS when the client is initialized with a shared key credential");
            const sas = (0, _blobSASSignatureValues.generateBlobSASQueryParameters)(Object.assign({
                containerName: this._containerName
            }, options), this.credential).toString();
            resolve((0, _utilsCommon.appendToURLQuery)(this.url, sas));
        });
    }
    /**
     * Creates a BlobBatchClient object to conduct batch operations.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch
     *
     * @returns A new BlobBatchClient object for this container.
     */ getBlobBatchClient() {
        return new (0, _blobBatchClient.BlobBatchClient)(this.url, this.pipeline);
    }
}

},{"tslib":"lRdW5","@azure/core-rest-pipeline":"d0mqv","@azure/core-util":"b31OK","@azure/core-auth":"2xRAB","./credentials/AnonymousCredential":"f0sOe","./credentials/StorageSharedKeyCredential":"jUFIX","./Pipeline":"bsozg","./StorageClient":"gO9Kx","./utils/tracing":"m0KjB","./utils/utils.common":"2SR3M","./sas/BlobSASSignatureValues":"SWffY","./BlobLeaseClient":"hZ8uc","./Clients":"kUV1b","./BlobBatchClient":"iF02i","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gO9Kx":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A StorageClient represents a based URL class for {@link BlobServiceClient}, {@link ContainerClient}
 * and etc.
 */ parcelHelpers.export(exports, "StorageClient", ()=>StorageClient);
var _storageContextClient = require("./StorageContextClient");
var _pipeline = require("./Pipeline");
var _utilsCommon = require("./utils/utils.common");
class StorageClient {
    /**
     * Creates an instance of StorageClient.
     * @param url - url to resource
     * @param pipeline - request policy pipeline.
     */ constructor(url, pipeline){
        // URL should be encoded and only once, protocol layer shouldn't encode URL again
        this.url = (0, _utilsCommon.escapeURLPath)(url);
        this.accountName = (0, _utilsCommon.getAccountNameFromUrl)(url);
        this.pipeline = pipeline;
        this.storageClientContext = new (0, _storageContextClient.StorageContextClient)(this.url, (0, _pipeline.getCoreClientOptions)(pipeline));
        this.isHttps = (0, _utilsCommon.iEqual)((0, _utilsCommon.getURLScheme)(this.url) || "", "https");
        this.credential = (0, _pipeline.getCredentialFromPipeline)(pipeline);
        // Override protocol layer's default content-type
        const storageClientContext = this.storageClientContext;
        storageClientContext.requestContentType = undefined;
    }
}

},{"./StorageContextClient":"agdqi","./Pipeline":"bsozg","./utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"agdqi":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @internal
 */ parcelHelpers.export(exports, "StorageContextClient", ()=>StorageContextClient);
var _src = require("./generated/src");
class StorageContextClient extends (0, _src.StorageClient) {
    async sendOperationRequest(operationArguments, operationSpec) {
        const operationSpecToSend = Object.assign({}, operationSpec);
        if (operationSpecToSend.path === "/{containerName}" || operationSpecToSend.path === "/{containerName}/{blob}") operationSpecToSend.path = "";
        return super.sendOperationRequest(operationArguments, operationSpecToSend);
    }
}

},{"./generated/src":"gfC4L","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gfC4L":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "StorageClient", ()=>(0, _storageClient.StorageClient));
var _models = require("./models");
parcelHelpers.exportAll(_models, exports);
var _storageClient = require("./storageClient");
var _operationsInterfaces = require("./operationsInterfaces");
parcelHelpers.exportAll(_operationsInterfaces, exports);

},{"./models":false,"./storageClient":"dCKex","./operationsInterfaces":false,"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dCKex":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "StorageClient", ()=>StorageClient);
var _coreHttpCompat = require("@azure/core-http-compat");
var _operations = require("./operations");
class StorageClient extends _coreHttpCompat.ExtendedServiceClient {
    /**
     * Initializes a new instance of the StorageClient class.
     * @param url The URL of the service account, container, or blob that is the target of the desired
     *            operation.
     * @param options The parameter options
     */ constructor(url, options){
        var _a, _b;
        if (url === undefined) throw new Error("'url' cannot be null");
        // Initializing default values for options
        if (!options) options = {};
        const defaults = {
            requestContentType: "application/json; charset=utf-8"
        };
        const packageDetails = `azsdk-js-azure-storage-blob/12.23.0`;
        const userAgentPrefix = options.userAgentOptions && options.userAgentOptions.userAgentPrefix ? `${options.userAgentOptions.userAgentPrefix} ${packageDetails}` : `${packageDetails}`;
        const optionsWithDefaults = Object.assign(Object.assign(Object.assign({}, defaults), options), {
            userAgentOptions: {
                userAgentPrefix
            },
            endpoint: (_b = (_a = options.endpoint) !== null && _a !== void 0 ? _a : options.baseUri) !== null && _b !== void 0 ? _b : "{url}"
        });
        super(optionsWithDefaults);
        // Parameter assignments
        this.url = url;
        // Assigning values to Constant parameters
        this.version = options.version || "2023-11-03";
        this.service = new (0, _operations.ServiceImpl)(this);
        this.container = new (0, _operations.ContainerImpl)(this);
        this.blob = new (0, _operations.BlobImpl)(this);
        this.pageBlob = new (0, _operations.PageBlobImpl)(this);
        this.appendBlob = new (0, _operations.AppendBlobImpl)(this);
        this.blockBlob = new (0, _operations.BlockBlobImpl)(this);
    }
}

},{"@azure/core-http-compat":"1I5Za","./operations":"j9faG","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j9faG":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _service = require("./service");
parcelHelpers.exportAll(_service, exports);
var _container = require("./container");
parcelHelpers.exportAll(_container, exports);
var _blob = require("./blob");
parcelHelpers.exportAll(_blob, exports);
var _pageBlob = require("./pageBlob");
parcelHelpers.exportAll(_pageBlob, exports);
var _appendBlob = require("./appendBlob");
parcelHelpers.exportAll(_appendBlob, exports);
var _blockBlob = require("./blockBlob");
parcelHelpers.exportAll(_blockBlob, exports);

},{"./service":"1ribJ","./container":"2faTT","./blob":"kt7P2","./pageBlob":"fsHo1","./appendBlob":"6Mh9Y","./blockBlob":"fsPW1","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1ribJ":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing Service operations. */ parcelHelpers.export(exports, "ServiceImpl", ()=>ServiceImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class ServiceImpl {
    /**
     * Initialize a new instance of the class Service class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * Sets properties for a storage account's Blob service endpoint, including properties for Storage
     * Analytics and CORS (Cross-Origin Resource Sharing) rules
     * @param blobServiceProperties The StorageService properties.
     * @param options The options parameters.
     */ setProperties(blobServiceProperties, options) {
        return this.client.sendOperationRequest({
            blobServiceProperties,
            options
        }, setPropertiesOperationSpec);
    }
    /**
     * gets the properties of a storage account's Blob service, including properties for Storage Analytics
     * and CORS (Cross-Origin Resource Sharing) rules.
     * @param options The options parameters.
     */ getProperties(options) {
        return this.client.sendOperationRequest({
            options
        }, getPropertiesOperationSpec);
    }
    /**
     * Retrieves statistics related to replication for the Blob service. It is only available on the
     * secondary location endpoint when read-access geo-redundant replication is enabled for the storage
     * account.
     * @param options The options parameters.
     */ getStatistics(options) {
        return this.client.sendOperationRequest({
            options
        }, getStatisticsOperationSpec);
    }
    /**
     * The List Containers Segment operation returns a list of the containers under the specified account
     * @param options The options parameters.
     */ listContainersSegment(options) {
        return this.client.sendOperationRequest({
            options
        }, listContainersSegmentOperationSpec);
    }
    /**
     * Retrieves a user delegation key for the Blob service. This is only a valid operation when using
     * bearer token authentication.
     * @param keyInfo Key information
     * @param options The options parameters.
     */ getUserDelegationKey(keyInfo, options) {
        return this.client.sendOperationRequest({
            keyInfo,
            options
        }, getUserDelegationKeyOperationSpec);
    }
    /**
     * Returns the sku name and account kind
     * @param options The options parameters.
     */ getAccountInfo(options) {
        return this.client.sendOperationRequest({
            options
        }, getAccountInfoOperationSpec);
    }
    /**
     * The Batch operation allows multiple API calls to be embedded into a single HTTP request.
     * @param contentLength The length of the request.
     * @param multipartContentType Required. The value of this header must be multipart/mixed with a batch
     *                             boundary. Example header value: multipart/mixed; boundary=batch_<GUID>
     * @param body Initial data
     * @param options The options parameters.
     */ submitBatch(contentLength, multipartContentType, body, options) {
        return this.client.sendOperationRequest({
            contentLength,
            multipartContentType,
            body,
            options
        }, submitBatchOperationSpec);
    }
    /**
     * The Filter Blobs operation enables callers to list blobs across all containers whose tags match a
     * given search expression.  Filter blobs searches across all containers within a storage account but
     * can be scoped within the expression to a single container.
     * @param options The options parameters.
     */ filterBlobs(options) {
        return this.client.sendOperationRequest({
            options
        }, filterBlobsOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const setPropertiesOperationSpec = {
    path: "/",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.ServiceSetPropertiesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceSetPropertiesExceptionHeaders
        }
    },
    requestBody: _parameters.blobServiceProperties,
    queryParameters: [
        _parameters.restype,
        _parameters.comp,
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const getPropertiesOperationSpec = {
    path: "/",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.BlobServiceProperties,
            headersMapper: _mappers.ServiceGetPropertiesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceGetPropertiesExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.restype,
        _parameters.comp,
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getStatisticsOperationSpec = {
    path: "/",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.BlobServiceStatistics,
            headersMapper: _mappers.ServiceGetStatisticsHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceGetStatisticsExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.restype,
        _parameters.timeoutInSeconds,
        _parameters.comp1
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const listContainersSegmentOperationSpec = {
    path: "/",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.ListContainersSegmentResponse,
            headersMapper: _mappers.ServiceListContainersSegmentHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceListContainersSegmentExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp2,
        _parameters.prefix,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.include
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getUserDelegationKeyOperationSpec = {
    path: "/",
    httpMethod: "POST",
    responses: {
        200: {
            bodyMapper: _mappers.UserDelegationKey,
            headersMapper: _mappers.ServiceGetUserDelegationKeyHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceGetUserDelegationKeyExceptionHeaders
        }
    },
    requestBody: _parameters.keyInfo,
    queryParameters: [
        _parameters.restype,
        _parameters.timeoutInSeconds,
        _parameters.comp3
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const getAccountInfoOperationSpec = {
    path: "/",
    httpMethod: "GET",
    responses: {
        200: {
            headersMapper: _mappers.ServiceGetAccountInfoHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceGetAccountInfoExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.restype1
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const submitBatchOperationSpec = {
    path: "/",
    httpMethod: "POST",
    responses: {
        202: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.ServiceSubmitBatchHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceSubmitBatchExceptionHeaders
        }
    },
    requestBody: _parameters.body,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp4
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.multipartContentType
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const filterBlobsOperationSpec = {
    path: "/",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.FilterBlobSegment,
            headersMapper: _mappers.ServiceFilterBlobsHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ServiceFilterBlobsExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.comp5,
        _parameters.where
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ZlYI":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlobServiceProperties", ()=>BlobServiceProperties);
parcelHelpers.export(exports, "Logging", ()=>Logging);
parcelHelpers.export(exports, "RetentionPolicy", ()=>RetentionPolicy);
parcelHelpers.export(exports, "Metrics", ()=>Metrics);
parcelHelpers.export(exports, "CorsRule", ()=>CorsRule);
parcelHelpers.export(exports, "StaticWebsite", ()=>StaticWebsite);
parcelHelpers.export(exports, "StorageError", ()=>StorageError);
parcelHelpers.export(exports, "BlobServiceStatistics", ()=>BlobServiceStatistics);
parcelHelpers.export(exports, "GeoReplication", ()=>GeoReplication);
parcelHelpers.export(exports, "ListContainersSegmentResponse", ()=>ListContainersSegmentResponse);
parcelHelpers.export(exports, "ContainerItem", ()=>ContainerItem);
parcelHelpers.export(exports, "ContainerProperties", ()=>ContainerProperties);
parcelHelpers.export(exports, "KeyInfo", ()=>KeyInfo);
parcelHelpers.export(exports, "UserDelegationKey", ()=>UserDelegationKey);
parcelHelpers.export(exports, "FilterBlobSegment", ()=>FilterBlobSegment);
parcelHelpers.export(exports, "FilterBlobItem", ()=>FilterBlobItem);
parcelHelpers.export(exports, "BlobTags", ()=>BlobTags);
parcelHelpers.export(exports, "BlobTag", ()=>BlobTag);
parcelHelpers.export(exports, "SignedIdentifier", ()=>SignedIdentifier);
parcelHelpers.export(exports, "AccessPolicy", ()=>AccessPolicy);
parcelHelpers.export(exports, "ListBlobsFlatSegmentResponse", ()=>ListBlobsFlatSegmentResponse);
parcelHelpers.export(exports, "BlobFlatListSegment", ()=>BlobFlatListSegment);
parcelHelpers.export(exports, "BlobItemInternal", ()=>BlobItemInternal);
parcelHelpers.export(exports, "BlobName", ()=>BlobName);
parcelHelpers.export(exports, "BlobPropertiesInternal", ()=>BlobPropertiesInternal);
parcelHelpers.export(exports, "ListBlobsHierarchySegmentResponse", ()=>ListBlobsHierarchySegmentResponse);
parcelHelpers.export(exports, "BlobHierarchyListSegment", ()=>BlobHierarchyListSegment);
parcelHelpers.export(exports, "BlobPrefix", ()=>BlobPrefix);
parcelHelpers.export(exports, "BlockLookupList", ()=>BlockLookupList);
parcelHelpers.export(exports, "BlockList", ()=>BlockList);
parcelHelpers.export(exports, "Block", ()=>Block);
parcelHelpers.export(exports, "PageList", ()=>PageList);
parcelHelpers.export(exports, "PageRange", ()=>PageRange);
parcelHelpers.export(exports, "ClearRange", ()=>ClearRange);
parcelHelpers.export(exports, "QueryRequest", ()=>QueryRequest);
parcelHelpers.export(exports, "QuerySerialization", ()=>QuerySerialization);
parcelHelpers.export(exports, "QueryFormat", ()=>QueryFormat);
parcelHelpers.export(exports, "DelimitedTextConfiguration", ()=>DelimitedTextConfiguration);
parcelHelpers.export(exports, "JsonTextConfiguration", ()=>JsonTextConfiguration);
parcelHelpers.export(exports, "ArrowConfiguration", ()=>ArrowConfiguration);
parcelHelpers.export(exports, "ArrowField", ()=>ArrowField);
parcelHelpers.export(exports, "ServiceSetPropertiesHeaders", ()=>ServiceSetPropertiesHeaders);
parcelHelpers.export(exports, "ServiceSetPropertiesExceptionHeaders", ()=>ServiceSetPropertiesExceptionHeaders);
parcelHelpers.export(exports, "ServiceGetPropertiesHeaders", ()=>ServiceGetPropertiesHeaders);
parcelHelpers.export(exports, "ServiceGetPropertiesExceptionHeaders", ()=>ServiceGetPropertiesExceptionHeaders);
parcelHelpers.export(exports, "ServiceGetStatisticsHeaders", ()=>ServiceGetStatisticsHeaders);
parcelHelpers.export(exports, "ServiceGetStatisticsExceptionHeaders", ()=>ServiceGetStatisticsExceptionHeaders);
parcelHelpers.export(exports, "ServiceListContainersSegmentHeaders", ()=>ServiceListContainersSegmentHeaders);
parcelHelpers.export(exports, "ServiceListContainersSegmentExceptionHeaders", ()=>ServiceListContainersSegmentExceptionHeaders);
parcelHelpers.export(exports, "ServiceGetUserDelegationKeyHeaders", ()=>ServiceGetUserDelegationKeyHeaders);
parcelHelpers.export(exports, "ServiceGetUserDelegationKeyExceptionHeaders", ()=>ServiceGetUserDelegationKeyExceptionHeaders);
parcelHelpers.export(exports, "ServiceGetAccountInfoHeaders", ()=>ServiceGetAccountInfoHeaders);
parcelHelpers.export(exports, "ServiceGetAccountInfoExceptionHeaders", ()=>ServiceGetAccountInfoExceptionHeaders);
parcelHelpers.export(exports, "ServiceSubmitBatchHeaders", ()=>ServiceSubmitBatchHeaders);
parcelHelpers.export(exports, "ServiceSubmitBatchExceptionHeaders", ()=>ServiceSubmitBatchExceptionHeaders);
parcelHelpers.export(exports, "ServiceFilterBlobsHeaders", ()=>ServiceFilterBlobsHeaders);
parcelHelpers.export(exports, "ServiceFilterBlobsExceptionHeaders", ()=>ServiceFilterBlobsExceptionHeaders);
parcelHelpers.export(exports, "ContainerCreateHeaders", ()=>ContainerCreateHeaders);
parcelHelpers.export(exports, "ContainerCreateExceptionHeaders", ()=>ContainerCreateExceptionHeaders);
parcelHelpers.export(exports, "ContainerGetPropertiesHeaders", ()=>ContainerGetPropertiesHeaders);
parcelHelpers.export(exports, "ContainerGetPropertiesExceptionHeaders", ()=>ContainerGetPropertiesExceptionHeaders);
parcelHelpers.export(exports, "ContainerDeleteHeaders", ()=>ContainerDeleteHeaders);
parcelHelpers.export(exports, "ContainerDeleteExceptionHeaders", ()=>ContainerDeleteExceptionHeaders);
parcelHelpers.export(exports, "ContainerSetMetadataHeaders", ()=>ContainerSetMetadataHeaders);
parcelHelpers.export(exports, "ContainerSetMetadataExceptionHeaders", ()=>ContainerSetMetadataExceptionHeaders);
parcelHelpers.export(exports, "ContainerGetAccessPolicyHeaders", ()=>ContainerGetAccessPolicyHeaders);
parcelHelpers.export(exports, "ContainerGetAccessPolicyExceptionHeaders", ()=>ContainerGetAccessPolicyExceptionHeaders);
parcelHelpers.export(exports, "ContainerSetAccessPolicyHeaders", ()=>ContainerSetAccessPolicyHeaders);
parcelHelpers.export(exports, "ContainerSetAccessPolicyExceptionHeaders", ()=>ContainerSetAccessPolicyExceptionHeaders);
parcelHelpers.export(exports, "ContainerRestoreHeaders", ()=>ContainerRestoreHeaders);
parcelHelpers.export(exports, "ContainerRestoreExceptionHeaders", ()=>ContainerRestoreExceptionHeaders);
parcelHelpers.export(exports, "ContainerRenameHeaders", ()=>ContainerRenameHeaders);
parcelHelpers.export(exports, "ContainerRenameExceptionHeaders", ()=>ContainerRenameExceptionHeaders);
parcelHelpers.export(exports, "ContainerSubmitBatchHeaders", ()=>ContainerSubmitBatchHeaders);
parcelHelpers.export(exports, "ContainerSubmitBatchExceptionHeaders", ()=>ContainerSubmitBatchExceptionHeaders);
parcelHelpers.export(exports, "ContainerFilterBlobsHeaders", ()=>ContainerFilterBlobsHeaders);
parcelHelpers.export(exports, "ContainerFilterBlobsExceptionHeaders", ()=>ContainerFilterBlobsExceptionHeaders);
parcelHelpers.export(exports, "ContainerAcquireLeaseHeaders", ()=>ContainerAcquireLeaseHeaders);
parcelHelpers.export(exports, "ContainerAcquireLeaseExceptionHeaders", ()=>ContainerAcquireLeaseExceptionHeaders);
parcelHelpers.export(exports, "ContainerReleaseLeaseHeaders", ()=>ContainerReleaseLeaseHeaders);
parcelHelpers.export(exports, "ContainerReleaseLeaseExceptionHeaders", ()=>ContainerReleaseLeaseExceptionHeaders);
parcelHelpers.export(exports, "ContainerRenewLeaseHeaders", ()=>ContainerRenewLeaseHeaders);
parcelHelpers.export(exports, "ContainerRenewLeaseExceptionHeaders", ()=>ContainerRenewLeaseExceptionHeaders);
parcelHelpers.export(exports, "ContainerBreakLeaseHeaders", ()=>ContainerBreakLeaseHeaders);
parcelHelpers.export(exports, "ContainerBreakLeaseExceptionHeaders", ()=>ContainerBreakLeaseExceptionHeaders);
parcelHelpers.export(exports, "ContainerChangeLeaseHeaders", ()=>ContainerChangeLeaseHeaders);
parcelHelpers.export(exports, "ContainerChangeLeaseExceptionHeaders", ()=>ContainerChangeLeaseExceptionHeaders);
parcelHelpers.export(exports, "ContainerListBlobFlatSegmentHeaders", ()=>ContainerListBlobFlatSegmentHeaders);
parcelHelpers.export(exports, "ContainerListBlobFlatSegmentExceptionHeaders", ()=>ContainerListBlobFlatSegmentExceptionHeaders);
parcelHelpers.export(exports, "ContainerListBlobHierarchySegmentHeaders", ()=>ContainerListBlobHierarchySegmentHeaders);
parcelHelpers.export(exports, "ContainerListBlobHierarchySegmentExceptionHeaders", ()=>ContainerListBlobHierarchySegmentExceptionHeaders);
parcelHelpers.export(exports, "ContainerGetAccountInfoHeaders", ()=>ContainerGetAccountInfoHeaders);
parcelHelpers.export(exports, "ContainerGetAccountInfoExceptionHeaders", ()=>ContainerGetAccountInfoExceptionHeaders);
parcelHelpers.export(exports, "BlobDownloadHeaders", ()=>BlobDownloadHeaders);
parcelHelpers.export(exports, "BlobDownloadExceptionHeaders", ()=>BlobDownloadExceptionHeaders);
parcelHelpers.export(exports, "BlobGetPropertiesHeaders", ()=>BlobGetPropertiesHeaders);
parcelHelpers.export(exports, "BlobGetPropertiesExceptionHeaders", ()=>BlobGetPropertiesExceptionHeaders);
parcelHelpers.export(exports, "BlobDeleteHeaders", ()=>BlobDeleteHeaders);
parcelHelpers.export(exports, "BlobDeleteExceptionHeaders", ()=>BlobDeleteExceptionHeaders);
parcelHelpers.export(exports, "BlobUndeleteHeaders", ()=>BlobUndeleteHeaders);
parcelHelpers.export(exports, "BlobUndeleteExceptionHeaders", ()=>BlobUndeleteExceptionHeaders);
parcelHelpers.export(exports, "BlobSetExpiryHeaders", ()=>BlobSetExpiryHeaders);
parcelHelpers.export(exports, "BlobSetExpiryExceptionHeaders", ()=>BlobSetExpiryExceptionHeaders);
parcelHelpers.export(exports, "BlobSetHttpHeadersHeaders", ()=>BlobSetHttpHeadersHeaders);
parcelHelpers.export(exports, "BlobSetHttpHeadersExceptionHeaders", ()=>BlobSetHttpHeadersExceptionHeaders);
parcelHelpers.export(exports, "BlobSetImmutabilityPolicyHeaders", ()=>BlobSetImmutabilityPolicyHeaders);
parcelHelpers.export(exports, "BlobSetImmutabilityPolicyExceptionHeaders", ()=>BlobSetImmutabilityPolicyExceptionHeaders);
parcelHelpers.export(exports, "BlobDeleteImmutabilityPolicyHeaders", ()=>BlobDeleteImmutabilityPolicyHeaders);
parcelHelpers.export(exports, "BlobDeleteImmutabilityPolicyExceptionHeaders", ()=>BlobDeleteImmutabilityPolicyExceptionHeaders);
parcelHelpers.export(exports, "BlobSetLegalHoldHeaders", ()=>BlobSetLegalHoldHeaders);
parcelHelpers.export(exports, "BlobSetLegalHoldExceptionHeaders", ()=>BlobSetLegalHoldExceptionHeaders);
parcelHelpers.export(exports, "BlobSetMetadataHeaders", ()=>BlobSetMetadataHeaders);
parcelHelpers.export(exports, "BlobSetMetadataExceptionHeaders", ()=>BlobSetMetadataExceptionHeaders);
parcelHelpers.export(exports, "BlobAcquireLeaseHeaders", ()=>BlobAcquireLeaseHeaders);
parcelHelpers.export(exports, "BlobAcquireLeaseExceptionHeaders", ()=>BlobAcquireLeaseExceptionHeaders);
parcelHelpers.export(exports, "BlobReleaseLeaseHeaders", ()=>BlobReleaseLeaseHeaders);
parcelHelpers.export(exports, "BlobReleaseLeaseExceptionHeaders", ()=>BlobReleaseLeaseExceptionHeaders);
parcelHelpers.export(exports, "BlobRenewLeaseHeaders", ()=>BlobRenewLeaseHeaders);
parcelHelpers.export(exports, "BlobRenewLeaseExceptionHeaders", ()=>BlobRenewLeaseExceptionHeaders);
parcelHelpers.export(exports, "BlobChangeLeaseHeaders", ()=>BlobChangeLeaseHeaders);
parcelHelpers.export(exports, "BlobChangeLeaseExceptionHeaders", ()=>BlobChangeLeaseExceptionHeaders);
parcelHelpers.export(exports, "BlobBreakLeaseHeaders", ()=>BlobBreakLeaseHeaders);
parcelHelpers.export(exports, "BlobBreakLeaseExceptionHeaders", ()=>BlobBreakLeaseExceptionHeaders);
parcelHelpers.export(exports, "BlobCreateSnapshotHeaders", ()=>BlobCreateSnapshotHeaders);
parcelHelpers.export(exports, "BlobCreateSnapshotExceptionHeaders", ()=>BlobCreateSnapshotExceptionHeaders);
parcelHelpers.export(exports, "BlobStartCopyFromURLHeaders", ()=>BlobStartCopyFromURLHeaders);
parcelHelpers.export(exports, "BlobStartCopyFromURLExceptionHeaders", ()=>BlobStartCopyFromURLExceptionHeaders);
parcelHelpers.export(exports, "BlobCopyFromURLHeaders", ()=>BlobCopyFromURLHeaders);
parcelHelpers.export(exports, "BlobCopyFromURLExceptionHeaders", ()=>BlobCopyFromURLExceptionHeaders);
parcelHelpers.export(exports, "BlobAbortCopyFromURLHeaders", ()=>BlobAbortCopyFromURLHeaders);
parcelHelpers.export(exports, "BlobAbortCopyFromURLExceptionHeaders", ()=>BlobAbortCopyFromURLExceptionHeaders);
parcelHelpers.export(exports, "BlobSetTierHeaders", ()=>BlobSetTierHeaders);
parcelHelpers.export(exports, "BlobSetTierExceptionHeaders", ()=>BlobSetTierExceptionHeaders);
parcelHelpers.export(exports, "BlobGetAccountInfoHeaders", ()=>BlobGetAccountInfoHeaders);
parcelHelpers.export(exports, "BlobGetAccountInfoExceptionHeaders", ()=>BlobGetAccountInfoExceptionHeaders);
parcelHelpers.export(exports, "BlobQueryHeaders", ()=>BlobQueryHeaders);
parcelHelpers.export(exports, "BlobQueryExceptionHeaders", ()=>BlobQueryExceptionHeaders);
parcelHelpers.export(exports, "BlobGetTagsHeaders", ()=>BlobGetTagsHeaders);
parcelHelpers.export(exports, "BlobGetTagsExceptionHeaders", ()=>BlobGetTagsExceptionHeaders);
parcelHelpers.export(exports, "BlobSetTagsHeaders", ()=>BlobSetTagsHeaders);
parcelHelpers.export(exports, "BlobSetTagsExceptionHeaders", ()=>BlobSetTagsExceptionHeaders);
parcelHelpers.export(exports, "PageBlobCreateHeaders", ()=>PageBlobCreateHeaders);
parcelHelpers.export(exports, "PageBlobCreateExceptionHeaders", ()=>PageBlobCreateExceptionHeaders);
parcelHelpers.export(exports, "PageBlobUploadPagesHeaders", ()=>PageBlobUploadPagesHeaders);
parcelHelpers.export(exports, "PageBlobUploadPagesExceptionHeaders", ()=>PageBlobUploadPagesExceptionHeaders);
parcelHelpers.export(exports, "PageBlobClearPagesHeaders", ()=>PageBlobClearPagesHeaders);
parcelHelpers.export(exports, "PageBlobClearPagesExceptionHeaders", ()=>PageBlobClearPagesExceptionHeaders);
parcelHelpers.export(exports, "PageBlobUploadPagesFromURLHeaders", ()=>PageBlobUploadPagesFromURLHeaders);
parcelHelpers.export(exports, "PageBlobUploadPagesFromURLExceptionHeaders", ()=>PageBlobUploadPagesFromURLExceptionHeaders);
parcelHelpers.export(exports, "PageBlobGetPageRangesHeaders", ()=>PageBlobGetPageRangesHeaders);
parcelHelpers.export(exports, "PageBlobGetPageRangesExceptionHeaders", ()=>PageBlobGetPageRangesExceptionHeaders);
parcelHelpers.export(exports, "PageBlobGetPageRangesDiffHeaders", ()=>PageBlobGetPageRangesDiffHeaders);
parcelHelpers.export(exports, "PageBlobGetPageRangesDiffExceptionHeaders", ()=>PageBlobGetPageRangesDiffExceptionHeaders);
parcelHelpers.export(exports, "PageBlobResizeHeaders", ()=>PageBlobResizeHeaders);
parcelHelpers.export(exports, "PageBlobResizeExceptionHeaders", ()=>PageBlobResizeExceptionHeaders);
parcelHelpers.export(exports, "PageBlobUpdateSequenceNumberHeaders", ()=>PageBlobUpdateSequenceNumberHeaders);
parcelHelpers.export(exports, "PageBlobUpdateSequenceNumberExceptionHeaders", ()=>PageBlobUpdateSequenceNumberExceptionHeaders);
parcelHelpers.export(exports, "PageBlobCopyIncrementalHeaders", ()=>PageBlobCopyIncrementalHeaders);
parcelHelpers.export(exports, "PageBlobCopyIncrementalExceptionHeaders", ()=>PageBlobCopyIncrementalExceptionHeaders);
parcelHelpers.export(exports, "AppendBlobCreateHeaders", ()=>AppendBlobCreateHeaders);
parcelHelpers.export(exports, "AppendBlobCreateExceptionHeaders", ()=>AppendBlobCreateExceptionHeaders);
parcelHelpers.export(exports, "AppendBlobAppendBlockHeaders", ()=>AppendBlobAppendBlockHeaders);
parcelHelpers.export(exports, "AppendBlobAppendBlockExceptionHeaders", ()=>AppendBlobAppendBlockExceptionHeaders);
parcelHelpers.export(exports, "AppendBlobAppendBlockFromUrlHeaders", ()=>AppendBlobAppendBlockFromUrlHeaders);
parcelHelpers.export(exports, "AppendBlobAppendBlockFromUrlExceptionHeaders", ()=>AppendBlobAppendBlockFromUrlExceptionHeaders);
parcelHelpers.export(exports, "AppendBlobSealHeaders", ()=>AppendBlobSealHeaders);
parcelHelpers.export(exports, "AppendBlobSealExceptionHeaders", ()=>AppendBlobSealExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobUploadHeaders", ()=>BlockBlobUploadHeaders);
parcelHelpers.export(exports, "BlockBlobUploadExceptionHeaders", ()=>BlockBlobUploadExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobPutBlobFromUrlHeaders", ()=>BlockBlobPutBlobFromUrlHeaders);
parcelHelpers.export(exports, "BlockBlobPutBlobFromUrlExceptionHeaders", ()=>BlockBlobPutBlobFromUrlExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobStageBlockHeaders", ()=>BlockBlobStageBlockHeaders);
parcelHelpers.export(exports, "BlockBlobStageBlockExceptionHeaders", ()=>BlockBlobStageBlockExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobStageBlockFromURLHeaders", ()=>BlockBlobStageBlockFromURLHeaders);
parcelHelpers.export(exports, "BlockBlobStageBlockFromURLExceptionHeaders", ()=>BlockBlobStageBlockFromURLExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobCommitBlockListHeaders", ()=>BlockBlobCommitBlockListHeaders);
parcelHelpers.export(exports, "BlockBlobCommitBlockListExceptionHeaders", ()=>BlockBlobCommitBlockListExceptionHeaders);
parcelHelpers.export(exports, "BlockBlobGetBlockListHeaders", ()=>BlockBlobGetBlockListHeaders);
parcelHelpers.export(exports, "BlockBlobGetBlockListExceptionHeaders", ()=>BlockBlobGetBlockListExceptionHeaders);
const BlobServiceProperties = {
    serializedName: "BlobServiceProperties",
    xmlName: "StorageServiceProperties",
    type: {
        name: "Composite",
        className: "BlobServiceProperties",
        modelProperties: {
            blobAnalyticsLogging: {
                serializedName: "Logging",
                xmlName: "Logging",
                type: {
                    name: "Composite",
                    className: "Logging"
                }
            },
            hourMetrics: {
                serializedName: "HourMetrics",
                xmlName: "HourMetrics",
                type: {
                    name: "Composite",
                    className: "Metrics"
                }
            },
            minuteMetrics: {
                serializedName: "MinuteMetrics",
                xmlName: "MinuteMetrics",
                type: {
                    name: "Composite",
                    className: "Metrics"
                }
            },
            cors: {
                serializedName: "Cors",
                xmlName: "Cors",
                xmlIsWrapped: true,
                xmlElementName: "CorsRule",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "CorsRule"
                        }
                    }
                }
            },
            defaultServiceVersion: {
                serializedName: "DefaultServiceVersion",
                xmlName: "DefaultServiceVersion",
                type: {
                    name: "String"
                }
            },
            deleteRetentionPolicy: {
                serializedName: "DeleteRetentionPolicy",
                xmlName: "DeleteRetentionPolicy",
                type: {
                    name: "Composite",
                    className: "RetentionPolicy"
                }
            },
            staticWebsite: {
                serializedName: "StaticWebsite",
                xmlName: "StaticWebsite",
                type: {
                    name: "Composite",
                    className: "StaticWebsite"
                }
            }
        }
    }
};
const Logging = {
    serializedName: "Logging",
    type: {
        name: "Composite",
        className: "Logging",
        modelProperties: {
            version: {
                serializedName: "Version",
                required: true,
                xmlName: "Version",
                type: {
                    name: "String"
                }
            },
            deleteProperty: {
                serializedName: "Delete",
                required: true,
                xmlName: "Delete",
                type: {
                    name: "Boolean"
                }
            },
            read: {
                serializedName: "Read",
                required: true,
                xmlName: "Read",
                type: {
                    name: "Boolean"
                }
            },
            write: {
                serializedName: "Write",
                required: true,
                xmlName: "Write",
                type: {
                    name: "Boolean"
                }
            },
            retentionPolicy: {
                serializedName: "RetentionPolicy",
                xmlName: "RetentionPolicy",
                type: {
                    name: "Composite",
                    className: "RetentionPolicy"
                }
            }
        }
    }
};
const RetentionPolicy = {
    serializedName: "RetentionPolicy",
    type: {
        name: "Composite",
        className: "RetentionPolicy",
        modelProperties: {
            enabled: {
                serializedName: "Enabled",
                required: true,
                xmlName: "Enabled",
                type: {
                    name: "Boolean"
                }
            },
            days: {
                constraints: {
                    InclusiveMinimum: 1
                },
                serializedName: "Days",
                xmlName: "Days",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const Metrics = {
    serializedName: "Metrics",
    type: {
        name: "Composite",
        className: "Metrics",
        modelProperties: {
            version: {
                serializedName: "Version",
                xmlName: "Version",
                type: {
                    name: "String"
                }
            },
            enabled: {
                serializedName: "Enabled",
                required: true,
                xmlName: "Enabled",
                type: {
                    name: "Boolean"
                }
            },
            includeAPIs: {
                serializedName: "IncludeAPIs",
                xmlName: "IncludeAPIs",
                type: {
                    name: "Boolean"
                }
            },
            retentionPolicy: {
                serializedName: "RetentionPolicy",
                xmlName: "RetentionPolicy",
                type: {
                    name: "Composite",
                    className: "RetentionPolicy"
                }
            }
        }
    }
};
const CorsRule = {
    serializedName: "CorsRule",
    type: {
        name: "Composite",
        className: "CorsRule",
        modelProperties: {
            allowedOrigins: {
                serializedName: "AllowedOrigins",
                required: true,
                xmlName: "AllowedOrigins",
                type: {
                    name: "String"
                }
            },
            allowedMethods: {
                serializedName: "AllowedMethods",
                required: true,
                xmlName: "AllowedMethods",
                type: {
                    name: "String"
                }
            },
            allowedHeaders: {
                serializedName: "AllowedHeaders",
                required: true,
                xmlName: "AllowedHeaders",
                type: {
                    name: "String"
                }
            },
            exposedHeaders: {
                serializedName: "ExposedHeaders",
                required: true,
                xmlName: "ExposedHeaders",
                type: {
                    name: "String"
                }
            },
            maxAgeInSeconds: {
                constraints: {
                    InclusiveMinimum: 0
                },
                serializedName: "MaxAgeInSeconds",
                required: true,
                xmlName: "MaxAgeInSeconds",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const StaticWebsite = {
    serializedName: "StaticWebsite",
    type: {
        name: "Composite",
        className: "StaticWebsite",
        modelProperties: {
            enabled: {
                serializedName: "Enabled",
                required: true,
                xmlName: "Enabled",
                type: {
                    name: "Boolean"
                }
            },
            indexDocument: {
                serializedName: "IndexDocument",
                xmlName: "IndexDocument",
                type: {
                    name: "String"
                }
            },
            errorDocument404Path: {
                serializedName: "ErrorDocument404Path",
                xmlName: "ErrorDocument404Path",
                type: {
                    name: "String"
                }
            },
            defaultIndexDocumentPath: {
                serializedName: "DefaultIndexDocumentPath",
                xmlName: "DefaultIndexDocumentPath",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const StorageError = {
    serializedName: "StorageError",
    type: {
        name: "Composite",
        className: "StorageError",
        modelProperties: {
            message: {
                serializedName: "Message",
                xmlName: "Message",
                type: {
                    name: "String"
                }
            },
            code: {
                serializedName: "Code",
                xmlName: "Code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobServiceStatistics = {
    serializedName: "BlobServiceStatistics",
    xmlName: "StorageServiceStats",
    type: {
        name: "Composite",
        className: "BlobServiceStatistics",
        modelProperties: {
            geoReplication: {
                serializedName: "GeoReplication",
                xmlName: "GeoReplication",
                type: {
                    name: "Composite",
                    className: "GeoReplication"
                }
            }
        }
    }
};
const GeoReplication = {
    serializedName: "GeoReplication",
    type: {
        name: "Composite",
        className: "GeoReplication",
        modelProperties: {
            status: {
                serializedName: "Status",
                required: true,
                xmlName: "Status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "live",
                        "bootstrap",
                        "unavailable"
                    ]
                }
            },
            lastSyncOn: {
                serializedName: "LastSyncTime",
                required: true,
                xmlName: "LastSyncTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ListContainersSegmentResponse = {
    serializedName: "ListContainersSegmentResponse",
    xmlName: "EnumerationResults",
    type: {
        name: "Composite",
        className: "ListContainersSegmentResponse",
        modelProperties: {
            serviceEndpoint: {
                serializedName: "ServiceEndpoint",
                required: true,
                xmlName: "ServiceEndpoint",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            prefix: {
                serializedName: "Prefix",
                xmlName: "Prefix",
                type: {
                    name: "String"
                }
            },
            marker: {
                serializedName: "Marker",
                xmlName: "Marker",
                type: {
                    name: "String"
                }
            },
            maxPageSize: {
                serializedName: "MaxResults",
                xmlName: "MaxResults",
                type: {
                    name: "Number"
                }
            },
            containerItems: {
                serializedName: "ContainerItems",
                required: true,
                xmlName: "Containers",
                xmlIsWrapped: true,
                xmlElementName: "Container",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "ContainerItem"
                        }
                    }
                }
            },
            continuationToken: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerItem = {
    serializedName: "ContainerItem",
    xmlName: "Container",
    type: {
        name: "Composite",
        className: "ContainerItem",
        modelProperties: {
            name: {
                serializedName: "Name",
                required: true,
                xmlName: "Name",
                type: {
                    name: "String"
                }
            },
            deleted: {
                serializedName: "Deleted",
                xmlName: "Deleted",
                type: {
                    name: "Boolean"
                }
            },
            version: {
                serializedName: "Version",
                xmlName: "Version",
                type: {
                    name: "String"
                }
            },
            properties: {
                serializedName: "Properties",
                xmlName: "Properties",
                type: {
                    name: "Composite",
                    className: "ContainerProperties"
                }
            },
            metadata: {
                serializedName: "Metadata",
                xmlName: "Metadata",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            }
        }
    }
};
const ContainerProperties = {
    serializedName: "ContainerProperties",
    type: {
        name: "Composite",
        className: "ContainerProperties",
        modelProperties: {
            lastModified: {
                serializedName: "Last-Modified",
                required: true,
                xmlName: "Last-Modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "Etag",
                required: true,
                xmlName: "Etag",
                type: {
                    name: "String"
                }
            },
            leaseStatus: {
                serializedName: "LeaseStatus",
                xmlName: "LeaseStatus",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            leaseState: {
                serializedName: "LeaseState",
                xmlName: "LeaseState",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseDuration: {
                serializedName: "LeaseDuration",
                xmlName: "LeaseDuration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            publicAccess: {
                serializedName: "PublicAccess",
                xmlName: "PublicAccess",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "container",
                        "blob"
                    ]
                }
            },
            hasImmutabilityPolicy: {
                serializedName: "HasImmutabilityPolicy",
                xmlName: "HasImmutabilityPolicy",
                type: {
                    name: "Boolean"
                }
            },
            hasLegalHold: {
                serializedName: "HasLegalHold",
                xmlName: "HasLegalHold",
                type: {
                    name: "Boolean"
                }
            },
            defaultEncryptionScope: {
                serializedName: "DefaultEncryptionScope",
                xmlName: "DefaultEncryptionScope",
                type: {
                    name: "String"
                }
            },
            preventEncryptionScopeOverride: {
                serializedName: "DenyEncryptionScopeOverride",
                xmlName: "DenyEncryptionScopeOverride",
                type: {
                    name: "Boolean"
                }
            },
            deletedOn: {
                serializedName: "DeletedTime",
                xmlName: "DeletedTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            remainingRetentionDays: {
                serializedName: "RemainingRetentionDays",
                xmlName: "RemainingRetentionDays",
                type: {
                    name: "Number"
                }
            },
            isImmutableStorageWithVersioningEnabled: {
                serializedName: "ImmutableStorageWithVersioningEnabled",
                xmlName: "ImmutableStorageWithVersioningEnabled",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const KeyInfo = {
    serializedName: "KeyInfo",
    type: {
        name: "Composite",
        className: "KeyInfo",
        modelProperties: {
            startsOn: {
                serializedName: "Start",
                required: true,
                xmlName: "Start",
                type: {
                    name: "String"
                }
            },
            expiresOn: {
                serializedName: "Expiry",
                required: true,
                xmlName: "Expiry",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const UserDelegationKey = {
    serializedName: "UserDelegationKey",
    type: {
        name: "Composite",
        className: "UserDelegationKey",
        modelProperties: {
            signedObjectId: {
                serializedName: "SignedOid",
                required: true,
                xmlName: "SignedOid",
                type: {
                    name: "String"
                }
            },
            signedTenantId: {
                serializedName: "SignedTid",
                required: true,
                xmlName: "SignedTid",
                type: {
                    name: "String"
                }
            },
            signedStartsOn: {
                serializedName: "SignedStart",
                required: true,
                xmlName: "SignedStart",
                type: {
                    name: "String"
                }
            },
            signedExpiresOn: {
                serializedName: "SignedExpiry",
                required: true,
                xmlName: "SignedExpiry",
                type: {
                    name: "String"
                }
            },
            signedService: {
                serializedName: "SignedService",
                required: true,
                xmlName: "SignedService",
                type: {
                    name: "String"
                }
            },
            signedVersion: {
                serializedName: "SignedVersion",
                required: true,
                xmlName: "SignedVersion",
                type: {
                    name: "String"
                }
            },
            value: {
                serializedName: "Value",
                required: true,
                xmlName: "Value",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FilterBlobSegment = {
    serializedName: "FilterBlobSegment",
    xmlName: "EnumerationResults",
    type: {
        name: "Composite",
        className: "FilterBlobSegment",
        modelProperties: {
            serviceEndpoint: {
                serializedName: "ServiceEndpoint",
                required: true,
                xmlName: "ServiceEndpoint",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            where: {
                serializedName: "Where",
                required: true,
                xmlName: "Where",
                type: {
                    name: "String"
                }
            },
            blobs: {
                serializedName: "Blobs",
                required: true,
                xmlName: "Blobs",
                xmlIsWrapped: true,
                xmlElementName: "Blob",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "FilterBlobItem"
                        }
                    }
                }
            },
            continuationToken: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FilterBlobItem = {
    serializedName: "FilterBlobItem",
    xmlName: "Blob",
    type: {
        name: "Composite",
        className: "FilterBlobItem",
        modelProperties: {
            name: {
                serializedName: "Name",
                required: true,
                xmlName: "Name",
                type: {
                    name: "String"
                }
            },
            containerName: {
                serializedName: "ContainerName",
                required: true,
                xmlName: "ContainerName",
                type: {
                    name: "String"
                }
            },
            tags: {
                serializedName: "Tags",
                xmlName: "Tags",
                type: {
                    name: "Composite",
                    className: "BlobTags"
                }
            }
        }
    }
};
const BlobTags = {
    serializedName: "BlobTags",
    xmlName: "Tags",
    type: {
        name: "Composite",
        className: "BlobTags",
        modelProperties: {
            blobTagSet: {
                serializedName: "BlobTagSet",
                required: true,
                xmlName: "TagSet",
                xmlIsWrapped: true,
                xmlElementName: "Tag",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobTag"
                        }
                    }
                }
            }
        }
    }
};
const BlobTag = {
    serializedName: "BlobTag",
    xmlName: "Tag",
    type: {
        name: "Composite",
        className: "BlobTag",
        modelProperties: {
            key: {
                serializedName: "Key",
                required: true,
                xmlName: "Key",
                type: {
                    name: "String"
                }
            },
            value: {
                serializedName: "Value",
                required: true,
                xmlName: "Value",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const SignedIdentifier = {
    serializedName: "SignedIdentifier",
    xmlName: "SignedIdentifier",
    type: {
        name: "Composite",
        className: "SignedIdentifier",
        modelProperties: {
            id: {
                serializedName: "Id",
                required: true,
                xmlName: "Id",
                type: {
                    name: "String"
                }
            },
            accessPolicy: {
                serializedName: "AccessPolicy",
                xmlName: "AccessPolicy",
                type: {
                    name: "Composite",
                    className: "AccessPolicy"
                }
            }
        }
    }
};
const AccessPolicy = {
    serializedName: "AccessPolicy",
    type: {
        name: "Composite",
        className: "AccessPolicy",
        modelProperties: {
            startsOn: {
                serializedName: "Start",
                xmlName: "Start",
                type: {
                    name: "String"
                }
            },
            expiresOn: {
                serializedName: "Expiry",
                xmlName: "Expiry",
                type: {
                    name: "String"
                }
            },
            permissions: {
                serializedName: "Permission",
                xmlName: "Permission",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ListBlobsFlatSegmentResponse = {
    serializedName: "ListBlobsFlatSegmentResponse",
    xmlName: "EnumerationResults",
    type: {
        name: "Composite",
        className: "ListBlobsFlatSegmentResponse",
        modelProperties: {
            serviceEndpoint: {
                serializedName: "ServiceEndpoint",
                required: true,
                xmlName: "ServiceEndpoint",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            containerName: {
                serializedName: "ContainerName",
                required: true,
                xmlName: "ContainerName",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            prefix: {
                serializedName: "Prefix",
                xmlName: "Prefix",
                type: {
                    name: "String"
                }
            },
            marker: {
                serializedName: "Marker",
                xmlName: "Marker",
                type: {
                    name: "String"
                }
            },
            maxPageSize: {
                serializedName: "MaxResults",
                xmlName: "MaxResults",
                type: {
                    name: "Number"
                }
            },
            segment: {
                serializedName: "Segment",
                xmlName: "Blobs",
                type: {
                    name: "Composite",
                    className: "BlobFlatListSegment"
                }
            },
            continuationToken: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobFlatListSegment = {
    serializedName: "BlobFlatListSegment",
    xmlName: "Blobs",
    type: {
        name: "Composite",
        className: "BlobFlatListSegment",
        modelProperties: {
            blobItems: {
                serializedName: "BlobItems",
                required: true,
                xmlName: "BlobItems",
                xmlElementName: "Blob",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobItemInternal"
                        }
                    }
                }
            }
        }
    }
};
const BlobItemInternal = {
    serializedName: "BlobItemInternal",
    xmlName: "Blob",
    type: {
        name: "Composite",
        className: "BlobItemInternal",
        modelProperties: {
            name: {
                serializedName: "Name",
                xmlName: "Name",
                type: {
                    name: "Composite",
                    className: "BlobName"
                }
            },
            deleted: {
                serializedName: "Deleted",
                required: true,
                xmlName: "Deleted",
                type: {
                    name: "Boolean"
                }
            },
            snapshot: {
                serializedName: "Snapshot",
                required: true,
                xmlName: "Snapshot",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "VersionId",
                xmlName: "VersionId",
                type: {
                    name: "String"
                }
            },
            isCurrentVersion: {
                serializedName: "IsCurrentVersion",
                xmlName: "IsCurrentVersion",
                type: {
                    name: "Boolean"
                }
            },
            properties: {
                serializedName: "Properties",
                xmlName: "Properties",
                type: {
                    name: "Composite",
                    className: "BlobPropertiesInternal"
                }
            },
            metadata: {
                serializedName: "Metadata",
                xmlName: "Metadata",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            blobTags: {
                serializedName: "BlobTags",
                xmlName: "Tags",
                type: {
                    name: "Composite",
                    className: "BlobTags"
                }
            },
            objectReplicationMetadata: {
                serializedName: "ObjectReplicationMetadata",
                xmlName: "OrMetadata",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            hasVersionsOnly: {
                serializedName: "HasVersionsOnly",
                xmlName: "HasVersionsOnly",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const BlobName = {
    serializedName: "BlobName",
    type: {
        name: "Composite",
        className: "BlobName",
        modelProperties: {
            encoded: {
                serializedName: "Encoded",
                xmlName: "Encoded",
                xmlIsAttribute: true,
                type: {
                    name: "Boolean"
                }
            },
            content: {
                serializedName: "content",
                xmlName: "content",
                xmlIsMsText: true,
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobPropertiesInternal = {
    serializedName: "BlobPropertiesInternal",
    xmlName: "Properties",
    type: {
        name: "Composite",
        className: "BlobPropertiesInternal",
        modelProperties: {
            createdOn: {
                serializedName: "Creation-Time",
                xmlName: "Creation-Time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            lastModified: {
                serializedName: "Last-Modified",
                required: true,
                xmlName: "Last-Modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "Etag",
                required: true,
                xmlName: "Etag",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "Content-Length",
                xmlName: "Content-Length",
                type: {
                    name: "Number"
                }
            },
            contentType: {
                serializedName: "Content-Type",
                xmlName: "Content-Type",
                type: {
                    name: "String"
                }
            },
            contentEncoding: {
                serializedName: "Content-Encoding",
                xmlName: "Content-Encoding",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "Content-Language",
                xmlName: "Content-Language",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "Content-MD5",
                xmlName: "Content-MD5",
                type: {
                    name: "ByteArray"
                }
            },
            contentDisposition: {
                serializedName: "Content-Disposition",
                xmlName: "Content-Disposition",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "Cache-Control",
                xmlName: "Cache-Control",
                type: {
                    name: "String"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            blobType: {
                serializedName: "BlobType",
                xmlName: "BlobType",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "BlockBlob",
                        "PageBlob",
                        "AppendBlob"
                    ]
                }
            },
            leaseStatus: {
                serializedName: "LeaseStatus",
                xmlName: "LeaseStatus",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            leaseState: {
                serializedName: "LeaseState",
                xmlName: "LeaseState",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseDuration: {
                serializedName: "LeaseDuration",
                xmlName: "LeaseDuration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            copyId: {
                serializedName: "CopyId",
                xmlName: "CopyId",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "CopyStatus",
                xmlName: "CopyStatus",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            copySource: {
                serializedName: "CopySource",
                xmlName: "CopySource",
                type: {
                    name: "String"
                }
            },
            copyProgress: {
                serializedName: "CopyProgress",
                xmlName: "CopyProgress",
                type: {
                    name: "String"
                }
            },
            copyCompletedOn: {
                serializedName: "CopyCompletionTime",
                xmlName: "CopyCompletionTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyStatusDescription: {
                serializedName: "CopyStatusDescription",
                xmlName: "CopyStatusDescription",
                type: {
                    name: "String"
                }
            },
            serverEncrypted: {
                serializedName: "ServerEncrypted",
                xmlName: "ServerEncrypted",
                type: {
                    name: "Boolean"
                }
            },
            incrementalCopy: {
                serializedName: "IncrementalCopy",
                xmlName: "IncrementalCopy",
                type: {
                    name: "Boolean"
                }
            },
            destinationSnapshot: {
                serializedName: "DestinationSnapshot",
                xmlName: "DestinationSnapshot",
                type: {
                    name: "String"
                }
            },
            deletedOn: {
                serializedName: "DeletedTime",
                xmlName: "DeletedTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            remainingRetentionDays: {
                serializedName: "RemainingRetentionDays",
                xmlName: "RemainingRetentionDays",
                type: {
                    name: "Number"
                }
            },
            accessTier: {
                serializedName: "AccessTier",
                xmlName: "AccessTier",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "P4",
                        "P6",
                        "P10",
                        "P15",
                        "P20",
                        "P30",
                        "P40",
                        "P50",
                        "P60",
                        "P70",
                        "P80",
                        "Hot",
                        "Cool",
                        "Archive",
                        "Cold"
                    ]
                }
            },
            accessTierInferred: {
                serializedName: "AccessTierInferred",
                xmlName: "AccessTierInferred",
                type: {
                    name: "Boolean"
                }
            },
            archiveStatus: {
                serializedName: "ArchiveStatus",
                xmlName: "ArchiveStatus",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "rehydrate-pending-to-hot",
                        "rehydrate-pending-to-cool",
                        "rehydrate-pending-to-cold"
                    ]
                }
            },
            customerProvidedKeySha256: {
                serializedName: "CustomerProvidedKeySha256",
                xmlName: "CustomerProvidedKeySha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "EncryptionScope",
                xmlName: "EncryptionScope",
                type: {
                    name: "String"
                }
            },
            accessTierChangedOn: {
                serializedName: "AccessTierChangeTime",
                xmlName: "AccessTierChangeTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            tagCount: {
                serializedName: "TagCount",
                xmlName: "TagCount",
                type: {
                    name: "Number"
                }
            },
            expiresOn: {
                serializedName: "Expiry-Time",
                xmlName: "Expiry-Time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isSealed: {
                serializedName: "Sealed",
                xmlName: "Sealed",
                type: {
                    name: "Boolean"
                }
            },
            rehydratePriority: {
                serializedName: "RehydratePriority",
                xmlName: "RehydratePriority",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "High",
                        "Standard"
                    ]
                }
            },
            lastAccessedOn: {
                serializedName: "LastAccessTime",
                xmlName: "LastAccessTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyExpiresOn: {
                serializedName: "ImmutabilityPolicyUntilDate",
                xmlName: "ImmutabilityPolicyUntilDate",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyMode: {
                serializedName: "ImmutabilityPolicyMode",
                xmlName: "ImmutabilityPolicyMode",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Mutable",
                        "Unlocked",
                        "Locked"
                    ]
                }
            },
            legalHold: {
                serializedName: "LegalHold",
                xmlName: "LegalHold",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const ListBlobsHierarchySegmentResponse = {
    serializedName: "ListBlobsHierarchySegmentResponse",
    xmlName: "EnumerationResults",
    type: {
        name: "Composite",
        className: "ListBlobsHierarchySegmentResponse",
        modelProperties: {
            serviceEndpoint: {
                serializedName: "ServiceEndpoint",
                required: true,
                xmlName: "ServiceEndpoint",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            containerName: {
                serializedName: "ContainerName",
                required: true,
                xmlName: "ContainerName",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            prefix: {
                serializedName: "Prefix",
                xmlName: "Prefix",
                type: {
                    name: "String"
                }
            },
            marker: {
                serializedName: "Marker",
                xmlName: "Marker",
                type: {
                    name: "String"
                }
            },
            maxPageSize: {
                serializedName: "MaxResults",
                xmlName: "MaxResults",
                type: {
                    name: "Number"
                }
            },
            delimiter: {
                serializedName: "Delimiter",
                xmlName: "Delimiter",
                type: {
                    name: "String"
                }
            },
            segment: {
                serializedName: "Segment",
                xmlName: "Blobs",
                type: {
                    name: "Composite",
                    className: "BlobHierarchyListSegment"
                }
            },
            continuationToken: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobHierarchyListSegment = {
    serializedName: "BlobHierarchyListSegment",
    xmlName: "Blobs",
    type: {
        name: "Composite",
        className: "BlobHierarchyListSegment",
        modelProperties: {
            blobPrefixes: {
                serializedName: "BlobPrefixes",
                xmlName: "BlobPrefixes",
                xmlElementName: "BlobPrefix",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobPrefix"
                        }
                    }
                }
            },
            blobItems: {
                serializedName: "BlobItems",
                required: true,
                xmlName: "BlobItems",
                xmlElementName: "Blob",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobItemInternal"
                        }
                    }
                }
            }
        }
    }
};
const BlobPrefix = {
    serializedName: "BlobPrefix",
    type: {
        name: "Composite",
        className: "BlobPrefix",
        modelProperties: {
            name: {
                serializedName: "Name",
                xmlName: "Name",
                type: {
                    name: "Composite",
                    className: "BlobName"
                }
            }
        }
    }
};
const BlockLookupList = {
    serializedName: "BlockLookupList",
    xmlName: "BlockList",
    type: {
        name: "Composite",
        className: "BlockLookupList",
        modelProperties: {
            committed: {
                serializedName: "Committed",
                xmlName: "Committed",
                xmlElementName: "Committed",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            uncommitted: {
                serializedName: "Uncommitted",
                xmlName: "Uncommitted",
                xmlElementName: "Uncommitted",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            latest: {
                serializedName: "Latest",
                xmlName: "Latest",
                xmlElementName: "Latest",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "String"
                        }
                    }
                }
            }
        }
    }
};
const BlockList = {
    serializedName: "BlockList",
    type: {
        name: "Composite",
        className: "BlockList",
        modelProperties: {
            committedBlocks: {
                serializedName: "CommittedBlocks",
                xmlName: "CommittedBlocks",
                xmlIsWrapped: true,
                xmlElementName: "Block",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "Block"
                        }
                    }
                }
            },
            uncommittedBlocks: {
                serializedName: "UncommittedBlocks",
                xmlName: "UncommittedBlocks",
                xmlIsWrapped: true,
                xmlElementName: "Block",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "Block"
                        }
                    }
                }
            }
        }
    }
};
const Block = {
    serializedName: "Block",
    type: {
        name: "Composite",
        className: "Block",
        modelProperties: {
            name: {
                serializedName: "Name",
                required: true,
                xmlName: "Name",
                type: {
                    name: "String"
                }
            },
            size: {
                serializedName: "Size",
                required: true,
                xmlName: "Size",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const PageList = {
    serializedName: "PageList",
    type: {
        name: "Composite",
        className: "PageList",
        modelProperties: {
            pageRange: {
                serializedName: "PageRange",
                xmlName: "PageRange",
                xmlElementName: "PageRange",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "PageRange"
                        }
                    }
                }
            },
            clearRange: {
                serializedName: "ClearRange",
                xmlName: "ClearRange",
                xmlElementName: "ClearRange",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "ClearRange"
                        }
                    }
                }
            },
            continuationToken: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageRange = {
    serializedName: "PageRange",
    xmlName: "PageRange",
    type: {
        name: "Composite",
        className: "PageRange",
        modelProperties: {
            start: {
                serializedName: "Start",
                required: true,
                xmlName: "Start",
                type: {
                    name: "Number"
                }
            },
            end: {
                serializedName: "End",
                required: true,
                xmlName: "End",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const ClearRange = {
    serializedName: "ClearRange",
    xmlName: "ClearRange",
    type: {
        name: "Composite",
        className: "ClearRange",
        modelProperties: {
            start: {
                serializedName: "Start",
                required: true,
                xmlName: "Start",
                type: {
                    name: "Number"
                }
            },
            end: {
                serializedName: "End",
                required: true,
                xmlName: "End",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const QueryRequest = {
    serializedName: "QueryRequest",
    xmlName: "QueryRequest",
    type: {
        name: "Composite",
        className: "QueryRequest",
        modelProperties: {
            queryType: {
                serializedName: "QueryType",
                required: true,
                xmlName: "QueryType",
                type: {
                    name: "String"
                }
            },
            expression: {
                serializedName: "Expression",
                required: true,
                xmlName: "Expression",
                type: {
                    name: "String"
                }
            },
            inputSerialization: {
                serializedName: "InputSerialization",
                xmlName: "InputSerialization",
                type: {
                    name: "Composite",
                    className: "QuerySerialization"
                }
            },
            outputSerialization: {
                serializedName: "OutputSerialization",
                xmlName: "OutputSerialization",
                type: {
                    name: "Composite",
                    className: "QuerySerialization"
                }
            }
        }
    }
};
const QuerySerialization = {
    serializedName: "QuerySerialization",
    type: {
        name: "Composite",
        className: "QuerySerialization",
        modelProperties: {
            format: {
                serializedName: "Format",
                xmlName: "Format",
                type: {
                    name: "Composite",
                    className: "QueryFormat"
                }
            }
        }
    }
};
const QueryFormat = {
    serializedName: "QueryFormat",
    type: {
        name: "Composite",
        className: "QueryFormat",
        modelProperties: {
            type: {
                serializedName: "Type",
                required: true,
                xmlName: "Type",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "delimited",
                        "json",
                        "arrow",
                        "parquet"
                    ]
                }
            },
            delimitedTextConfiguration: {
                serializedName: "DelimitedTextConfiguration",
                xmlName: "DelimitedTextConfiguration",
                type: {
                    name: "Composite",
                    className: "DelimitedTextConfiguration"
                }
            },
            jsonTextConfiguration: {
                serializedName: "JsonTextConfiguration",
                xmlName: "JsonTextConfiguration",
                type: {
                    name: "Composite",
                    className: "JsonTextConfiguration"
                }
            },
            arrowConfiguration: {
                serializedName: "ArrowConfiguration",
                xmlName: "ArrowConfiguration",
                type: {
                    name: "Composite",
                    className: "ArrowConfiguration"
                }
            },
            parquetTextConfiguration: {
                serializedName: "ParquetTextConfiguration",
                xmlName: "ParquetTextConfiguration",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "any"
                        }
                    }
                }
            }
        }
    }
};
const DelimitedTextConfiguration = {
    serializedName: "DelimitedTextConfiguration",
    xmlName: "DelimitedTextConfiguration",
    type: {
        name: "Composite",
        className: "DelimitedTextConfiguration",
        modelProperties: {
            columnSeparator: {
                serializedName: "ColumnSeparator",
                xmlName: "ColumnSeparator",
                type: {
                    name: "String"
                }
            },
            fieldQuote: {
                serializedName: "FieldQuote",
                xmlName: "FieldQuote",
                type: {
                    name: "String"
                }
            },
            recordSeparator: {
                serializedName: "RecordSeparator",
                xmlName: "RecordSeparator",
                type: {
                    name: "String"
                }
            },
            escapeChar: {
                serializedName: "EscapeChar",
                xmlName: "EscapeChar",
                type: {
                    name: "String"
                }
            },
            headersPresent: {
                serializedName: "HeadersPresent",
                xmlName: "HasHeaders",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const JsonTextConfiguration = {
    serializedName: "JsonTextConfiguration",
    xmlName: "JsonTextConfiguration",
    type: {
        name: "Composite",
        className: "JsonTextConfiguration",
        modelProperties: {
            recordSeparator: {
                serializedName: "RecordSeparator",
                xmlName: "RecordSeparator",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ArrowConfiguration = {
    serializedName: "ArrowConfiguration",
    xmlName: "ArrowConfiguration",
    type: {
        name: "Composite",
        className: "ArrowConfiguration",
        modelProperties: {
            schema: {
                serializedName: "Schema",
                required: true,
                xmlName: "Schema",
                xmlIsWrapped: true,
                xmlElementName: "Field",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "ArrowField"
                        }
                    }
                }
            }
        }
    }
};
const ArrowField = {
    serializedName: "ArrowField",
    xmlName: "Field",
    type: {
        name: "Composite",
        className: "ArrowField",
        modelProperties: {
            type: {
                serializedName: "Type",
                required: true,
                xmlName: "Type",
                type: {
                    name: "String"
                }
            },
            name: {
                serializedName: "Name",
                xmlName: "Name",
                type: {
                    name: "String"
                }
            },
            precision: {
                serializedName: "Precision",
                xmlName: "Precision",
                type: {
                    name: "Number"
                }
            },
            scale: {
                serializedName: "Scale",
                xmlName: "Scale",
                type: {
                    name: "Number"
                }
            }
        }
    }
};
const ServiceSetPropertiesHeaders = {
    serializedName: "Service_setPropertiesHeaders",
    type: {
        name: "Composite",
        className: "ServiceSetPropertiesHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceSetPropertiesExceptionHeaders = {
    serializedName: "Service_setPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceSetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetPropertiesHeaders = {
    serializedName: "Service_getPropertiesHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetPropertiesHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetPropertiesExceptionHeaders = {
    serializedName: "Service_getPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetStatisticsHeaders = {
    serializedName: "Service_getStatisticsHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetStatisticsHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetStatisticsExceptionHeaders = {
    serializedName: "Service_getStatisticsExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetStatisticsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceListContainersSegmentHeaders = {
    serializedName: "Service_listContainersSegmentHeaders",
    type: {
        name: "Composite",
        className: "ServiceListContainersSegmentHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceListContainersSegmentExceptionHeaders = {
    serializedName: "Service_listContainersSegmentExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceListContainersSegmentExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetUserDelegationKeyHeaders = {
    serializedName: "Service_getUserDelegationKeyHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetUserDelegationKeyHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetUserDelegationKeyExceptionHeaders = {
    serializedName: "Service_getUserDelegationKeyExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetUserDelegationKeyExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetAccountInfoHeaders = {
    serializedName: "Service_getAccountInfoHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetAccountInfoHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            skuName: {
                serializedName: "x-ms-sku-name",
                xmlName: "x-ms-sku-name",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Standard_LRS",
                        "Standard_GRS",
                        "Standard_RAGRS",
                        "Standard_ZRS",
                        "Premium_LRS"
                    ]
                }
            },
            accountKind: {
                serializedName: "x-ms-account-kind",
                xmlName: "x-ms-account-kind",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Storage",
                        "BlobStorage",
                        "StorageV2",
                        "FileStorage",
                        "BlockBlobStorage"
                    ]
                }
            },
            isHierarchicalNamespaceEnabled: {
                serializedName: "x-ms-is-hns-enabled",
                xmlName: "x-ms-is-hns-enabled",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceGetAccountInfoExceptionHeaders = {
    serializedName: "Service_getAccountInfoExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceGetAccountInfoExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceSubmitBatchHeaders = {
    serializedName: "Service_submitBatchHeaders",
    type: {
        name: "Composite",
        className: "ServiceSubmitBatchHeaders",
        modelProperties: {
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceSubmitBatchExceptionHeaders = {
    serializedName: "Service_submitBatchExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceSubmitBatchExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceFilterBlobsHeaders = {
    serializedName: "Service_filterBlobsHeaders",
    type: {
        name: "Composite",
        className: "ServiceFilterBlobsHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceFilterBlobsExceptionHeaders = {
    serializedName: "Service_filterBlobsExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceFilterBlobsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerCreateHeaders = {
    serializedName: "Container_createHeaders",
    type: {
        name: "Composite",
        className: "ContainerCreateHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerCreateExceptionHeaders = {
    serializedName: "Container_createExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerCreateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerGetPropertiesHeaders = {
    serializedName: "Container_getPropertiesHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetPropertiesHeaders",
        modelProperties: {
            metadata: {
                serializedName: "x-ms-meta",
                headerCollectionPrefix: "x-ms-meta-",
                xmlName: "x-ms-meta",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobPublicAccess: {
                serializedName: "x-ms-blob-public-access",
                xmlName: "x-ms-blob-public-access",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "container",
                        "blob"
                    ]
                }
            },
            hasImmutabilityPolicy: {
                serializedName: "x-ms-has-immutability-policy",
                xmlName: "x-ms-has-immutability-policy",
                type: {
                    name: "Boolean"
                }
            },
            hasLegalHold: {
                serializedName: "x-ms-has-legal-hold",
                xmlName: "x-ms-has-legal-hold",
                type: {
                    name: "Boolean"
                }
            },
            defaultEncryptionScope: {
                serializedName: "x-ms-default-encryption-scope",
                xmlName: "x-ms-default-encryption-scope",
                type: {
                    name: "String"
                }
            },
            denyEncryptionScopeOverride: {
                serializedName: "x-ms-deny-encryption-scope-override",
                xmlName: "x-ms-deny-encryption-scope-override",
                type: {
                    name: "Boolean"
                }
            },
            isImmutableStorageWithVersioningEnabled: {
                serializedName: "x-ms-immutable-storage-with-versioning-enabled",
                xmlName: "x-ms-immutable-storage-with-versioning-enabled",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerGetPropertiesExceptionHeaders = {
    serializedName: "Container_getPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerDeleteHeaders = {
    serializedName: "Container_deleteHeaders",
    type: {
        name: "Composite",
        className: "ContainerDeleteHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerDeleteExceptionHeaders = {
    serializedName: "Container_deleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerDeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSetMetadataHeaders = {
    serializedName: "Container_setMetadataHeaders",
    type: {
        name: "Composite",
        className: "ContainerSetMetadataHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSetMetadataExceptionHeaders = {
    serializedName: "Container_setMetadataExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerSetMetadataExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerGetAccessPolicyHeaders = {
    serializedName: "Container_getAccessPolicyHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetAccessPolicyHeaders",
        modelProperties: {
            blobPublicAccess: {
                serializedName: "x-ms-blob-public-access",
                xmlName: "x-ms-blob-public-access",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "container",
                        "blob"
                    ]
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerGetAccessPolicyExceptionHeaders = {
    serializedName: "Container_getAccessPolicyExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetAccessPolicyExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSetAccessPolicyHeaders = {
    serializedName: "Container_setAccessPolicyHeaders",
    type: {
        name: "Composite",
        className: "ContainerSetAccessPolicyHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSetAccessPolicyExceptionHeaders = {
    serializedName: "Container_setAccessPolicyExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerSetAccessPolicyExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerRestoreHeaders = {
    serializedName: "Container_restoreHeaders",
    type: {
        name: "Composite",
        className: "ContainerRestoreHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerRestoreExceptionHeaders = {
    serializedName: "Container_restoreExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerRestoreExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerRenameHeaders = {
    serializedName: "Container_renameHeaders",
    type: {
        name: "Composite",
        className: "ContainerRenameHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerRenameExceptionHeaders = {
    serializedName: "Container_renameExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerRenameExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSubmitBatchHeaders = {
    serializedName: "Container_submitBatchHeaders",
    type: {
        name: "Composite",
        className: "ContainerSubmitBatchHeaders",
        modelProperties: {
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerSubmitBatchExceptionHeaders = {
    serializedName: "Container_submitBatchExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerSubmitBatchExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerFilterBlobsHeaders = {
    serializedName: "Container_filterBlobsHeaders",
    type: {
        name: "Composite",
        className: "ContainerFilterBlobsHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerFilterBlobsExceptionHeaders = {
    serializedName: "Container_filterBlobsExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerFilterBlobsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerAcquireLeaseHeaders = {
    serializedName: "Container_acquireLeaseHeaders",
    type: {
        name: "Composite",
        className: "ContainerAcquireLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerAcquireLeaseExceptionHeaders = {
    serializedName: "Container_acquireLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerAcquireLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerReleaseLeaseHeaders = {
    serializedName: "Container_releaseLeaseHeaders",
    type: {
        name: "Composite",
        className: "ContainerReleaseLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerReleaseLeaseExceptionHeaders = {
    serializedName: "Container_releaseLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerReleaseLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerRenewLeaseHeaders = {
    serializedName: "Container_renewLeaseHeaders",
    type: {
        name: "Composite",
        className: "ContainerRenewLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerRenewLeaseExceptionHeaders = {
    serializedName: "Container_renewLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerRenewLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerBreakLeaseHeaders = {
    serializedName: "Container_breakLeaseHeaders",
    type: {
        name: "Composite",
        className: "ContainerBreakLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseTime: {
                serializedName: "x-ms-lease-time",
                xmlName: "x-ms-lease-time",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerBreakLeaseExceptionHeaders = {
    serializedName: "Container_breakLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerBreakLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerChangeLeaseHeaders = {
    serializedName: "Container_changeLeaseHeaders",
    type: {
        name: "Composite",
        className: "ContainerChangeLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const ContainerChangeLeaseExceptionHeaders = {
    serializedName: "Container_changeLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerChangeLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerListBlobFlatSegmentHeaders = {
    serializedName: "Container_listBlobFlatSegmentHeaders",
    type: {
        name: "Composite",
        className: "ContainerListBlobFlatSegmentHeaders",
        modelProperties: {
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerListBlobFlatSegmentExceptionHeaders = {
    serializedName: "Container_listBlobFlatSegmentExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerListBlobFlatSegmentExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerListBlobHierarchySegmentHeaders = {
    serializedName: "Container_listBlobHierarchySegmentHeaders",
    type: {
        name: "Composite",
        className: "ContainerListBlobHierarchySegmentHeaders",
        modelProperties: {
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerListBlobHierarchySegmentExceptionHeaders = {
    serializedName: "Container_listBlobHierarchySegmentExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerListBlobHierarchySegmentExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ContainerGetAccountInfoHeaders = {
    serializedName: "Container_getAccountInfoHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetAccountInfoHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            skuName: {
                serializedName: "x-ms-sku-name",
                xmlName: "x-ms-sku-name",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Standard_LRS",
                        "Standard_GRS",
                        "Standard_RAGRS",
                        "Standard_ZRS",
                        "Premium_LRS"
                    ]
                }
            },
            accountKind: {
                serializedName: "x-ms-account-kind",
                xmlName: "x-ms-account-kind",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Storage",
                        "BlobStorage",
                        "StorageV2",
                        "FileStorage",
                        "BlockBlobStorage"
                    ]
                }
            }
        }
    }
};
const ContainerGetAccountInfoExceptionHeaders = {
    serializedName: "Container_getAccountInfoExceptionHeaders",
    type: {
        name: "Composite",
        className: "ContainerGetAccountInfoExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobDownloadHeaders = {
    serializedName: "Blob_downloadHeaders",
    type: {
        name: "Composite",
        className: "BlobDownloadHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            createdOn: {
                serializedName: "x-ms-creation-time",
                xmlName: "x-ms-creation-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            metadata: {
                serializedName: "x-ms-meta",
                headerCollectionPrefix: "x-ms-meta-",
                xmlName: "x-ms-meta",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            objectReplicationPolicyId: {
                serializedName: "x-ms-or-policy-id",
                xmlName: "x-ms-or-policy-id",
                type: {
                    name: "String"
                }
            },
            objectReplicationRules: {
                serializedName: "x-ms-or",
                headerCollectionPrefix: "x-ms-or-",
                xmlName: "x-ms-or",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            contentRange: {
                serializedName: "content-range",
                xmlName: "content-range",
                type: {
                    name: "String"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            blobType: {
                serializedName: "x-ms-blob-type",
                xmlName: "x-ms-blob-type",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "BlockBlob",
                        "PageBlob",
                        "AppendBlob"
                    ]
                }
            },
            copyCompletedOn: {
                serializedName: "x-ms-copy-completion-time",
                xmlName: "x-ms-copy-completion-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyStatusDescription: {
                serializedName: "x-ms-copy-status-description",
                xmlName: "x-ms-copy-status-description",
                type: {
                    name: "String"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyProgress: {
                serializedName: "x-ms-copy-progress",
                xmlName: "x-ms-copy-progress",
                type: {
                    name: "String"
                }
            },
            copySource: {
                serializedName: "x-ms-copy-source",
                xmlName: "x-ms-copy-source",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "x-ms-copy-status",
                xmlName: "x-ms-copy-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            isCurrentVersion: {
                serializedName: "x-ms-is-current-version",
                xmlName: "x-ms-is-current-version",
                type: {
                    name: "Boolean"
                }
            },
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobCommittedBlockCount: {
                serializedName: "x-ms-blob-committed-block-count",
                xmlName: "x-ms-blob-committed-block-count",
                type: {
                    name: "Number"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-server-encrypted",
                xmlName: "x-ms-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            blobContentMD5: {
                serializedName: "x-ms-blob-content-md5",
                xmlName: "x-ms-blob-content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            tagCount: {
                serializedName: "x-ms-tag-count",
                xmlName: "x-ms-tag-count",
                type: {
                    name: "Number"
                }
            },
            isSealed: {
                serializedName: "x-ms-blob-sealed",
                xmlName: "x-ms-blob-sealed",
                type: {
                    name: "Boolean"
                }
            },
            lastAccessed: {
                serializedName: "x-ms-last-access-time",
                xmlName: "x-ms-last-access-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyExpiresOn: {
                serializedName: "x-ms-immutability-policy-until-date",
                xmlName: "x-ms-immutability-policy-until-date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyMode: {
                serializedName: "x-ms-immutability-policy-mode",
                xmlName: "x-ms-immutability-policy-mode",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Mutable",
                        "Unlocked",
                        "Locked"
                    ]
                }
            },
            legalHold: {
                serializedName: "x-ms-legal-hold",
                xmlName: "x-ms-legal-hold",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            },
            contentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            }
        }
    }
};
const BlobDownloadExceptionHeaders = {
    serializedName: "Blob_downloadExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobDownloadExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobGetPropertiesHeaders = {
    serializedName: "Blob_getPropertiesHeaders",
    type: {
        name: "Composite",
        className: "BlobGetPropertiesHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            createdOn: {
                serializedName: "x-ms-creation-time",
                xmlName: "x-ms-creation-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            metadata: {
                serializedName: "x-ms-meta",
                headerCollectionPrefix: "x-ms-meta-",
                xmlName: "x-ms-meta",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            objectReplicationPolicyId: {
                serializedName: "x-ms-or-policy-id",
                xmlName: "x-ms-or-policy-id",
                type: {
                    name: "String"
                }
            },
            objectReplicationRules: {
                serializedName: "x-ms-or",
                headerCollectionPrefix: "x-ms-or-",
                xmlName: "x-ms-or",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            blobType: {
                serializedName: "x-ms-blob-type",
                xmlName: "x-ms-blob-type",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "BlockBlob",
                        "PageBlob",
                        "AppendBlob"
                    ]
                }
            },
            copyCompletedOn: {
                serializedName: "x-ms-copy-completion-time",
                xmlName: "x-ms-copy-completion-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyStatusDescription: {
                serializedName: "x-ms-copy-status-description",
                xmlName: "x-ms-copy-status-description",
                type: {
                    name: "String"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyProgress: {
                serializedName: "x-ms-copy-progress",
                xmlName: "x-ms-copy-progress",
                type: {
                    name: "String"
                }
            },
            copySource: {
                serializedName: "x-ms-copy-source",
                xmlName: "x-ms-copy-source",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "x-ms-copy-status",
                xmlName: "x-ms-copy-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            isIncrementalCopy: {
                serializedName: "x-ms-incremental-copy",
                xmlName: "x-ms-incremental-copy",
                type: {
                    name: "Boolean"
                }
            },
            destinationSnapshot: {
                serializedName: "x-ms-copy-destination-snapshot",
                xmlName: "x-ms-copy-destination-snapshot",
                type: {
                    name: "String"
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            blobCommittedBlockCount: {
                serializedName: "x-ms-blob-committed-block-count",
                xmlName: "x-ms-blob-committed-block-count",
                type: {
                    name: "Number"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-server-encrypted",
                xmlName: "x-ms-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            accessTier: {
                serializedName: "x-ms-access-tier",
                xmlName: "x-ms-access-tier",
                type: {
                    name: "String"
                }
            },
            accessTierInferred: {
                serializedName: "x-ms-access-tier-inferred",
                xmlName: "x-ms-access-tier-inferred",
                type: {
                    name: "Boolean"
                }
            },
            archiveStatus: {
                serializedName: "x-ms-archive-status",
                xmlName: "x-ms-archive-status",
                type: {
                    name: "String"
                }
            },
            accessTierChangedOn: {
                serializedName: "x-ms-access-tier-change-time",
                xmlName: "x-ms-access-tier-change-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            isCurrentVersion: {
                serializedName: "x-ms-is-current-version",
                xmlName: "x-ms-is-current-version",
                type: {
                    name: "Boolean"
                }
            },
            tagCount: {
                serializedName: "x-ms-tag-count",
                xmlName: "x-ms-tag-count",
                type: {
                    name: "Number"
                }
            },
            expiresOn: {
                serializedName: "x-ms-expiry-time",
                xmlName: "x-ms-expiry-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isSealed: {
                serializedName: "x-ms-blob-sealed",
                xmlName: "x-ms-blob-sealed",
                type: {
                    name: "Boolean"
                }
            },
            rehydratePriority: {
                serializedName: "x-ms-rehydrate-priority",
                xmlName: "x-ms-rehydrate-priority",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "High",
                        "Standard"
                    ]
                }
            },
            lastAccessed: {
                serializedName: "x-ms-last-access-time",
                xmlName: "x-ms-last-access-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyExpiresOn: {
                serializedName: "x-ms-immutability-policy-until-date",
                xmlName: "x-ms-immutability-policy-until-date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyMode: {
                serializedName: "x-ms-immutability-policy-mode",
                xmlName: "x-ms-immutability-policy-mode",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Mutable",
                        "Unlocked",
                        "Locked"
                    ]
                }
            },
            legalHold: {
                serializedName: "x-ms-legal-hold",
                xmlName: "x-ms-legal-hold",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobGetPropertiesExceptionHeaders = {
    serializedName: "Blob_getPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobGetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobDeleteHeaders = {
    serializedName: "Blob_deleteHeaders",
    type: {
        name: "Composite",
        className: "BlobDeleteHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobDeleteExceptionHeaders = {
    serializedName: "Blob_deleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobDeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobUndeleteHeaders = {
    serializedName: "Blob_undeleteHeaders",
    type: {
        name: "Composite",
        className: "BlobUndeleteHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobUndeleteExceptionHeaders = {
    serializedName: "Blob_undeleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobUndeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetExpiryHeaders = {
    serializedName: "Blob_setExpiryHeaders",
    type: {
        name: "Composite",
        className: "BlobSetExpiryHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobSetExpiryExceptionHeaders = {
    serializedName: "Blob_setExpiryExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetExpiryExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetHttpHeadersHeaders = {
    serializedName: "Blob_setHttpHeadersHeaders",
    type: {
        name: "Composite",
        className: "BlobSetHttpHeadersHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetHttpHeadersExceptionHeaders = {
    serializedName: "Blob_setHttpHeadersExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetHttpHeadersExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetImmutabilityPolicyHeaders = {
    serializedName: "Blob_setImmutabilityPolicyHeaders",
    type: {
        name: "Composite",
        className: "BlobSetImmutabilityPolicyHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyExpiry: {
                serializedName: "x-ms-immutability-policy-until-date",
                xmlName: "x-ms-immutability-policy-until-date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            immutabilityPolicyMode: {
                serializedName: "x-ms-immutability-policy-mode",
                xmlName: "x-ms-immutability-policy-mode",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Mutable",
                        "Unlocked",
                        "Locked"
                    ]
                }
            }
        }
    }
};
const BlobSetImmutabilityPolicyExceptionHeaders = {
    serializedName: "Blob_setImmutabilityPolicyExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetImmutabilityPolicyExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobDeleteImmutabilityPolicyHeaders = {
    serializedName: "Blob_deleteImmutabilityPolicyHeaders",
    type: {
        name: "Composite",
        className: "BlobDeleteImmutabilityPolicyHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobDeleteImmutabilityPolicyExceptionHeaders = {
    serializedName: "Blob_deleteImmutabilityPolicyExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobDeleteImmutabilityPolicyExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetLegalHoldHeaders = {
    serializedName: "Blob_setLegalHoldHeaders",
    type: {
        name: "Composite",
        className: "BlobSetLegalHoldHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            legalHold: {
                serializedName: "x-ms-legal-hold",
                xmlName: "x-ms-legal-hold",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const BlobSetLegalHoldExceptionHeaders = {
    serializedName: "Blob_setLegalHoldExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetLegalHoldExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetMetadataHeaders = {
    serializedName: "Blob_setMetadataHeaders",
    type: {
        name: "Composite",
        className: "BlobSetMetadataHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetMetadataExceptionHeaders = {
    serializedName: "Blob_setMetadataExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetMetadataExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobAcquireLeaseHeaders = {
    serializedName: "Blob_acquireLeaseHeaders",
    type: {
        name: "Composite",
        className: "BlobAcquireLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobAcquireLeaseExceptionHeaders = {
    serializedName: "Blob_acquireLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobAcquireLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobReleaseLeaseHeaders = {
    serializedName: "Blob_releaseLeaseHeaders",
    type: {
        name: "Composite",
        className: "BlobReleaseLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobReleaseLeaseExceptionHeaders = {
    serializedName: "Blob_releaseLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobReleaseLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobRenewLeaseHeaders = {
    serializedName: "Blob_renewLeaseHeaders",
    type: {
        name: "Composite",
        className: "BlobRenewLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobRenewLeaseExceptionHeaders = {
    serializedName: "Blob_renewLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobRenewLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobChangeLeaseHeaders = {
    serializedName: "Blob_changeLeaseHeaders",
    type: {
        name: "Composite",
        className: "BlobChangeLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            leaseId: {
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobChangeLeaseExceptionHeaders = {
    serializedName: "Blob_changeLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobChangeLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobBreakLeaseHeaders = {
    serializedName: "Blob_breakLeaseHeaders",
    type: {
        name: "Composite",
        className: "BlobBreakLeaseHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            leaseTime: {
                serializedName: "x-ms-lease-time",
                xmlName: "x-ms-lease-time",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const BlobBreakLeaseExceptionHeaders = {
    serializedName: "Blob_breakLeaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobBreakLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobCreateSnapshotHeaders = {
    serializedName: "Blob_createSnapshotHeaders",
    type: {
        name: "Composite",
        className: "BlobCreateSnapshotHeaders",
        modelProperties: {
            snapshot: {
                serializedName: "x-ms-snapshot",
                xmlName: "x-ms-snapshot",
                type: {
                    name: "String"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobCreateSnapshotExceptionHeaders = {
    serializedName: "Blob_createSnapshotExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobCreateSnapshotExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobStartCopyFromURLHeaders = {
    serializedName: "Blob_startCopyFromURLHeaders",
    type: {
        name: "Composite",
        className: "BlobStartCopyFromURLHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "x-ms-copy-status",
                xmlName: "x-ms-copy-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobStartCopyFromURLExceptionHeaders = {
    serializedName: "Blob_startCopyFromURLExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobStartCopyFromURLExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobCopyFromURLHeaders = {
    serializedName: "Blob_copyFromURLHeaders",
    type: {
        name: "Composite",
        className: "BlobCopyFromURLHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                defaultValue: "success",
                isConstant: true,
                serializedName: "x-ms-copy-status",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobCopyFromURLExceptionHeaders = {
    serializedName: "Blob_copyFromURLExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobCopyFromURLExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobAbortCopyFromURLHeaders = {
    serializedName: "Blob_abortCopyFromURLHeaders",
    type: {
        name: "Composite",
        className: "BlobAbortCopyFromURLHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobAbortCopyFromURLExceptionHeaders = {
    serializedName: "Blob_abortCopyFromURLExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobAbortCopyFromURLExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetTierHeaders = {
    serializedName: "Blob_setTierHeaders",
    type: {
        name: "Composite",
        className: "BlobSetTierHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetTierExceptionHeaders = {
    serializedName: "Blob_setTierExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetTierExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobGetAccountInfoHeaders = {
    serializedName: "Blob_getAccountInfoHeaders",
    type: {
        name: "Composite",
        className: "BlobGetAccountInfoHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            skuName: {
                serializedName: "x-ms-sku-name",
                xmlName: "x-ms-sku-name",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Standard_LRS",
                        "Standard_GRS",
                        "Standard_RAGRS",
                        "Standard_ZRS",
                        "Premium_LRS"
                    ]
                }
            },
            accountKind: {
                serializedName: "x-ms-account-kind",
                xmlName: "x-ms-account-kind",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "Storage",
                        "BlobStorage",
                        "StorageV2",
                        "FileStorage",
                        "BlockBlobStorage"
                    ]
                }
            }
        }
    }
};
const BlobGetAccountInfoExceptionHeaders = {
    serializedName: "Blob_getAccountInfoExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobGetAccountInfoExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobQueryHeaders = {
    serializedName: "Blob_queryHeaders",
    type: {
        name: "Composite",
        className: "BlobQueryHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            metadata: {
                serializedName: "x-ms-meta",
                headerCollectionPrefix: "x-ms-meta-",
                xmlName: "x-ms-meta",
                type: {
                    name: "Dictionary",
                    value: {
                        type: {
                            name: "String"
                        }
                    }
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            contentRange: {
                serializedName: "content-range",
                xmlName: "content-range",
                type: {
                    name: "String"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            blobType: {
                serializedName: "x-ms-blob-type",
                xmlName: "x-ms-blob-type",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "BlockBlob",
                        "PageBlob",
                        "AppendBlob"
                    ]
                }
            },
            copyCompletionTime: {
                serializedName: "x-ms-copy-completion-time",
                xmlName: "x-ms-copy-completion-time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyStatusDescription: {
                serializedName: "x-ms-copy-status-description",
                xmlName: "x-ms-copy-status-description",
                type: {
                    name: "String"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyProgress: {
                serializedName: "x-ms-copy-progress",
                xmlName: "x-ms-copy-progress",
                type: {
                    name: "String"
                }
            },
            copySource: {
                serializedName: "x-ms-copy-source",
                xmlName: "x-ms-copy-source",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "x-ms-copy-status",
                xmlName: "x-ms-copy-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "infinite",
                        "fixed"
                    ]
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "available",
                        "leased",
                        "expired",
                        "breaking",
                        "broken"
                    ]
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "locked",
                        "unlocked"
                    ]
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobCommittedBlockCount: {
                serializedName: "x-ms-blob-committed-block-count",
                xmlName: "x-ms-blob-committed-block-count",
                type: {
                    name: "Number"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-server-encrypted",
                xmlName: "x-ms-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            blobContentMD5: {
                serializedName: "x-ms-blob-content-md5",
                xmlName: "x-ms-blob-content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            },
            contentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            }
        }
    }
};
const BlobQueryExceptionHeaders = {
    serializedName: "Blob_queryExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobQueryExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobGetTagsHeaders = {
    serializedName: "Blob_getTagsHeaders",
    type: {
        name: "Composite",
        className: "BlobGetTagsHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobGetTagsExceptionHeaders = {
    serializedName: "Blob_getTagsExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobGetTagsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetTagsHeaders = {
    serializedName: "Blob_setTagsHeaders",
    type: {
        name: "Composite",
        className: "BlobSetTagsHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobSetTagsExceptionHeaders = {
    serializedName: "Blob_setTagsExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlobSetTagsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobCreateHeaders = {
    serializedName: "PageBlob_createHeaders",
    type: {
        name: "Composite",
        className: "PageBlobCreateHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobCreateExceptionHeaders = {
    serializedName: "PageBlob_createExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobCreateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUploadPagesHeaders = {
    serializedName: "PageBlob_uploadPagesHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUploadPagesHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUploadPagesExceptionHeaders = {
    serializedName: "PageBlob_uploadPagesExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUploadPagesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobClearPagesHeaders = {
    serializedName: "PageBlob_clearPagesHeaders",
    type: {
        name: "Composite",
        className: "PageBlobClearPagesHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobClearPagesExceptionHeaders = {
    serializedName: "PageBlob_clearPagesExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobClearPagesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUploadPagesFromURLHeaders = {
    serializedName: "PageBlob_uploadPagesFromURLHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUploadPagesFromURLHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUploadPagesFromURLExceptionHeaders = {
    serializedName: "PageBlob_uploadPagesFromURLExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUploadPagesFromURLExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobGetPageRangesHeaders = {
    serializedName: "PageBlob_getPageRangesHeaders",
    type: {
        name: "Composite",
        className: "PageBlobGetPageRangesHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            blobContentLength: {
                serializedName: "x-ms-blob-content-length",
                xmlName: "x-ms-blob-content-length",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobGetPageRangesExceptionHeaders = {
    serializedName: "PageBlob_getPageRangesExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobGetPageRangesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobGetPageRangesDiffHeaders = {
    serializedName: "PageBlob_getPageRangesDiffHeaders",
    type: {
        name: "Composite",
        className: "PageBlobGetPageRangesDiffHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            blobContentLength: {
                serializedName: "x-ms-blob-content-length",
                xmlName: "x-ms-blob-content-length",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobGetPageRangesDiffExceptionHeaders = {
    serializedName: "PageBlob_getPageRangesDiffExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobGetPageRangesDiffExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobResizeHeaders = {
    serializedName: "PageBlob_resizeHeaders",
    type: {
        name: "Composite",
        className: "PageBlobResizeHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobResizeExceptionHeaders = {
    serializedName: "PageBlob_resizeExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobResizeExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUpdateSequenceNumberHeaders = {
    serializedName: "PageBlob_updateSequenceNumberHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUpdateSequenceNumberHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobUpdateSequenceNumberExceptionHeaders = {
    serializedName: "PageBlob_updateSequenceNumberExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobUpdateSequenceNumberExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobCopyIncrementalHeaders = {
    serializedName: "PageBlob_copyIncrementalHeaders",
    type: {
        name: "Composite",
        className: "PageBlobCopyIncrementalHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyId: {
                serializedName: "x-ms-copy-id",
                xmlName: "x-ms-copy-id",
                type: {
                    name: "String"
                }
            },
            copyStatus: {
                serializedName: "x-ms-copy-status",
                xmlName: "x-ms-copy-status",
                type: {
                    name: "Enum",
                    allowedValues: [
                        "pending",
                        "success",
                        "aborted",
                        "failed"
                    ]
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PageBlobCopyIncrementalExceptionHeaders = {
    serializedName: "PageBlob_copyIncrementalExceptionHeaders",
    type: {
        name: "Composite",
        className: "PageBlobCopyIncrementalExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobCreateHeaders = {
    serializedName: "AppendBlob_createHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobCreateHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobCreateExceptionHeaders = {
    serializedName: "AppendBlob_createExceptionHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobCreateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobAppendBlockHeaders = {
    serializedName: "AppendBlob_appendBlockHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobAppendBlockHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobAppendOffset: {
                serializedName: "x-ms-blob-append-offset",
                xmlName: "x-ms-blob-append-offset",
                type: {
                    name: "String"
                }
            },
            blobCommittedBlockCount: {
                serializedName: "x-ms-blob-committed-block-count",
                xmlName: "x-ms-blob-committed-block-count",
                type: {
                    name: "Number"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobAppendBlockExceptionHeaders = {
    serializedName: "AppendBlob_appendBlockExceptionHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobAppendBlockExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobAppendBlockFromUrlHeaders = {
    serializedName: "AppendBlob_appendBlockFromUrlHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobAppendBlockFromUrlHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            blobAppendOffset: {
                serializedName: "x-ms-blob-append-offset",
                xmlName: "x-ms-blob-append-offset",
                type: {
                    name: "String"
                }
            },
            blobCommittedBlockCount: {
                serializedName: "x-ms-blob-committed-block-count",
                xmlName: "x-ms-blob-committed-block-count",
                type: {
                    name: "Number"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobAppendBlockFromUrlExceptionHeaders = {
    serializedName: "AppendBlob_appendBlockFromUrlExceptionHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobAppendBlockFromUrlExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const AppendBlobSealHeaders = {
    serializedName: "AppendBlob_sealHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobSealHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isSealed: {
                serializedName: "x-ms-blob-sealed",
                xmlName: "x-ms-blob-sealed",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const AppendBlobSealExceptionHeaders = {
    serializedName: "AppendBlob_sealExceptionHeaders",
    type: {
        name: "Composite",
        className: "AppendBlobSealExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobUploadHeaders = {
    serializedName: "BlockBlob_uploadHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobUploadHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobUploadExceptionHeaders = {
    serializedName: "BlockBlob_uploadExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobUploadExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobPutBlobFromUrlHeaders = {
    serializedName: "BlockBlob_putBlobFromUrlHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobPutBlobFromUrlHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobPutBlobFromUrlExceptionHeaders = {
    serializedName: "BlockBlob_putBlobFromUrlExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobPutBlobFromUrlExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobStageBlockHeaders = {
    serializedName: "BlockBlob_stageBlockHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobStageBlockHeaders",
        modelProperties: {
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobStageBlockExceptionHeaders = {
    serializedName: "BlockBlob_stageBlockExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobStageBlockExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobStageBlockFromURLHeaders = {
    serializedName: "BlockBlob_stageBlockFromURLHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobStageBlockFromURLHeaders",
        modelProperties: {
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobStageBlockFromURLExceptionHeaders = {
    serializedName: "BlockBlob_stageBlockFromURLExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobStageBlockFromURLExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobCommitBlockListHeaders = {
    serializedName: "BlockBlob_commitBlockListHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobCommitBlockListHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "x-ms-version-id",
                xmlName: "x-ms-version-id",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            },
            encryptionKeySha256: {
                serializedName: "x-ms-encryption-key-sha256",
                xmlName: "x-ms-encryption-key-sha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "x-ms-encryption-scope",
                xmlName: "x-ms-encryption-scope",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobCommitBlockListExceptionHeaders = {
    serializedName: "BlockBlob_commitBlockListExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobCommitBlockListExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobGetBlockListHeaders = {
    serializedName: "BlockBlob_getBlockListHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobGetBlockListHeaders",
        modelProperties: {
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            blobContentLength: {
                serializedName: "x-ms-blob-content-length",
                xmlName: "x-ms-blob-content-length",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlockBlobGetBlockListExceptionHeaders = {
    serializedName: "BlockBlob_getBlockListExceptionHeaders",
    type: {
        name: "Composite",
        className: "BlockBlobGetBlockListExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dORMS":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "contentType", ()=>contentType);
parcelHelpers.export(exports, "blobServiceProperties", ()=>blobServiceProperties);
parcelHelpers.export(exports, "accept", ()=>accept);
parcelHelpers.export(exports, "url", ()=>url);
parcelHelpers.export(exports, "restype", ()=>restype);
parcelHelpers.export(exports, "comp", ()=>comp);
parcelHelpers.export(exports, "timeoutInSeconds", ()=>timeoutInSeconds);
parcelHelpers.export(exports, "version", ()=>version);
parcelHelpers.export(exports, "requestId", ()=>requestId);
parcelHelpers.export(exports, "accept1", ()=>accept1);
parcelHelpers.export(exports, "comp1", ()=>comp1);
parcelHelpers.export(exports, "comp2", ()=>comp2);
parcelHelpers.export(exports, "prefix", ()=>prefix);
parcelHelpers.export(exports, "marker", ()=>marker);
parcelHelpers.export(exports, "maxPageSize", ()=>maxPageSize);
parcelHelpers.export(exports, "include", ()=>include);
parcelHelpers.export(exports, "keyInfo", ()=>keyInfo);
parcelHelpers.export(exports, "comp3", ()=>comp3);
parcelHelpers.export(exports, "restype1", ()=>restype1);
parcelHelpers.export(exports, "body", ()=>body);
parcelHelpers.export(exports, "comp4", ()=>comp4);
parcelHelpers.export(exports, "contentLength", ()=>contentLength);
parcelHelpers.export(exports, "multipartContentType", ()=>multipartContentType);
parcelHelpers.export(exports, "comp5", ()=>comp5);
parcelHelpers.export(exports, "where", ()=>where);
parcelHelpers.export(exports, "restype2", ()=>restype2);
parcelHelpers.export(exports, "metadata", ()=>metadata);
parcelHelpers.export(exports, "access", ()=>access);
parcelHelpers.export(exports, "defaultEncryptionScope", ()=>defaultEncryptionScope);
parcelHelpers.export(exports, "preventEncryptionScopeOverride", ()=>preventEncryptionScopeOverride);
parcelHelpers.export(exports, "leaseId", ()=>leaseId);
parcelHelpers.export(exports, "ifModifiedSince", ()=>ifModifiedSince);
parcelHelpers.export(exports, "ifUnmodifiedSince", ()=>ifUnmodifiedSince);
parcelHelpers.export(exports, "comp6", ()=>comp6);
parcelHelpers.export(exports, "comp7", ()=>comp7);
parcelHelpers.export(exports, "containerAcl", ()=>containerAcl);
parcelHelpers.export(exports, "comp8", ()=>comp8);
parcelHelpers.export(exports, "deletedContainerName", ()=>deletedContainerName);
parcelHelpers.export(exports, "deletedContainerVersion", ()=>deletedContainerVersion);
parcelHelpers.export(exports, "comp9", ()=>comp9);
parcelHelpers.export(exports, "sourceContainerName", ()=>sourceContainerName);
parcelHelpers.export(exports, "sourceLeaseId", ()=>sourceLeaseId);
parcelHelpers.export(exports, "comp10", ()=>comp10);
parcelHelpers.export(exports, "action", ()=>action);
parcelHelpers.export(exports, "duration", ()=>duration);
parcelHelpers.export(exports, "proposedLeaseId", ()=>proposedLeaseId);
parcelHelpers.export(exports, "action1", ()=>action1);
parcelHelpers.export(exports, "leaseId1", ()=>leaseId1);
parcelHelpers.export(exports, "action2", ()=>action2);
parcelHelpers.export(exports, "action3", ()=>action3);
parcelHelpers.export(exports, "breakPeriod", ()=>breakPeriod);
parcelHelpers.export(exports, "action4", ()=>action4);
parcelHelpers.export(exports, "proposedLeaseId1", ()=>proposedLeaseId1);
parcelHelpers.export(exports, "include1", ()=>include1);
parcelHelpers.export(exports, "delimiter", ()=>delimiter);
parcelHelpers.export(exports, "snapshot", ()=>snapshot);
parcelHelpers.export(exports, "versionId", ()=>versionId);
parcelHelpers.export(exports, "range", ()=>range);
parcelHelpers.export(exports, "rangeGetContentMD5", ()=>rangeGetContentMD5);
parcelHelpers.export(exports, "rangeGetContentCRC64", ()=>rangeGetContentCRC64);
parcelHelpers.export(exports, "encryptionKey", ()=>encryptionKey);
parcelHelpers.export(exports, "encryptionKeySha256", ()=>encryptionKeySha256);
parcelHelpers.export(exports, "encryptionAlgorithm", ()=>encryptionAlgorithm);
parcelHelpers.export(exports, "ifMatch", ()=>ifMatch);
parcelHelpers.export(exports, "ifNoneMatch", ()=>ifNoneMatch);
parcelHelpers.export(exports, "ifTags", ()=>ifTags);
parcelHelpers.export(exports, "deleteSnapshots", ()=>deleteSnapshots);
parcelHelpers.export(exports, "blobDeleteType", ()=>blobDeleteType);
parcelHelpers.export(exports, "comp11", ()=>comp11);
parcelHelpers.export(exports, "expiryOptions", ()=>expiryOptions);
parcelHelpers.export(exports, "expiresOn", ()=>expiresOn);
parcelHelpers.export(exports, "blobCacheControl", ()=>blobCacheControl);
parcelHelpers.export(exports, "blobContentType", ()=>blobContentType);
parcelHelpers.export(exports, "blobContentMD5", ()=>blobContentMD5);
parcelHelpers.export(exports, "blobContentEncoding", ()=>blobContentEncoding);
parcelHelpers.export(exports, "blobContentLanguage", ()=>blobContentLanguage);
parcelHelpers.export(exports, "blobContentDisposition", ()=>blobContentDisposition);
parcelHelpers.export(exports, "comp12", ()=>comp12);
parcelHelpers.export(exports, "immutabilityPolicyExpiry", ()=>immutabilityPolicyExpiry);
parcelHelpers.export(exports, "immutabilityPolicyMode", ()=>immutabilityPolicyMode);
parcelHelpers.export(exports, "comp13", ()=>comp13);
parcelHelpers.export(exports, "legalHold", ()=>legalHold);
parcelHelpers.export(exports, "encryptionScope", ()=>encryptionScope);
parcelHelpers.export(exports, "comp14", ()=>comp14);
parcelHelpers.export(exports, "tier", ()=>tier);
parcelHelpers.export(exports, "rehydratePriority", ()=>rehydratePriority);
parcelHelpers.export(exports, "sourceIfModifiedSince", ()=>sourceIfModifiedSince);
parcelHelpers.export(exports, "sourceIfUnmodifiedSince", ()=>sourceIfUnmodifiedSince);
parcelHelpers.export(exports, "sourceIfMatch", ()=>sourceIfMatch);
parcelHelpers.export(exports, "sourceIfNoneMatch", ()=>sourceIfNoneMatch);
parcelHelpers.export(exports, "sourceIfTags", ()=>sourceIfTags);
parcelHelpers.export(exports, "copySource", ()=>copySource);
parcelHelpers.export(exports, "blobTagsString", ()=>blobTagsString);
parcelHelpers.export(exports, "sealBlob", ()=>sealBlob);
parcelHelpers.export(exports, "legalHold1", ()=>legalHold1);
parcelHelpers.export(exports, "xMsRequiresSync", ()=>xMsRequiresSync);
parcelHelpers.export(exports, "sourceContentMD5", ()=>sourceContentMD5);
parcelHelpers.export(exports, "copySourceAuthorization", ()=>copySourceAuthorization);
parcelHelpers.export(exports, "copySourceTags", ()=>copySourceTags);
parcelHelpers.export(exports, "comp15", ()=>comp15);
parcelHelpers.export(exports, "copyActionAbortConstant", ()=>copyActionAbortConstant);
parcelHelpers.export(exports, "copyId", ()=>copyId);
parcelHelpers.export(exports, "comp16", ()=>comp16);
parcelHelpers.export(exports, "tier1", ()=>tier1);
parcelHelpers.export(exports, "queryRequest", ()=>queryRequest);
parcelHelpers.export(exports, "comp17", ()=>comp17);
parcelHelpers.export(exports, "comp18", ()=>comp18);
parcelHelpers.export(exports, "tags", ()=>tags);
parcelHelpers.export(exports, "transactionalContentMD5", ()=>transactionalContentMD5);
parcelHelpers.export(exports, "transactionalContentCrc64", ()=>transactionalContentCrc64);
parcelHelpers.export(exports, "blobType", ()=>blobType);
parcelHelpers.export(exports, "blobContentLength", ()=>blobContentLength);
parcelHelpers.export(exports, "blobSequenceNumber", ()=>blobSequenceNumber);
parcelHelpers.export(exports, "contentType1", ()=>contentType1);
parcelHelpers.export(exports, "body1", ()=>body1);
parcelHelpers.export(exports, "accept2", ()=>accept2);
parcelHelpers.export(exports, "comp19", ()=>comp19);
parcelHelpers.export(exports, "pageWrite", ()=>pageWrite);
parcelHelpers.export(exports, "ifSequenceNumberLessThanOrEqualTo", ()=>ifSequenceNumberLessThanOrEqualTo);
parcelHelpers.export(exports, "ifSequenceNumberLessThan", ()=>ifSequenceNumberLessThan);
parcelHelpers.export(exports, "ifSequenceNumberEqualTo", ()=>ifSequenceNumberEqualTo);
parcelHelpers.export(exports, "pageWrite1", ()=>pageWrite1);
parcelHelpers.export(exports, "sourceUrl", ()=>sourceUrl);
parcelHelpers.export(exports, "sourceRange", ()=>sourceRange);
parcelHelpers.export(exports, "sourceContentCrc64", ()=>sourceContentCrc64);
parcelHelpers.export(exports, "range1", ()=>range1);
parcelHelpers.export(exports, "comp20", ()=>comp20);
parcelHelpers.export(exports, "prevsnapshot", ()=>prevsnapshot);
parcelHelpers.export(exports, "prevSnapshotUrl", ()=>prevSnapshotUrl);
parcelHelpers.export(exports, "sequenceNumberAction", ()=>sequenceNumberAction);
parcelHelpers.export(exports, "comp21", ()=>comp21);
parcelHelpers.export(exports, "blobType1", ()=>blobType1);
parcelHelpers.export(exports, "comp22", ()=>comp22);
parcelHelpers.export(exports, "maxSize", ()=>maxSize);
parcelHelpers.export(exports, "appendPosition", ()=>appendPosition);
parcelHelpers.export(exports, "sourceRange1", ()=>sourceRange1);
parcelHelpers.export(exports, "comp23", ()=>comp23);
parcelHelpers.export(exports, "blobType2", ()=>blobType2);
parcelHelpers.export(exports, "copySourceBlobProperties", ()=>copySourceBlobProperties);
parcelHelpers.export(exports, "comp24", ()=>comp24);
parcelHelpers.export(exports, "blockId", ()=>blockId);
parcelHelpers.export(exports, "blocks", ()=>blocks);
parcelHelpers.export(exports, "comp25", ()=>comp25);
parcelHelpers.export(exports, "listType", ()=>listType);
var _mappers = require("../models/mappers");
const contentType = {
    parameterPath: [
        "options",
        "contentType"
    ],
    mapper: {
        defaultValue: "application/xml",
        isConstant: true,
        serializedName: "Content-Type",
        type: {
            name: "String"
        }
    }
};
const blobServiceProperties = {
    parameterPath: "blobServiceProperties",
    mapper: (0, _mappers.BlobServiceProperties)
};
const accept = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/xml",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const url = {
    parameterPath: "url",
    mapper: {
        serializedName: "url",
        required: true,
        xmlName: "url",
        type: {
            name: "String"
        }
    },
    skipEncoding: true
};
const restype = {
    parameterPath: "restype",
    mapper: {
        defaultValue: "service",
        isConstant: true,
        serializedName: "restype",
        type: {
            name: "String"
        }
    }
};
const comp = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "properties",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const timeoutInSeconds = {
    parameterPath: [
        "options",
        "timeoutInSeconds"
    ],
    mapper: {
        constraints: {
            InclusiveMinimum: 0
        },
        serializedName: "timeout",
        xmlName: "timeout",
        type: {
            name: "Number"
        }
    }
};
const version = {
    parameterPath: "version",
    mapper: {
        defaultValue: "2024-05-04",
        isConstant: true,
        serializedName: "x-ms-version",
        type: {
            name: "String"
        }
    }
};
const requestId = {
    parameterPath: [
        "options",
        "requestId"
    ],
    mapper: {
        serializedName: "x-ms-client-request-id",
        xmlName: "x-ms-client-request-id",
        type: {
            name: "String"
        }
    }
};
const accept1 = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/xml",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const comp1 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "stats",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const comp2 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "list",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const prefix = {
    parameterPath: [
        "options",
        "prefix"
    ],
    mapper: {
        serializedName: "prefix",
        xmlName: "prefix",
        type: {
            name: "String"
        }
    }
};
const marker = {
    parameterPath: [
        "options",
        "marker"
    ],
    mapper: {
        serializedName: "marker",
        xmlName: "marker",
        type: {
            name: "String"
        }
    }
};
const maxPageSize = {
    parameterPath: [
        "options",
        "maxPageSize"
    ],
    mapper: {
        constraints: {
            InclusiveMinimum: 1
        },
        serializedName: "maxresults",
        xmlName: "maxresults",
        type: {
            name: "Number"
        }
    }
};
const include = {
    parameterPath: [
        "options",
        "include"
    ],
    mapper: {
        serializedName: "include",
        xmlName: "include",
        xmlElementName: "ListContainersIncludeType",
        type: {
            name: "Sequence",
            element: {
                type: {
                    name: "Enum",
                    allowedValues: [
                        "metadata",
                        "deleted",
                        "system"
                    ]
                }
            }
        }
    },
    collectionFormat: "CSV"
};
const keyInfo = {
    parameterPath: "keyInfo",
    mapper: (0, _mappers.KeyInfo)
};
const comp3 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "userdelegationkey",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const restype1 = {
    parameterPath: "restype",
    mapper: {
        defaultValue: "account",
        isConstant: true,
        serializedName: "restype",
        type: {
            name: "String"
        }
    }
};
const body = {
    parameterPath: "body",
    mapper: {
        serializedName: "body",
        required: true,
        xmlName: "body",
        type: {
            name: "Stream"
        }
    }
};
const comp4 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "batch",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const contentLength = {
    parameterPath: "contentLength",
    mapper: {
        serializedName: "Content-Length",
        required: true,
        xmlName: "Content-Length",
        type: {
            name: "Number"
        }
    }
};
const multipartContentType = {
    parameterPath: "multipartContentType",
    mapper: {
        serializedName: "Content-Type",
        required: true,
        xmlName: "Content-Type",
        type: {
            name: "String"
        }
    }
};
const comp5 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "blobs",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const where = {
    parameterPath: [
        "options",
        "where"
    ],
    mapper: {
        serializedName: "where",
        xmlName: "where",
        type: {
            name: "String"
        }
    }
};
const restype2 = {
    parameterPath: "restype",
    mapper: {
        defaultValue: "container",
        isConstant: true,
        serializedName: "restype",
        type: {
            name: "String"
        }
    }
};
const metadata = {
    parameterPath: [
        "options",
        "metadata"
    ],
    mapper: {
        serializedName: "x-ms-meta",
        xmlName: "x-ms-meta",
        headerCollectionPrefix: "x-ms-meta-",
        type: {
            name: "Dictionary",
            value: {
                type: {
                    name: "String"
                }
            }
        }
    }
};
const access = {
    parameterPath: [
        "options",
        "access"
    ],
    mapper: {
        serializedName: "x-ms-blob-public-access",
        xmlName: "x-ms-blob-public-access",
        type: {
            name: "Enum",
            allowedValues: [
                "container",
                "blob"
            ]
        }
    }
};
const defaultEncryptionScope = {
    parameterPath: [
        "options",
        "containerEncryptionScope",
        "defaultEncryptionScope"
    ],
    mapper: {
        serializedName: "x-ms-default-encryption-scope",
        xmlName: "x-ms-default-encryption-scope",
        type: {
            name: "String"
        }
    }
};
const preventEncryptionScopeOverride = {
    parameterPath: [
        "options",
        "containerEncryptionScope",
        "preventEncryptionScopeOverride"
    ],
    mapper: {
        serializedName: "x-ms-deny-encryption-scope-override",
        xmlName: "x-ms-deny-encryption-scope-override",
        type: {
            name: "Boolean"
        }
    }
};
const leaseId = {
    parameterPath: [
        "options",
        "leaseAccessConditions",
        "leaseId"
    ],
    mapper: {
        serializedName: "x-ms-lease-id",
        xmlName: "x-ms-lease-id",
        type: {
            name: "String"
        }
    }
};
const ifModifiedSince = {
    parameterPath: [
        "options",
        "modifiedAccessConditions",
        "ifModifiedSince"
    ],
    mapper: {
        serializedName: "If-Modified-Since",
        xmlName: "If-Modified-Since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const ifUnmodifiedSince = {
    parameterPath: [
        "options",
        "modifiedAccessConditions",
        "ifUnmodifiedSince"
    ],
    mapper: {
        serializedName: "If-Unmodified-Since",
        xmlName: "If-Unmodified-Since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const comp6 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "metadata",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const comp7 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "acl",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const containerAcl = {
    parameterPath: [
        "options",
        "containerAcl"
    ],
    mapper: {
        serializedName: "containerAcl",
        xmlName: "SignedIdentifiers",
        xmlIsWrapped: true,
        xmlElementName: "SignedIdentifier",
        type: {
            name: "Sequence",
            element: {
                type: {
                    name: "Composite",
                    className: "SignedIdentifier"
                }
            }
        }
    }
};
const comp8 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "undelete",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const deletedContainerName = {
    parameterPath: [
        "options",
        "deletedContainerName"
    ],
    mapper: {
        serializedName: "x-ms-deleted-container-name",
        xmlName: "x-ms-deleted-container-name",
        type: {
            name: "String"
        }
    }
};
const deletedContainerVersion = {
    parameterPath: [
        "options",
        "deletedContainerVersion"
    ],
    mapper: {
        serializedName: "x-ms-deleted-container-version",
        xmlName: "x-ms-deleted-container-version",
        type: {
            name: "String"
        }
    }
};
const comp9 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "rename",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const sourceContainerName = {
    parameterPath: "sourceContainerName",
    mapper: {
        serializedName: "x-ms-source-container-name",
        required: true,
        xmlName: "x-ms-source-container-name",
        type: {
            name: "String"
        }
    }
};
const sourceLeaseId = {
    parameterPath: [
        "options",
        "sourceLeaseId"
    ],
    mapper: {
        serializedName: "x-ms-source-lease-id",
        xmlName: "x-ms-source-lease-id",
        type: {
            name: "String"
        }
    }
};
const comp10 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "lease",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const action = {
    parameterPath: "action",
    mapper: {
        defaultValue: "acquire",
        isConstant: true,
        serializedName: "x-ms-lease-action",
        type: {
            name: "String"
        }
    }
};
const duration = {
    parameterPath: [
        "options",
        "duration"
    ],
    mapper: {
        serializedName: "x-ms-lease-duration",
        xmlName: "x-ms-lease-duration",
        type: {
            name: "Number"
        }
    }
};
const proposedLeaseId = {
    parameterPath: [
        "options",
        "proposedLeaseId"
    ],
    mapper: {
        serializedName: "x-ms-proposed-lease-id",
        xmlName: "x-ms-proposed-lease-id",
        type: {
            name: "String"
        }
    }
};
const action1 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "release",
        isConstant: true,
        serializedName: "x-ms-lease-action",
        type: {
            name: "String"
        }
    }
};
const leaseId1 = {
    parameterPath: "leaseId",
    mapper: {
        serializedName: "x-ms-lease-id",
        required: true,
        xmlName: "x-ms-lease-id",
        type: {
            name: "String"
        }
    }
};
const action2 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "renew",
        isConstant: true,
        serializedName: "x-ms-lease-action",
        type: {
            name: "String"
        }
    }
};
const action3 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "break",
        isConstant: true,
        serializedName: "x-ms-lease-action",
        type: {
            name: "String"
        }
    }
};
const breakPeriod = {
    parameterPath: [
        "options",
        "breakPeriod"
    ],
    mapper: {
        serializedName: "x-ms-lease-break-period",
        xmlName: "x-ms-lease-break-period",
        type: {
            name: "Number"
        }
    }
};
const action4 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "change",
        isConstant: true,
        serializedName: "x-ms-lease-action",
        type: {
            name: "String"
        }
    }
};
const proposedLeaseId1 = {
    parameterPath: "proposedLeaseId",
    mapper: {
        serializedName: "x-ms-proposed-lease-id",
        required: true,
        xmlName: "x-ms-proposed-lease-id",
        type: {
            name: "String"
        }
    }
};
const include1 = {
    parameterPath: [
        "options",
        "include"
    ],
    mapper: {
        serializedName: "include",
        xmlName: "include",
        xmlElementName: "ListBlobsIncludeItem",
        type: {
            name: "Sequence",
            element: {
                type: {
                    name: "Enum",
                    allowedValues: [
                        "copy",
                        "deleted",
                        "metadata",
                        "snapshots",
                        "uncommittedblobs",
                        "versions",
                        "tags",
                        "immutabilitypolicy",
                        "legalhold",
                        "deletedwithversions"
                    ]
                }
            }
        }
    },
    collectionFormat: "CSV"
};
const delimiter = {
    parameterPath: "delimiter",
    mapper: {
        serializedName: "delimiter",
        required: true,
        xmlName: "delimiter",
        type: {
            name: "String"
        }
    }
};
const snapshot = {
    parameterPath: [
        "options",
        "snapshot"
    ],
    mapper: {
        serializedName: "snapshot",
        xmlName: "snapshot",
        type: {
            name: "String"
        }
    }
};
const versionId = {
    parameterPath: [
        "options",
        "versionId"
    ],
    mapper: {
        serializedName: "versionid",
        xmlName: "versionid",
        type: {
            name: "String"
        }
    }
};
const range = {
    parameterPath: [
        "options",
        "range"
    ],
    mapper: {
        serializedName: "x-ms-range",
        xmlName: "x-ms-range",
        type: {
            name: "String"
        }
    }
};
const rangeGetContentMD5 = {
    parameterPath: [
        "options",
        "rangeGetContentMD5"
    ],
    mapper: {
        serializedName: "x-ms-range-get-content-md5",
        xmlName: "x-ms-range-get-content-md5",
        type: {
            name: "Boolean"
        }
    }
};
const rangeGetContentCRC64 = {
    parameterPath: [
        "options",
        "rangeGetContentCRC64"
    ],
    mapper: {
        serializedName: "x-ms-range-get-content-crc64",
        xmlName: "x-ms-range-get-content-crc64",
        type: {
            name: "Boolean"
        }
    }
};
const encryptionKey = {
    parameterPath: [
        "options",
        "cpkInfo",
        "encryptionKey"
    ],
    mapper: {
        serializedName: "x-ms-encryption-key",
        xmlName: "x-ms-encryption-key",
        type: {
            name: "String"
        }
    }
};
const encryptionKeySha256 = {
    parameterPath: [
        "options",
        "cpkInfo",
        "encryptionKeySha256"
    ],
    mapper: {
        serializedName: "x-ms-encryption-key-sha256",
        xmlName: "x-ms-encryption-key-sha256",
        type: {
            name: "String"
        }
    }
};
const encryptionAlgorithm = {
    parameterPath: [
        "options",
        "cpkInfo",
        "encryptionAlgorithm"
    ],
    mapper: {
        serializedName: "x-ms-encryption-algorithm",
        xmlName: "x-ms-encryption-algorithm",
        type: {
            name: "String"
        }
    }
};
const ifMatch = {
    parameterPath: [
        "options",
        "modifiedAccessConditions",
        "ifMatch"
    ],
    mapper: {
        serializedName: "If-Match",
        xmlName: "If-Match",
        type: {
            name: "String"
        }
    }
};
const ifNoneMatch = {
    parameterPath: [
        "options",
        "modifiedAccessConditions",
        "ifNoneMatch"
    ],
    mapper: {
        serializedName: "If-None-Match",
        xmlName: "If-None-Match",
        type: {
            name: "String"
        }
    }
};
const ifTags = {
    parameterPath: [
        "options",
        "modifiedAccessConditions",
        "ifTags"
    ],
    mapper: {
        serializedName: "x-ms-if-tags",
        xmlName: "x-ms-if-tags",
        type: {
            name: "String"
        }
    }
};
const deleteSnapshots = {
    parameterPath: [
        "options",
        "deleteSnapshots"
    ],
    mapper: {
        serializedName: "x-ms-delete-snapshots",
        xmlName: "x-ms-delete-snapshots",
        type: {
            name: "Enum",
            allowedValues: [
                "include",
                "only"
            ]
        }
    }
};
const blobDeleteType = {
    parameterPath: [
        "options",
        "blobDeleteType"
    ],
    mapper: {
        serializedName: "deletetype",
        xmlName: "deletetype",
        type: {
            name: "String"
        }
    }
};
const comp11 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "expiry",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const expiryOptions = {
    parameterPath: "expiryOptions",
    mapper: {
        serializedName: "x-ms-expiry-option",
        required: true,
        xmlName: "x-ms-expiry-option",
        type: {
            name: "String"
        }
    }
};
const expiresOn = {
    parameterPath: [
        "options",
        "expiresOn"
    ],
    mapper: {
        serializedName: "x-ms-expiry-time",
        xmlName: "x-ms-expiry-time",
        type: {
            name: "String"
        }
    }
};
const blobCacheControl = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobCacheControl"
    ],
    mapper: {
        serializedName: "x-ms-blob-cache-control",
        xmlName: "x-ms-blob-cache-control",
        type: {
            name: "String"
        }
    }
};
const blobContentType = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobContentType"
    ],
    mapper: {
        serializedName: "x-ms-blob-content-type",
        xmlName: "x-ms-blob-content-type",
        type: {
            name: "String"
        }
    }
};
const blobContentMD5 = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobContentMD5"
    ],
    mapper: {
        serializedName: "x-ms-blob-content-md5",
        xmlName: "x-ms-blob-content-md5",
        type: {
            name: "ByteArray"
        }
    }
};
const blobContentEncoding = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobContentEncoding"
    ],
    mapper: {
        serializedName: "x-ms-blob-content-encoding",
        xmlName: "x-ms-blob-content-encoding",
        type: {
            name: "String"
        }
    }
};
const blobContentLanguage = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobContentLanguage"
    ],
    mapper: {
        serializedName: "x-ms-blob-content-language",
        xmlName: "x-ms-blob-content-language",
        type: {
            name: "String"
        }
    }
};
const blobContentDisposition = {
    parameterPath: [
        "options",
        "blobHttpHeaders",
        "blobContentDisposition"
    ],
    mapper: {
        serializedName: "x-ms-blob-content-disposition",
        xmlName: "x-ms-blob-content-disposition",
        type: {
            name: "String"
        }
    }
};
const comp12 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "immutabilityPolicies",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const immutabilityPolicyExpiry = {
    parameterPath: [
        "options",
        "immutabilityPolicyExpiry"
    ],
    mapper: {
        serializedName: "x-ms-immutability-policy-until-date",
        xmlName: "x-ms-immutability-policy-until-date",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const immutabilityPolicyMode = {
    parameterPath: [
        "options",
        "immutabilityPolicyMode"
    ],
    mapper: {
        serializedName: "x-ms-immutability-policy-mode",
        xmlName: "x-ms-immutability-policy-mode",
        type: {
            name: "Enum",
            allowedValues: [
                "Mutable",
                "Unlocked",
                "Locked"
            ]
        }
    }
};
const comp13 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "legalhold",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const legalHold = {
    parameterPath: "legalHold",
    mapper: {
        serializedName: "x-ms-legal-hold",
        required: true,
        xmlName: "x-ms-legal-hold",
        type: {
            name: "Boolean"
        }
    }
};
const encryptionScope = {
    parameterPath: [
        "options",
        "encryptionScope"
    ],
    mapper: {
        serializedName: "x-ms-encryption-scope",
        xmlName: "x-ms-encryption-scope",
        type: {
            name: "String"
        }
    }
};
const comp14 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "snapshot",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const tier = {
    parameterPath: [
        "options",
        "tier"
    ],
    mapper: {
        serializedName: "x-ms-access-tier",
        xmlName: "x-ms-access-tier",
        type: {
            name: "Enum",
            allowedValues: [
                "P4",
                "P6",
                "P10",
                "P15",
                "P20",
                "P30",
                "P40",
                "P50",
                "P60",
                "P70",
                "P80",
                "Hot",
                "Cool",
                "Archive",
                "Cold"
            ]
        }
    }
};
const rehydratePriority = {
    parameterPath: [
        "options",
        "rehydratePriority"
    ],
    mapper: {
        serializedName: "x-ms-rehydrate-priority",
        xmlName: "x-ms-rehydrate-priority",
        type: {
            name: "Enum",
            allowedValues: [
                "High",
                "Standard"
            ]
        }
    }
};
const sourceIfModifiedSince = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfModifiedSince"
    ],
    mapper: {
        serializedName: "x-ms-source-if-modified-since",
        xmlName: "x-ms-source-if-modified-since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const sourceIfUnmodifiedSince = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfUnmodifiedSince"
    ],
    mapper: {
        serializedName: "x-ms-source-if-unmodified-since",
        xmlName: "x-ms-source-if-unmodified-since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const sourceIfMatch = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfMatch"
    ],
    mapper: {
        serializedName: "x-ms-source-if-match",
        xmlName: "x-ms-source-if-match",
        type: {
            name: "String"
        }
    }
};
const sourceIfNoneMatch = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfNoneMatch"
    ],
    mapper: {
        serializedName: "x-ms-source-if-none-match",
        xmlName: "x-ms-source-if-none-match",
        type: {
            name: "String"
        }
    }
};
const sourceIfTags = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfTags"
    ],
    mapper: {
        serializedName: "x-ms-source-if-tags",
        xmlName: "x-ms-source-if-tags",
        type: {
            name: "String"
        }
    }
};
const copySource = {
    parameterPath: "copySource",
    mapper: {
        serializedName: "x-ms-copy-source",
        required: true,
        xmlName: "x-ms-copy-source",
        type: {
            name: "String"
        }
    }
};
const blobTagsString = {
    parameterPath: [
        "options",
        "blobTagsString"
    ],
    mapper: {
        serializedName: "x-ms-tags",
        xmlName: "x-ms-tags",
        type: {
            name: "String"
        }
    }
};
const sealBlob = {
    parameterPath: [
        "options",
        "sealBlob"
    ],
    mapper: {
        serializedName: "x-ms-seal-blob",
        xmlName: "x-ms-seal-blob",
        type: {
            name: "Boolean"
        }
    }
};
const legalHold1 = {
    parameterPath: [
        "options",
        "legalHold"
    ],
    mapper: {
        serializedName: "x-ms-legal-hold",
        xmlName: "x-ms-legal-hold",
        type: {
            name: "Boolean"
        }
    }
};
const xMsRequiresSync = {
    parameterPath: "xMsRequiresSync",
    mapper: {
        defaultValue: "true",
        isConstant: true,
        serializedName: "x-ms-requires-sync",
        type: {
            name: "String"
        }
    }
};
const sourceContentMD5 = {
    parameterPath: [
        "options",
        "sourceContentMD5"
    ],
    mapper: {
        serializedName: "x-ms-source-content-md5",
        xmlName: "x-ms-source-content-md5",
        type: {
            name: "ByteArray"
        }
    }
};
const copySourceAuthorization = {
    parameterPath: [
        "options",
        "copySourceAuthorization"
    ],
    mapper: {
        serializedName: "x-ms-copy-source-authorization",
        xmlName: "x-ms-copy-source-authorization",
        type: {
            name: "String"
        }
    }
};
const copySourceTags = {
    parameterPath: [
        "options",
        "copySourceTags"
    ],
    mapper: {
        serializedName: "x-ms-copy-source-tag-option",
        xmlName: "x-ms-copy-source-tag-option",
        type: {
            name: "Enum",
            allowedValues: [
                "REPLACE",
                "COPY"
            ]
        }
    }
};
const comp15 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "copy",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const copyActionAbortConstant = {
    parameterPath: "copyActionAbortConstant",
    mapper: {
        defaultValue: "abort",
        isConstant: true,
        serializedName: "x-ms-copy-action",
        type: {
            name: "String"
        }
    }
};
const copyId = {
    parameterPath: "copyId",
    mapper: {
        serializedName: "copyid",
        required: true,
        xmlName: "copyid",
        type: {
            name: "String"
        }
    }
};
const comp16 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "tier",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const tier1 = {
    parameterPath: "tier",
    mapper: {
        serializedName: "x-ms-access-tier",
        required: true,
        xmlName: "x-ms-access-tier",
        type: {
            name: "Enum",
            allowedValues: [
                "P4",
                "P6",
                "P10",
                "P15",
                "P20",
                "P30",
                "P40",
                "P50",
                "P60",
                "P70",
                "P80",
                "Hot",
                "Cool",
                "Archive",
                "Cold"
            ]
        }
    }
};
const queryRequest = {
    parameterPath: [
        "options",
        "queryRequest"
    ],
    mapper: (0, _mappers.QueryRequest)
};
const comp17 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "query",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const comp18 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "tags",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const tags = {
    parameterPath: [
        "options",
        "tags"
    ],
    mapper: (0, _mappers.BlobTags)
};
const transactionalContentMD5 = {
    parameterPath: [
        "options",
        "transactionalContentMD5"
    ],
    mapper: {
        serializedName: "Content-MD5",
        xmlName: "Content-MD5",
        type: {
            name: "ByteArray"
        }
    }
};
const transactionalContentCrc64 = {
    parameterPath: [
        "options",
        "transactionalContentCrc64"
    ],
    mapper: {
        serializedName: "x-ms-content-crc64",
        xmlName: "x-ms-content-crc64",
        type: {
            name: "ByteArray"
        }
    }
};
const blobType = {
    parameterPath: "blobType",
    mapper: {
        defaultValue: "PageBlob",
        isConstant: true,
        serializedName: "x-ms-blob-type",
        type: {
            name: "String"
        }
    }
};
const blobContentLength = {
    parameterPath: "blobContentLength",
    mapper: {
        serializedName: "x-ms-blob-content-length",
        required: true,
        xmlName: "x-ms-blob-content-length",
        type: {
            name: "Number"
        }
    }
};
const blobSequenceNumber = {
    parameterPath: [
        "options",
        "blobSequenceNumber"
    ],
    mapper: {
        defaultValue: 0,
        serializedName: "x-ms-blob-sequence-number",
        xmlName: "x-ms-blob-sequence-number",
        type: {
            name: "Number"
        }
    }
};
const contentType1 = {
    parameterPath: [
        "options",
        "contentType"
    ],
    mapper: {
        defaultValue: "application/octet-stream",
        isConstant: true,
        serializedName: "Content-Type",
        type: {
            name: "String"
        }
    }
};
const body1 = {
    parameterPath: "body",
    mapper: {
        serializedName: "body",
        required: true,
        xmlName: "body",
        type: {
            name: "Stream"
        }
    }
};
const accept2 = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/xml",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const comp19 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "page",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const pageWrite = {
    parameterPath: "pageWrite",
    mapper: {
        defaultValue: "update",
        isConstant: true,
        serializedName: "x-ms-page-write",
        type: {
            name: "String"
        }
    }
};
const ifSequenceNumberLessThanOrEqualTo = {
    parameterPath: [
        "options",
        "sequenceNumberAccessConditions",
        "ifSequenceNumberLessThanOrEqualTo"
    ],
    mapper: {
        serializedName: "x-ms-if-sequence-number-le",
        xmlName: "x-ms-if-sequence-number-le",
        type: {
            name: "Number"
        }
    }
};
const ifSequenceNumberLessThan = {
    parameterPath: [
        "options",
        "sequenceNumberAccessConditions",
        "ifSequenceNumberLessThan"
    ],
    mapper: {
        serializedName: "x-ms-if-sequence-number-lt",
        xmlName: "x-ms-if-sequence-number-lt",
        type: {
            name: "Number"
        }
    }
};
const ifSequenceNumberEqualTo = {
    parameterPath: [
        "options",
        "sequenceNumberAccessConditions",
        "ifSequenceNumberEqualTo"
    ],
    mapper: {
        serializedName: "x-ms-if-sequence-number-eq",
        xmlName: "x-ms-if-sequence-number-eq",
        type: {
            name: "Number"
        }
    }
};
const pageWrite1 = {
    parameterPath: "pageWrite",
    mapper: {
        defaultValue: "clear",
        isConstant: true,
        serializedName: "x-ms-page-write",
        type: {
            name: "String"
        }
    }
};
const sourceUrl = {
    parameterPath: "sourceUrl",
    mapper: {
        serializedName: "x-ms-copy-source",
        required: true,
        xmlName: "x-ms-copy-source",
        type: {
            name: "String"
        }
    }
};
const sourceRange = {
    parameterPath: "sourceRange",
    mapper: {
        serializedName: "x-ms-source-range",
        required: true,
        xmlName: "x-ms-source-range",
        type: {
            name: "String"
        }
    }
};
const sourceContentCrc64 = {
    parameterPath: [
        "options",
        "sourceContentCrc64"
    ],
    mapper: {
        serializedName: "x-ms-source-content-crc64",
        xmlName: "x-ms-source-content-crc64",
        type: {
            name: "ByteArray"
        }
    }
};
const range1 = {
    parameterPath: "range",
    mapper: {
        serializedName: "x-ms-range",
        required: true,
        xmlName: "x-ms-range",
        type: {
            name: "String"
        }
    }
};
const comp20 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "pagelist",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const prevsnapshot = {
    parameterPath: [
        "options",
        "prevsnapshot"
    ],
    mapper: {
        serializedName: "prevsnapshot",
        xmlName: "prevsnapshot",
        type: {
            name: "String"
        }
    }
};
const prevSnapshotUrl = {
    parameterPath: [
        "options",
        "prevSnapshotUrl"
    ],
    mapper: {
        serializedName: "x-ms-previous-snapshot-url",
        xmlName: "x-ms-previous-snapshot-url",
        type: {
            name: "String"
        }
    }
};
const sequenceNumberAction = {
    parameterPath: "sequenceNumberAction",
    mapper: {
        serializedName: "x-ms-sequence-number-action",
        required: true,
        xmlName: "x-ms-sequence-number-action",
        type: {
            name: "Enum",
            allowedValues: [
                "max",
                "update",
                "increment"
            ]
        }
    }
};
const comp21 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "incrementalcopy",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const blobType1 = {
    parameterPath: "blobType",
    mapper: {
        defaultValue: "AppendBlob",
        isConstant: true,
        serializedName: "x-ms-blob-type",
        type: {
            name: "String"
        }
    }
};
const comp22 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "appendblock",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const maxSize = {
    parameterPath: [
        "options",
        "appendPositionAccessConditions",
        "maxSize"
    ],
    mapper: {
        serializedName: "x-ms-blob-condition-maxsize",
        xmlName: "x-ms-blob-condition-maxsize",
        type: {
            name: "Number"
        }
    }
};
const appendPosition = {
    parameterPath: [
        "options",
        "appendPositionAccessConditions",
        "appendPosition"
    ],
    mapper: {
        serializedName: "x-ms-blob-condition-appendpos",
        xmlName: "x-ms-blob-condition-appendpos",
        type: {
            name: "Number"
        }
    }
};
const sourceRange1 = {
    parameterPath: [
        "options",
        "sourceRange"
    ],
    mapper: {
        serializedName: "x-ms-source-range",
        xmlName: "x-ms-source-range",
        type: {
            name: "String"
        }
    }
};
const comp23 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "seal",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const blobType2 = {
    parameterPath: "blobType",
    mapper: {
        defaultValue: "BlockBlob",
        isConstant: true,
        serializedName: "x-ms-blob-type",
        type: {
            name: "String"
        }
    }
};
const copySourceBlobProperties = {
    parameterPath: [
        "options",
        "copySourceBlobProperties"
    ],
    mapper: {
        serializedName: "x-ms-copy-source-blob-properties",
        xmlName: "x-ms-copy-source-blob-properties",
        type: {
            name: "Boolean"
        }
    }
};
const comp24 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "block",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const blockId = {
    parameterPath: "blockId",
    mapper: {
        serializedName: "blockid",
        required: true,
        xmlName: "blockid",
        type: {
            name: "String"
        }
    }
};
const blocks = {
    parameterPath: "blocks",
    mapper: (0, _mappers.BlockLookupList)
};
const comp25 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "blocklist",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const listType = {
    parameterPath: "listType",
    mapper: {
        defaultValue: "committed",
        serializedName: "blocklisttype",
        required: true,
        xmlName: "blocklisttype",
        type: {
            name: "Enum",
            allowedValues: [
                "committed",
                "uncommitted",
                "all"
            ]
        }
    }
};

},{"../models/mappers":"2ZlYI","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2faTT":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing Container operations. */ parcelHelpers.export(exports, "ContainerImpl", ()=>ContainerImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class ContainerImpl {
    /**
     * Initialize a new instance of the class Container class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * creates a new container under the specified account. If the container with the same name already
     * exists, the operation fails
     * @param options The options parameters.
     */ create(options) {
        return this.client.sendOperationRequest({
            options
        }, createOperationSpec);
    }
    /**
     * returns all user-defined metadata and system properties for the specified container. The data
     * returned does not include the container's list of blobs
     * @param options The options parameters.
     */ getProperties(options) {
        return this.client.sendOperationRequest({
            options
        }, getPropertiesOperationSpec);
    }
    /**
     * operation marks the specified container for deletion. The container and any blobs contained within
     * it are later deleted during garbage collection
     * @param options The options parameters.
     */ delete(options) {
        return this.client.sendOperationRequest({
            options
        }, deleteOperationSpec);
    }
    /**
     * operation sets one or more user-defined name-value pairs for the specified container.
     * @param options The options parameters.
     */ setMetadata(options) {
        return this.client.sendOperationRequest({
            options
        }, setMetadataOperationSpec);
    }
    /**
     * gets the permissions for the specified container. The permissions indicate whether container data
     * may be accessed publicly.
     * @param options The options parameters.
     */ getAccessPolicy(options) {
        return this.client.sendOperationRequest({
            options
        }, getAccessPolicyOperationSpec);
    }
    /**
     * sets the permissions for the specified container. The permissions indicate whether blobs in a
     * container may be accessed publicly.
     * @param options The options parameters.
     */ setAccessPolicy(options) {
        return this.client.sendOperationRequest({
            options
        }, setAccessPolicyOperationSpec);
    }
    /**
     * Restores a previously-deleted container.
     * @param options The options parameters.
     */ restore(options) {
        return this.client.sendOperationRequest({
            options
        }, restoreOperationSpec);
    }
    /**
     * Renames an existing container.
     * @param sourceContainerName Required.  Specifies the name of the container to rename.
     * @param options The options parameters.
     */ rename(sourceContainerName, options) {
        return this.client.sendOperationRequest({
            sourceContainerName,
            options
        }, renameOperationSpec);
    }
    /**
     * The Batch operation allows multiple API calls to be embedded into a single HTTP request.
     * @param contentLength The length of the request.
     * @param multipartContentType Required. The value of this header must be multipart/mixed with a batch
     *                             boundary. Example header value: multipart/mixed; boundary=batch_<GUID>
     * @param body Initial data
     * @param options The options parameters.
     */ submitBatch(contentLength, multipartContentType, body, options) {
        return this.client.sendOperationRequest({
            contentLength,
            multipartContentType,
            body,
            options
        }, submitBatchOperationSpec);
    }
    /**
     * The Filter Blobs operation enables callers to list blobs in a container whose tags match a given
     * search expression.  Filter blobs searches within the given container.
     * @param options The options parameters.
     */ filterBlobs(options) {
        return this.client.sendOperationRequest({
            options
        }, filterBlobsOperationSpec);
    }
    /**
     * [Update] establishes and manages a lock on a container for delete operations. The lock duration can
     * be 15 to 60 seconds, or can be infinite
     * @param options The options parameters.
     */ acquireLease(options) {
        return this.client.sendOperationRequest({
            options
        }, acquireLeaseOperationSpec);
    }
    /**
     * [Update] establishes and manages a lock on a container for delete operations. The lock duration can
     * be 15 to 60 seconds, or can be infinite
     * @param leaseId Specifies the current lease ID on the resource.
     * @param options The options parameters.
     */ releaseLease(leaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            options
        }, releaseLeaseOperationSpec);
    }
    /**
     * [Update] establishes and manages a lock on a container for delete operations. The lock duration can
     * be 15 to 60 seconds, or can be infinite
     * @param leaseId Specifies the current lease ID on the resource.
     * @param options The options parameters.
     */ renewLease(leaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            options
        }, renewLeaseOperationSpec);
    }
    /**
     * [Update] establishes and manages a lock on a container for delete operations. The lock duration can
     * be 15 to 60 seconds, or can be infinite
     * @param options The options parameters.
     */ breakLease(options) {
        return this.client.sendOperationRequest({
            options
        }, breakLeaseOperationSpec);
    }
    /**
     * [Update] establishes and manages a lock on a container for delete operations. The lock duration can
     * be 15 to 60 seconds, or can be infinite
     * @param leaseId Specifies the current lease ID on the resource.
     * @param proposedLeaseId Proposed lease ID, in a GUID string format. The Blob service returns 400
     *                        (Invalid request) if the proposed lease ID is not in the correct format. See Guid Constructor
     *                        (String) for a list of valid GUID string formats.
     * @param options The options parameters.
     */ changeLease(leaseId, proposedLeaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            proposedLeaseId,
            options
        }, changeLeaseOperationSpec);
    }
    /**
     * [Update] The List Blobs operation returns a list of the blobs under the specified container
     * @param options The options parameters.
     */ listBlobFlatSegment(options) {
        return this.client.sendOperationRequest({
            options
        }, listBlobFlatSegmentOperationSpec);
    }
    /**
     * [Update] The List Blobs operation returns a list of the blobs under the specified container
     * @param delimiter When the request includes this parameter, the operation returns a BlobPrefix
     *                  element in the response body that acts as a placeholder for all blobs whose names begin with the
     *                  same substring up to the appearance of the delimiter character. The delimiter may be a single
     *                  character or a string.
     * @param options The options parameters.
     */ listBlobHierarchySegment(delimiter, options) {
        return this.client.sendOperationRequest({
            delimiter,
            options
        }, listBlobHierarchySegmentOperationSpec);
    }
    /**
     * Returns the sku name and account kind
     * @param options The options parameters.
     */ getAccountInfo(options) {
        return this.client.sendOperationRequest({
            options
        }, getAccountInfoOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const createOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.ContainerCreateHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerCreateExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.access,
        _parameters.defaultEncryptionScope,
        _parameters.preventEncryptionScopeOverride
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getPropertiesOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            headersMapper: _mappers.ContainerGetPropertiesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerGetPropertiesExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId
    ],
    isXML: true,
    serializer: xmlSerializer
};
const deleteOperationSpec = {
    path: "/{containerName}",
    httpMethod: "DELETE",
    responses: {
        202: {
            headersMapper: _mappers.ContainerDeleteHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerDeleteExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setMetadataOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerSetMetadataHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerSetMetadataExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp6
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getAccessPolicyOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: {
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "SignedIdentifier"
                        }
                    }
                },
                serializedName: "SignedIdentifiers",
                xmlName: "SignedIdentifiers",
                xmlIsWrapped: true,
                xmlElementName: "SignedIdentifier"
            },
            headersMapper: _mappers.ContainerGetAccessPolicyHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerGetAccessPolicyExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp7
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setAccessPolicyOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerSetAccessPolicyHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerSetAccessPolicyExceptionHeaders
        }
    },
    requestBody: _parameters.containerAcl,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp7
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.access,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const restoreOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.ContainerRestoreHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerRestoreExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp8
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.deletedContainerName,
        _parameters.deletedContainerVersion
    ],
    isXML: true,
    serializer: xmlSerializer
};
const renameOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerRenameHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerRenameExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp9
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.sourceContainerName,
        _parameters.sourceLeaseId
    ],
    isXML: true,
    serializer: xmlSerializer
};
const submitBatchOperationSpec = {
    path: "/{containerName}",
    httpMethod: "POST",
    responses: {
        202: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.ContainerSubmitBatchHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerSubmitBatchExceptionHeaders
        }
    },
    requestBody: _parameters.body,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp4,
        _parameters.restype2
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.multipartContentType
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const filterBlobsOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.FilterBlobSegment,
            headersMapper: _mappers.ContainerFilterBlobsHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerFilterBlobsExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.comp5,
        _parameters.where,
        _parameters.restype2
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const acquireLeaseOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.ContainerAcquireLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerAcquireLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action,
        _parameters.duration,
        _parameters.proposedLeaseId
    ],
    isXML: true,
    serializer: xmlSerializer
};
const releaseLeaseOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerReleaseLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerReleaseLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action1,
        _parameters.leaseId1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const renewLeaseOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerRenewLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerRenewLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.leaseId1,
        _parameters.action2
    ],
    isXML: true,
    serializer: xmlSerializer
};
const breakLeaseOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.ContainerBreakLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerBreakLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action3,
        _parameters.breakPeriod
    ],
    isXML: true,
    serializer: xmlSerializer
};
const changeLeaseOperationSpec = {
    path: "/{containerName}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.ContainerChangeLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerChangeLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.restype2,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.leaseId1,
        _parameters.action4,
        _parameters.proposedLeaseId1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const listBlobFlatSegmentOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.ListBlobsFlatSegmentResponse,
            headersMapper: _mappers.ContainerListBlobFlatSegmentHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerListBlobFlatSegmentExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp2,
        _parameters.prefix,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.restype2,
        _parameters.include1
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const listBlobHierarchySegmentOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.ListBlobsHierarchySegmentResponse,
            headersMapper: _mappers.ContainerListBlobHierarchySegmentHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerListBlobHierarchySegmentExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp2,
        _parameters.prefix,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.restype2,
        _parameters.include1,
        _parameters.delimiter
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getAccountInfoOperationSpec = {
    path: "/{containerName}",
    httpMethod: "GET",
    responses: {
        200: {
            headersMapper: _mappers.ContainerGetAccountInfoHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.ContainerGetAccountInfoExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.restype1
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kt7P2":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing Blob operations. */ parcelHelpers.export(exports, "BlobImpl", ()=>BlobImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class BlobImpl {
    /**
     * Initialize a new instance of the class Blob class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * The Download operation reads or downloads a blob from the system, including its metadata and
     * properties. You can also call Download to read a snapshot.
     * @param options The options parameters.
     */ download(options) {
        return this.client.sendOperationRequest({
            options
        }, downloadOperationSpec);
    }
    /**
     * The Get Properties operation returns all user-defined metadata, standard HTTP properties, and system
     * properties for the blob. It does not return the content of the blob.
     * @param options The options parameters.
     */ getProperties(options) {
        return this.client.sendOperationRequest({
            options
        }, getPropertiesOperationSpec);
    }
    /**
     * If the storage account's soft delete feature is disabled then, when a blob is deleted, it is
     * permanently removed from the storage account. If the storage account's soft delete feature is
     * enabled, then, when a blob is deleted, it is marked for deletion and becomes inaccessible
     * immediately. However, the blob service retains the blob or snapshot for the number of days specified
     * by the DeleteRetentionPolicy section of [Storage service properties]
     * (Set-Blob-Service-Properties.md). After the specified number of days has passed, the blob's data is
     * permanently removed from the storage account. Note that you continue to be charged for the
     * soft-deleted blob's storage until it is permanently removed. Use the List Blobs API and specify the
     * "include=deleted" query parameter to discover which blobs and snapshots have been soft deleted. You
     * can then use the Undelete Blob API to restore a soft-deleted blob. All other operations on a
     * soft-deleted blob or snapshot causes the service to return an HTTP status code of 404
     * (ResourceNotFound).
     * @param options The options parameters.
     */ delete(options) {
        return this.client.sendOperationRequest({
            options
        }, deleteOperationSpec);
    }
    /**
     * Undelete a blob that was previously soft deleted
     * @param options The options parameters.
     */ undelete(options) {
        return this.client.sendOperationRequest({
            options
        }, undeleteOperationSpec);
    }
    /**
     * Sets the time a blob will expire and be deleted.
     * @param expiryOptions Required. Indicates mode of the expiry time
     * @param options The options parameters.
     */ setExpiry(expiryOptions, options) {
        return this.client.sendOperationRequest({
            expiryOptions,
            options
        }, setExpiryOperationSpec);
    }
    /**
     * The Set HTTP Headers operation sets system properties on the blob
     * @param options The options parameters.
     */ setHttpHeaders(options) {
        return this.client.sendOperationRequest({
            options
        }, setHttpHeadersOperationSpec);
    }
    /**
     * The Set Immutability Policy operation sets the immutability policy on the blob
     * @param options The options parameters.
     */ setImmutabilityPolicy(options) {
        return this.client.sendOperationRequest({
            options
        }, setImmutabilityPolicyOperationSpec);
    }
    /**
     * The Delete Immutability Policy operation deletes the immutability policy on the blob
     * @param options The options parameters.
     */ deleteImmutabilityPolicy(options) {
        return this.client.sendOperationRequest({
            options
        }, deleteImmutabilityPolicyOperationSpec);
    }
    /**
     * The Set Legal Hold operation sets a legal hold on the blob.
     * @param legalHold Specified if a legal hold should be set on the blob.
     * @param options The options parameters.
     */ setLegalHold(legalHold, options) {
        return this.client.sendOperationRequest({
            legalHold,
            options
        }, setLegalHoldOperationSpec);
    }
    /**
     * The Set Blob Metadata operation sets user-defined metadata for the specified blob as one or more
     * name-value pairs
     * @param options The options parameters.
     */ setMetadata(options) {
        return this.client.sendOperationRequest({
            options
        }, setMetadataOperationSpec);
    }
    /**
     * [Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
     * operations
     * @param options The options parameters.
     */ acquireLease(options) {
        return this.client.sendOperationRequest({
            options
        }, acquireLeaseOperationSpec);
    }
    /**
     * [Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
     * operations
     * @param leaseId Specifies the current lease ID on the resource.
     * @param options The options parameters.
     */ releaseLease(leaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            options
        }, releaseLeaseOperationSpec);
    }
    /**
     * [Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
     * operations
     * @param leaseId Specifies the current lease ID on the resource.
     * @param options The options parameters.
     */ renewLease(leaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            options
        }, renewLeaseOperationSpec);
    }
    /**
     * [Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
     * operations
     * @param leaseId Specifies the current lease ID on the resource.
     * @param proposedLeaseId Proposed lease ID, in a GUID string format. The Blob service returns 400
     *                        (Invalid request) if the proposed lease ID is not in the correct format. See Guid Constructor
     *                        (String) for a list of valid GUID string formats.
     * @param options The options parameters.
     */ changeLease(leaseId, proposedLeaseId, options) {
        return this.client.sendOperationRequest({
            leaseId,
            proposedLeaseId,
            options
        }, changeLeaseOperationSpec);
    }
    /**
     * [Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
     * operations
     * @param options The options parameters.
     */ breakLease(options) {
        return this.client.sendOperationRequest({
            options
        }, breakLeaseOperationSpec);
    }
    /**
     * The Create Snapshot operation creates a read-only snapshot of a blob
     * @param options The options parameters.
     */ createSnapshot(options) {
        return this.client.sendOperationRequest({
            options
        }, createSnapshotOperationSpec);
    }
    /**
     * The Start Copy From URL operation copies a blob or an internet resource to a new blob.
     * @param copySource Specifies the name of the source page blob snapshot. This value is a URL of up to
     *                   2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it would
     *                   appear in a request URI. The source blob must either be public or must be authenticated via a shared
     *                   access signature.
     * @param options The options parameters.
     */ startCopyFromURL(copySource, options) {
        return this.client.sendOperationRequest({
            copySource,
            options
        }, startCopyFromURLOperationSpec);
    }
    /**
     * The Copy From URL operation copies a blob or an internet resource to a new blob. It will not return
     * a response until the copy is complete.
     * @param copySource Specifies the name of the source page blob snapshot. This value is a URL of up to
     *                   2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it would
     *                   appear in a request URI. The source blob must either be public or must be authenticated via a shared
     *                   access signature.
     * @param options The options parameters.
     */ copyFromURL(copySource, options) {
        return this.client.sendOperationRequest({
            copySource,
            options
        }, copyFromURLOperationSpec);
    }
    /**
     * The Abort Copy From URL operation aborts a pending Copy From URL operation, and leaves a destination
     * blob with zero length and full metadata.
     * @param copyId The copy identifier provided in the x-ms-copy-id header of the original Copy Blob
     *               operation.
     * @param options The options parameters.
     */ abortCopyFromURL(copyId, options) {
        return this.client.sendOperationRequest({
            copyId,
            options
        }, abortCopyFromURLOperationSpec);
    }
    /**
     * The Set Tier operation sets the tier on a blob. The operation is allowed on a page blob in a premium
     * storage account and on a block blob in a blob storage account (locally redundant storage only). A
     * premium page blob's tier determines the allowed size, IOPS, and bandwidth of the blob. A block
     * blob's tier determines Hot/Cool/Archive storage type. This operation does not update the blob's
     * ETag.
     * @param tier Indicates the tier to be set on the blob.
     * @param options The options parameters.
     */ setTier(tier, options) {
        return this.client.sendOperationRequest({
            tier,
            options
        }, setTierOperationSpec);
    }
    /**
     * Returns the sku name and account kind
     * @param options The options parameters.
     */ getAccountInfo(options) {
        return this.client.sendOperationRequest({
            options
        }, getAccountInfoOperationSpec);
    }
    /**
     * The Query operation enables users to select/project on blob data by providing simple query
     * expressions.
     * @param options The options parameters.
     */ query(options) {
        return this.client.sendOperationRequest({
            options
        }, queryOperationSpec);
    }
    /**
     * The Get Tags operation enables users to get the tags associated with a blob.
     * @param options The options parameters.
     */ getTags(options) {
        return this.client.sendOperationRequest({
            options
        }, getTagsOperationSpec);
    }
    /**
     * The Set Tags operation enables users to set tags on a blob.
     * @param options The options parameters.
     */ setTags(options) {
        return this.client.sendOperationRequest({
            options
        }, setTagsOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const downloadOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.BlobDownloadHeaders
        },
        206: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.BlobDownloadHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobDownloadExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.versionId
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.range,
        _parameters.rangeGetContentMD5,
        _parameters.rangeGetContentCRC64,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getPropertiesOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "HEAD",
    responses: {
        200: {
            headersMapper: _mappers.BlobGetPropertiesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobGetPropertiesExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.versionId
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const deleteOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "DELETE",
    responses: {
        202: {
            headersMapper: _mappers.BlobDeleteHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobDeleteExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.versionId,
        _parameters.blobDeleteType
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.deleteSnapshots
    ],
    isXML: true,
    serializer: xmlSerializer
};
const undeleteOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobUndeleteHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobUndeleteExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp8
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setExpiryOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetExpiryHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetExpiryExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp11
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.expiryOptions,
        _parameters.expiresOn
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setHttpHeadersOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetHttpHeadersHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetHttpHeadersExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setImmutabilityPolicyOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetImmutabilityPolicyHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetImmutabilityPolicyExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp12
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifUnmodifiedSince,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode
    ],
    isXML: true,
    serializer: xmlSerializer
};
const deleteImmutabilityPolicyOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "DELETE",
    responses: {
        200: {
            headersMapper: _mappers.BlobDeleteImmutabilityPolicyHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobDeleteImmutabilityPolicyExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp12
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setLegalHoldOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetLegalHoldHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetLegalHoldExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp13
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.legalHold
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setMetadataOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetMetadataHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetMetadataExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp6
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope
    ],
    isXML: true,
    serializer: xmlSerializer
};
const acquireLeaseOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlobAcquireLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobAcquireLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action,
        _parameters.duration,
        _parameters.proposedLeaseId,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const releaseLeaseOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobReleaseLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobReleaseLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action1,
        _parameters.leaseId1,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const renewLeaseOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobRenewLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobRenewLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.leaseId1,
        _parameters.action2,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const changeLeaseOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobChangeLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobChangeLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.leaseId1,
        _parameters.action4,
        _parameters.proposedLeaseId1,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const breakLeaseOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.BlobBreakLeaseHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobBreakLeaseExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp10
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.action3,
        _parameters.breakPeriod,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const createSnapshotOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlobCreateSnapshotHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobCreateSnapshotExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp14
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope
    ],
    isXML: true,
    serializer: xmlSerializer
};
const startCopyFromURLOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.BlobStartCopyFromURLHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobStartCopyFromURLExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.tier,
        _parameters.rehydratePriority,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.sourceIfTags,
        _parameters.copySource,
        _parameters.blobTagsString,
        _parameters.sealBlob,
        _parameters.legalHold1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const copyFromURLOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.BlobCopyFromURLHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobCopyFromURLExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.encryptionScope,
        _parameters.tier,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.copySource,
        _parameters.blobTagsString,
        _parameters.legalHold1,
        _parameters.xMsRequiresSync,
        _parameters.sourceContentMD5,
        _parameters.copySourceAuthorization,
        _parameters.copySourceTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const abortCopyFromURLOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        204: {
            headersMapper: _mappers.BlobAbortCopyFromURLHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobAbortCopyFromURLExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp15,
        _parameters.copyId
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.copyActionAbortConstant
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setTierOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.BlobSetTierHeaders
        },
        202: {
            headersMapper: _mappers.BlobSetTierHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetTierExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.versionId,
        _parameters.comp16
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifTags,
        _parameters.rehydratePriority,
        _parameters.tier1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getAccountInfoOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            headersMapper: _mappers.BlobGetAccountInfoHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobGetAccountInfoExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.restype1
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const queryOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "POST",
    responses: {
        200: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.BlobQueryHeaders
        },
        206: {
            bodyMapper: {
                type: {
                    name: "Stream"
                },
                serializedName: "parsedResponse"
            },
            headersMapper: _mappers.BlobQueryHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobQueryExceptionHeaders
        }
    },
    requestBody: _parameters.queryRequest,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.comp17
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const getTagsOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.BlobTags,
            headersMapper: _mappers.BlobGetTagsHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobGetTagsExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.versionId,
        _parameters.comp18
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const setTagsOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        204: {
            headersMapper: _mappers.BlobSetTagsHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlobSetTagsExceptionHeaders
        }
    },
    requestBody: _parameters.tags,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.versionId,
        _parameters.comp18
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.leaseId,
        _parameters.ifTags,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fsHo1":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing PageBlob operations. */ parcelHelpers.export(exports, "PageBlobImpl", ()=>PageBlobImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class PageBlobImpl {
    /**
     * Initialize a new instance of the class PageBlob class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * The Create operation creates a new page blob.
     * @param contentLength The length of the request.
     * @param blobContentLength This header specifies the maximum size for the page blob, up to 1 TB. The
     *                          page blob size must be aligned to a 512-byte boundary.
     * @param options The options parameters.
     */ create(contentLength, blobContentLength, options) {
        return this.client.sendOperationRequest({
            contentLength,
            blobContentLength,
            options
        }, createOperationSpec);
    }
    /**
     * The Upload Pages operation writes a range of pages to a page blob
     * @param contentLength The length of the request.
     * @param body Initial data
     * @param options The options parameters.
     */ uploadPages(contentLength, body, options) {
        return this.client.sendOperationRequest({
            contentLength,
            body,
            options
        }, uploadPagesOperationSpec);
    }
    /**
     * The Clear Pages operation clears a set of pages from a page blob
     * @param contentLength The length of the request.
     * @param options The options parameters.
     */ clearPages(contentLength, options) {
        return this.client.sendOperationRequest({
            contentLength,
            options
        }, clearPagesOperationSpec);
    }
    /**
     * The Upload Pages operation writes a range of pages to a page blob where the contents are read from a
     * URL
     * @param sourceUrl Specify a URL to the copy source.
     * @param sourceRange Bytes of source data in the specified range. The length of this range should
     *                    match the ContentLength header and x-ms-range/Range destination range header.
     * @param contentLength The length of the request.
     * @param range The range of bytes to which the source range would be written. The range should be 512
     *              aligned and range-end is required.
     * @param options The options parameters.
     */ uploadPagesFromURL(sourceUrl, sourceRange, contentLength, range, options) {
        return this.client.sendOperationRequest({
            sourceUrl,
            sourceRange,
            contentLength,
            range,
            options
        }, uploadPagesFromURLOperationSpec);
    }
    /**
     * The Get Page Ranges operation returns the list of valid page ranges for a page blob or snapshot of a
     * page blob
     * @param options The options parameters.
     */ getPageRanges(options) {
        return this.client.sendOperationRequest({
            options
        }, getPageRangesOperationSpec);
    }
    /**
     * The Get Page Ranges Diff operation returns the list of valid page ranges for a page blob that were
     * changed between target blob and previous snapshot.
     * @param options The options parameters.
     */ getPageRangesDiff(options) {
        return this.client.sendOperationRequest({
            options
        }, getPageRangesDiffOperationSpec);
    }
    /**
     * Resize the Blob
     * @param blobContentLength This header specifies the maximum size for the page blob, up to 1 TB. The
     *                          page blob size must be aligned to a 512-byte boundary.
     * @param options The options parameters.
     */ resize(blobContentLength, options) {
        return this.client.sendOperationRequest({
            blobContentLength,
            options
        }, resizeOperationSpec);
    }
    /**
     * Update the sequence number of the blob
     * @param sequenceNumberAction Required if the x-ms-blob-sequence-number header is set for the request.
     *                             This property applies to page blobs only. This property indicates how the service should modify the
     *                             blob's sequence number
     * @param options The options parameters.
     */ updateSequenceNumber(sequenceNumberAction, options) {
        return this.client.sendOperationRequest({
            sequenceNumberAction,
            options
        }, updateSequenceNumberOperationSpec);
    }
    /**
     * The Copy Incremental operation copies a snapshot of the source page blob to a destination page blob.
     * The snapshot is copied such that only the differential changes between the previously copied
     * snapshot are transferred to the destination. The copied snapshots are complete copies of the
     * original snapshot and can be read or copied from as usual. This API is supported since REST version
     * 2016-05-31.
     * @param copySource Specifies the name of the source page blob snapshot. This value is a URL of up to
     *                   2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it would
     *                   appear in a request URI. The source blob must either be public or must be authenticated via a shared
     *                   access signature.
     * @param options The options parameters.
     */ copyIncremental(copySource, options) {
        return this.client.sendOperationRequest({
            copySource,
            options
        }, copyIncrementalOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const createOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.PageBlobCreateHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobCreateExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.encryptionScope,
        _parameters.tier,
        _parameters.blobTagsString,
        _parameters.legalHold1,
        _parameters.blobType,
        _parameters.blobContentLength,
        _parameters.blobSequenceNumber
    ],
    isXML: true,
    serializer: xmlSerializer
};
const uploadPagesOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.PageBlobUploadPagesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobUploadPagesExceptionHeaders
        }
    },
    requestBody: _parameters.body1,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp19
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.range,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64,
        _parameters.contentType1,
        _parameters.accept2,
        _parameters.pageWrite,
        _parameters.ifSequenceNumberLessThanOrEqualTo,
        _parameters.ifSequenceNumberLessThan,
        _parameters.ifSequenceNumberEqualTo
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "binary",
    serializer: xmlSerializer
};
const clearPagesOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.PageBlobClearPagesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobClearPagesExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp19
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.range,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.ifSequenceNumberLessThanOrEqualTo,
        _parameters.ifSequenceNumberLessThan,
        _parameters.ifSequenceNumberEqualTo,
        _parameters.pageWrite1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const uploadPagesFromURLOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.PageBlobUploadPagesFromURLHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobUploadPagesFromURLExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp19
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.sourceContentMD5,
        _parameters.copySourceAuthorization,
        _parameters.pageWrite,
        _parameters.ifSequenceNumberLessThanOrEqualTo,
        _parameters.ifSequenceNumberLessThan,
        _parameters.ifSequenceNumberEqualTo,
        _parameters.sourceUrl,
        _parameters.sourceRange,
        _parameters.sourceContentCrc64,
        _parameters.range1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getPageRangesOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.PageList,
            headersMapper: _mappers.PageBlobGetPageRangesHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobGetPageRangesExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.snapshot,
        _parameters.comp20
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.range,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};
const getPageRangesDiffOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.PageList,
            headersMapper: _mappers.PageBlobGetPageRangesDiffHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobGetPageRangesDiffExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.marker,
        _parameters.maxPageSize,
        _parameters.snapshot,
        _parameters.comp20,
        _parameters.prevsnapshot
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.range,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.prevSnapshotUrl
    ],
    isXML: true,
    serializer: xmlSerializer
};
const resizeOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.PageBlobResizeHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobResizeExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.blobContentLength
    ],
    isXML: true,
    serializer: xmlSerializer
};
const updateSequenceNumberOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.PageBlobUpdateSequenceNumberHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobUpdateSequenceNumberExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.comp,
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobSequenceNumber,
        _parameters.sequenceNumberAction
    ],
    isXML: true,
    serializer: xmlSerializer
};
const copyIncrementalOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        202: {
            headersMapper: _mappers.PageBlobCopyIncrementalHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.PageBlobCopyIncrementalExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp21
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.copySource
    ],
    isXML: true,
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6Mh9Y":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing AppendBlob operations. */ parcelHelpers.export(exports, "AppendBlobImpl", ()=>AppendBlobImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class AppendBlobImpl {
    /**
     * Initialize a new instance of the class AppendBlob class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * The Create Append Blob operation creates a new append blob.
     * @param contentLength The length of the request.
     * @param options The options parameters.
     */ create(contentLength, options) {
        return this.client.sendOperationRequest({
            contentLength,
            options
        }, createOperationSpec);
    }
    /**
     * The Append Block operation commits a new block of data to the end of an existing append blob. The
     * Append Block operation is permitted only if the blob was created with x-ms-blob-type set to
     * AppendBlob. Append Block is supported only on version 2015-02-21 version or later.
     * @param contentLength The length of the request.
     * @param body Initial data
     * @param options The options parameters.
     */ appendBlock(contentLength, body, options) {
        return this.client.sendOperationRequest({
            contentLength,
            body,
            options
        }, appendBlockOperationSpec);
    }
    /**
     * The Append Block operation commits a new block of data to the end of an existing append blob where
     * the contents are read from a source url. The Append Block operation is permitted only if the blob
     * was created with x-ms-blob-type set to AppendBlob. Append Block is supported only on version
     * 2015-02-21 version or later.
     * @param sourceUrl Specify a URL to the copy source.
     * @param contentLength The length of the request.
     * @param options The options parameters.
     */ appendBlockFromUrl(sourceUrl, contentLength, options) {
        return this.client.sendOperationRequest({
            sourceUrl,
            contentLength,
            options
        }, appendBlockFromUrlOperationSpec);
    }
    /**
     * The Seal operation seals the Append Blob to make it read-only. Seal is supported only on version
     * 2019-12-12 version or later.
     * @param options The options parameters.
     */ seal(options) {
        return this.client.sendOperationRequest({
            options
        }, sealOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const createOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.AppendBlobCreateHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.AppendBlobCreateExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.encryptionScope,
        _parameters.blobTagsString,
        _parameters.legalHold1,
        _parameters.blobType1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const appendBlockOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.AppendBlobAppendBlockHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.AppendBlobAppendBlockExceptionHeaders
        }
    },
    requestBody: _parameters.body1,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp22
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64,
        _parameters.contentType1,
        _parameters.accept2,
        _parameters.maxSize,
        _parameters.appendPosition
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "binary",
    serializer: xmlSerializer
};
const appendBlockFromUrlOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.AppendBlobAppendBlockFromUrlHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.AppendBlobAppendBlockFromUrlExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp22
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.encryptionScope,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.sourceContentMD5,
        _parameters.copySourceAuthorization,
        _parameters.transactionalContentMD5,
        _parameters.sourceUrl,
        _parameters.sourceContentCrc64,
        _parameters.maxSize,
        _parameters.appendPosition,
        _parameters.sourceRange1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const sealOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: _mappers.AppendBlobSealHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.AppendBlobSealExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp23
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.appendPosition
    ],
    isXML: true,
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fsPW1":[function(require,module,exports) {
/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/** Class containing BlockBlob operations. */ parcelHelpers.export(exports, "BlockBlobImpl", ()=>BlockBlobImpl);
var _coreClient = require("@azure/core-client");
var _mappers = require("../models/mappers");
var _parameters = require("../models/parameters");
class BlockBlobImpl {
    /**
     * Initialize a new instance of the class BlockBlob class.
     * @param client Reference to the service client
     */ constructor(client){
        this.client = client;
    }
    /**
     * The Upload Block Blob operation updates the content of an existing block blob. Updating an existing
     * block blob overwrites any existing metadata on the blob. Partial updates are not supported with Put
     * Blob; the content of the existing blob is overwritten with the content of the new blob. To perform a
     * partial update of the content of a block blob, use the Put Block List operation.
     * @param contentLength The length of the request.
     * @param body Initial data
     * @param options The options parameters.
     */ upload(contentLength, body, options) {
        return this.client.sendOperationRequest({
            contentLength,
            body,
            options
        }, uploadOperationSpec);
    }
    /**
     * The Put Blob from URL operation creates a new Block Blob where the contents of the blob are read
     * from a given URL.  This API is supported beginning with the 2020-04-08 version. Partial updates are
     * not supported with Put Blob from URL; the content of an existing blob is overwritten with the
     * content of the new blob.  To perform partial updates to a block blobs contents using a source URL,
     * use the Put Block from URL API in conjunction with Put Block List.
     * @param contentLength The length of the request.
     * @param copySource Specifies the name of the source page blob snapshot. This value is a URL of up to
     *                   2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it would
     *                   appear in a request URI. The source blob must either be public or must be authenticated via a shared
     *                   access signature.
     * @param options The options parameters.
     */ putBlobFromUrl(contentLength, copySource, options) {
        return this.client.sendOperationRequest({
            contentLength,
            copySource,
            options
        }, putBlobFromUrlOperationSpec);
    }
    /**
     * The Stage Block operation creates a new block to be committed as part of a blob
     * @param blockId A valid Base64 string value that identifies the block. Prior to encoding, the string
     *                must be less than or equal to 64 bytes in size. For a given blob, the length of the value specified
     *                for the blockid parameter must be the same size for each block.
     * @param contentLength The length of the request.
     * @param body Initial data
     * @param options The options parameters.
     */ stageBlock(blockId, contentLength, body, options) {
        return this.client.sendOperationRequest({
            blockId,
            contentLength,
            body,
            options
        }, stageBlockOperationSpec);
    }
    /**
     * The Stage Block operation creates a new block to be committed as part of a blob where the contents
     * are read from a URL.
     * @param blockId A valid Base64 string value that identifies the block. Prior to encoding, the string
     *                must be less than or equal to 64 bytes in size. For a given blob, the length of the value specified
     *                for the blockid parameter must be the same size for each block.
     * @param contentLength The length of the request.
     * @param sourceUrl Specify a URL to the copy source.
     * @param options The options parameters.
     */ stageBlockFromURL(blockId, contentLength, sourceUrl, options) {
        return this.client.sendOperationRequest({
            blockId,
            contentLength,
            sourceUrl,
            options
        }, stageBlockFromURLOperationSpec);
    }
    /**
     * The Commit Block List operation writes a blob by specifying the list of block IDs that make up the
     * blob. In order to be written as part of a blob, a block must have been successfully written to the
     * server in a prior Put Block operation. You can call Put Block List to update a blob by uploading
     * only those blocks that have changed, then committing the new and existing blocks together. You can
     * do this by specifying whether to commit a block from the committed block list or from the
     * uncommitted block list, or to commit the most recently uploaded version of the block, whichever list
     * it may belong to.
     * @param blocks Blob Blocks.
     * @param options The options parameters.
     */ commitBlockList(blocks, options) {
        return this.client.sendOperationRequest({
            blocks,
            options
        }, commitBlockListOperationSpec);
    }
    /**
     * The Get Block List operation retrieves the list of blocks that have been uploaded as part of a block
     * blob
     * @param listType Specifies whether to return the list of committed blocks, the list of uncommitted
     *                 blocks, or both lists together.
     * @param options The options parameters.
     */ getBlockList(listType, options) {
        return this.client.sendOperationRequest({
            listType,
            options
        }, getBlockListOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = _coreClient.createSerializer(_mappers, /* isXml */ true);
const uploadOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlockBlobUploadHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobUploadExceptionHeaders
        }
    },
    requestBody: _parameters.body1,
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.encryptionScope,
        _parameters.tier,
        _parameters.blobTagsString,
        _parameters.legalHold1,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64,
        _parameters.contentType1,
        _parameters.accept2,
        _parameters.blobType2
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "binary",
    serializer: xmlSerializer
};
const putBlobFromUrlOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlockBlobPutBlobFromUrlHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobPutBlobFromUrlExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition,
        _parameters.encryptionScope,
        _parameters.tier,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.sourceIfTags,
        _parameters.copySource,
        _parameters.blobTagsString,
        _parameters.sourceContentMD5,
        _parameters.copySourceAuthorization,
        _parameters.copySourceTags,
        _parameters.transactionalContentMD5,
        _parameters.blobType2,
        _parameters.copySourceBlobProperties
    ],
    isXML: true,
    serializer: xmlSerializer
};
const stageBlockOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlockBlobStageBlockHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobStageBlockExceptionHeaders
        }
    },
    requestBody: _parameters.body1,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp24,
        _parameters.blockId
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.encryptionScope,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64,
        _parameters.contentType1,
        _parameters.accept2
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "binary",
    serializer: xmlSerializer
};
const stageBlockFromURLOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlockBlobStageBlockFromURLHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobStageBlockFromURLExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp24,
        _parameters.blockId
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.contentLength,
        _parameters.leaseId,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.encryptionScope,
        _parameters.sourceIfModifiedSince,
        _parameters.sourceIfUnmodifiedSince,
        _parameters.sourceIfMatch,
        _parameters.sourceIfNoneMatch,
        _parameters.sourceContentMD5,
        _parameters.copySourceAuthorization,
        _parameters.sourceUrl,
        _parameters.sourceContentCrc64,
        _parameters.sourceRange1
    ],
    isXML: true,
    serializer: xmlSerializer
};
const commitBlockListOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: _mappers.BlockBlobCommitBlockListHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobCommitBlockListExceptionHeaders
        }
    },
    requestBody: _parameters.blocks,
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.comp25
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.contentType,
        _parameters.accept,
        _parameters.version,
        _parameters.requestId,
        _parameters.metadata,
        _parameters.leaseId,
        _parameters.ifModifiedSince,
        _parameters.ifUnmodifiedSince,
        _parameters.encryptionKey,
        _parameters.encryptionKeySha256,
        _parameters.encryptionAlgorithm,
        _parameters.ifMatch,
        _parameters.ifNoneMatch,
        _parameters.ifTags,
        _parameters.blobCacheControl,
        _parameters.blobContentType,
        _parameters.blobContentMD5,
        _parameters.blobContentEncoding,
        _parameters.blobContentLanguage,
        _parameters.blobContentDisposition,
        _parameters.immutabilityPolicyExpiry,
        _parameters.immutabilityPolicyMode,
        _parameters.encryptionScope,
        _parameters.tier,
        _parameters.blobTagsString,
        _parameters.legalHold1,
        _parameters.transactionalContentMD5,
        _parameters.transactionalContentCrc64
    ],
    isXML: true,
    contentType: "application/xml; charset=utf-8",
    mediaType: "xml",
    serializer: xmlSerializer
};
const getBlockListOperationSpec = {
    path: "/{containerName}/{blob}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: _mappers.BlockList,
            headersMapper: _mappers.BlockBlobGetBlockListHeaders
        },
        default: {
            bodyMapper: _mappers.StorageError,
            headersMapper: _mappers.BlockBlobGetBlockListExceptionHeaders
        }
    },
    queryParameters: [
        _parameters.timeoutInSeconds,
        _parameters.snapshot,
        _parameters.comp25,
        _parameters.listType
    ],
    urlParameters: [
        _parameters.url
    ],
    headerParameters: [
        _parameters.version,
        _parameters.requestId,
        _parameters.accept1,
        _parameters.leaseId,
        _parameters.ifTags
    ],
    isXML: true,
    serializer: xmlSerializer
};

},{"@azure/core-client":"eVlwR","../models/mappers":"2ZlYI","../models/parameters":"dORMS","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"m0KjB":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "tracingClient", ()=>tracingClient);
var _coreTracing = require("@azure/core-tracing");
var _constants = require("./constants");
const tracingClient = (0, _coreTracing.createTracingClient)({
    packageName: "@azure/storage-blob",
    packageVersion: (0, _constants.SDK_VERSION),
    namespace: "Microsoft.Storage"
});

},{"@azure/core-tracing":"fmgv7","./constants":"4gX5x","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"SWffY":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "generateBlobSASQueryParameters", ()=>generateBlobSASQueryParameters);
var _blobSASPermissions = require("./BlobSASPermissions");
var _containerSASPermissions = require("./ContainerSASPermissions");
var _storageSharedKeyCredential = require("../credentials/StorageSharedKeyCredential");
var _userDelegationKeyCredential = require("../credentials/UserDelegationKeyCredential");
var _sasIPRange = require("./SasIPRange");
var _sasqueryParameters = require("./SASQueryParameters");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
function generateBlobSASQueryParameters(blobSASSignatureValues, sharedKeyCredentialOrUserDelegationKey, accountName) {
    const version = blobSASSignatureValues.version ? blobSASSignatureValues.version : (0, _constants.SERVICE_VERSION);
    const sharedKeyCredential = sharedKeyCredentialOrUserDelegationKey instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) ? sharedKeyCredentialOrUserDelegationKey : undefined;
    let userDelegationKeyCredential;
    if (sharedKeyCredential === undefined && accountName !== undefined) userDelegationKeyCredential = new (0, _userDelegationKeyCredential.UserDelegationKeyCredential)(accountName, sharedKeyCredentialOrUserDelegationKey);
    if (sharedKeyCredential === undefined && userDelegationKeyCredential === undefined) throw TypeError("Invalid sharedKeyCredential, userDelegationKey or accountName.");
    // Version 2020-12-06 adds support for encryptionscope in SAS.
    if (version >= "2020-12-06") {
        if (sharedKeyCredential !== undefined) return generateBlobSASQueryParameters20201206(blobSASSignatureValues, sharedKeyCredential);
        else return generateBlobSASQueryParametersUDK20201206(blobSASSignatureValues, userDelegationKeyCredential);
    }
    // Version 2019-12-12 adds support for the blob tags permission.
    // Version 2018-11-09 adds support for the signed resource and signed blob snapshot time fields.
    // https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas#constructing-the-signature-string
    if (version >= "2018-11-09") {
        if (sharedKeyCredential !== undefined) return generateBlobSASQueryParameters20181109(blobSASSignatureValues, sharedKeyCredential);
        else {
            // Version 2020-02-10 delegation SAS signature construction includes preauthorizedAgentObjectId, agentObjectId, correlationId.
            if (version >= "2020-02-10") return generateBlobSASQueryParametersUDK20200210(blobSASSignatureValues, userDelegationKeyCredential);
            else return generateBlobSASQueryParametersUDK20181109(blobSASSignatureValues, userDelegationKeyCredential);
        }
    }
    if (version >= "2015-04-05") {
        if (sharedKeyCredential !== undefined) return generateBlobSASQueryParameters20150405(blobSASSignatureValues, sharedKeyCredential);
        else throw new RangeError("'version' must be >= '2018-11-09' when generating user delegation SAS using user delegation key.");
    }
    throw new RangeError("'version' must be >= '2015-04-05'.");
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2015-04-05 AND BEFORE 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * @param blobSASSignatureValues -
 * @param sharedKeyCredential -
 */ function generateBlobSASQueryParameters20150405(blobSASSignatureValues, sharedKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    if (!blobSASSignatureValues.identifier && !(blobSASSignatureValues.permissions && blobSASSignatureValues.expiresOn)) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when 'identifier' is not provided.");
    let resource = "c";
    if (blobSASSignatureValues.blobName) resource = "b";
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(sharedKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        blobSASSignatureValues.identifier,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        blobSASSignatureValues.cacheControl ? blobSASSignatureValues.cacheControl : "",
        blobSASSignatureValues.contentDisposition ? blobSASSignatureValues.contentDisposition : "",
        blobSASSignatureValues.contentEncoding ? blobSASSignatureValues.contentEncoding : "",
        blobSASSignatureValues.contentLanguage ? blobSASSignatureValues.contentLanguage : "",
        blobSASSignatureValues.contentType ? blobSASSignatureValues.contentType : ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * @param blobSASSignatureValues -
 * @param sharedKeyCredential -
 */ function generateBlobSASQueryParameters20181109(blobSASSignatureValues, sharedKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    if (!blobSASSignatureValues.identifier && !(blobSASSignatureValues.permissions && blobSASSignatureValues.expiresOn)) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when 'identifier' is not provided.");
    let resource = "c";
    let timestamp = blobSASSignatureValues.snapshotTime;
    if (blobSASSignatureValues.blobName) {
        resource = "b";
        if (blobSASSignatureValues.snapshotTime) resource = "bs";
        else if (blobSASSignatureValues.versionId) {
            resource = "bv";
            timestamp = blobSASSignatureValues.versionId;
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(sharedKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        blobSASSignatureValues.identifier,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        resource,
        timestamp,
        blobSASSignatureValues.cacheControl ? blobSASSignatureValues.cacheControl : "",
        blobSASSignatureValues.contentDisposition ? blobSASSignatureValues.contentDisposition : "",
        blobSASSignatureValues.contentEncoding ? blobSASSignatureValues.contentEncoding : "",
        blobSASSignatureValues.contentLanguage ? blobSASSignatureValues.contentLanguage : "",
        blobSASSignatureValues.contentType ? blobSASSignatureValues.contentType : ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2020-12-06.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * @param blobSASSignatureValues -
 * @param sharedKeyCredential -
 */ function generateBlobSASQueryParameters20201206(blobSASSignatureValues, sharedKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    if (!blobSASSignatureValues.identifier && !(blobSASSignatureValues.permissions && blobSASSignatureValues.expiresOn)) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when 'identifier' is not provided.");
    let resource = "c";
    let timestamp = blobSASSignatureValues.snapshotTime;
    if (blobSASSignatureValues.blobName) {
        resource = "b";
        if (blobSASSignatureValues.snapshotTime) resource = "bs";
        else if (blobSASSignatureValues.versionId) {
            resource = "bv";
            timestamp = blobSASSignatureValues.versionId;
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(sharedKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        blobSASSignatureValues.identifier,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        resource,
        timestamp,
        blobSASSignatureValues.encryptionScope,
        blobSASSignatureValues.cacheControl ? blobSASSignatureValues.cacheControl : "",
        blobSASSignatureValues.contentDisposition ? blobSASSignatureValues.contentDisposition : "",
        blobSASSignatureValues.contentEncoding ? blobSASSignatureValues.contentEncoding : "",
        blobSASSignatureValues.contentLanguage ? blobSASSignatureValues.contentLanguage : "",
        blobSASSignatureValues.contentType ? blobSASSignatureValues.contentType : ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType, undefined, undefined, undefined, blobSASSignatureValues.encryptionScope);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn.
 *
 * WARNING: identifier will be ignored, permissions and expiresOn are required.
 *
 * @param blobSASSignatureValues -
 * @param userDelegationKeyCredential -
 */ function generateBlobSASQueryParametersUDK20181109(blobSASSignatureValues, userDelegationKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    // Stored access policies are not supported for a user delegation SAS.
    if (!blobSASSignatureValues.permissions || !blobSASSignatureValues.expiresOn) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when generating user delegation SAS.");
    let resource = "c";
    let timestamp = blobSASSignatureValues.snapshotTime;
    if (blobSASSignatureValues.blobName) {
        resource = "b";
        if (blobSASSignatureValues.snapshotTime) resource = "bs";
        else if (blobSASSignatureValues.versionId) {
            resource = "bv";
            timestamp = blobSASSignatureValues.versionId;
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(userDelegationKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        userDelegationKeyCredential.userDelegationKey.signedObjectId,
        userDelegationKeyCredential.userDelegationKey.signedTenantId,
        userDelegationKeyCredential.userDelegationKey.signedStartsOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedStartsOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedExpiresOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedExpiresOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedService,
        userDelegationKeyCredential.userDelegationKey.signedVersion,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        resource,
        timestamp,
        blobSASSignatureValues.cacheControl,
        blobSASSignatureValues.contentDisposition,
        blobSASSignatureValues.contentEncoding,
        blobSASSignatureValues.contentLanguage,
        blobSASSignatureValues.contentType
    ].join("\n");
    const signature = userDelegationKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType, userDelegationKeyCredential.userDelegationKey);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2020-02-10.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn.
 *
 * WARNING: identifier will be ignored, permissions and expiresOn are required.
 *
 * @param blobSASSignatureValues -
 * @param userDelegationKeyCredential -
 */ function generateBlobSASQueryParametersUDK20200210(blobSASSignatureValues, userDelegationKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    // Stored access policies are not supported for a user delegation SAS.
    if (!blobSASSignatureValues.permissions || !blobSASSignatureValues.expiresOn) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when generating user delegation SAS.");
    let resource = "c";
    let timestamp = blobSASSignatureValues.snapshotTime;
    if (blobSASSignatureValues.blobName) {
        resource = "b";
        if (blobSASSignatureValues.snapshotTime) resource = "bs";
        else if (blobSASSignatureValues.versionId) {
            resource = "bv";
            timestamp = blobSASSignatureValues.versionId;
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(userDelegationKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        userDelegationKeyCredential.userDelegationKey.signedObjectId,
        userDelegationKeyCredential.userDelegationKey.signedTenantId,
        userDelegationKeyCredential.userDelegationKey.signedStartsOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedStartsOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedExpiresOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedExpiresOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedService,
        userDelegationKeyCredential.userDelegationKey.signedVersion,
        blobSASSignatureValues.preauthorizedAgentObjectId,
        undefined,
        blobSASSignatureValues.correlationId,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        resource,
        timestamp,
        blobSASSignatureValues.cacheControl,
        blobSASSignatureValues.contentDisposition,
        blobSASSignatureValues.contentEncoding,
        blobSASSignatureValues.contentLanguage,
        blobSASSignatureValues.contentType
    ].join("\n");
    const signature = userDelegationKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType, userDelegationKeyCredential.userDelegationKey, blobSASSignatureValues.preauthorizedAgentObjectId, blobSASSignatureValues.correlationId);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2020-12-06.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn.
 *
 * WARNING: identifier will be ignored, permissions and expiresOn are required.
 *
 * @param blobSASSignatureValues -
 * @param userDelegationKeyCredential -
 */ function generateBlobSASQueryParametersUDK20201206(blobSASSignatureValues, userDelegationKeyCredential) {
    blobSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues);
    // Stored access policies are not supported for a user delegation SAS.
    if (!blobSASSignatureValues.permissions || !blobSASSignatureValues.expiresOn) throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when generating user delegation SAS.");
    let resource = "c";
    let timestamp = blobSASSignatureValues.snapshotTime;
    if (blobSASSignatureValues.blobName) {
        resource = "b";
        if (blobSASSignatureValues.snapshotTime) resource = "bs";
        else if (blobSASSignatureValues.versionId) {
            resource = "bv";
            timestamp = blobSASSignatureValues.versionId;
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (blobSASSignatureValues.permissions) {
        if (blobSASSignatureValues.blobName) verifiedPermissions = (0, _blobSASPermissions.BlobSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
        else verifiedPermissions = (0, _containerSASPermissions.ContainerSASPermissions).parse(blobSASSignatureValues.permissions.toString()).toString();
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        blobSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.startsOn, false) : "",
        blobSASSignatureValues.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(blobSASSignatureValues.expiresOn, false) : "",
        getCanonicalName(userDelegationKeyCredential.accountName, blobSASSignatureValues.containerName, blobSASSignatureValues.blobName),
        userDelegationKeyCredential.userDelegationKey.signedObjectId,
        userDelegationKeyCredential.userDelegationKey.signedTenantId,
        userDelegationKeyCredential.userDelegationKey.signedStartsOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedStartsOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedExpiresOn ? (0, _utilsCommon.truncatedISO8061Date)(userDelegationKeyCredential.userDelegationKey.signedExpiresOn, false) : "",
        userDelegationKeyCredential.userDelegationKey.signedService,
        userDelegationKeyCredential.userDelegationKey.signedVersion,
        blobSASSignatureValues.preauthorizedAgentObjectId,
        undefined,
        blobSASSignatureValues.correlationId,
        blobSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(blobSASSignatureValues.ipRange) : "",
        blobSASSignatureValues.protocol ? blobSASSignatureValues.protocol : "",
        blobSASSignatureValues.version,
        resource,
        timestamp,
        blobSASSignatureValues.encryptionScope,
        blobSASSignatureValues.cacheControl,
        blobSASSignatureValues.contentDisposition,
        blobSASSignatureValues.contentEncoding,
        blobSASSignatureValues.contentLanguage,
        blobSASSignatureValues.contentType
    ].join("\n");
    const signature = userDelegationKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(blobSASSignatureValues.version, signature, verifiedPermissions, undefined, undefined, blobSASSignatureValues.protocol, blobSASSignatureValues.startsOn, blobSASSignatureValues.expiresOn, blobSASSignatureValues.ipRange, blobSASSignatureValues.identifier, resource, blobSASSignatureValues.cacheControl, blobSASSignatureValues.contentDisposition, blobSASSignatureValues.contentEncoding, blobSASSignatureValues.contentLanguage, blobSASSignatureValues.contentType, userDelegationKeyCredential.userDelegationKey, blobSASSignatureValues.preauthorizedAgentObjectId, blobSASSignatureValues.correlationId, blobSASSignatureValues.encryptionScope);
}
function getCanonicalName(accountName, containerName, blobName) {
    // Container: "/blob/account/containerName"
    // Blob:      "/blob/account/containerName/blobName"
    const elements = [
        `/blob/${accountName}/${containerName}`
    ];
    if (blobName) elements.push(`/${blobName}`);
    return elements.join("");
}
function SASSignatureValuesSanityCheckAndAutofill(blobSASSignatureValues) {
    const version = blobSASSignatureValues.version ? blobSASSignatureValues.version : (0, _constants.SERVICE_VERSION);
    if (blobSASSignatureValues.snapshotTime && version < "2018-11-09") throw RangeError("'version' must be >= '2018-11-09' when providing 'snapshotTime'.");
    if (blobSASSignatureValues.blobName === undefined && blobSASSignatureValues.snapshotTime) throw RangeError("Must provide 'blobName' when providing 'snapshotTime'.");
    if (blobSASSignatureValues.versionId && version < "2019-10-10") throw RangeError("'version' must be >= '2019-10-10' when providing 'versionId'.");
    if (blobSASSignatureValues.blobName === undefined && blobSASSignatureValues.versionId) throw RangeError("Must provide 'blobName' when providing 'versionId'.");
    if (blobSASSignatureValues.permissions && blobSASSignatureValues.permissions.setImmutabilityPolicy && version < "2020-08-04") throw RangeError("'version' must be >= '2020-08-04' when provided 'i' permission.");
    if (blobSASSignatureValues.permissions && blobSASSignatureValues.permissions.deleteVersion && version < "2019-10-10") throw RangeError("'version' must be >= '2019-10-10' when providing 'x' permission.");
    if (blobSASSignatureValues.permissions && blobSASSignatureValues.permissions.permanentDelete && version < "2019-10-10") throw RangeError("'version' must be >= '2019-10-10' when providing 'y' permission.");
    if (blobSASSignatureValues.permissions && blobSASSignatureValues.permissions.tag && version < "2019-12-12") throw RangeError("'version' must be >= '2019-12-12' when providing 't' permission.");
    if (version < "2020-02-10" && blobSASSignatureValues.permissions && (blobSASSignatureValues.permissions.move || blobSASSignatureValues.permissions.execute)) throw RangeError("'version' must be >= '2020-02-10' when providing the 'm' or 'e' permission.");
    if (version < "2021-04-10" && blobSASSignatureValues.permissions && blobSASSignatureValues.permissions.filterByTags) throw RangeError("'version' must be >= '2021-04-10' when providing the 'f' permission.");
    if (version < "2020-02-10" && (blobSASSignatureValues.preauthorizedAgentObjectId || blobSASSignatureValues.correlationId)) throw RangeError("'version' must be >= '2020-02-10' when providing 'preauthorizedAgentObjectId' or 'correlationId'.");
    if (blobSASSignatureValues.encryptionScope && version < "2020-12-06") throw RangeError("'version' must be >= '2020-12-06' when provided 'encryptionScope' in SAS.");
    blobSASSignatureValues.version = version;
    return blobSASSignatureValues;
}

},{"./BlobSASPermissions":"fEJiX","./ContainerSASPermissions":"dxYpk","../credentials/StorageSharedKeyCredential":"jUFIX","../credentials/UserDelegationKeyCredential":"h8KFP","./SasIPRange":"aH3sX","./SASQueryParameters":"gMQnk","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fEJiX":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a blob. Setting
 * a value to true means that any SAS which uses these permissions will grant permissions for that operation. Once all
 * the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link BlobSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlobSASPermissions", ()=>BlobSASPermissions);
class BlobSASPermissions {
    constructor(){
        /**
         * Specifies Read access granted.
         */ this.read = false;
        /**
         * Specifies Add access granted.
         */ this.add = false;
        /**
         * Specifies Create access granted.
         */ this.create = false;
        /**
         * Specifies Write access granted.
         */ this.write = false;
        /**
         * Specifies Delete access granted.
         */ this.delete = false;
        /**
         * Specifies Delete version access granted.
         */ this.deleteVersion = false;
        /**
         * Specfies Tag access granted.
         */ this.tag = false;
        /**
         * Specifies Move access granted.
         */ this.move = false;
        /**
         * Specifies Execute access granted.
         */ this.execute = false;
        /**
         * Specifies SetImmutabilityPolicy access granted.
         */ this.setImmutabilityPolicy = false;
        /**
         * Specifies that Permanent Delete is permitted.
         */ this.permanentDelete = false;
    }
    /**
     * Creates a {@link BlobSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */ static parse(permissions) {
        const blobSASPermissions = new BlobSASPermissions();
        for (const char of permissions)switch(char){
            case "r":
                blobSASPermissions.read = true;
                break;
            case "a":
                blobSASPermissions.add = true;
                break;
            case "c":
                blobSASPermissions.create = true;
                break;
            case "w":
                blobSASPermissions.write = true;
                break;
            case "d":
                blobSASPermissions.delete = true;
                break;
            case "x":
                blobSASPermissions.deleteVersion = true;
                break;
            case "t":
                blobSASPermissions.tag = true;
                break;
            case "m":
                blobSASPermissions.move = true;
                break;
            case "e":
                blobSASPermissions.execute = true;
                break;
            case "i":
                blobSASPermissions.setImmutabilityPolicy = true;
                break;
            case "y":
                blobSASPermissions.permanentDelete = true;
                break;
            default:
                throw new RangeError(`Invalid permission: ${char}`);
        }
        return blobSASPermissions;
    }
    /**
     * Creates a {@link BlobSASPermissions} from a raw object which contains same keys as it
     * and boolean values for them.
     *
     * @param permissionLike -
     */ static from(permissionLike) {
        const blobSASPermissions = new BlobSASPermissions();
        if (permissionLike.read) blobSASPermissions.read = true;
        if (permissionLike.add) blobSASPermissions.add = true;
        if (permissionLike.create) blobSASPermissions.create = true;
        if (permissionLike.write) blobSASPermissions.write = true;
        if (permissionLike.delete) blobSASPermissions.delete = true;
        if (permissionLike.deleteVersion) blobSASPermissions.deleteVersion = true;
        if (permissionLike.tag) blobSASPermissions.tag = true;
        if (permissionLike.move) blobSASPermissions.move = true;
        if (permissionLike.execute) blobSASPermissions.execute = true;
        if (permissionLike.setImmutabilityPolicy) blobSASPermissions.setImmutabilityPolicy = true;
        if (permissionLike.permanentDelete) blobSASPermissions.permanentDelete = true;
        return blobSASPermissions;
    }
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * @returns A string which represents the BlobSASPermissions
     */ toString() {
        const permissions = [];
        if (this.read) permissions.push("r");
        if (this.add) permissions.push("a");
        if (this.create) permissions.push("c");
        if (this.write) permissions.push("w");
        if (this.delete) permissions.push("d");
        if (this.deleteVersion) permissions.push("x");
        if (this.tag) permissions.push("t");
        if (this.move) permissions.push("m");
        if (this.execute) permissions.push("e");
        if (this.setImmutabilityPolicy) permissions.push("i");
        if (this.permanentDelete) permissions.push("y");
        return permissions.join("");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dxYpk":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a container.
 * Setting a value to true means that any SAS which uses these permissions will grant permissions for that operation.
 * Once all the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link BlobSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ContainerSASPermissions", ()=>ContainerSASPermissions);
class ContainerSASPermissions {
    constructor(){
        /**
         * Specifies Read access granted.
         */ this.read = false;
        /**
         * Specifies Add access granted.
         */ this.add = false;
        /**
         * Specifies Create access granted.
         */ this.create = false;
        /**
         * Specifies Write access granted.
         */ this.write = false;
        /**
         * Specifies Delete access granted.
         */ this.delete = false;
        /**
         * Specifies Delete version access granted.
         */ this.deleteVersion = false;
        /**
         * Specifies List access granted.
         */ this.list = false;
        /**
         * Specfies Tag access granted.
         */ this.tag = false;
        /**
         * Specifies Move access granted.
         */ this.move = false;
        /**
         * Specifies Execute access granted.
         */ this.execute = false;
        /**
         * Specifies SetImmutabilityPolicy access granted.
         */ this.setImmutabilityPolicy = false;
        /**
         * Specifies that Permanent Delete is permitted.
         */ this.permanentDelete = false;
        /**
         * Specifies that Filter Blobs by Tags is permitted.
         */ this.filterByTags = false;
    }
    /**
     * Creates an {@link ContainerSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */ static parse(permissions) {
        const containerSASPermissions = new ContainerSASPermissions();
        for (const char of permissions)switch(char){
            case "r":
                containerSASPermissions.read = true;
                break;
            case "a":
                containerSASPermissions.add = true;
                break;
            case "c":
                containerSASPermissions.create = true;
                break;
            case "w":
                containerSASPermissions.write = true;
                break;
            case "d":
                containerSASPermissions.delete = true;
                break;
            case "l":
                containerSASPermissions.list = true;
                break;
            case "t":
                containerSASPermissions.tag = true;
                break;
            case "x":
                containerSASPermissions.deleteVersion = true;
                break;
            case "m":
                containerSASPermissions.move = true;
                break;
            case "e":
                containerSASPermissions.execute = true;
                break;
            case "i":
                containerSASPermissions.setImmutabilityPolicy = true;
                break;
            case "y":
                containerSASPermissions.permanentDelete = true;
                break;
            case "f":
                containerSASPermissions.filterByTags = true;
                break;
            default:
                throw new RangeError(`Invalid permission ${char}`);
        }
        return containerSASPermissions;
    }
    /**
     * Creates a {@link ContainerSASPermissions} from a raw object which contains same keys as it
     * and boolean values for them.
     *
     * @param permissionLike -
     */ static from(permissionLike) {
        const containerSASPermissions = new ContainerSASPermissions();
        if (permissionLike.read) containerSASPermissions.read = true;
        if (permissionLike.add) containerSASPermissions.add = true;
        if (permissionLike.create) containerSASPermissions.create = true;
        if (permissionLike.write) containerSASPermissions.write = true;
        if (permissionLike.delete) containerSASPermissions.delete = true;
        if (permissionLike.list) containerSASPermissions.list = true;
        if (permissionLike.deleteVersion) containerSASPermissions.deleteVersion = true;
        if (permissionLike.tag) containerSASPermissions.tag = true;
        if (permissionLike.move) containerSASPermissions.move = true;
        if (permissionLike.execute) containerSASPermissions.execute = true;
        if (permissionLike.setImmutabilityPolicy) containerSASPermissions.setImmutabilityPolicy = true;
        if (permissionLike.permanentDelete) containerSASPermissions.permanentDelete = true;
        if (permissionLike.filterByTags) containerSASPermissions.filterByTags = true;
        return containerSASPermissions;
    }
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * The order of the characters should be as specified here to ensure correctness.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     */ toString() {
        const permissions = [];
        if (this.read) permissions.push("r");
        if (this.add) permissions.push("a");
        if (this.create) permissions.push("c");
        if (this.write) permissions.push("w");
        if (this.delete) permissions.push("d");
        if (this.deleteVersion) permissions.push("x");
        if (this.list) permissions.push("l");
        if (this.tag) permissions.push("t");
        if (this.move) permissions.push("m");
        if (this.execute) permissions.push("e");
        if (this.setImmutabilityPolicy) permissions.push("i");
        if (this.permanentDelete) permissions.push("y");
        if (this.filterByTags) permissions.push("f");
        return permissions.join("");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h8KFP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "UserDelegationKeyCredential", ()=>UserDelegationKeyCredential);
class UserDelegationKeyCredential {
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aH3sX":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Generate SasIPRange format string. For example:
 *
 * "8.8.8.8" or "1.1.1.1-255.255.255.255"
 *
 * @param ipRange -
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ipRangeToString", ()=>ipRangeToString);
function ipRangeToString(ipRange) {
    return ipRange.end ? `${ipRange.start}-${ipRange.end}` : ipRange.start;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gMQnk":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "SASProtocol", ()=>SASProtocol);
/**
 * Represents the components that make up an Azure Storage SAS' query parameters. This type is not constructed directly
 * by the user; it is only generated by the {@link AccountSASSignatureValues} and {@link BlobSASSignatureValues}
 * types. Once generated, it can be encoded into a {@link String} and appended to a URL directly (though caution should
 * be taken here in case there are existing query parameters, which might affect the appropriate means of appending
 * these query parameters).
 *
 * NOTE: Instances of this class are immutable.
 */ parcelHelpers.export(exports, "SASQueryParameters", ()=>SASQueryParameters);
var _sasIPRange = require("./SasIPRange");
var _utilsCommon = require("../utils/utils.common");
var SASProtocol;
(function(SASProtocol) {
    /**
     * Protocol that allows HTTPS only
     */ SASProtocol["Https"] = "https";
    /**
     * Protocol that allows both HTTPS and HTTP
     */ SASProtocol["HttpsAndHttp"] = "https,http";
})(SASProtocol || (SASProtocol = {}));
class SASQueryParameters {
    /**
     * Optional. IP range allowed for this SAS.
     *
     * @readonly
     */ get ipRange() {
        if (this.ipRangeInner) return {
            end: this.ipRangeInner.end,
            start: this.ipRangeInner.start
        };
        return undefined;
    }
    constructor(version, signature, permissionsOrOptions, services, resourceTypes, protocol, startsOn, expiresOn, ipRange, identifier, resource, cacheControl, contentDisposition, contentEncoding, contentLanguage, contentType, userDelegationKey, preauthorizedAgentObjectId, correlationId, encryptionScope){
        this.version = version;
        this.signature = signature;
        if (permissionsOrOptions !== undefined && typeof permissionsOrOptions !== "string") {
            // SASQueryParametersOptions
            this.permissions = permissionsOrOptions.permissions;
            this.services = permissionsOrOptions.services;
            this.resourceTypes = permissionsOrOptions.resourceTypes;
            this.protocol = permissionsOrOptions.protocol;
            this.startsOn = permissionsOrOptions.startsOn;
            this.expiresOn = permissionsOrOptions.expiresOn;
            this.ipRangeInner = permissionsOrOptions.ipRange;
            this.identifier = permissionsOrOptions.identifier;
            this.encryptionScope = permissionsOrOptions.encryptionScope;
            this.resource = permissionsOrOptions.resource;
            this.cacheControl = permissionsOrOptions.cacheControl;
            this.contentDisposition = permissionsOrOptions.contentDisposition;
            this.contentEncoding = permissionsOrOptions.contentEncoding;
            this.contentLanguage = permissionsOrOptions.contentLanguage;
            this.contentType = permissionsOrOptions.contentType;
            if (permissionsOrOptions.userDelegationKey) {
                this.signedOid = permissionsOrOptions.userDelegationKey.signedObjectId;
                this.signedTenantId = permissionsOrOptions.userDelegationKey.signedTenantId;
                this.signedStartsOn = permissionsOrOptions.userDelegationKey.signedStartsOn;
                this.signedExpiresOn = permissionsOrOptions.userDelegationKey.signedExpiresOn;
                this.signedService = permissionsOrOptions.userDelegationKey.signedService;
                this.signedVersion = permissionsOrOptions.userDelegationKey.signedVersion;
                this.preauthorizedAgentObjectId = permissionsOrOptions.preauthorizedAgentObjectId;
                this.correlationId = permissionsOrOptions.correlationId;
            }
        } else {
            this.services = services;
            this.resourceTypes = resourceTypes;
            this.expiresOn = expiresOn;
            this.permissions = permissionsOrOptions;
            this.protocol = protocol;
            this.startsOn = startsOn;
            this.ipRangeInner = ipRange;
            this.encryptionScope = encryptionScope;
            this.identifier = identifier;
            this.resource = resource;
            this.cacheControl = cacheControl;
            this.contentDisposition = contentDisposition;
            this.contentEncoding = contentEncoding;
            this.contentLanguage = contentLanguage;
            this.contentType = contentType;
            if (userDelegationKey) {
                this.signedOid = userDelegationKey.signedObjectId;
                this.signedTenantId = userDelegationKey.signedTenantId;
                this.signedStartsOn = userDelegationKey.signedStartsOn;
                this.signedExpiresOn = userDelegationKey.signedExpiresOn;
                this.signedService = userDelegationKey.signedService;
                this.signedVersion = userDelegationKey.signedVersion;
                this.preauthorizedAgentObjectId = preauthorizedAgentObjectId;
                this.correlationId = correlationId;
            }
        }
    }
    /**
     * Encodes all SAS query parameters into a string that can be appended to a URL.
     *
     */ toString() {
        const params = [
            "sv",
            "ss",
            "srt",
            "spr",
            "st",
            "se",
            "sip",
            "si",
            "ses",
            "skoid",
            "sktid",
            "skt",
            "ske",
            "sks",
            "skv",
            "sr",
            "sp",
            "sig",
            "rscc",
            "rscd",
            "rsce",
            "rscl",
            "rsct",
            "saoid",
            "scid"
        ];
        const queries = [];
        for (const param of params)switch(param){
            case "sv":
                this.tryAppendQueryParameter(queries, param, this.version);
                break;
            case "ss":
                this.tryAppendQueryParameter(queries, param, this.services);
                break;
            case "srt":
                this.tryAppendQueryParameter(queries, param, this.resourceTypes);
                break;
            case "spr":
                this.tryAppendQueryParameter(queries, param, this.protocol);
                break;
            case "st":
                this.tryAppendQueryParameter(queries, param, this.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(this.startsOn, false) : undefined);
                break;
            case "se":
                this.tryAppendQueryParameter(queries, param, this.expiresOn ? (0, _utilsCommon.truncatedISO8061Date)(this.expiresOn, false) : undefined);
                break;
            case "sip":
                this.tryAppendQueryParameter(queries, param, this.ipRange ? (0, _sasIPRange.ipRangeToString)(this.ipRange) : undefined);
                break;
            case "si":
                this.tryAppendQueryParameter(queries, param, this.identifier);
                break;
            case "ses":
                this.tryAppendQueryParameter(queries, param, this.encryptionScope);
                break;
            case "skoid":
                this.tryAppendQueryParameter(queries, param, this.signedOid);
                break;
            case "sktid":
                this.tryAppendQueryParameter(queries, param, this.signedTenantId);
                break;
            case "skt":
                this.tryAppendQueryParameter(queries, param, this.signedStartsOn ? (0, _utilsCommon.truncatedISO8061Date)(this.signedStartsOn, false) : undefined);
                break;
            case "ske":
                this.tryAppendQueryParameter(queries, param, this.signedExpiresOn ? (0, _utilsCommon.truncatedISO8061Date)(this.signedExpiresOn, false) : undefined);
                break;
            case "sks":
                this.tryAppendQueryParameter(queries, param, this.signedService);
                break;
            case "skv":
                this.tryAppendQueryParameter(queries, param, this.signedVersion);
                break;
            case "sr":
                this.tryAppendQueryParameter(queries, param, this.resource);
                break;
            case "sp":
                this.tryAppendQueryParameter(queries, param, this.permissions);
                break;
            case "sig":
                this.tryAppendQueryParameter(queries, param, this.signature);
                break;
            case "rscc":
                this.tryAppendQueryParameter(queries, param, this.cacheControl);
                break;
            case "rscd":
                this.tryAppendQueryParameter(queries, param, this.contentDisposition);
                break;
            case "rsce":
                this.tryAppendQueryParameter(queries, param, this.contentEncoding);
                break;
            case "rscl":
                this.tryAppendQueryParameter(queries, param, this.contentLanguage);
                break;
            case "rsct":
                this.tryAppendQueryParameter(queries, param, this.contentType);
                break;
            case "saoid":
                this.tryAppendQueryParameter(queries, param, this.preauthorizedAgentObjectId);
                break;
            case "scid":
                this.tryAppendQueryParameter(queries, param, this.correlationId);
                break;
        }
        return queries.join("&");
    }
    /**
     * A private helper method used to filter and append query key/value pairs into an array.
     *
     * @param queries -
     * @param key -
     * @param value -
     */ tryAppendQueryParameter(queries, key, value) {
        if (!value) return;
        key = encodeURIComponent(key);
        value = encodeURIComponent(value);
        if (key.length > 0 && value.length > 0) queries.push(`${key}=${value}`);
    }
}

},{"./SasIPRange":"aH3sX","../utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hZ8uc":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A client that manages leases for a {@link ContainerClient} or a {@link BlobClient}.
 */ parcelHelpers.export(exports, "BlobLeaseClient", ()=>BlobLeaseClient);
var _coreUtil = require("@azure/core-util");
var _constants = require("./utils/constants");
var _tracing = require("./utils/tracing");
var _utilsCommon = require("./utils/utils.common");
class BlobLeaseClient {
    /**
     * Gets the lease Id.
     *
     * @readonly
     */ get leaseId() {
        return this._leaseId;
    }
    /**
     * Gets the url.
     *
     * @readonly
     */ get url() {
        return this._url;
    }
    /**
     * Creates an instance of BlobLeaseClient.
     * @param client - The client to make the lease operation requests.
     * @param leaseId - Initial proposed lease id.
     */ constructor(client, leaseId){
        const clientContext = client.storageClientContext;
        this._url = client.url;
        if (client.name === undefined) {
            this._isContainer = true;
            this._containerOrBlobOperation = clientContext.container;
        } else {
            this._isContainer = false;
            this._containerOrBlobOperation = clientContext.blob;
        }
        if (!leaseId) leaseId = (0, _coreUtil.randomUUID)();
        this._leaseId = leaseId;
    }
    /**
     * Establishes and manages a lock on a container for delete operations, or on a blob
     * for write and delete operations.
     * The lock duration can be 15 to 60 seconds, or can be infinite.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container
     * and
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob
     *
     * @param duration - Must be between 15 to 60 seconds, or infinite (-1)
     * @param options - option to configure lease management operations.
     * @returns Response data for acquire lease operation.
     */ async acquireLease(duration, options = {}) {
        var _a, _b, _c, _d, _e;
        if (this._isContainer && (((_a = options.conditions) === null || _a === void 0 ? void 0 : _a.ifMatch) && ((_b = options.conditions) === null || _b === void 0 ? void 0 : _b.ifMatch) !== (0, _constants.ETagNone) || ((_c = options.conditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch) && ((_d = options.conditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch) !== (0, _constants.ETagNone) || ((_e = options.conditions) === null || _e === void 0 ? void 0 : _e.tagConditions))) throw new RangeError("The IfMatch, IfNoneMatch and tags access conditions are ignored by the service. Values other than undefined or their default values are not acceptable.");
        return (0, _tracing.tracingClient).withSpan("BlobLeaseClient-acquireLease", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this._containerOrBlobOperation.acquireLease({
                abortSignal: options.abortSignal,
                duration,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                proposedLeaseId: this._leaseId,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * To change the ID of the lease.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container
     * and
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob
     *
     * @param proposedLeaseId - the proposed new lease Id.
     * @param options - option to configure lease management operations.
     * @returns Response data for change lease operation.
     */ async changeLease(proposedLeaseId, options = {}) {
        var _a, _b, _c, _d, _e;
        if (this._isContainer && (((_a = options.conditions) === null || _a === void 0 ? void 0 : _a.ifMatch) && ((_b = options.conditions) === null || _b === void 0 ? void 0 : _b.ifMatch) !== (0, _constants.ETagNone) || ((_c = options.conditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch) && ((_d = options.conditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch) !== (0, _constants.ETagNone) || ((_e = options.conditions) === null || _e === void 0 ? void 0 : _e.tagConditions))) throw new RangeError("The IfMatch, IfNoneMatch and tags access conditions are ignored by the service. Values other than undefined or their default values are not acceptable.");
        return (0, _tracing.tracingClient).withSpan("BlobLeaseClient-changeLease", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this._containerOrBlobOperation.changeLease(this._leaseId, proposedLeaseId, {
                abortSignal: options.abortSignal,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            this._leaseId = proposedLeaseId;
            return response;
        });
    }
    /**
     * To free the lease if it is no longer needed so that another client may
     * immediately acquire a lease against the container or the blob.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container
     * and
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob
     *
     * @param options - option to configure lease management operations.
     * @returns Response data for release lease operation.
     */ async releaseLease(options = {}) {
        var _a, _b, _c, _d, _e;
        if (this._isContainer && (((_a = options.conditions) === null || _a === void 0 ? void 0 : _a.ifMatch) && ((_b = options.conditions) === null || _b === void 0 ? void 0 : _b.ifMatch) !== (0, _constants.ETagNone) || ((_c = options.conditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch) && ((_d = options.conditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch) !== (0, _constants.ETagNone) || ((_e = options.conditions) === null || _e === void 0 ? void 0 : _e.tagConditions))) throw new RangeError("The IfMatch, IfNoneMatch and tags access conditions are ignored by the service. Values other than undefined or their default values are not acceptable.");
        return (0, _tracing.tracingClient).withSpan("BlobLeaseClient-releaseLease", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this._containerOrBlobOperation.releaseLease(this._leaseId, {
                abortSignal: options.abortSignal,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * To renew the lease.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container
     * and
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob
     *
     * @param options - Optional option to configure lease management operations.
     * @returns Response data for renew lease operation.
     */ async renewLease(options = {}) {
        var _a, _b, _c, _d, _e;
        if (this._isContainer && (((_a = options.conditions) === null || _a === void 0 ? void 0 : _a.ifMatch) && ((_b = options.conditions) === null || _b === void 0 ? void 0 : _b.ifMatch) !== (0, _constants.ETagNone) || ((_c = options.conditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch) && ((_d = options.conditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch) !== (0, _constants.ETagNone) || ((_e = options.conditions) === null || _e === void 0 ? void 0 : _e.tagConditions))) throw new RangeError("The IfMatch, IfNoneMatch and tags access conditions are ignored by the service. Values other than undefined or their default values are not acceptable.");
        return (0, _tracing.tracingClient).withSpan("BlobLeaseClient-renewLease", options, async (updatedOptions)=>{
            var _a;
            return this._containerOrBlobOperation.renewLease(this._leaseId, {
                abortSignal: options.abortSignal,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            });
        });
    }
    /**
     * To end the lease but ensure that another client cannot acquire a new lease
     * until the current lease period has expired.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container
     * and
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob
     *
     * @param breakPeriod - Break period
     * @param options - Optional options to configure lease management operations.
     * @returns Response data for break lease operation.
     */ async breakLease(breakPeriod, options = {}) {
        var _a, _b, _c, _d, _e;
        if (this._isContainer && (((_a = options.conditions) === null || _a === void 0 ? void 0 : _a.ifMatch) && ((_b = options.conditions) === null || _b === void 0 ? void 0 : _b.ifMatch) !== (0, _constants.ETagNone) || ((_c = options.conditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch) && ((_d = options.conditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch) !== (0, _constants.ETagNone) || ((_e = options.conditions) === null || _e === void 0 ? void 0 : _e.tagConditions))) throw new RangeError("The IfMatch, IfNoneMatch and tags access conditions are ignored by the service. Values other than undefined or their default values are not acceptable.");
        return (0, _tracing.tracingClient).withSpan("BlobLeaseClient-breakLease", options, async (updatedOptions)=>{
            var _a;
            const operationOptions = {
                abortSignal: options.abortSignal,
                breakPeriod,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            };
            return (0, _utilsCommon.assertResponse)(await this._containerOrBlobOperation.breakLease(operationOptions));
        });
    }
}

},{"@azure/core-util":"b31OK","./utils/constants":"4gX5x","./utils/tracing":"m0KjB","./utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kUV1b":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A BlobClient represents a URL to an Azure Storage blob; the blob may be a block blob,
 * append blob, or page blob.
 */ parcelHelpers.export(exports, "BlobClient", ()=>BlobClient);
/**
 * AppendBlobClient defines a set of operations applicable to append blobs.
 */ parcelHelpers.export(exports, "AppendBlobClient", ()=>AppendBlobClient);
/**
 * BlockBlobClient defines a set of operations applicable to block blobs.
 */ parcelHelpers.export(exports, "BlockBlobClient", ()=>BlockBlobClient);
/**
 * PageBlobClient defines a set of operations applicable to page blobs.
 */ parcelHelpers.export(exports, "PageBlobClient", ()=>PageBlobClient);
var _tslib = require("tslib");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreAuth = require("@azure/core-auth");
var _coreUtil = require("@azure/core-util");
var _blobDownloadResponse = require("./BlobDownloadResponse");
var _blobQueryResponse = require("./BlobQueryResponse");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _storageSharedKeyCredential = require("./credentials/StorageSharedKeyCredential");
var _models = require("./models");
var _pageBlobRangeResponse = require("./PageBlobRangeResponse");
var _pipeline = require("./Pipeline");
var _blobStartCopyFromUrlPoller = require("./pollers/BlobStartCopyFromUrlPoller");
var _range = require("./Range");
var _storageClient = require("./StorageClient");
var _batch = require("./utils/Batch");
var _src = require("../../storage-common/src");
var _constants = require("./utils/constants");
var _tracing = require("./utils/tracing");
var _utilsCommon = require("./utils/utils.common");
var _utilsNode = require("./utils/utils.node");
var _blobSASSignatureValues = require("./sas/BlobSASSignatureValues");
var _blobLeaseClient = require("./BlobLeaseClient");
var Buffer = require("d85f5683f78ac6e9").Buffer;
class BlobClient extends (0, _storageClient.StorageClient) {
    /**
     * The name of the blob.
     */ get name() {
        return this._name;
    }
    /**
     * The name of the storage container the blob is associated with.
     */ get containerName() {
        return this._containerName;
    }
    constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        options = options || {};
        let pipeline;
        let url;
        if ((0, _pipeline.isPipelineLike)(credentialOrPipelineOrContainerName)) {
            // (url: string, pipeline: Pipeline)
            url = urlOrConnectionString;
            pipeline = credentialOrPipelineOrContainerName;
        } else if ((0, _coreUtil.isNode) && credentialOrPipelineOrContainerName instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipelineOrContainerName instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipelineOrContainerName)) {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            url = urlOrConnectionString;
            options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(credentialOrPipelineOrContainerName, options);
        } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== "string") {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            // The second parameter is undefined. Use anonymous credential.
            url = urlOrConnectionString;
            if (blobNameOrOptions && typeof blobNameOrOptions !== "string") options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === "string" && blobNameOrOptions && typeof blobNameOrOptions === "string") {
            // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)
            const containerName = credentialOrPipelineOrContainerName;
            const blobName = blobNameOrOptions;
            const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(urlOrConnectionString);
            if (extractedCreds.kind === "AccountConnString") {
                if (0, _coreUtil.isNode) {
                    const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                    url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));
                    if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                    pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                } else throw new Error("Account connection string is only supported in Node.js environment");
            } else if (extractedCreds.kind === "SASConnString") {
                url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + "?" + extractedCreds.accountSas;
                pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        } else throw new Error("Expecting non-empty strings for containerName and blobName parameters");
        super(url, pipeline);
        ({ blobName: this._name, containerName: this._containerName } = this.getBlobAndContainerNamesFromUrl());
        this.blobContext = this.storageClientContext.blob;
        this._snapshot = (0, _utilsCommon.getURLParameter)(this.url, (0, _constants.URLConstants).Parameters.SNAPSHOT);
        this._versionId = (0, _utilsCommon.getURLParameter)(this.url, (0, _constants.URLConstants).Parameters.VERSIONID);
    }
    /**
     * Creates a new BlobClient object identical to the source but with the specified snapshot timestamp.
     * Provide "" will remove the snapshot and return a Client to the base blob.
     *
     * @param snapshot - The snapshot timestamp.
     * @returns A new BlobClient object identical to the source but with the specified snapshot timestamp
     */ withSnapshot(snapshot) {
        return new BlobClient((0, _utilsCommon.setURLParameter)(this.url, (0, _constants.URLConstants).Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);
    }
    /**
     * Creates a new BlobClient object pointing to a version of this blob.
     * Provide "" will remove the versionId and return a Client to the base blob.
     *
     * @param versionId - The versionId.
     * @returns A new BlobClient object pointing to the version of this blob.
     */ withVersion(versionId) {
        return new BlobClient((0, _utilsCommon.setURLParameter)(this.url, (0, _constants.URLConstants).Parameters.VERSIONID, versionId.length === 0 ? undefined : versionId), this.pipeline);
    }
    /**
     * Creates a AppendBlobClient object.
     *
     */ getAppendBlobClient() {
        return new AppendBlobClient(this.url, this.pipeline);
    }
    /**
     * Creates a BlockBlobClient object.
     *
     */ getBlockBlobClient() {
        return new BlockBlobClient(this.url, this.pipeline);
    }
    /**
     * Creates a PageBlobClient object.
     *
     */ getPageBlobClient() {
        return new PageBlobClient(this.url, this.pipeline);
    }
    /**
     * Reads or downloads a blob from the system, including its metadata and properties.
     * You can also call Get Blob to read a snapshot.
     *
     * * In Node.js, data returns in a Readable stream readableStreamBody
     * * In browsers, data returns in a promise blobBody
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob
     *
     * @param offset - From which position of the blob to download, greater than or equal to 0
     * @param count - How much data to be downloaded, greater than 0. Will download to the end when undefined
     * @param options - Optional options to Blob Download operation.
     *
     *
     * Example usage (Node.js):
     *
     * ```js
     * // Download and convert a blob to a string
     * const downloadBlockBlobResponse = await blobClient.download();
     * const downloaded = await streamToBuffer(downloadBlockBlobResponse.readableStreamBody);
     * console.log("Downloaded blob content:", downloaded.toString());
     *
     * async function streamToBuffer(readableStream) {
     * return new Promise((resolve, reject) => {
     * const chunks = [];
     * readableStream.on("data", (data) => {
     * chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     * });
     * readableStream.on("end", () => {
     * resolve(Buffer.concat(chunks));
     * });
     * readableStream.on("error", reject);
     * });
     * }
     * ```
     *
     * Example usage (browser):
     *
     * ```js
     * // Download and convert a blob to a string
     * const downloadBlockBlobResponse = await blobClient.download();
     * const downloaded = await blobToString(await downloadBlockBlobResponse.blobBody);
     * console.log(
     *   "Downloaded blob content",
     *   downloaded
     * );
     *
     * async function blobToString(blob: Blob): Promise<string> {
     *   const fileReader = new FileReader();
     *   return new Promise<string>((resolve, reject) => {
     *     fileReader.onloadend = (ev: any) => {
     *       resolve(ev.target!.result);
     *     };
     *     fileReader.onerror = reject;
     *     fileReader.readAsText(blob);
     *   });
     * }
     * ```
     */ async download(offset = 0, count, options = {}) {
        options.conditions = options.conditions || {};
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlobClient-download", options, async (updatedOptions)=>{
            var _a;
            const res = (0, _utilsCommon.assertResponse)(await this.blobContext.download({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                requestOptions: {
                    onDownloadProgress: (0, _coreUtil.isNode) ? undefined : options.onProgress
                },
                range: offset === 0 && !count ? undefined : (0, _range.rangeToString)({
                    offset,
                    count
                }),
                rangeGetContentMD5: options.rangeGetContentMD5,
                rangeGetContentCRC64: options.rangeGetContentCrc64,
                snapshot: options.snapshot,
                cpkInfo: options.customerProvidedKey,
                tracingOptions: updatedOptions.tracingOptions
            }));
            const wrappedRes = Object.assign(Object.assign({}, res), {
                _response: res._response,
                objectReplicationDestinationPolicyId: res.objectReplicationPolicyId,
                objectReplicationSourceProperties: (0, _utilsCommon.parseObjectReplicationRecord)(res.objectReplicationRules)
            });
            // Return browser response immediately
            if (!(0, _coreUtil.isNode)) return wrappedRes;
            // We support retrying when download stream unexpected ends in Node.js runtime
            // Following code shouldn't be bundled into browser build, however some
            // bundlers may try to bundle following code and "FileReadResponse.ts".
            // In this case, "FileDownloadResponse.browser.ts" will be used as a shim of "FileDownloadResponse.ts"
            // The config is in package.json "browser" field
            if (options.maxRetryRequests === undefined || options.maxRetryRequests < 0) // TODO: Default value or make it a required parameter?
            options.maxRetryRequests = (0, _constants.DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS);
            if (res.contentLength === undefined) throw new RangeError(`File download response doesn't contain valid content length header`);
            if (!res.etag) throw new RangeError(`File download response doesn't contain valid etag header`);
            return new (0, _blobDownloadResponse.BlobDownloadResponse)(wrappedRes, async (start)=>{
                var _a;
                const updatedDownloadOptions = {
                    leaseAccessConditions: options.conditions,
                    modifiedAccessConditions: {
                        ifMatch: options.conditions.ifMatch || res.etag,
                        ifModifiedSince: options.conditions.ifModifiedSince,
                        ifNoneMatch: options.conditions.ifNoneMatch,
                        ifUnmodifiedSince: options.conditions.ifUnmodifiedSince,
                        ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                    },
                    range: (0, _range.rangeToString)({
                        count: offset + res.contentLength - start,
                        offset: start
                    }),
                    rangeGetContentMD5: options.rangeGetContentMD5,
                    rangeGetContentCRC64: options.rangeGetContentCrc64,
                    snapshot: options.snapshot,
                    cpkInfo: options.customerProvidedKey
                };
                // Debug purpose only
                // console.log(
                //   `Read from internal stream, range: ${
                //     updatedOptions.range
                //   }, options: ${JSON.stringify(updatedOptions)}`
                // );
                return (await this.blobContext.download(Object.assign({
                    abortSignal: options.abortSignal
                }, updatedDownloadOptions))).readableStreamBody;
            }, offset, res.contentLength, {
                maxRetryRequests: options.maxRetryRequests,
                onProgress: options.onProgress
            });
        });
    }
    /**
     * Returns true if the Azure blob resource represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing blob might be deleted by other clients or
     * applications. Vice versa new blobs might be added by other clients or applications after this
     * function completes.
     *
     * @param options - options to Exists operation.
     */ async exists(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-exists", options, async (updatedOptions)=>{
            try {
                (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
                await this.getProperties({
                    abortSignal: options.abortSignal,
                    customerProvidedKey: options.customerProvidedKey,
                    conditions: options.conditions,
                    tracingOptions: updatedOptions.tracingOptions
                });
                return true;
            } catch (e) {
                if (e.statusCode === 404) // Expected exception when checking blob existence
                return false;
                else if (e.statusCode === 409 && (e.details.errorCode === (0, _constants.BlobUsesCustomerSpecifiedEncryptionMsg) || e.details.errorCode === (0, _constants.BlobDoesNotUseCustomerSpecifiedEncryption))) // Expected exception when checking blob existence
                return true;
                throw e;
            }
        });
    }
    /**
     * Returns all user-defined metadata, standard HTTP properties, and system properties
     * for the blob. It does not return the content of the blob.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the methods of {@link ContainerClient} that list blobs using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @param options - Optional options to Get Properties operation.
     */ async getProperties(options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlobClient-getProperties", options, async (updatedOptions)=>{
            var _a;
            const res = (0, _utilsCommon.assertResponse)(await this.blobContext.getProperties({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                tracingOptions: updatedOptions.tracingOptions
            }));
            return Object.assign(Object.assign({}, res), {
                _response: res._response,
                objectReplicationDestinationPolicyId: res.objectReplicationPolicyId,
                objectReplicationSourceProperties: (0, _utilsCommon.parseObjectReplicationRecord)(res.objectReplicationRules)
            });
        });
    }
    /**
     * Marks the specified blob or snapshot for deletion. The blob is later deleted
     * during garbage collection. Note that in order to delete a blob, you must delete
     * all of its snapshots. You can delete both at the same time with the Delete
     * Blob operation.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-blob
     *
     * @param options - Optional options to Blob Delete operation.
     */ async delete(options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("BlobClient-delete", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.delete({
                abortSignal: options.abortSignal,
                deleteSnapshots: options.deleteSnapshots,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Marks the specified blob or snapshot for deletion if it exists. The blob is later deleted
     * during garbage collection. Note that in order to delete a blob, you must delete
     * all of its snapshots. You can delete both at the same time with the Delete
     * Blob operation.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-blob
     *
     * @param options - Optional options to Blob Delete operation.
     */ async deleteIfExists(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-deleteIfExists", options, async (updatedOptions)=>{
            var _a, _b;
            try {
                const res = (0, _utilsCommon.assertResponse)(await this.delete(updatedOptions));
                return Object.assign(Object.assign({
                    succeeded: true
                }, res), {
                    _response: res._response
                });
            } catch (e) {
                if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "BlobNotFound") return Object.assign(Object.assign({
                    succeeded: false
                }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {
                    _response: e.response
                });
                throw e;
            }
        });
    }
    /**
     * Restores the contents and metadata of soft deleted blob and any associated
     * soft deleted snapshots. Undelete Blob is supported only on version 2017-07-29
     * or later.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/undelete-blob
     *
     * @param options - Optional options to Blob Undelete operation.
     */ async undelete(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-undelete", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blobContext.undelete({
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets system properties on the blob.
     *
     * If no value provided, or no value provided for the specified blob HTTP headers,
     * these blob HTTP headers without a value will be cleared.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties
     *
     * @param blobHTTPHeaders - If no value provided, or no value provided for
     *                                                   the specified blob HTTP headers, these blob HTTP
     *                                                   headers without a value will be cleared.
     *                                                   A common header to set is `blobContentType`
     *                                                   enabling the browser to provide functionality
     *                                                   based on file type.
     * @param options - Optional options to Blob Set HTTP Headers operation.
     */ async setHTTPHeaders(blobHTTPHeaders, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlobClient-setHTTPHeaders", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setHttpHeaders({
                abortSignal: options.abortSignal,
                blobHttpHeaders: blobHTTPHeaders,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                // cpkInfo: options.customerProvidedKey, // CPK is not included in Swagger, should change this back when this issue is fixed in Swagger.
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets user-defined metadata for the specified blob as one or more name-value pairs.
     *
     * If no option provided, or no metadata defined in the parameter, the blob
     * metadata will be removed.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata
     *
     * @param metadata - Replace existing metadata with this value.
     *                               If no value provided the existing metadata will be removed.
     * @param options - Optional options to Set Metadata operation.
     */ async setMetadata(metadata, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlobClient-setMetadata", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setMetadata({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets tags on the underlying blob.
     * A blob can have up to 10 tags. Tag keys must be between 1 and 128 characters.  Tag values must be between 0 and 256 characters.
     * Valid tag key and value characters include lower and upper case letters, digits (0-9),
     * space (' '), plus ('+'), minus ('-'), period ('.'), foward slash ('/'), colon (':'), equals ('='), and underscore ('_').
     *
     * @param tags -
     * @param options -
     */ async setTags(tags, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-setTags", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setTags({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions,
                tags: (0, _utilsCommon.toBlobTags)(tags)
            }));
        });
    }
    /**
     * Gets the tags associated with the underlying blob.
     *
     * @param options -
     */ async getTags(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-getTags", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this.blobContext.getTags({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            const wrappedResponse = Object.assign(Object.assign({}, response), {
                _response: response._response,
                tags: (0, _utilsCommon.toTags)({
                    blobTagSet: response.blobTagSet
                }) || {}
            });
            return wrappedResponse;
        });
    }
    /**
     * Get a {@link BlobLeaseClient} that manages leases on the blob.
     *
     * @param proposeLeaseId - Initial proposed lease Id.
     * @returns A new BlobLeaseClient object for managing leases on the blob.
     */ getBlobLeaseClient(proposeLeaseId) {
        return new (0, _blobLeaseClient.BlobLeaseClient)(this, proposeLeaseId);
    }
    /**
     * Creates a read-only snapshot of a blob.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/snapshot-blob
     *
     * @param options - Optional options to the Blob Create Snapshot operation.
     */ async createSnapshot(options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlobClient-createSnapshot", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.createSnapshot({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Asynchronously copies a blob to a destination within the storage account.
     * This method returns a long running operation poller that allows you to wait
     * indefinitely until the copy is completed.
     * You can also cancel a copy before it is completed by calling `cancelOperation` on the poller.
     * Note that the onProgress callback will not be invoked if the operation completes in the first
     * request, and attempting to cancel a completed copy will result in an error being thrown.
     *
     * In version 2012-02-12 and later, the source for a Copy Blob operation can be
     * a committed blob in any Azure storage account.
     * Beginning with version 2015-02-21, the source for a Copy Blob operation can be
     * an Azure file in any Azure storage account.
     * Only storage accounts created on or after June 7th, 2012 allow the Copy Blob
     * operation to copy from another storage account.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob
     *
     * Example using automatic polling:
     *
     * ```js
     * const copyPoller = await blobClient.beginCopyFromURL('url');
     * const result = await copyPoller.pollUntilDone();
     * ```
     *
     * Example using manual polling:
     *
     * ```js
     * const copyPoller = await blobClient.beginCopyFromURL('url');
     * while (!poller.isDone()) {
     *    await poller.poll();
     * }
     * const result = copyPoller.getResult();
     * ```
     *
     * Example using progress updates:
     *
     * ```js
     * const copyPoller = await blobClient.beginCopyFromURL('url', {
     *   onProgress(state) {
     *     console.log(`Progress: ${state.copyProgress}`);
     *   }
     * });
     * const result = await copyPoller.pollUntilDone();
     * ```
     *
     * Example using a changing polling interval (default 15 seconds):
     *
     * ```js
     * const copyPoller = await blobClient.beginCopyFromURL('url', {
     *   intervalInMs: 1000 // poll blob every 1 second for copy progress
     * });
     * const result = await copyPoller.pollUntilDone();
     * ```
     *
     * Example using copy cancellation:
     *
     * ```js
     * const copyPoller = await blobClient.beginCopyFromURL('url');
     * // cancel operation after starting it.
     * try {
     *   await copyPoller.cancelOperation();
     *   // calls to get the result now throw PollerCancelledError
     *   await copyPoller.getResult();
     * } catch (err) {
     *   if (err.name === 'PollerCancelledError') {
     *     console.log('The copy was cancelled.');
     *   }
     * }
     * ```
     *
     * @param copySource - url to the source Azure Blob/File.
     * @param options - Optional options to the Blob Start Copy From URL operation.
     */ async beginCopyFromURL(copySource, options = {}) {
        const client = {
            abortCopyFromURL: (...args)=>this.abortCopyFromURL(...args),
            getProperties: (...args)=>this.getProperties(...args),
            startCopyFromURL: (...args)=>this.startCopyFromURL(...args)
        };
        const poller = new (0, _blobStartCopyFromUrlPoller.BlobBeginCopyFromUrlPoller)({
            blobClient: client,
            copySource,
            intervalInMs: options.intervalInMs,
            onProgress: options.onProgress,
            resumeFrom: options.resumeFrom,
            startCopyFromURLOptions: options
        });
        // Trigger the startCopyFromURL call by calling poll.
        // Any errors from this method should be surfaced to the user.
        await poller.poll();
        return poller;
    }
    /**
     * Aborts a pending asynchronous Copy Blob operation, and leaves a destination blob with zero
     * length and full metadata. Version 2012-02-12 and newer.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/abort-copy-blob
     *
     * @param copyId - Id of the Copy From URL operation.
     * @param options - Optional options to the Blob Abort Copy From URL operation.
     */ async abortCopyFromURL(copyId, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-abortCopyFromURL", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blobContext.abortCopyFromURL(copyId, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * The synchronous Copy From URL operation copies a blob or an internet resource to a new blob. It will not
     * return a response until the copy is complete.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob-from-url
     *
     * @param copySource - The source URL to copy from, Shared Access Signature(SAS) maybe needed for authentication
     * @param options -
     */ async syncCopyFromURL(copySource, options = {}) {
        options.conditions = options.conditions || {};
        options.sourceConditions = options.sourceConditions || {};
        return (0, _tracing.tracingClient).withSpan("BlobClient-syncCopyFromURL", options, async (updatedOptions)=>{
            var _a, _b, _c, _d, _e, _f, _g;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.copyFromURL(copySource, {
                abortSignal: options.abortSignal,
                metadata: options.metadata,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                sourceModifiedAccessConditions: {
                    sourceIfMatch: (_b = options.sourceConditions) === null || _b === void 0 ? void 0 : _b.ifMatch,
                    sourceIfModifiedSince: (_c = options.sourceConditions) === null || _c === void 0 ? void 0 : _c.ifModifiedSince,
                    sourceIfNoneMatch: (_d = options.sourceConditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch,
                    sourceIfUnmodifiedSince: (_e = options.sourceConditions) === null || _e === void 0 ? void 0 : _e.ifUnmodifiedSince
                },
                sourceContentMD5: options.sourceContentMD5,
                copySourceAuthorization: (0, _utilsCommon.httpAuthorizationToString)(options.sourceAuthorization),
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                immutabilityPolicyExpiry: (_f = options.immutabilityPolicy) === null || _f === void 0 ? void 0 : _f.expiriesOn,
                immutabilityPolicyMode: (_g = options.immutabilityPolicy) === null || _g === void 0 ? void 0 : _g.policyMode,
                legalHold: options.legalHold,
                encryptionScope: options.encryptionScope,
                copySourceTags: options.copySourceTags,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets the tier on a blob. The operation is allowed on a page blob in a premium
     * storage account and on a block blob in a blob storage account (locally redundant
     * storage only). A premium page blob's tier determines the allowed size, IOPS,
     * and bandwidth of the blob. A block blob's tier determines Hot/Cool/Archive
     * storage type. This operation does not update the blob's ETag.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-tier
     *
     * @param tier - The tier to be set on the blob. Valid values are Hot, Cool, or Archive.
     * @param options - Optional options to the Blob Set Tier operation.
     */ async setAccessTier(tier, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-setAccessTier", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setTier((0, _models.toAccessTier)(tier), {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                rehydratePriority: options.rehydratePriority,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    async downloadToBuffer(param1, param2, param3, param4 = {}) {
        var _a;
        let buffer;
        let offset = 0;
        let count = 0;
        let options = param4;
        if (param1 instanceof Buffer) {
            buffer = param1;
            offset = param2 || 0;
            count = typeof param3 === "number" ? param3 : 0;
        } else {
            offset = typeof param1 === "number" ? param1 : 0;
            count = typeof param2 === "number" ? param2 : 0;
            options = param3 || {};
        }
        let blockSize = (_a = options.blockSize) !== null && _a !== void 0 ? _a : 0;
        if (blockSize < 0) throw new RangeError("blockSize option must be >= 0");
        if (blockSize === 0) blockSize = (0, _constants.DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES);
        if (offset < 0) throw new RangeError("offset option must be >= 0");
        if (count && count <= 0) throw new RangeError("count option must be greater than 0");
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("BlobClient-downloadToBuffer", options, async (updatedOptions)=>{
            // Customer doesn't specify length, get it
            if (!count) {
                const response = await this.getProperties(Object.assign(Object.assign({}, options), {
                    tracingOptions: updatedOptions.tracingOptions
                }));
                count = response.contentLength - offset;
                if (count < 0) throw new RangeError(`offset ${offset} shouldn't be larger than blob size ${response.contentLength}`);
            }
            // Allocate the buffer of size = count if the buffer is not provided
            if (!buffer) try {
                buffer = Buffer.alloc(count);
            } catch (error) {
                throw new Error(`Unable to allocate the buffer of size: ${count}(in bytes). Please try passing your own buffer to the "downloadToBuffer" method or try using other methods like "download" or "downloadToFile".\t ${error.message}`);
            }
            if (buffer.length < count) throw new RangeError(`The buffer's size should be equal to or larger than the request count of bytes: ${count}`);
            let transferProgress = 0;
            const batch = new (0, _batch.Batch)(options.concurrency);
            for(let off = offset; off < offset + count; off = off + blockSize)batch.addOperation(async ()=>{
                // Exclusive chunk end position
                let chunkEnd = offset + count;
                if (off + blockSize < chunkEnd) chunkEnd = off + blockSize;
                const response = await this.download(off, chunkEnd - off, {
                    abortSignal: options.abortSignal,
                    conditions: options.conditions,
                    maxRetryRequests: options.maxRetryRequestsPerBlock,
                    customerProvidedKey: options.customerProvidedKey,
                    tracingOptions: updatedOptions.tracingOptions
                });
                const stream = response.readableStreamBody;
                await (0, _utilsNode.streamToBuffer)(stream, buffer, off - offset, chunkEnd - offset);
                // Update progress after block is downloaded, in case of block trying
                // Could provide finer grained progress updating inside HTTP requests,
                // only if convenience layer download try is enabled
                transferProgress += chunkEnd - off;
                if (options.onProgress) options.onProgress({
                    loadedBytes: transferProgress
                });
            });
            await batch.do();
            return buffer;
        });
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Downloads an Azure Blob to a local file.
     * Fails if the the given file path already exits.
     * Offset and count are optional, pass 0 and undefined respectively to download the entire blob.
     *
     * @param filePath -
     * @param offset - From which position of the block blob to download.
     * @param count - How much data to be downloaded. Will download to the end when passing undefined.
     * @param options - Options to Blob download options.
     * @returns The response data for blob download operation,
     *                                                 but with readableStreamBody set to undefined since its
     *                                                 content is already read and written into a local file
     *                                                 at the specified path.
     */ async downloadToFile(filePath, offset = 0, count, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-downloadToFile", options, async (updatedOptions)=>{
            const response = await this.download(offset, count, Object.assign(Object.assign({}, options), {
                tracingOptions: updatedOptions.tracingOptions
            }));
            if (response.readableStreamBody) await (0, _utilsNode.readStreamToLocalFile)(response.readableStreamBody, filePath);
            // The stream is no longer accessible so setting it to undefined.
            response.blobDownloadStream = undefined;
            return response;
        });
    }
    getBlobAndContainerNamesFromUrl() {
        let containerName;
        let blobName;
        try {
            //  URL may look like the following
            // "https://myaccount.blob.core.windows.net/mycontainer/blob?sasString";
            // "https://myaccount.blob.core.windows.net/mycontainer/blob";
            // "https://myaccount.blob.core.windows.net/mycontainer/blob/a.txt?sasString";
            // "https://myaccount.blob.core.windows.net/mycontainer/blob/a.txt";
            // IPv4/IPv6 address hosts, Endpoints - `http://127.0.0.1:10000/devstoreaccount1/containername/blob`
            // http://localhost:10001/devstoreaccount1/containername/blob
            const parsedUrl = new URL(this.url);
            if (parsedUrl.host.split(".")[1] === "blob") {
                // "https://myaccount.blob.core.windows.net/containername/blob".
                // .getPath() -> /containername/blob
                const pathComponents = parsedUrl.pathname.match("/([^/]*)(/(.*))?");
                containerName = pathComponents[1];
                blobName = pathComponents[3];
            } else if ((0, _utilsCommon.isIpEndpointStyle)(parsedUrl)) {
                // IPv4/IPv6 address hosts... Example - http://192.0.0.10:10001/devstoreaccount1/containername/blob
                // Single word domain without a [dot] in the endpoint... Example - http://localhost:10001/devstoreaccount1/containername/blob
                // .getPath() -> /devstoreaccount1/containername/blob
                const pathComponents = parsedUrl.pathname.match("/([^/]*)/([^/]*)(/(.*))?");
                containerName = pathComponents[2];
                blobName = pathComponents[4];
            } else {
                // "https://customdomain.com/containername/blob".
                // .getPath() -> /containername/blob
                const pathComponents = parsedUrl.pathname.match("/([^/]*)(/(.*))?");
                containerName = pathComponents[1];
                blobName = pathComponents[3];
            }
            // decode the encoded blobName, containerName - to get all the special characters that might be present in them
            containerName = decodeURIComponent(containerName);
            blobName = decodeURIComponent(blobName);
            // Azure Storage Server will replace "\" with "/" in the blob names
            //   doing the same in the SDK side so that the user doesn't have to replace "\" instances in the blobName
            blobName = blobName.replace(/\\/g, "/");
            if (!containerName) throw new Error("Provided containerName is invalid.");
            return {
                blobName,
                containerName
            };
        } catch (error) {
            throw new Error("Unable to extract blobName and containerName with provided information.");
        }
    }
    /**
     * Asynchronously copies a blob to a destination within the storage account.
     * In version 2012-02-12 and later, the source for a Copy Blob operation can be
     * a committed blob in any Azure storage account.
     * Beginning with version 2015-02-21, the source for a Copy Blob operation can be
     * an Azure file in any Azure storage account.
     * Only storage accounts created on or after June 7th, 2012 allow the Copy Blob
     * operation to copy from another storage account.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob
     *
     * @param copySource - url to the source Azure Blob/File.
     * @param options - Optional options to the Blob Start Copy From URL operation.
     */ async startCopyFromURL(copySource, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-startCopyFromURL", options, async (updatedOptions)=>{
            var _a, _b, _c;
            options.conditions = options.conditions || {};
            options.sourceConditions = options.sourceConditions || {};
            return (0, _utilsCommon.assertResponse)(await this.blobContext.startCopyFromURL(copySource, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                sourceModifiedAccessConditions: {
                    sourceIfMatch: options.sourceConditions.ifMatch,
                    sourceIfModifiedSince: options.sourceConditions.ifModifiedSince,
                    sourceIfNoneMatch: options.sourceConditions.ifNoneMatch,
                    sourceIfUnmodifiedSince: options.sourceConditions.ifUnmodifiedSince,
                    sourceIfTags: options.sourceConditions.tagConditions
                },
                immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,
                immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,
                legalHold: options.legalHold,
                rehydratePriority: options.rehydratePriority,
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                sealBlob: options.sealBlob,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Only available for BlobClient constructed with a shared key credential.
     *
     * Generates a Blob Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */ generateSasUrl(options) {
        return new Promise((resolve)=>{
            if (!(this.credential instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential))) throw new RangeError("Can only generate the SAS when the client is initialized with a shared key credential");
            const sas = (0, _blobSASSignatureValues.generateBlobSASQueryParameters)(Object.assign({
                containerName: this._containerName,
                blobName: this._name,
                snapshotTime: this._snapshot,
                versionId: this._versionId
            }, options), this.credential).toString();
            resolve((0, _utilsCommon.appendToURLQuery)(this.url, sas));
        });
    }
    /**
     * Delete the immutablility policy on the blob.
     *
     * @param options - Optional options to delete immutability policy on the blob.
     */ async deleteImmutabilityPolicy(options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-deleteImmutabilityPolicy", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blobContext.deleteImmutabilityPolicy({
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Set immutability policy on the blob.
     *
     * @param options - Optional options to set immutability policy on the blob.
     */ async setImmutabilityPolicy(immutabilityPolicy, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-setImmutabilityPolicy", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setImmutabilityPolicy({
                immutabilityPolicyExpiry: immutabilityPolicy.expiriesOn,
                immutabilityPolicyMode: immutabilityPolicy.policyMode,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Set legal hold on the blob.
     *
     * @param options - Optional options to set legal hold on the blob.
     */ async setLegalHold(legalHoldEnabled, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlobClient-setLegalHold", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blobContext.setLegalHold(legalHoldEnabled, {
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
}
class AppendBlobClient extends BlobClient {
    constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.
        //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);
        let pipeline;
        let url;
        options = options || {};
        if ((0, _pipeline.isPipelineLike)(credentialOrPipelineOrContainerName)) {
            // (url: string, pipeline: Pipeline)
            url = urlOrConnectionString;
            pipeline = credentialOrPipelineOrContainerName;
        } else if ((0, _coreUtil.isNode) && credentialOrPipelineOrContainerName instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipelineOrContainerName instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipelineOrContainerName)) {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)      url = urlOrConnectionString;
            url = urlOrConnectionString;
            options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(credentialOrPipelineOrContainerName, options);
        } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== "string") {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            url = urlOrConnectionString;
            // The second parameter is undefined. Use anonymous credential.
            pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === "string" && blobNameOrOptions && typeof blobNameOrOptions === "string") {
            // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)
            const containerName = credentialOrPipelineOrContainerName;
            const blobName = blobNameOrOptions;
            const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(urlOrConnectionString);
            if (extractedCreds.kind === "AccountConnString") {
                if (0, _coreUtil.isNode) {
                    const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                    url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));
                    if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                    pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                } else throw new Error("Account connection string is only supported in Node.js environment");
            } else if (extractedCreds.kind === "SASConnString") {
                url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + "?" + extractedCreds.accountSas;
                pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        } else throw new Error("Expecting non-empty strings for containerName and blobName parameters");
        super(url, pipeline);
        this.appendBlobContext = this.storageClientContext.appendBlob;
    }
    /**
     * Creates a new AppendBlobClient object identical to the source but with the
     * specified snapshot timestamp.
     * Provide "" will remove the snapshot and return a Client to the base blob.
     *
     * @param snapshot - The snapshot timestamp.
     * @returns A new AppendBlobClient object identical to the source but with the specified snapshot timestamp.
     */ withSnapshot(snapshot) {
        return new AppendBlobClient((0, _utilsCommon.setURLParameter)(this.url, (0, _constants.URLConstants).Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);
    }
    /**
     * Creates a 0-length append blob. Call AppendBlock to append data to an append blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param options - Options to the Append Block Create operation.
     *
     *
     * Example usage:
     *
     * ```js
     * const appendBlobClient = containerClient.getAppendBlobClient("<blob name>");
     * await appendBlobClient.create();
     * ```
     */ async create(options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("AppendBlobClient-create", options, async (updatedOptions)=>{
            var _a, _b, _c;
            return (0, _utilsCommon.assertResponse)(await this.appendBlobContext.create(0, {
                abortSignal: options.abortSignal,
                blobHttpHeaders: options.blobHTTPHeaders,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,
                immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,
                legalHold: options.legalHold,
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Creates a 0-length append blob. Call AppendBlock to append data to an append blob.
     * If the blob with the same name already exists, the content of the existing blob will remain unchanged.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param options -
     */ async createIfNotExists(options = {}) {
        const conditions = {
            ifNoneMatch: (0, _constants.ETagAny)
        };
        return (0, _tracing.tracingClient).withSpan("AppendBlobClient-createIfNotExists", options, async (updatedOptions)=>{
            var _a, _b;
            try {
                const res = (0, _utilsCommon.assertResponse)(await this.create(Object.assign(Object.assign({}, updatedOptions), {
                    conditions
                })));
                return Object.assign(Object.assign({
                    succeeded: true
                }, res), {
                    _response: res._response
                });
            } catch (e) {
                if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "BlobAlreadyExists") return Object.assign(Object.assign({
                    succeeded: false
                }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {
                    _response: e.response
                });
                throw e;
            }
        });
    }
    /**
     * Seals the append blob, making it read only.
     *
     * @param options -
     */ async seal(options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("AppendBlobClient-seal", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.appendBlobContext.seal({
                abortSignal: options.abortSignal,
                appendPositionAccessConditions: options.conditions,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Commits a new block of data to the end of the existing append blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/append-block
     *
     * @param body - Data to be appended.
     * @param contentLength - Length of the body in bytes.
     * @param options - Options to the Append Block operation.
     *
     *
     * Example usage:
     *
     * ```js
     * const content = "Hello World!";
     *
     * // Create a new append blob and append data to the blob.
     * const newAppendBlobClient = containerClient.getAppendBlobClient("<blob name>");
     * await newAppendBlobClient.create();
     * await newAppendBlobClient.appendBlock(content, content.length);
     *
     * // Append data to an existing append blob.
     * const existingAppendBlobClient = containerClient.getAppendBlobClient("<blob name>");
     * await existingAppendBlobClient.appendBlock(content, content.length);
     * ```
     */ async appendBlock(body, contentLength, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("AppendBlobClient-appendBlock", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.appendBlobContext.appendBlock(contentLength, body, {
                abortSignal: options.abortSignal,
                appendPositionAccessConditions: options.conditions,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                requestOptions: {
                    onUploadProgress: options.onProgress
                },
                transactionalContentMD5: options.transactionalContentMD5,
                transactionalContentCrc64: options.transactionalContentCrc64,
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * The Append Block operation commits a new block of data to the end of an existing append blob
     * where the contents are read from a source url.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/append-block-from-url
     *
     * @param sourceURL -
     *                 The url to the blob that will be the source of the copy. A source blob in the same storage account can
     *                 be authenticated via Shared Key. However, if the source is a blob in another account, the source blob
     *                 must either be public or must be authenticated via a shared access signature. If the source blob is
     *                 public, no authentication is required to perform the operation.
     * @param sourceOffset - Offset in source to be appended
     * @param count - Number of bytes to be appended as a block
     * @param options -
     */ async appendBlockFromURL(sourceURL, sourceOffset, count, options = {}) {
        options.conditions = options.conditions || {};
        options.sourceConditions = options.sourceConditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("AppendBlobClient-appendBlockFromURL", options, async (updatedOptions)=>{
            var _a, _b, _c, _d, _e;
            return (0, _utilsCommon.assertResponse)(await this.appendBlobContext.appendBlockFromUrl(sourceURL, 0, {
                abortSignal: options.abortSignal,
                sourceRange: (0, _range.rangeToString)({
                    offset: sourceOffset,
                    count
                }),
                sourceContentMD5: options.sourceContentMD5,
                sourceContentCrc64: options.sourceContentCrc64,
                leaseAccessConditions: options.conditions,
                appendPositionAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                sourceModifiedAccessConditions: {
                    sourceIfMatch: (_b = options.sourceConditions) === null || _b === void 0 ? void 0 : _b.ifMatch,
                    sourceIfModifiedSince: (_c = options.sourceConditions) === null || _c === void 0 ? void 0 : _c.ifModifiedSince,
                    sourceIfNoneMatch: (_d = options.sourceConditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch,
                    sourceIfUnmodifiedSince: (_e = options.sourceConditions) === null || _e === void 0 ? void 0 : _e.ifUnmodifiedSince
                },
                copySourceAuthorization: (0, _utilsCommon.httpAuthorizationToString)(options.sourceAuthorization),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
}
class BlockBlobClient extends BlobClient {
    constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.
        //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);
        let pipeline;
        let url;
        options = options || {};
        if ((0, _pipeline.isPipelineLike)(credentialOrPipelineOrContainerName)) {
            // (url: string, pipeline: Pipeline)
            url = urlOrConnectionString;
            pipeline = credentialOrPipelineOrContainerName;
        } else if ((0, _coreUtil.isNode) && credentialOrPipelineOrContainerName instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipelineOrContainerName instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipelineOrContainerName)) {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            url = urlOrConnectionString;
            options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(credentialOrPipelineOrContainerName, options);
        } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== "string") {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            // The second parameter is undefined. Use anonymous credential.
            url = urlOrConnectionString;
            if (blobNameOrOptions && typeof blobNameOrOptions !== "string") options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === "string" && blobNameOrOptions && typeof blobNameOrOptions === "string") {
            // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)
            const containerName = credentialOrPipelineOrContainerName;
            const blobName = blobNameOrOptions;
            const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(urlOrConnectionString);
            if (extractedCreds.kind === "AccountConnString") {
                if (0, _coreUtil.isNode) {
                    const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                    url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));
                    if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                    pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                } else throw new Error("Account connection string is only supported in Node.js environment");
            } else if (extractedCreds.kind === "SASConnString") {
                url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + "?" + extractedCreds.accountSas;
                pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        } else throw new Error("Expecting non-empty strings for containerName and blobName parameters");
        super(url, pipeline);
        this.blockBlobContext = this.storageClientContext.blockBlob;
        this._blobContext = this.storageClientContext.blob;
    }
    /**
     * Creates a new BlockBlobClient object identical to the source but with the
     * specified snapshot timestamp.
     * Provide "" will remove the snapshot and return a URL to the base blob.
     *
     * @param snapshot - The snapshot timestamp.
     * @returns A new BlockBlobClient object identical to the source but with the specified snapshot timestamp.
     */ withSnapshot(snapshot) {
        return new BlockBlobClient((0, _utilsCommon.setURLParameter)(this.url, (0, _constants.URLConstants).Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Quick query for a JSON or CSV formatted blob.
     *
     * Example usage (Node.js):
     *
     * ```js
     * // Query and convert a blob to a string
     * const queryBlockBlobResponse = await blockBlobClient.query("select * from BlobStorage");
     * const downloaded = (await streamToBuffer(queryBlockBlobResponse.readableStreamBody)).toString();
     * console.log("Query blob content:", downloaded);
     *
     * async function streamToBuffer(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     *     });
     *     readableStream.on("end", () => {
     *       resolve(Buffer.concat(chunks));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * @param query -
     * @param options -
     */ async query(query, options = {}) {
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        if (!(0, _coreUtil.isNode)) throw new Error("This operation currently is only supported in Node.js.");
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-query", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this._blobContext.query({
                abortSignal: options.abortSignal,
                queryRequest: {
                    queryType: "SQL",
                    expression: query,
                    inputSerialization: (0, _utilsCommon.toQuerySerialization)(options.inputTextConfiguration),
                    outputSerialization: (0, _utilsCommon.toQuerySerialization)(options.outputTextConfiguration)
                },
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                tracingOptions: updatedOptions.tracingOptions
            }));
            return new (0, _blobQueryResponse.BlobQueryResponse)(response, {
                abortSignal: options.abortSignal,
                onProgress: options.onProgress,
                onError: options.onError
            });
        });
    }
    /**
     * Creates a new block blob, or updates the content of an existing block blob.
     * Updating an existing block blob overwrites any existing metadata on the blob.
     * Partial updates are not supported; the content of the existing blob is
     * overwritten with the new content. To perform a partial update of a block blob's,
     * use {@link stageBlock} and {@link commitBlockList}.
     *
     * This is a non-parallel uploading method, please use {@link uploadFile},
     * {@link uploadStream} or {@link uploadBrowserData} for better performance
     * with concurrency uploading.
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param body - Blob, string, ArrayBuffer, ArrayBufferView or a function
     *                               which returns a new Readable stream whose offset is from data source beginning.
     * @param contentLength - Length of body in bytes. Use Buffer.byteLength() to calculate body length for a
     *                               string including non non-Base64/Hex-encoded characters.
     * @param options - Options to the Block Blob Upload operation.
     * @returns Response data for the Block Blob Upload operation.
     *
     * Example usage:
     *
     * ```js
     * const content = "Hello world!";
     * const uploadBlobResponse = await blockBlobClient.upload(content, content.length);
     * ```
     */ async upload(body, contentLength, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-upload", options, async (updatedOptions)=>{
            var _a, _b, _c;
            return (0, _utilsCommon.assertResponse)(await this.blockBlobContext.upload(contentLength, body, {
                abortSignal: options.abortSignal,
                blobHttpHeaders: options.blobHTTPHeaders,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                requestOptions: {
                    onUploadProgress: options.onProgress
                },
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,
                immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,
                legalHold: options.legalHold,
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Creates a new Block Blob where the contents of the blob are read from a given URL.
     * This API is supported beginning with the 2020-04-08 version. Partial updates
     * are not supported with Put Blob from URL; the content of an existing blob is overwritten with
     * the content of the new blob.  To perform partial updates to a block blobs contents using a
     * source URL, use {@link stageBlockFromURL} and {@link commitBlockList}.
     *
     * @param sourceURL - Specifies the URL of the blob. The value
     *                           may be a URL of up to 2 KB in length that specifies a blob.
     *                           The value should be URL-encoded as it would appear
     *                           in a request URI. The source blob must either be public
     *                           or must be authenticated via a shared access signature.
     *                           If the source blob is public, no authentication is required
     *                           to perform the operation. Here are some examples of source object URLs:
     *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob
     *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>
     * @param options - Optional parameters.
     */ async syncUploadFromURL(sourceURL, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-syncUploadFromURL", options, async (updatedOptions)=>{
            var _a, _b, _c, _d, _e, _f;
            return (0, _utilsCommon.assertResponse)(await this.blockBlobContext.putBlobFromUrl(0, sourceURL, Object.assign(Object.assign({}, options), {
                blobHttpHeaders: options.blobHTTPHeaders,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                sourceModifiedAccessConditions: {
                    sourceIfMatch: (_b = options.sourceConditions) === null || _b === void 0 ? void 0 : _b.ifMatch,
                    sourceIfModifiedSince: (_c = options.sourceConditions) === null || _c === void 0 ? void 0 : _c.ifModifiedSince,
                    sourceIfNoneMatch: (_d = options.sourceConditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch,
                    sourceIfUnmodifiedSince: (_e = options.sourceConditions) === null || _e === void 0 ? void 0 : _e.ifUnmodifiedSince,
                    sourceIfTags: (_f = options.sourceConditions) === null || _f === void 0 ? void 0 : _f.tagConditions
                },
                cpkInfo: options.customerProvidedKey,
                copySourceAuthorization: (0, _utilsCommon.httpAuthorizationToString)(options.sourceAuthorization),
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                copySourceTags: options.copySourceTags,
                tracingOptions: updatedOptions.tracingOptions
            })));
        });
    }
    /**
     * Uploads the specified block to the block blob's "staging area" to be later
     * committed by a call to commitBlockList.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-block
     *
     * @param blockId - A 64-byte value that is base64-encoded
     * @param body - Data to upload to the staging area.
     * @param contentLength - Number of bytes to upload.
     * @param options - Options to the Block Blob Stage Block operation.
     * @returns Response data for the Block Blob Stage Block operation.
     */ async stageBlock(blockId, body, contentLength, options = {}) {
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-stageBlock", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blockBlobContext.stageBlock(blockId, contentLength, body, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                requestOptions: {
                    onUploadProgress: options.onProgress
                },
                transactionalContentMD5: options.transactionalContentMD5,
                transactionalContentCrc64: options.transactionalContentCrc64,
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * The Stage Block From URL operation creates a new block to be committed as part
     * of a blob where the contents are read from a URL.
     * This API is available starting in version 2018-03-28.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/put-block-from-url
     *
     * @param blockId - A 64-byte value that is base64-encoded
     * @param sourceURL - Specifies the URL of the blob. The value
     *                           may be a URL of up to 2 KB in length that specifies a blob.
     *                           The value should be URL-encoded as it would appear
     *                           in a request URI. The source blob must either be public
     *                           or must be authenticated via a shared access signature.
     *                           If the source blob is public, no authentication is required
     *                           to perform the operation. Here are some examples of source object URLs:
     *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob
     *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>
     * @param offset - From which position of the blob to download, greater than or equal to 0
     * @param count - How much data to be downloaded, greater than 0. Will download to the end when undefined
     * @param options - Options to the Block Blob Stage Block From URL operation.
     * @returns Response data for the Block Blob Stage Block From URL operation.
     */ async stageBlockFromURL(blockId, sourceURL, offset = 0, count, options = {}) {
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-stageBlockFromURL", options, async (updatedOptions)=>{
            return (0, _utilsCommon.assertResponse)(await this.blockBlobContext.stageBlockFromURL(blockId, 0, sourceURL, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                sourceContentMD5: options.sourceContentMD5,
                sourceContentCrc64: options.sourceContentCrc64,
                sourceRange: offset === 0 && !count ? undefined : (0, _range.rangeToString)({
                    offset,
                    count
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                copySourceAuthorization: (0, _utilsCommon.httpAuthorizationToString)(options.sourceAuthorization),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Writes a blob by specifying the list of block IDs that make up the blob.
     * In order to be written as part of a blob, a block must have been successfully written
     * to the server in a prior {@link stageBlock} operation. You can call {@link commitBlockList} to
     * update a blob by uploading only those blocks that have changed, then committing the new and existing
     * blocks together. Any blocks not specified in the block list and permanently deleted.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-block-list
     *
     * @param blocks -  Array of 64-byte value that is base64-encoded
     * @param options - Options to the Block Blob Commit Block List operation.
     * @returns Response data for the Block Blob Commit Block List operation.
     */ async commitBlockList(blocks, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-commitBlockList", options, async (updatedOptions)=>{
            var _a, _b, _c;
            return (0, _utilsCommon.assertResponse)(await this.blockBlobContext.commitBlockList({
                latest: blocks
            }, {
                abortSignal: options.abortSignal,
                blobHttpHeaders: options.blobHTTPHeaders,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,
                immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,
                legalHold: options.legalHold,
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Returns the list of blocks that have been uploaded as part of a block blob
     * using the specified block list filter.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-block-list
     *
     * @param listType - Specifies whether to return the list of committed blocks,
     *                                        the list of uncommitted blocks, or both lists together.
     * @param options - Options to the Block Blob Get Block List operation.
     * @returns Response data for the Block Blob Get Block List operation.
     */ async getBlockList(listType, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-getBlockList", options, async (updatedOptions)=>{
            var _a;
            const res = (0, _utilsCommon.assertResponse)(await this.blockBlobContext.getBlockList(listType, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            if (!res.committedBlocks) res.committedBlocks = [];
            if (!res.uncommittedBlocks) res.uncommittedBlocks = [];
            return res;
        });
    }
    // High level functions
    /**
     * Uploads a Buffer(Node.js)/Blob(browsers)/ArrayBuffer/ArrayBufferView object to a BlockBlob.
     *
     * When data length is no more than the specifiled {@link BlockBlobParallelUploadOptions.maxSingleShotSize} (default is
     * {@link BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES}), this method will use 1 {@link upload} call to finish the upload.
     * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call {@link commitBlockList}
     * to commit the block list.
     *
     * A common {@link BlockBlobParallelUploadOptions.blobHTTPHeaders} option to set is
     * `blobContentType`, enabling the browser to provide
     * functionality based on file type.
     *
     * @param data - Buffer(Node.js), Blob, ArrayBuffer or ArrayBufferView
     * @param options -
     */ async uploadData(data, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-uploadData", options, async (updatedOptions)=>{
            if (0, _coreUtil.isNode) {
                let buffer;
                if (data instanceof Buffer) buffer = data;
                else if (data instanceof ArrayBuffer) buffer = Buffer.from(data);
                else {
                    data;
                    buffer = Buffer.from(data.buffer, data.byteOffset, data.byteLength);
                }
                return this.uploadSeekableInternal((offset, size)=>buffer.slice(offset, offset + size), buffer.byteLength, updatedOptions);
            } else {
                const browserBlob = new Blob([
                    data
                ]);
                return this.uploadSeekableInternal((offset, size)=>browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);
            }
        });
    }
    /**
     * ONLY AVAILABLE IN BROWSERS.
     *
     * Uploads a browser Blob/File/ArrayBuffer/ArrayBufferView object to block blob.
     *
     * When buffer length lesser than or equal to 256MB, this method will use 1 upload call to finish the upload.
     * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call
     * {@link commitBlockList} to commit the block list.
     *
     * A common {@link BlockBlobParallelUploadOptions.blobHTTPHeaders} option to set is
     * `blobContentType`, enabling the browser to provide
     * functionality based on file type.
     *
     * @deprecated Use {@link uploadData} instead.
     *
     * @param browserData - Blob, File, ArrayBuffer or ArrayBufferView
     * @param options - Options to upload browser data.
     * @returns Response data for the Blob Upload operation.
     */ async uploadBrowserData(browserData, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-uploadBrowserData", options, async (updatedOptions)=>{
            const browserBlob = new Blob([
                browserData
            ]);
            return this.uploadSeekableInternal((offset, size)=>browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);
        });
    }
    /**
     *
     * Uploads data to block blob. Requires a bodyFactory as the data source,
     * which need to return a {@link HttpRequestBody} object with the offset and size provided.
     *
     * When data length is no more than the specified {@link BlockBlobParallelUploadOptions.maxSingleShotSize} (default is
     * {@link BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES}), this method will use 1 {@link upload} call to finish the upload.
     * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call {@link commitBlockList}
     * to commit the block list.
     *
     * @param bodyFactory -
     * @param size - size of the data to upload.
     * @param options - Options to Upload to Block Blob operation.
     * @returns Response data for the Blob Upload operation.
     */ async uploadSeekableInternal(bodyFactory, size, options = {}) {
        var _a, _b;
        let blockSize = (_a = options.blockSize) !== null && _a !== void 0 ? _a : 0;
        if (blockSize < 0 || blockSize > (0, _constants.BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES)) throw new RangeError(`blockSize option must be >= 0 and <= ${(0, _constants.BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES)}`);
        const maxSingleShotSize = (_b = options.maxSingleShotSize) !== null && _b !== void 0 ? _b : (0, _constants.BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES);
        if (maxSingleShotSize < 0 || maxSingleShotSize > (0, _constants.BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES)) throw new RangeError(`maxSingleShotSize option must be >= 0 and <= ${(0, _constants.BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES)}`);
        if (blockSize === 0) {
            if (size > (0, _constants.BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES) * (0, _constants.BLOCK_BLOB_MAX_BLOCKS)) throw new RangeError(`${size} is too larger to upload to a block blob.`);
            if (size > maxSingleShotSize) {
                blockSize = Math.ceil(size / (0, _constants.BLOCK_BLOB_MAX_BLOCKS));
                if (blockSize < (0, _constants.DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES)) blockSize = (0, _constants.DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES);
            }
        }
        if (!options.blobHTTPHeaders) options.blobHTTPHeaders = {};
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-uploadSeekableInternal", options, async (updatedOptions)=>{
            if (size <= maxSingleShotSize) return (0, _utilsCommon.assertResponse)(await this.upload(bodyFactory(0, size), size, updatedOptions));
            const numBlocks = Math.floor((size - 1) / blockSize) + 1;
            if (numBlocks > (0, _constants.BLOCK_BLOB_MAX_BLOCKS)) throw new RangeError(`The buffer's size is too big or the BlockSize is too small;` + `the number of blocks must be <= ${0, _constants.BLOCK_BLOB_MAX_BLOCKS}`);
            const blockList = [];
            const blockIDPrefix = (0, _coreUtil.randomUUID)();
            let transferProgress = 0;
            const batch = new (0, _batch.Batch)(options.concurrency);
            for(let i = 0; i < numBlocks; i++)batch.addOperation(async ()=>{
                const blockID = (0, _utilsCommon.generateBlockID)(blockIDPrefix, i);
                const start = blockSize * i;
                const end = i === numBlocks - 1 ? size : start + blockSize;
                const contentLength = end - start;
                blockList.push(blockID);
                await this.stageBlock(blockID, bodyFactory(start, contentLength), contentLength, {
                    abortSignal: options.abortSignal,
                    conditions: options.conditions,
                    encryptionScope: options.encryptionScope,
                    tracingOptions: updatedOptions.tracingOptions
                });
                // Update progress after block is successfully uploaded to server, in case of block trying
                // TODO: Hook with convenience layer progress event in finer level
                transferProgress += contentLength;
                if (options.onProgress) options.onProgress({
                    loadedBytes: transferProgress
                });
            });
            await batch.do();
            return this.commitBlockList(blockList, updatedOptions);
        });
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a local file in blocks to a block blob.
     *
     * When file size lesser than or equal to 256MB, this method will use 1 upload call to finish the upload.
     * Otherwise, this method will call stageBlock to upload blocks, and finally call commitBlockList
     * to commit the block list.
     *
     * @param filePath - Full path of local file
     * @param options - Options to Upload to Block Blob operation.
     * @returns Response data for the Blob Upload operation.
     */ async uploadFile(filePath, options = {}) {
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-uploadFile", options, async (updatedOptions)=>{
            const size = (await (0, _utilsNode.fsStat)(filePath)).size;
            return this.uploadSeekableInternal((offset, count)=>{
                return ()=>(0, _utilsNode.fsCreateReadStream)(filePath, {
                        autoClose: true,
                        end: count ? offset + count - 1 : Infinity,
                        start: offset
                    });
            }, size, Object.assign(Object.assign({}, options), {
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a Node.js Readable stream into block blob.
     *
     * PERFORMANCE IMPROVEMENT TIPS:
     * * Input stream highWaterMark is better to set a same value with bufferSize
     *    parameter, which will avoid Buffer.concat() operations.
     *
     * @param stream - Node.js Readable stream
     * @param bufferSize - Size of every buffer allocated, also the block size in the uploaded block blob. Default value is 8MB
     * @param maxConcurrency -  Max concurrency indicates the max number of buffers that can be allocated,
     *                                 positive correlation with max uploading concurrency. Default value is 5
     * @param options - Options to Upload Stream to Block Blob operation.
     * @returns Response data for the Blob Upload operation.
     */ async uploadStream(stream, bufferSize = (0, _constants.DEFAULT_BLOCK_BUFFER_SIZE_BYTES), maxConcurrency = 5, options = {}) {
        if (!options.blobHTTPHeaders) options.blobHTTPHeaders = {};
        if (!options.conditions) options.conditions = {};
        return (0, _tracing.tracingClient).withSpan("BlockBlobClient-uploadStream", options, async (updatedOptions)=>{
            let blockNum = 0;
            const blockIDPrefix = (0, _coreUtil.randomUUID)();
            let transferProgress = 0;
            const blockList = [];
            const scheduler = new (0, _src.BufferScheduler)(stream, bufferSize, maxConcurrency, async (body, length)=>{
                const blockID = (0, _utilsCommon.generateBlockID)(blockIDPrefix, blockNum);
                blockList.push(blockID);
                blockNum++;
                await this.stageBlock(blockID, body, length, {
                    conditions: options.conditions,
                    encryptionScope: options.encryptionScope,
                    tracingOptions: updatedOptions.tracingOptions
                });
                // Update progress after block is successfully uploaded to server, in case of block trying
                transferProgress += length;
                if (options.onProgress) options.onProgress({
                    loadedBytes: transferProgress
                });
            }, // concurrency should set a smaller value than maxConcurrency, which is helpful to
            // reduce the possibility when a outgoing handler waits for stream data, in
            // this situation, outgoing handlers are blocked.
            // Outgoing queue shouldn't be empty.
            Math.ceil(maxConcurrency / 4 * 3));
            await scheduler.do();
            return (0, _utilsCommon.assertResponse)(await this.commitBlockList(blockList, Object.assign(Object.assign({}, options), {
                tracingOptions: updatedOptions.tracingOptions
            })));
        });
    }
}
class PageBlobClient extends BlobClient {
    constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.
        //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);
        let pipeline;
        let url;
        options = options || {};
        if ((0, _pipeline.isPipelineLike)(credentialOrPipelineOrContainerName)) {
            // (url: string, pipeline: Pipeline)
            url = urlOrConnectionString;
            pipeline = credentialOrPipelineOrContainerName;
        } else if ((0, _coreUtil.isNode) && credentialOrPipelineOrContainerName instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrPipelineOrContainerName instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrPipelineOrContainerName)) {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            url = urlOrConnectionString;
            options = blobNameOrOptions;
            pipeline = (0, _pipeline.newPipeline)(credentialOrPipelineOrContainerName, options);
        } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== "string") {
            // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)
            // The second parameter is undefined. Use anonymous credential.
            url = urlOrConnectionString;
            pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === "string" && blobNameOrOptions && typeof blobNameOrOptions === "string") {
            // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)
            const containerName = credentialOrPipelineOrContainerName;
            const blobName = blobNameOrOptions;
            const extractedCreds = (0, _utilsCommon.extractConnectionStringParts)(urlOrConnectionString);
            if (extractedCreds.kind === "AccountConnString") {
                if (0, _coreUtil.isNode) {
                    const sharedKeyCredential = new (0, _storageSharedKeyCredential.StorageSharedKeyCredential)(extractedCreds.accountName, extractedCreds.accountKey);
                    url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));
                    if (!options.proxyOptions) options.proxyOptions = (0, _coreRestPipeline.getDefaultProxySettings)(extractedCreds.proxyUri);
                    pipeline = (0, _pipeline.newPipeline)(sharedKeyCredential, options);
                } else throw new Error("Account connection string is only supported in Node.js environment");
            } else if (extractedCreds.kind === "SASConnString") {
                url = (0, _utilsCommon.appendToURLPath)((0, _utilsCommon.appendToURLPath)(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + "?" + extractedCreds.accountSas;
                pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
            } else throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        } else throw new Error("Expecting non-empty strings for containerName and blobName parameters");
        super(url, pipeline);
        this.pageBlobContext = this.storageClientContext.pageBlob;
    }
    /**
     * Creates a new PageBlobClient object identical to the source but with the
     * specified snapshot timestamp.
     * Provide "" will remove the snapshot and return a Client to the base blob.
     *
     * @param snapshot - The snapshot timestamp.
     * @returns A new PageBlobClient object identical to the source but with the specified snapshot timestamp.
     */ withSnapshot(snapshot) {
        return new PageBlobClient((0, _utilsCommon.setURLParameter)(this.url, (0, _constants.URLConstants).Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);
    }
    /**
     * Creates a page blob of the specified length. Call uploadPages to upload data
     * data to a page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param size - size of the page blob.
     * @param options - Options to the Page Blob Create operation.
     * @returns Response data for the Page Blob Create operation.
     */ async create(size, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-create", options, async (updatedOptions)=>{
            var _a, _b, _c;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.create(0, size, {
                abortSignal: options.abortSignal,
                blobHttpHeaders: options.blobHTTPHeaders,
                blobSequenceNumber: options.blobSequenceNumber,
                leaseAccessConditions: options.conditions,
                metadata: options.metadata,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,
                immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,
                legalHold: options.legalHold,
                tier: (0, _models.toAccessTier)(options.tier),
                blobTagsString: (0, _utilsCommon.toBlobTagsString)(options.tags),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Creates a page blob of the specified length. Call uploadPages to upload data
     * data to a page blob. If the blob with the same name already exists, the content
     * of the existing blob will remain unchanged.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-blob
     *
     * @param size - size of the page blob.
     * @param options -
     */ async createIfNotExists(size, options = {}) {
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-createIfNotExists", options, async (updatedOptions)=>{
            var _a, _b;
            try {
                const conditions = {
                    ifNoneMatch: (0, _constants.ETagAny)
                };
                const res = (0, _utilsCommon.assertResponse)(await this.create(size, Object.assign(Object.assign({}, options), {
                    conditions,
                    tracingOptions: updatedOptions.tracingOptions
                })));
                return Object.assign(Object.assign({
                    succeeded: true
                }, res), {
                    _response: res._response
                });
            } catch (e) {
                if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "BlobAlreadyExists") return Object.assign(Object.assign({
                    succeeded: false
                }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {
                    _response: e.response
                });
                throw e;
            }
        });
    }
    /**
     * Writes 1 or more pages to the page blob. The start and end offsets must be a multiple of 512.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-page
     *
     * @param body - Data to upload
     * @param offset - Offset of destination page blob
     * @param count - Content length of the body, also number of bytes to be uploaded
     * @param options - Options to the Page Blob Upload Pages operation.
     * @returns Response data for the Page Blob Upload Pages operation.
     */ async uploadPages(body, offset, count, options = {}) {
        options.conditions = options.conditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-uploadPages", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.uploadPages(count, body, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                requestOptions: {
                    onUploadProgress: options.onProgress
                },
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                sequenceNumberAccessConditions: options.conditions,
                transactionalContentMD5: options.transactionalContentMD5,
                transactionalContentCrc64: options.transactionalContentCrc64,
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * The Upload Pages operation writes a range of pages to a page blob where the
     * contents are read from a URL.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/put-page-from-url
     *
     * @param sourceURL - Specify a URL to the copy source, Shared Access Signature(SAS) maybe needed for authentication
     * @param sourceOffset - The source offset to copy from. Pass 0 to copy from the beginning of source page blob
     * @param destOffset - Offset of destination page blob
     * @param count - Number of bytes to be uploaded from source page blob
     * @param options -
     */ async uploadPagesFromURL(sourceURL, sourceOffset, destOffset, count, options = {}) {
        options.conditions = options.conditions || {};
        options.sourceConditions = options.sourceConditions || {};
        (0, _models.ensureCpkIfSpecified)(options.customerProvidedKey, this.isHttps);
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-uploadPagesFromURL", options, async (updatedOptions)=>{
            var _a, _b, _c, _d, _e;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.uploadPagesFromURL(sourceURL, (0, _range.rangeToString)({
                offset: sourceOffset,
                count
            }), 0, (0, _range.rangeToString)({
                offset: destOffset,
                count
            }), {
                abortSignal: options.abortSignal,
                sourceContentMD5: options.sourceContentMD5,
                sourceContentCrc64: options.sourceContentCrc64,
                leaseAccessConditions: options.conditions,
                sequenceNumberAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                sourceModifiedAccessConditions: {
                    sourceIfMatch: (_b = options.sourceConditions) === null || _b === void 0 ? void 0 : _b.ifMatch,
                    sourceIfModifiedSince: (_c = options.sourceConditions) === null || _c === void 0 ? void 0 : _c.ifModifiedSince,
                    sourceIfNoneMatch: (_d = options.sourceConditions) === null || _d === void 0 ? void 0 : _d.ifNoneMatch,
                    sourceIfUnmodifiedSince: (_e = options.sourceConditions) === null || _e === void 0 ? void 0 : _e.ifUnmodifiedSince
                },
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                copySourceAuthorization: (0, _utilsCommon.httpAuthorizationToString)(options.sourceAuthorization),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Frees the specified pages from the page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/put-page
     *
     * @param offset - Starting byte position of the pages to clear.
     * @param count - Number of bytes to clear.
     * @param options - Options to the Page Blob Clear Pages operation.
     * @returns Response data for the Page Blob Clear Pages operation.
     */ async clearPages(offset = 0, count, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-clearPages", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.clearPages(0, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                sequenceNumberAccessConditions: options.conditions,
                cpkInfo: options.customerProvidedKey,
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Returns the list of valid page ranges for a page blob or snapshot of a page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param options - Options to the Page Blob Get Ranges operation.
     * @returns Response data for the Page Blob Get Ranges operation.
     */ async getPageRanges(offset = 0, count, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-getPageRanges", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this.pageBlobContext.getPageRanges({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            return (0, _pageBlobRangeResponse.rangeResponseFromModel)(response);
        });
    }
    /**
     * getPageRangesSegment returns a single segment of page ranges starting from the
     * specified Marker. Use an empty Marker to start enumeration from the beginning.
     * After getting a segment, process it, and then call getPageRangesSegment again
     * (passing the the previously-returned Marker) to get the next segment.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param marker - A string value that identifies the portion of the list to be returned with the next list operation.
     * @param options - Options to PageBlob Get Page Ranges Segment operation.
     */ async listPageRangesSegment(offset = 0, count, marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-getPageRangesSegment", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.getPageRanges({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                marker: marker,
                maxPageSize: options.maxPageSize,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Returns an AsyncIterableIterator for {@link PageBlobGetPageRangesResponseModel}
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param marker - A string value that identifies the portion of
     *                          the get of page ranges to be returned with the next getting operation. The
     *                          operation returns the ContinuationToken value within the response body if the
     *                          getting operation did not return all page ranges remaining within the current page.
     *                          The ContinuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of get
     *                          items. The marker value is opaque to the client.
     * @param options - Options to List Page Ranges operation.
     */ listPageRangeItemSegments() {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listPageRangeItemSegments_1(offset = 0, count, marker, options = {}) {
            let getPageRangeItemSegmentsResponse;
            if (!!marker || marker === undefined) do {
                getPageRangeItemSegmentsResponse = yield (0, _tslib.__await)(this.listPageRangesSegment(offset, count, marker, options));
                marker = getPageRangeItemSegmentsResponse.continuationToken;
                yield yield (0, _tslib.__await)((yield (0, _tslib.__await)(getPageRangeItemSegmentsResponse)));
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator of {@link PageRangeInfo} objects
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param options - Options to List Page Ranges operation.
     */ listPageRangeItems() {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listPageRangeItems_1(offset = 0, count, options = {}) {
            var _a, e_1, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.listPageRangeItemSegments(offset, count, marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const getPageRangesSegment = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)((0, _utilsCommon.ExtractPageRangeInfoItems)(getPageRangesSegment)))));
                }
            } catch (e_1_1) {
                e_1 = {
                    error: e_1_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_1) throw e_1.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to list of page ranges for a page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     *  .byPage() returns an async iterable iterator to list of page ranges for a page blob.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the pageBlobClient before you run these snippets,
     * // Can be obtained from `blobServiceClient.getContainerClient("<your-container-name>").getPageBlobClient("<your-blob-name>");`
     * let i = 1;
     * for await (const pageRange of pageBlobClient.listPageRanges()) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = pageBlobClient.listPageRanges();
     * let pageRangeItem = await iter.next();
     * while (!pageRangeItem.done) {
     *   console.log(`Page range ${i++}: ${pageRangeItem.value.start} - ${pageRangeItem.value.end}, IsClear: ${pageRangeItem.value.isClear}`);
     *   pageRangeItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of pageBlobClient.listPageRanges().byPage({ maxPageSize: 20 })) {
     *   for (const pageRange of response) {
     *     console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = pageBlobClient.listPageRanges().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 page ranges
     * for (const pageRange of response) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = pageBlobClient.listPageRanges().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 page ranges
     * for (const blob of response) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     * ```
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param options - Options to the Page Blob Get Ranges operation.
     * @returns An asyncIterableIterator that supports paging.
     */ listPageRanges(offset = 0, count, options = {}) {
        options.conditions = options.conditions || {};
        // AsyncIterableIterator to iterate over blobs
        const iter = this.listPageRangeItems(offset, count, options);
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.listPageRangeItemSegments(offset, count, settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, options));
            }
        };
    }
    /**
     * Gets the collection of page ranges that differ between a specified snapshot and this page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     * @param offset - Starting byte position of the page blob
     * @param count - Number of bytes to get ranges diff.
     * @param prevSnapshot - Timestamp of snapshot to retrieve the difference.
     * @param options - Options to the Page Blob Get Page Ranges Diff operation.
     * @returns Response data for the Page Blob Get Page Range Diff operation.
     */ async getPageRangesDiff(offset, count, prevSnapshot, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-getPageRangesDiff", options, async (updatedOptions)=>{
            var _a;
            const result = (0, _utilsCommon.assertResponse)(await this.pageBlobContext.getPageRangesDiff({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                prevsnapshot: prevSnapshot,
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            return (0, _pageBlobRangeResponse.rangeResponseFromModel)(result);
        });
    }
    /**
     * getPageRangesDiffSegment returns a single segment of page ranges starting from the
     * specified Marker for difference between previous snapshot and the target page blob.
     * Use an empty Marker to start enumeration from the beginning.
     * After getting a segment, process it, and then call getPageRangesDiffSegment again
     * (passing the the previously-returned Marker) to get the next segment.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param prevSnapshotOrUrl - Timestamp of snapshot to retrieve the difference or URL of snapshot to retrieve the difference.
     * @param marker - A string value that identifies the portion of the get to be returned with the next get operation.
     * @param options - Options to the Page Blob Get Page Ranges Diff operation.
     */ async listPageRangesDiffSegment(offset, count, prevSnapshotOrUrl, marker, options = {}) {
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-getPageRangesDiffSegment", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.getPageRangesDiff({
                abortSignal: options === null || options === void 0 ? void 0 : options.abortSignal,
                leaseAccessConditions: options === null || options === void 0 ? void 0 : options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options === null || options === void 0 ? void 0 : options.conditions), {
                    ifTags: (_a = options === null || options === void 0 ? void 0 : options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                prevsnapshot: prevSnapshotOrUrl,
                range: (0, _range.rangeToString)({
                    offset: offset,
                    count: count
                }),
                marker: marker,
                maxPageSize: options === null || options === void 0 ? void 0 : options.maxPageSize,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Returns an AsyncIterableIterator for {@link PageBlobGetPageRangesDiffResponseModel}
     *
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param prevSnapshotOrUrl - Timestamp of snapshot to retrieve the difference or URL of snapshot to retrieve the difference.
     * @param marker - A string value that identifies the portion of
     *                          the get of page ranges to be returned with the next getting operation. The
     *                          operation returns the ContinuationToken value within the response body if the
     *                          getting operation did not return all page ranges remaining within the current page.
     *                          The ContinuationToken value can be used as the value for
     *                          the marker parameter in a subsequent call to request the next page of get
     *                          items. The marker value is opaque to the client.
     * @param options - Options to the Page Blob Get Page Ranges Diff operation.
     */ listPageRangeDiffItemSegments(offset, count, prevSnapshotOrUrl, marker, options) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listPageRangeDiffItemSegments_1() {
            let getPageRangeItemSegmentsResponse;
            if (!!marker || marker === undefined) do {
                getPageRangeItemSegmentsResponse = yield (0, _tslib.__await)(this.listPageRangesDiffSegment(offset, count, prevSnapshotOrUrl, marker, options));
                marker = getPageRangeItemSegmentsResponse.continuationToken;
                yield yield (0, _tslib.__await)((yield (0, _tslib.__await)(getPageRangeItemSegmentsResponse)));
            }while (marker);
        });
    }
    /**
     * Returns an AsyncIterableIterator of {@link PageRangeInfo} objects
     *
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param prevSnapshotOrUrl - Timestamp of snapshot to retrieve the difference or URL of snapshot to retrieve the difference.
     * @param options - Options to the Page Blob Get Page Ranges Diff operation.
     */ listPageRangeDiffItems(offset, count, prevSnapshotOrUrl, options) {
        return (0, _tslib.__asyncGenerator)(this, arguments, function* listPageRangeDiffItems_1() {
            var _a, e_2, _b, _c;
            let marker;
            try {
                for(var _d = true, _e = (0, _tslib.__asyncValues)(this.listPageRangeDiffItemSegments(offset, count, prevSnapshotOrUrl, marker, options)), _f; _f = yield (0, _tslib.__await)(_e.next()), _a = _f.done, !_a; _d = true){
                    _c = _f.value;
                    _d = false;
                    const getPageRangesSegment = _c;
                    yield (0, _tslib.__await)((yield* (0, _tslib.__asyncDelegator)((0, _tslib.__asyncValues)((0, _utilsCommon.ExtractPageRangeInfoItems)(getPageRangesSegment)))));
                }
            } catch (e_2_1) {
                e_2 = {
                    error: e_2_1
                };
            } finally{
                try {
                    if (!_d && !_a && (_b = _e.return)) yield (0, _tslib.__await)(_b.call(_e));
                } finally{
                    if (e_2) throw e_2.error;
                }
            }
        });
    }
    /**
     * Returns an async iterable iterator to list of page ranges that differ between a specified snapshot and this page blob.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     *  .byPage() returns an async iterable iterator to list of page ranges that differ between a specified snapshot and this page blob.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the pageBlobClient before you run these snippets,
     * // Can be obtained from `blobServiceClient.getContainerClient("<your-container-name>").getPageBlobClient("<your-blob-name>");`
     * let i = 1;
     * for await (const pageRange of pageBlobClient.listPageRangesDiff()) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = pageBlobClient.listPageRangesDiff();
     * let pageRangeItem = await iter.next();
     * while (!pageRangeItem.done) {
     *   console.log(`Page range ${i++}: ${pageRangeItem.value.start} - ${pageRangeItem.value.end}, IsClear: ${pageRangeItem.value.isClear}`);
     *   pageRangeItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of pageBlobClient.listPageRangesDiff().byPage({ maxPageSize: 20 })) {
     *   for (const pageRange of response) {
     *     console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = pageBlobClient.listPageRangesDiff().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 page ranges
     * for (const pageRange of response) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = pageBlobClient.listPageRangesDiff().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 page ranges
     * for (const blob of response) {
     *   console.log(`Page range ${i++}: ${pageRange.start} - ${pageRange.end}`);
     * }
     * ```
     * @param offset - Starting byte position of the page ranges.
     * @param count - Number of bytes to get.
     * @param prevSnapshot - Timestamp of snapshot to retrieve the difference.
     * @param options - Options to the Page Blob Get Ranges operation.
     * @returns An asyncIterableIterator that supports paging.
     */ listPageRangesDiff(offset, count, prevSnapshot, options = {}) {
        options.conditions = options.conditions || {};
        // AsyncIterableIterator to iterate over blobs
        const iter = this.listPageRangeDiffItems(offset, count, prevSnapshot, Object.assign({}, options));
        return {
            /**
             * The next method, part of the iteration protocol
             */ next () {
                return iter.next();
            },
            /**
             * The connection to the async iterator, part of the iteration protocol
             */ [Symbol.asyncIterator] () {
                return this;
            },
            /**
             * Return an AsyncIterableIterator that works a page at a time
             */ byPage: (settings = {})=>{
                return this.listPageRangeDiffItemSegments(offset, count, prevSnapshot, settings.continuationToken, Object.assign({
                    maxPageSize: settings.maxPageSize
                }, options));
            }
        };
    }
    /**
     * Gets the collection of page ranges that differ between a specified snapshot and this page blob for managed disks.
     * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges
     *
     * @param offset - Starting byte position of the page blob
     * @param count - Number of bytes to get ranges diff.
     * @param prevSnapshotUrl - URL of snapshot to retrieve the difference.
     * @param options - Options to the Page Blob Get Page Ranges Diff operation.
     * @returns Response data for the Page Blob Get Page Range Diff operation.
     */ async getPageRangesDiffForManagedDisks(offset, count, prevSnapshotUrl, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-GetPageRangesDiffForManagedDisks", options, async (updatedOptions)=>{
            var _a;
            const response = (0, _utilsCommon.assertResponse)(await this.pageBlobContext.getPageRangesDiff({
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                prevSnapshotUrl,
                range: (0, _range.rangeToString)({
                    offset,
                    count
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
            return (0, _pageBlobRangeResponse.rangeResponseFromModel)(response);
        });
    }
    /**
     * Resizes the page blob to the specified size (which must be a multiple of 512).
     * @see https://docs.microsoft.com/rest/api/storageservices/set-blob-properties
     *
     * @param size - Target size
     * @param options - Options to the Page Blob Resize operation.
     * @returns Response data for the Page Blob Resize operation.
     */ async resize(size, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-resize", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.resize(size, {
                abortSignal: options.abortSignal,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                encryptionScope: options.encryptionScope,
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Sets a page blob's sequence number.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties
     *
     * @param sequenceNumberAction - Indicates how the service should modify the blob's sequence number.
     * @param sequenceNumber - Required if sequenceNumberAction is max or update
     * @param options - Options to the Page Blob Update Sequence Number operation.
     * @returns Response data for the Page Blob Update Sequence Number operation.
     */ async updateSequenceNumber(sequenceNumberAction, sequenceNumber, options = {}) {
        options.conditions = options.conditions || {};
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-updateSequenceNumber", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.updateSequenceNumber(sequenceNumberAction, {
                abortSignal: options.abortSignal,
                blobSequenceNumber: sequenceNumber,
                leaseAccessConditions: options.conditions,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
    /**
     * Begins an operation to start an incremental copy from one page blob's snapshot to this page blob.
     * The snapshot is copied such that only the differential changes between the previously
     * copied snapshot are transferred to the destination.
     * The copied snapshots are complete copies of the original snapshot and can be read or copied from as usual.
     * @see https://docs.microsoft.com/rest/api/storageservices/incremental-copy-blob
     * @see https://docs.microsoft.com/en-us/azure/virtual-machines/windows/incremental-snapshots
     *
     * @param copySource - Specifies the name of the source page blob snapshot. For example,
     *                            https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>
     * @param options - Options to the Page Blob Copy Incremental operation.
     * @returns Response data for the Page Blob Copy Incremental operation.
     */ async startCopyIncremental(copySource, options = {}) {
        return (0, _tracing.tracingClient).withSpan("PageBlobClient-startCopyIncremental", options, async (updatedOptions)=>{
            var _a;
            return (0, _utilsCommon.assertResponse)(await this.pageBlobContext.copyIncremental(copySource, {
                abortSignal: options.abortSignal,
                modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {
                    ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions
                }),
                tracingOptions: updatedOptions.tracingOptions
            }));
        });
    }
}

},{"d85f5683f78ac6e9":"fCgem","tslib":"lRdW5","@azure/core-rest-pipeline":"d0mqv","@azure/core-auth":"2xRAB","@azure/core-util":"b31OK","./BlobDownloadResponse":"2JWvO","./BlobQueryResponse":"4nEoT","./credentials/AnonymousCredential":"f0sOe","./credentials/StorageSharedKeyCredential":"jUFIX","./models":"179yc","./PageBlobRangeResponse":"eVYB7","./Pipeline":"bsozg","./pollers/BlobStartCopyFromUrlPoller":"9CFs1","./Range":"6C9e2","./StorageClient":"gO9Kx","./utils/Batch":"l9Xq9","../../storage-common/src":"h0c80","./utils/constants":"4gX5x","./utils/tracing":"m0KjB","./utils/utils.common":"2SR3M","./utils/utils.node":"8nPkP","./sas/BlobSASSignatureValues":"SWffY","./BlobLeaseClient":"hZ8uc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2JWvO":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
// This file is used as a shim of "BlobDownloadResponse" for some browser bundlers
// when trying to bundle "BlobDownloadResponse"
// "BlobDownloadResponse" class is only available in Node.js runtime
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlobDownloadResponse", ()=>BlobDownloadResponse);
const BlobDownloadResponse = 1;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4nEoT":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN BROWSER RUNTIME.
 *
 * BlobQueryResponse implements BlobDownloadResponseModel interface, and in browser runtime it will
 * parse avor data returned by blob query.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlobQueryResponse", ()=>BlobQueryResponse);
class BlobQueryResponse {
    /**
     * Indicates that the service supports
     * requests for partial file content.
     *
     * @readonly
     */ get acceptRanges() {
        return this.originalResponse.acceptRanges;
    }
    /**
     * Returns if it was previously specified
     * for the file.
     *
     * @readonly
     */ get cacheControl() {
        return this.originalResponse.cacheControl;
    }
    /**
     * Returns the value that was specified
     * for the 'x-ms-content-disposition' header and specifies how to process the
     * response.
     *
     * @readonly
     */ get contentDisposition() {
        return this.originalResponse.contentDisposition;
    }
    /**
     * Returns the value that was specified
     * for the Content-Encoding request header.
     *
     * @readonly
     */ get contentEncoding() {
        return this.originalResponse.contentEncoding;
    }
    /**
     * Returns the value that was specified
     * for the Content-Language request header.
     *
     * @readonly
     */ get contentLanguage() {
        return this.originalResponse.contentLanguage;
    }
    /**
     * The current sequence number for a
     * page blob. This header is not returned for block blobs or append blobs.
     *
     * @readonly
     */ get blobSequenceNumber() {
        return this.originalResponse.blobSequenceNumber;
    }
    /**
     * The blob's type. Possible values include:
     * 'BlockBlob', 'PageBlob', 'AppendBlob'.
     *
     * @readonly
     */ get blobType() {
        return this.originalResponse.blobType;
    }
    /**
     * The number of bytes present in the
     * response body.
     *
     * @readonly
     */ get contentLength() {
        return this.originalResponse.contentLength;
    }
    /**
     * If the file has an MD5 hash and the
     * request is to read the full file, this response header is returned so that
     * the client can check for message content integrity. If the request is to
     * read a specified range and the 'x-ms-range-get-content-md5' is set to
     * true, then the request returns an MD5 hash for the range, as long as the
     * range size is less than or equal to 4 MB. If neither of these sets of
     * conditions is true, then no value is returned for the 'Content-MD5'
     * header.
     *
     * @readonly
     */ get contentMD5() {
        return this.originalResponse.contentMD5;
    }
    /**
     * Indicates the range of bytes returned if
     * the client requested a subset of the file by setting the Range request
     * header.
     *
     * @readonly
     */ get contentRange() {
        return this.originalResponse.contentRange;
    }
    /**
     * The content type specified for the file.
     * The default content type is 'application/octet-stream'
     *
     * @readonly
     */ get contentType() {
        return this.originalResponse.contentType;
    }
    /**
     * Conclusion time of the last attempted
     * Copy File operation where this file was the destination file. This value
     * can specify the time of a completed, aborted, or failed copy attempt.
     *
     * @readonly
     */ get copyCompletedOn() {
        return undefined;
    }
    /**
     * String identifier for the last attempted Copy
     * File operation where this file was the destination file.
     *
     * @readonly
     */ get copyId() {
        return this.originalResponse.copyId;
    }
    /**
     * Contains the number of bytes copied and
     * the total bytes in the source in the last attempted Copy File operation
     * where this file was the destination file. Can show between 0 and
     * Content-Length bytes copied.
     *
     * @readonly
     */ get copyProgress() {
        return this.originalResponse.copyProgress;
    }
    /**
     * URL up to 2KB in length that specifies the
     * source file used in the last attempted Copy File operation where this file
     * was the destination file.
     *
     * @readonly
     */ get copySource() {
        return this.originalResponse.copySource;
    }
    /**
     * State of the copy operation
     * identified by 'x-ms-copy-id'. Possible values include: 'pending',
     * 'success', 'aborted', 'failed'
     *
     * @readonly
     */ get copyStatus() {
        return this.originalResponse.copyStatus;
    }
    /**
     * Only appears when
     * x-ms-copy-status is failed or pending. Describes cause of fatal or
     * non-fatal copy operation failure.
     *
     * @readonly
     */ get copyStatusDescription() {
        return this.originalResponse.copyStatusDescription;
    }
    /**
     * When a blob is leased,
     * specifies whether the lease is of infinite or fixed duration. Possible
     * values include: 'infinite', 'fixed'.
     *
     * @readonly
     */ get leaseDuration() {
        return this.originalResponse.leaseDuration;
    }
    /**
     * Lease state of the blob. Possible
     * values include: 'available', 'leased', 'expired', 'breaking', 'broken'.
     *
     * @readonly
     */ get leaseState() {
        return this.originalResponse.leaseState;
    }
    /**
     * The current lease status of the
     * blob. Possible values include: 'locked', 'unlocked'.
     *
     * @readonly
     */ get leaseStatus() {
        return this.originalResponse.leaseStatus;
    }
    /**
     * A UTC date/time value generated by the service that
     * indicates the time at which the response was initiated.
     *
     * @readonly
     */ get date() {
        return this.originalResponse.date;
    }
    /**
     * The number of committed blocks
     * present in the blob. This header is returned only for append blobs.
     *
     * @readonly
     */ get blobCommittedBlockCount() {
        return this.originalResponse.blobCommittedBlockCount;
    }
    /**
     * The ETag contains a value that you can use to
     * perform operations conditionally, in quotes.
     *
     * @readonly
     */ get etag() {
        return this.originalResponse.etag;
    }
    /**
     * The error code.
     *
     * @readonly
     */ get errorCode() {
        return this.originalResponse.errorCode;
    }
    /**
     * The value of this header is set to
     * true if the file data and application metadata are completely encrypted
     * using the specified algorithm. Otherwise, the value is set to false (when
     * the file is unencrypted, or if only parts of the file/application metadata
     * are encrypted).
     *
     * @readonly
     */ get isServerEncrypted() {
        return this.originalResponse.isServerEncrypted;
    }
    /**
     * If the blob has a MD5 hash, and if
     * request contains range header (Range or x-ms-range), this response header
     * is returned with the value of the whole blob's MD5 value. This value may
     * or may not be equal to the value returned in Content-MD5 header, with the
     * latter calculated from the requested range.
     *
     * @readonly
     */ get blobContentMD5() {
        return this.originalResponse.blobContentMD5;
    }
    /**
     * Returns the date and time the file was last
     * modified. Any operation that modifies the file or its properties updates
     * the last modified time.
     *
     * @readonly
     */ get lastModified() {
        return this.originalResponse.lastModified;
    }
    /**
     * A name-value pair
     * to associate with a file storage object.
     *
     * @readonly
     */ get metadata() {
        return this.originalResponse.metadata;
    }
    /**
     * This header uniquely identifies the request
     * that was made and can be used for troubleshooting the request.
     *
     * @readonly
     */ get requestId() {
        return this.originalResponse.requestId;
    }
    /**
     * If a client request id header is sent in the request, this header will be present in the
     * response with the same value.
     *
     * @readonly
     */ get clientRequestId() {
        return this.originalResponse.clientRequestId;
    }
    /**
     * Indicates the version of the File service used
     * to execute the request.
     *
     * @readonly
     */ get version() {
        return this.originalResponse.version;
    }
    /**
     * The SHA-256 hash of the encryption key used to encrypt the blob. This value is only returned
     * when the blob was encrypted with a customer-provided key.
     *
     * @readonly
     */ get encryptionKeySha256() {
        return this.originalResponse.encryptionKeySha256;
    }
    /**
     * If the request is to read a specified range and the x-ms-range-get-content-crc64 is set to
     * true, then the request returns a crc64 for the range, as long as the range size is less than
     * or equal to 4 MB. If both x-ms-range-get-content-crc64 & x-ms-range-get-content-md5 is
     * specified in the same request, it will fail with 400(Bad Request)
     */ get contentCrc64() {
        return this.originalResponse.contentCrc64;
    }
    /**
     * The response body as a browser Blob.
     * Always undefined in node.js.
     *
     * @readonly
     */ get blobBody() {
        throw Error(`Quick query in browser is not supported yet.`);
    }
    /**
     * The response body as a node.js Readable stream.
     * Always undefined in the browser.
     *
     * @readonly
     */ get readableStreamBody() {
        return undefined;
    }
    /**
     * The HTTP response.
     */ get _response() {
        return this.originalResponse._response;
    }
    /**
     * Creates an instance of BlobQueryResponse.
     *
     * @param originalResponse -
     * @param options -
     */ constructor(originalResponse, _options = {}){
        this.originalResponse = originalResponse;
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"179yc":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlockBlobTier", ()=>BlockBlobTier);
parcelHelpers.export(exports, "PremiumPageBlobTier", ()=>PremiumPageBlobTier);
parcelHelpers.export(exports, "toAccessTier", ()=>toAccessTier);
parcelHelpers.export(exports, "ensureCpkIfSpecified", ()=>ensureCpkIfSpecified);
parcelHelpers.export(exports, "StorageBlobAudience", ()=>StorageBlobAudience);
/**
 *
 * To get OAuth audience for a storage account for blob service.
 */ parcelHelpers.export(exports, "getBlobServiceAccountAudience", ()=>getBlobServiceAccountAudience);
var _constants = require("./utils/constants");
var BlockBlobTier;
(function(BlockBlobTier) {
    /**
     * Optimized for storing data that is accessed frequently.
     */ BlockBlobTier["Hot"] = "Hot";
    /**
     * Optimized for storing data that is infrequently accessed and stored for at least 30 days.
     */ BlockBlobTier["Cool"] = "Cool";
    /**
     * Optimized for storing data that is rarely accessed.
     */ BlockBlobTier["Cold"] = "Cold";
    /**
     * Optimized for storing data that is rarely accessed and stored for at least 180 days
     * with flexible latency requirements (on the order of hours).
     */ BlockBlobTier["Archive"] = "Archive";
})(BlockBlobTier || (BlockBlobTier = {}));
var PremiumPageBlobTier;
(function(PremiumPageBlobTier) {
    /**
     * P4 Tier.
     */ PremiumPageBlobTier["P4"] = "P4";
    /**
     * P6 Tier.
     */ PremiumPageBlobTier["P6"] = "P6";
    /**
     * P10 Tier.
     */ PremiumPageBlobTier["P10"] = "P10";
    /**
     * P15 Tier.
     */ PremiumPageBlobTier["P15"] = "P15";
    /**
     * P20 Tier.
     */ PremiumPageBlobTier["P20"] = "P20";
    /**
     * P30 Tier.
     */ PremiumPageBlobTier["P30"] = "P30";
    /**
     * P40 Tier.
     */ PremiumPageBlobTier["P40"] = "P40";
    /**
     * P50 Tier.
     */ PremiumPageBlobTier["P50"] = "P50";
    /**
     * P60 Tier.
     */ PremiumPageBlobTier["P60"] = "P60";
    /**
     * P70 Tier.
     */ PremiumPageBlobTier["P70"] = "P70";
    /**
     * P80 Tier.
     */ PremiumPageBlobTier["P80"] = "P80";
})(PremiumPageBlobTier || (PremiumPageBlobTier = {}));
function toAccessTier(tier) {
    if (tier === undefined) return undefined;
    return tier; // No more check if string is a valid AccessTier, and left this to underlay logic to decide(service).
}
function ensureCpkIfSpecified(cpk, isHttps) {
    if (cpk && !isHttps) throw new RangeError("Customer-provided encryption key must be used over HTTPS.");
    if (cpk && !cpk.encryptionAlgorithm) cpk.encryptionAlgorithm = (0, _constants.EncryptionAlgorithmAES25);
}
var StorageBlobAudience;
(function(StorageBlobAudience) {
    /**
     * The OAuth scope to use to retrieve an AAD token for Azure Storage.
     */ StorageBlobAudience["StorageOAuthScopes"] = "https://storage.azure.com/.default";
    /**
     * The OAuth scope to use to retrieve an AAD token for Azure Disk.
     */ StorageBlobAudience["DiskComputeOAuthScopes"] = "https://disk.compute.azure.com/.default";
})(StorageBlobAudience || (StorageBlobAudience = {}));
function getBlobServiceAccountAudience(storageAccountName) {
    return `https://${storageAccountName}.blob.core.windows.net/.default`;
}

},{"./utils/constants":"4gX5x","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eVYB7":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Function that converts PageRange and ClearRange to a common Range object.
 * PageRange and ClearRange have start and end while Range offset and count
 * this function normalizes to Range.
 * @param response - Model PageBlob Range response
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "rangeResponseFromModel", ()=>rangeResponseFromModel);
function rangeResponseFromModel(response) {
    const pageRange = (response._response.parsedBody.pageRange || []).map((x)=>({
            offset: x.start,
            count: x.end - x.start
        }));
    const clearRange = (response._response.parsedBody.clearRange || []).map((x)=>({
            offset: x.start,
            count: x.end - x.start
        }));
    return Object.assign(Object.assign({}, response), {
        pageRange,
        clearRange,
        _response: Object.assign(Object.assign({}, response._response), {
            parsedBody: {
                pageRange,
                clearRange
            }
        })
    });
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9CFs1":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * This is the poller returned by {@link BlobClient.beginCopyFromURL}.
 * This can not be instantiated directly outside of this package.
 *
 * @hidden
 */ parcelHelpers.export(exports, "BlobBeginCopyFromUrlPoller", ()=>BlobBeginCopyFromUrlPoller);
var _coreUtil = require("@azure/core-util");
var _coreLro = require("@azure/core-lro");
class BlobBeginCopyFromUrlPoller extends (0, _coreLro.Poller) {
    constructor(options){
        const { blobClient, copySource, intervalInMs = 15000, onProgress, resumeFrom, startCopyFromURLOptions } = options;
        let state;
        if (resumeFrom) state = JSON.parse(resumeFrom).state;
        const operation = makeBlobBeginCopyFromURLPollOperation(Object.assign(Object.assign({}, state), {
            blobClient,
            copySource,
            startCopyFromURLOptions
        }));
        super(operation);
        if (typeof onProgress === "function") this.onProgress(onProgress);
        this.intervalInMs = intervalInMs;
    }
    delay() {
        return (0, _coreUtil.delay)(this.intervalInMs);
    }
}
/**
 * Note: Intentionally using function expression over arrow function expression
 * so that the function can be invoked with a different context.
 * This affects what `this` refers to.
 * @hidden
 */ const cancel = async function cancel(options = {}) {
    const state = this.state;
    const { copyId } = state;
    if (state.isCompleted) return makeBlobBeginCopyFromURLPollOperation(state);
    if (!copyId) {
        state.isCancelled = true;
        return makeBlobBeginCopyFromURLPollOperation(state);
    }
    // if abortCopyFromURL throws, it will bubble up to user's poller.cancelOperation call
    await state.blobClient.abortCopyFromURL(copyId, {
        abortSignal: options.abortSignal
    });
    state.isCancelled = true;
    return makeBlobBeginCopyFromURLPollOperation(state);
};
/**
 * Note: Intentionally using function expression over arrow function expression
 * so that the function can be invoked with a different context.
 * This affects what `this` refers to.
 * @hidden
 */ const update = async function update(options = {}) {
    const state = this.state;
    const { blobClient, copySource, startCopyFromURLOptions } = state;
    if (!state.isStarted) {
        state.isStarted = true;
        const result = await blobClient.startCopyFromURL(copySource, startCopyFromURLOptions);
        // copyId is needed to abort
        state.copyId = result.copyId;
        if (result.copyStatus === "success") {
            state.result = result;
            state.isCompleted = true;
        }
    } else if (!state.isCompleted) try {
        const result = await state.blobClient.getProperties({
            abortSignal: options.abortSignal
        });
        const { copyStatus, copyProgress } = result;
        const prevCopyProgress = state.copyProgress;
        if (copyProgress) state.copyProgress = copyProgress;
        if (copyStatus === "pending" && copyProgress !== prevCopyProgress && typeof options.fireProgress === "function") // trigger in setTimeout, or swallow error?
        options.fireProgress(state);
        else if (copyStatus === "success") {
            state.result = result;
            state.isCompleted = true;
        } else if (copyStatus === "failed") {
            state.error = new Error(`Blob copy failed with reason: "${result.copyStatusDescription || "unknown"}"`);
            state.isCompleted = true;
        }
    } catch (err) {
        state.error = err;
        state.isCompleted = true;
    }
    return makeBlobBeginCopyFromURLPollOperation(state);
};
/**
 * Note: Intentionally using function expression over arrow function expression
 * so that the function can be invoked with a different context.
 * This affects what `this` refers to.
 * @hidden
 */ const toString = function toString() {
    return JSON.stringify({
        state: this.state
    }, (key, value)=>{
        // remove blobClient from serialized state since a client can't be hydrated from this info.
        if (key === "blobClient") return undefined;
        return value;
    });
};
/**
 * Creates a poll operation given the provided state.
 * @hidden
 */ function makeBlobBeginCopyFromURLPollOperation(state) {
    return {
        state: Object.assign({}, state),
        cancel,
        toString,
        update
    };
}

},{"@azure/core-util":"b31OK","@azure/core-lro":"1yADq","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1yADq":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createHttpPoller", ()=>(0, _pollerJs.createHttpPoller));
var _pollerJs = require("./http/poller.js");
/**
 * This can be uncommented to expose the protocol-agnostic poller
 */ // export {
//   BuildCreatePollerOptions,
//   Operation,
//   CreatePollerOptions,
//   OperationConfig,
//   RestorableOperationState,
// } from "./poller/models";
// export { buildCreatePoller } from "./poller/poller";
/** legacy */ var _indexJs = require("./legacy/lroEngine/index.js");
parcelHelpers.exportAll(_indexJs, exports);
var _pollerJs1 = require("./legacy/poller.js");
parcelHelpers.exportAll(_pollerJs1, exports);
var _pollOperationJs = require("./legacy/pollOperation.js");
parcelHelpers.exportAll(_pollOperationJs, exports);

},{"./http/poller.js":"kvMtZ","./legacy/lroEngine/index.js":"ktHZr","./legacy/poller.js":"9uddL","./legacy/pollOperation.js":"7LG63","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kvMtZ":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Creates a poller that can be used to poll a long-running operation.
 * @param lro - Description of the long-running operation
 * @param options - options to configure the poller
 * @returns an initialized poller
 */ parcelHelpers.export(exports, "createHttpPoller", ()=>createHttpPoller);
var _operationJs = require("./operation.js");
var _pollerJs = require("../poller/poller.js");
async function createHttpPoller(lro, options) {
    const { resourceLocationConfig, intervalInMs, processResult, restoreFrom, updateState, withOperationLocation, resolveOnUnsuccessful = false } = options || {};
    return (0, _pollerJs.buildCreatePoller)({
        getStatusFromInitialResponse: (0, _operationJs.getStatusFromInitialResponse),
        getStatusFromPollResponse: (0, _operationJs.getOperationStatus),
        isOperationError: (0, _operationJs.isOperationError),
        getOperationLocation: (0, _operationJs.getOperationLocation),
        getResourceLocation: (0, _operationJs.getResourceLocation),
        getPollingInterval: (0, _operationJs.parseRetryAfter),
        getError: (0, _operationJs.getErrorFromResponse),
        resolveOnUnsuccessful
    })({
        init: async ()=>{
            const response = await lro.sendInitialRequest();
            const config = (0, _operationJs.inferLroMode)({
                rawResponse: response.rawResponse,
                requestPath: lro.requestPath,
                requestMethod: lro.requestMethod,
                resourceLocationConfig
            });
            return Object.assign({
                response,
                operationLocation: config === null || config === void 0 ? void 0 : config.operationLocation,
                resourceLocation: config === null || config === void 0 ? void 0 : config.resourceLocation
            }, (config === null || config === void 0 ? void 0 : config.mode) ? {
                metadata: {
                    mode: config.mode
                }
            } : {});
        },
        poll: lro.sendPollRequest
    }, {
        intervalInMs,
        withOperationLocation,
        restoreFrom,
        updateState,
        processResult: processResult ? ({ flatResponse }, state)=>processResult(flatResponse, state) : ({ flatResponse })=>flatResponse
    });
}

},{"./operation.js":"832j4","../poller/poller.js":"3anhV","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"832j4":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "inferLroMode", ()=>inferLroMode);
parcelHelpers.export(exports, "parseRetryAfter", ()=>parseRetryAfter);
parcelHelpers.export(exports, "getErrorFromResponse", ()=>getErrorFromResponse);
parcelHelpers.export(exports, "getStatusFromInitialResponse", ()=>getStatusFromInitialResponse);
/**
 * Initiates the long-running operation.
 */ parcelHelpers.export(exports, "initHttpOperation", ()=>initHttpOperation);
parcelHelpers.export(exports, "getOperationLocation", ()=>getOperationLocation);
parcelHelpers.export(exports, "getOperationStatus", ()=>getOperationStatus);
parcelHelpers.export(exports, "getResourceLocation", ()=>getResourceLocation);
parcelHelpers.export(exports, "isOperationError", ()=>isOperationError);
/** Polls the long-running operation. */ parcelHelpers.export(exports, "pollHttpOperation", ()=>pollHttpOperation);
var _operationJs = require("../poller/operation.js");
var _loggerJs = require("../logger.js");
function getOperationLocationPollingUrl(inputs) {
    const { azureAsyncOperation, operationLocation } = inputs;
    return operationLocation !== null && operationLocation !== void 0 ? operationLocation : azureAsyncOperation;
}
function getLocationHeader(rawResponse) {
    return rawResponse.headers["location"];
}
function getOperationLocationHeader(rawResponse) {
    return rawResponse.headers["operation-location"];
}
function getAzureAsyncOperationHeader(rawResponse) {
    return rawResponse.headers["azure-asyncoperation"];
}
function findResourceLocation(inputs) {
    var _a;
    const { location, requestMethod, requestPath, resourceLocationConfig } = inputs;
    switch(requestMethod){
        case "PUT":
            return requestPath;
        case "DELETE":
            return undefined;
        case "PATCH":
            return (_a = getDefault()) !== null && _a !== void 0 ? _a : requestPath;
        default:
            return getDefault();
    }
    function getDefault() {
        switch(resourceLocationConfig){
            case "azure-async-operation":
                return undefined;
            case "original-uri":
                return requestPath;
            case "location":
            default:
                return location;
        }
    }
}
function inferLroMode(inputs) {
    const { rawResponse, requestMethod, requestPath, resourceLocationConfig } = inputs;
    const operationLocation = getOperationLocationHeader(rawResponse);
    const azureAsyncOperation = getAzureAsyncOperationHeader(rawResponse);
    const pollingUrl = getOperationLocationPollingUrl({
        operationLocation,
        azureAsyncOperation
    });
    const location = getLocationHeader(rawResponse);
    const normalizedRequestMethod = requestMethod === null || requestMethod === void 0 ? void 0 : requestMethod.toLocaleUpperCase();
    if (pollingUrl !== undefined) return {
        mode: "OperationLocation",
        operationLocation: pollingUrl,
        resourceLocation: findResourceLocation({
            requestMethod: normalizedRequestMethod,
            location,
            requestPath,
            resourceLocationConfig
        })
    };
    else if (location !== undefined) return {
        mode: "ResourceLocation",
        operationLocation: location
    };
    else if (normalizedRequestMethod === "PUT" && requestPath) return {
        mode: "Body",
        operationLocation: requestPath
    };
    else return undefined;
}
function transformStatus(inputs) {
    const { status, statusCode } = inputs;
    if (typeof status !== "string" && status !== undefined) throw new Error(`Polling was unsuccessful. Expected status to have a string value or no value but it has instead: ${status}. This doesn't necessarily indicate the operation has failed. Check your Azure subscription or resource status for more information.`);
    switch(status === null || status === void 0 ? void 0 : status.toLocaleLowerCase()){
        case undefined:
            return toOperationStatus(statusCode);
        case "succeeded":
            return "succeeded";
        case "failed":
            return "failed";
        case "running":
        case "accepted":
        case "started":
        case "canceling":
        case "cancelling":
            return "running";
        case "canceled":
        case "cancelled":
            return "canceled";
        default:
            (0, _loggerJs.logger).verbose(`LRO: unrecognized operation status: ${status}`);
            return status;
    }
}
function getStatus(rawResponse) {
    var _a;
    const { status } = (_a = rawResponse.body) !== null && _a !== void 0 ? _a : {};
    return transformStatus({
        status,
        statusCode: rawResponse.statusCode
    });
}
function getProvisioningState(rawResponse) {
    var _a, _b;
    const { properties, provisioningState } = (_a = rawResponse.body) !== null && _a !== void 0 ? _a : {};
    const status = (_b = properties === null || properties === void 0 ? void 0 : properties.provisioningState) !== null && _b !== void 0 ? _b : provisioningState;
    return transformStatus({
        status,
        statusCode: rawResponse.statusCode
    });
}
function toOperationStatus(statusCode) {
    if (statusCode === 202) return "running";
    else if (statusCode < 300) return "succeeded";
    else return "failed";
}
function parseRetryAfter({ rawResponse }) {
    const retryAfter = rawResponse.headers["retry-after"];
    if (retryAfter !== undefined) {
        // Retry-After header value is either in HTTP date format, or in seconds
        const retryAfterInSeconds = parseInt(retryAfter);
        return isNaN(retryAfterInSeconds) ? calculatePollingIntervalFromDate(new Date(retryAfter)) : retryAfterInSeconds * 1000;
    }
    return undefined;
}
function getErrorFromResponse(response) {
    const error = accessBodyProperty(response, "error");
    if (!error) {
        (0, _loggerJs.logger).warning(`The long-running operation failed but there is no error property in the response's body`);
        return;
    }
    if (!error.code || !error.message) {
        (0, _loggerJs.logger).warning(`The long-running operation failed but the error property in the response's body doesn't contain code or message`);
        return;
    }
    return error;
}
function calculatePollingIntervalFromDate(retryAfterDate) {
    const timeNow = Math.floor(new Date().getTime());
    const retryAfterTime = retryAfterDate.getTime();
    if (timeNow < retryAfterTime) return retryAfterTime - timeNow;
    return undefined;
}
function getStatusFromInitialResponse(inputs) {
    const { response, state, operationLocation } = inputs;
    function helper() {
        var _a;
        const mode = (_a = state.config.metadata) === null || _a === void 0 ? void 0 : _a["mode"];
        switch(mode){
            case undefined:
                return toOperationStatus(response.rawResponse.statusCode);
            case "Body":
                return getOperationStatus(response, state);
            default:
                return "running";
        }
    }
    const status = helper();
    return status === "running" && operationLocation === undefined ? "succeeded" : status;
}
async function initHttpOperation(inputs) {
    const { stateProxy, resourceLocationConfig, processResult, lro, setErrorAsResult } = inputs;
    return (0, _operationJs.initOperation)({
        init: async ()=>{
            const response = await lro.sendInitialRequest();
            const config = inferLroMode({
                rawResponse: response.rawResponse,
                requestPath: lro.requestPath,
                requestMethod: lro.requestMethod,
                resourceLocationConfig
            });
            return Object.assign({
                response,
                operationLocation: config === null || config === void 0 ? void 0 : config.operationLocation,
                resourceLocation: config === null || config === void 0 ? void 0 : config.resourceLocation
            }, (config === null || config === void 0 ? void 0 : config.mode) ? {
                metadata: {
                    mode: config.mode
                }
            } : {});
        },
        stateProxy,
        processResult: processResult ? ({ flatResponse }, state)=>processResult(flatResponse, state) : ({ flatResponse })=>flatResponse,
        getOperationStatus: getStatusFromInitialResponse,
        setErrorAsResult
    });
}
function getOperationLocation({ rawResponse }, state) {
    var _a;
    const mode = (_a = state.config.metadata) === null || _a === void 0 ? void 0 : _a["mode"];
    switch(mode){
        case "OperationLocation":
            return getOperationLocationPollingUrl({
                operationLocation: getOperationLocationHeader(rawResponse),
                azureAsyncOperation: getAzureAsyncOperationHeader(rawResponse)
            });
        case "ResourceLocation":
            return getLocationHeader(rawResponse);
        case "Body":
        default:
            return undefined;
    }
}
function getOperationStatus({ rawResponse }, state) {
    var _a;
    const mode = (_a = state.config.metadata) === null || _a === void 0 ? void 0 : _a["mode"];
    switch(mode){
        case "OperationLocation":
            return getStatus(rawResponse);
        case "ResourceLocation":
            return toOperationStatus(rawResponse.statusCode);
        case "Body":
            return getProvisioningState(rawResponse);
        default:
            throw new Error(`Internal error: Unexpected operation mode: ${mode}`);
    }
}
function accessBodyProperty({ flatResponse, rawResponse }, prop) {
    var _a, _b;
    return (_a = flatResponse === null || flatResponse === void 0 ? void 0 : flatResponse[prop]) !== null && _a !== void 0 ? _a : (_b = rawResponse.body) === null || _b === void 0 ? void 0 : _b[prop];
}
function getResourceLocation(res, state) {
    const loc = accessBodyProperty(res, "resourceLocation");
    if (loc && typeof loc === "string") state.config.resourceLocation = loc;
    return state.config.resourceLocation;
}
function isOperationError(e) {
    return e.name === "RestError";
}
async function pollHttpOperation(inputs) {
    const { lro, stateProxy, options, processResult, updateState, setDelay, state, setErrorAsResult } = inputs;
    return (0, _operationJs.pollOperation)({
        state,
        stateProxy,
        setDelay,
        processResult: processResult ? ({ flatResponse }, inputState)=>processResult(flatResponse, inputState) : ({ flatResponse })=>flatResponse,
        getError: getErrorFromResponse,
        updateState,
        getPollingInterval: parseRetryAfter,
        getOperationLocation,
        getOperationStatus,
        isOperationError,
        getResourceLocation,
        options,
        /**
         * The expansion here is intentional because `lro` could be an object that
         * references an inner this, so we need to preserve a reference to it.
         */ poll: async (location, inputOptions)=>lro.sendPollRequest(location, inputOptions),
        setErrorAsResult
    });
}

},{"../poller/operation.js":"12Zcj","../logger.js":"4SdSF","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"12Zcj":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Deserializes the state
 */ parcelHelpers.export(exports, "deserializeState", ()=>deserializeState);
/**
 * Initiates the long-running operation.
 */ parcelHelpers.export(exports, "initOperation", ()=>initOperation);
/** Polls the long-running operation. */ parcelHelpers.export(exports, "pollOperation", ()=>pollOperation);
var _loggerJs = require("../logger.js");
var _constantsJs = require("./constants.js");
function deserializeState(serializedState) {
    try {
        return JSON.parse(serializedState).state;
    } catch (e) {
        throw new Error(`Unable to deserialize input state: ${serializedState}`);
    }
}
function setStateError(inputs) {
    const { state, stateProxy, isOperationError } = inputs;
    return (error)=>{
        if (isOperationError(error)) {
            stateProxy.setError(state, error);
            stateProxy.setFailed(state);
        }
        throw error;
    };
}
function appendReadableErrorMessage(currentMessage, innerMessage) {
    let message = currentMessage;
    if (message.slice(-1) !== ".") message = message + ".";
    return message + " " + innerMessage;
}
function simplifyError(err) {
    let message = err.message;
    let code = err.code;
    let curErr = err;
    while(curErr.innererror){
        curErr = curErr.innererror;
        code = curErr.code;
        message = appendReadableErrorMessage(message, curErr.message);
    }
    return {
        code,
        message
    };
}
function processOperationStatus(result) {
    const { state, stateProxy, status, isDone, processResult, getError, response, setErrorAsResult } = result;
    switch(status){
        case "succeeded":
            stateProxy.setSucceeded(state);
            break;
        case "failed":
            {
                const err = getError === null || getError === void 0 ? void 0 : getError(response);
                let postfix = "";
                if (err) {
                    const { code, message } = simplifyError(err);
                    postfix = `. ${code}. ${message}`;
                }
                const errStr = `The long-running operation has failed${postfix}`;
                stateProxy.setError(state, new Error(errStr));
                stateProxy.setFailed(state);
                (0, _loggerJs.logger).warning(errStr);
                break;
            }
        case "canceled":
            stateProxy.setCanceled(state);
            break;
    }
    if ((isDone === null || isDone === void 0 ? void 0 : isDone(response, state)) || isDone === undefined && [
        "succeeded",
        "canceled"
    ].concat(setErrorAsResult ? [] : [
        "failed"
    ]).includes(status)) stateProxy.setResult(state, buildResult({
        response,
        state,
        processResult
    }));
}
function buildResult(inputs) {
    const { processResult, response, state } = inputs;
    return processResult ? processResult(response, state) : response;
}
async function initOperation(inputs) {
    const { init, stateProxy, processResult, getOperationStatus, withOperationLocation, setErrorAsResult } = inputs;
    const { operationLocation, resourceLocation, metadata, response } = await init();
    if (operationLocation) withOperationLocation === null || withOperationLocation === void 0 || withOperationLocation(operationLocation, false);
    const config = {
        metadata,
        operationLocation,
        resourceLocation
    };
    (0, _loggerJs.logger).verbose(`LRO: Operation description:`, config);
    const state = stateProxy.initState(config);
    const status = getOperationStatus({
        response,
        state,
        operationLocation
    });
    processOperationStatus({
        state,
        status,
        stateProxy,
        response,
        setErrorAsResult,
        processResult
    });
    return state;
}
async function pollOperationHelper(inputs) {
    const { poll, state, stateProxy, operationLocation, getOperationStatus, getResourceLocation, isOperationError, options } = inputs;
    const response = await poll(operationLocation, options).catch(setStateError({
        state,
        stateProxy,
        isOperationError
    }));
    const status = getOperationStatus(response, state);
    (0, _loggerJs.logger).verbose(`LRO: Status:\n\tPolling from: ${state.config.operationLocation}\n\tOperation status: ${status}\n\tPolling status: ${(0, _constantsJs.terminalStates).includes(status) ? "Stopped" : "Running"}`);
    if (status === "succeeded") {
        const resourceLocation = getResourceLocation(response, state);
        if (resourceLocation !== undefined) return {
            response: await poll(resourceLocation).catch(setStateError({
                state,
                stateProxy,
                isOperationError
            })),
            status
        };
    }
    return {
        response,
        status
    };
}
async function pollOperation(inputs) {
    const { poll, state, stateProxy, options, getOperationStatus, getResourceLocation, getOperationLocation, isOperationError, withOperationLocation, getPollingInterval, processResult, getError, updateState, setDelay, isDone, setErrorAsResult } = inputs;
    const { operationLocation } = state.config;
    if (operationLocation !== undefined) {
        const { response, status } = await pollOperationHelper({
            poll,
            getOperationStatus,
            state,
            stateProxy,
            operationLocation,
            getResourceLocation,
            isOperationError,
            options
        });
        processOperationStatus({
            status,
            response,
            state,
            stateProxy,
            isDone,
            processResult,
            getError,
            setErrorAsResult
        });
        if (!(0, _constantsJs.terminalStates).includes(status)) {
            const intervalInMs = getPollingInterval === null || getPollingInterval === void 0 ? void 0 : getPollingInterval(response);
            if (intervalInMs) setDelay(intervalInMs);
            const location = getOperationLocation === null || getOperationLocation === void 0 ? void 0 : getOperationLocation(response, state);
            if (location !== undefined) {
                const isUpdated = operationLocation !== location;
                state.config.operationLocation = location;
                withOperationLocation === null || withOperationLocation === void 0 || withOperationLocation(location, isUpdated);
            } else withOperationLocation === null || withOperationLocation === void 0 || withOperationLocation(operationLocation, false);
        }
        updateState === null || updateState === void 0 || updateState(state, response);
    }
}

},{"../logger.js":"4SdSF","./constants.js":"jCOJU","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4SdSF":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "logger", ()=>logger);
var _logger = require("@azure/logger");
const logger = (0, _logger.createClientLogger)("core-lro");

},{"@azure/logger":"cnBke","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jCOJU":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The default time interval to wait before sending the next polling request.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "POLL_INTERVAL_IN_MS", ()=>POLL_INTERVAL_IN_MS);
parcelHelpers.export(exports, "terminalStates", ()=>terminalStates);
const POLL_INTERVAL_IN_MS = 2000;
const terminalStates = [
    "succeeded",
    "canceled",
    "failed"
];

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3anhV":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Returns a poller factory.
 */ parcelHelpers.export(exports, "buildCreatePoller", ()=>buildCreatePoller);
var _operationJs = require("./operation.js");
var _constantsJs = require("./constants.js");
var _coreUtil = require("@azure/core-util");
const createStateProxy = ()=>({
        /**
     * The state at this point is created to be of type OperationState<TResult>.
     * It will be updated later to be of type TState when the
     * customer-provided callback, `updateState`, is called during polling.
     */ initState: (config)=>({
                status: "running",
                config
            }),
        setCanceled: (state)=>state.status = "canceled",
        setError: (state, error)=>state.error = error,
        setResult: (state, result)=>state.result = result,
        setRunning: (state)=>state.status = "running",
        setSucceeded: (state)=>state.status = "succeeded",
        setFailed: (state)=>state.status = "failed",
        getError: (state)=>state.error,
        getResult: (state)=>state.result,
        isCanceled: (state)=>state.status === "canceled",
        isFailed: (state)=>state.status === "failed",
        isRunning: (state)=>state.status === "running",
        isSucceeded: (state)=>state.status === "succeeded"
    });
function buildCreatePoller(inputs) {
    const { getOperationLocation, getStatusFromInitialResponse, getStatusFromPollResponse, isOperationError, getResourceLocation, getPollingInterval, getError, resolveOnUnsuccessful } = inputs;
    return async ({ init, poll }, options)=>{
        const { processResult, updateState, withOperationLocation: withOperationLocationCallback, intervalInMs = (0, _constantsJs.POLL_INTERVAL_IN_MS), restoreFrom } = options || {};
        const stateProxy = createStateProxy();
        const withOperationLocation = withOperationLocationCallback ? (()=>{
            let called = false;
            return (operationLocation, isUpdated)=>{
                if (isUpdated) withOperationLocationCallback(operationLocation);
                else if (!called) withOperationLocationCallback(operationLocation);
                called = true;
            };
        })() : undefined;
        const state = restoreFrom ? (0, _operationJs.deserializeState)(restoreFrom) : await (0, _operationJs.initOperation)({
            init,
            stateProxy,
            processResult,
            getOperationStatus: getStatusFromInitialResponse,
            withOperationLocation,
            setErrorAsResult: !resolveOnUnsuccessful
        });
        let resultPromise;
        const abortController = new AbortController();
        const handlers = new Map();
        const handleProgressEvents = async ()=>handlers.forEach((h)=>h(state));
        const cancelErrMsg = "Operation was canceled";
        let currentPollIntervalInMs = intervalInMs;
        const poller = {
            getOperationState: ()=>state,
            getResult: ()=>state.result,
            isDone: ()=>[
                    "succeeded",
                    "failed",
                    "canceled"
                ].includes(state.status),
            isStopped: ()=>resultPromise === undefined,
            stopPolling: ()=>{
                abortController.abort();
            },
            toString: ()=>JSON.stringify({
                    state
                }),
            onProgress: (callback)=>{
                const s = Symbol();
                handlers.set(s, callback);
                return ()=>handlers.delete(s);
            },
            pollUntilDone: (pollOptions)=>resultPromise !== null && resultPromise !== void 0 ? resultPromise : resultPromise = (async ()=>{
                    const { abortSignal: inputAbortSignal } = pollOptions || {};
                    // In the future we can use AbortSignal.any() instead
                    function abortListener() {
                        abortController.abort();
                    }
                    const abortSignal = abortController.signal;
                    if (inputAbortSignal === null || inputAbortSignal === void 0 ? void 0 : inputAbortSignal.aborted) abortController.abort();
                    else if (!abortSignal.aborted) inputAbortSignal === null || inputAbortSignal === void 0 || inputAbortSignal.addEventListener("abort", abortListener, {
                        once: true
                    });
                    try {
                        if (!poller.isDone()) {
                            await poller.poll({
                                abortSignal
                            });
                            while(!poller.isDone()){
                                await (0, _coreUtil.delay)(currentPollIntervalInMs, {
                                    abortSignal
                                });
                                await poller.poll({
                                    abortSignal
                                });
                            }
                        }
                    } finally{
                        inputAbortSignal === null || inputAbortSignal === void 0 || inputAbortSignal.removeEventListener("abort", abortListener);
                    }
                    if (resolveOnUnsuccessful) return poller.getResult();
                    else switch(state.status){
                        case "succeeded":
                            return poller.getResult();
                        case "canceled":
                            throw new Error(cancelErrMsg);
                        case "failed":
                            throw state.error;
                        case "notStarted":
                        case "running":
                            throw new Error(`Polling completed without succeeding or failing`);
                    }
                })().finally(()=>{
                    resultPromise = undefined;
                }),
            async poll (pollOptions) {
                if (resolveOnUnsuccessful) {
                    if (poller.isDone()) return;
                } else switch(state.status){
                    case "succeeded":
                        return;
                    case "canceled":
                        throw new Error(cancelErrMsg);
                    case "failed":
                        throw state.error;
                }
                await (0, _operationJs.pollOperation)({
                    poll,
                    state,
                    stateProxy,
                    getOperationLocation,
                    isOperationError,
                    withOperationLocation,
                    getPollingInterval,
                    getOperationStatus: getStatusFromPollResponse,
                    getResourceLocation,
                    processResult,
                    getError,
                    updateState,
                    options: pollOptions,
                    setDelay: (pollIntervalInMs)=>{
                        currentPollIntervalInMs = pollIntervalInMs;
                    },
                    setErrorAsResult: !resolveOnUnsuccessful
                });
                await handleProgressEvents();
                if (!resolveOnUnsuccessful) switch(state.status){
                    case "canceled":
                        throw new Error(cancelErrMsg);
                    case "failed":
                        throw state.error;
                }
            }
        };
        return poller;
    };
}

},{"./operation.js":"12Zcj","./constants.js":"jCOJU","@azure/core-util":"b31OK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ktHZr":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "LroEngine", ()=>(0, _lroEngineJs.LroEngine));
var _lroEngineJs = require("./lroEngine.js");

},{"./lroEngine.js":"8Oguj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Oguj":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * The LRO Engine, a class that performs polling.
 */ parcelHelpers.export(exports, "LroEngine", ()=>LroEngine);
var _operationJs = require("./operation.js");
var _constantsJs = require("../../poller/constants.js");
var _pollerJs = require("../poller.js");
var _operationJs1 = require("../../poller/operation.js");
class LroEngine extends (0, _pollerJs.Poller) {
    constructor(lro, options){
        const { intervalInMs = (0, _constantsJs.POLL_INTERVAL_IN_MS), resumeFrom, resolveOnUnsuccessful = false, isDone, lroResourceLocationConfig, processResult, updateState } = options || {};
        const state = resumeFrom ? (0, _operationJs1.deserializeState)(resumeFrom) : {};
        const operation = new (0, _operationJs.GenericPollOperation)(state, lro, !resolveOnUnsuccessful, lroResourceLocationConfig, processResult, updateState, isDone);
        super(operation);
        this.resolveOnUnsuccessful = resolveOnUnsuccessful;
        this.config = {
            intervalInMs: intervalInMs
        };
        operation.setPollerConfig(this.config);
    }
    /**
     * The method used by the poller to wait before attempting to update its operation.
     */ delay() {
        return new Promise((resolve)=>setTimeout(()=>resolve(), this.config.intervalInMs));
    }
}

},{"./operation.js":"gFr2n","../../poller/constants.js":"jCOJU","../poller.js":"9uddL","../../poller/operation.js":"12Zcj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gFr2n":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "GenericPollOperation", ()=>GenericPollOperation);
var _operationJs = require("../../http/operation.js");
var _loggerJs = require("../../logger.js");
const createStateProxy = ()=>({
        initState: (config)=>({
                config,
                isStarted: true
            }),
        setCanceled: (state)=>state.isCancelled = true,
        setError: (state, error)=>state.error = error,
        setResult: (state, result)=>state.result = result,
        setRunning: (state)=>state.isStarted = true,
        setSucceeded: (state)=>state.isCompleted = true,
        setFailed: ()=>{
        /** empty body */ },
        getError: (state)=>state.error,
        getResult: (state)=>state.result,
        isCanceled: (state)=>!!state.isCancelled,
        isFailed: (state)=>!!state.error,
        isRunning: (state)=>!!state.isStarted,
        isSucceeded: (state)=>Boolean(state.isCompleted && !state.isCancelled && !state.error)
    });
class GenericPollOperation {
    constructor(state, lro, setErrorAsResult, lroResourceLocationConfig, processResult, updateState, isDone){
        this.state = state;
        this.lro = lro;
        this.setErrorAsResult = setErrorAsResult;
        this.lroResourceLocationConfig = lroResourceLocationConfig;
        this.processResult = processResult;
        this.updateState = updateState;
        this.isDone = isDone;
    }
    setPollerConfig(pollerConfig) {
        this.pollerConfig = pollerConfig;
    }
    async update(options) {
        var _a;
        const stateProxy = createStateProxy();
        if (!this.state.isStarted) this.state = Object.assign(Object.assign({}, this.state), await (0, _operationJs.initHttpOperation)({
            lro: this.lro,
            stateProxy,
            resourceLocationConfig: this.lroResourceLocationConfig,
            processResult: this.processResult,
            setErrorAsResult: this.setErrorAsResult
        }));
        const updateState = this.updateState;
        const isDone = this.isDone;
        if (!this.state.isCompleted && this.state.error === undefined) await (0, _operationJs.pollHttpOperation)({
            lro: this.lro,
            state: this.state,
            stateProxy,
            processResult: this.processResult,
            updateState: updateState ? (state, { rawResponse })=>updateState(state, rawResponse) : undefined,
            isDone: isDone ? ({ flatResponse }, state)=>isDone(flatResponse, state) : undefined,
            options,
            setDelay: (intervalInMs)=>{
                this.pollerConfig.intervalInMs = intervalInMs;
            },
            setErrorAsResult: this.setErrorAsResult
        });
        (_a = options === null || options === void 0 ? void 0 : options.fireProgress) === null || _a === void 0 || _a.call(options, this.state);
        return this;
    }
    async cancel() {
        (0, _loggerJs.logger).error("`cancelOperation` is deprecated because it wasn't implemented");
        return this;
    }
    /**
     * Serializes the Poller operation.
     */ toString() {
        return JSON.stringify({
            state: this.state
        });
    }
}

},{"../../http/operation.js":"832j4","../../logger.js":"4SdSF","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9uddL":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * When a poller is manually stopped through the `stopPolling` method,
 * the poller will be rejected with an instance of the PollerStoppedError.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "PollerStoppedError", ()=>PollerStoppedError);
/**
 * When the operation is cancelled, the poller will be rejected with an instance
 * of the PollerCancelledError.
 */ parcelHelpers.export(exports, "PollerCancelledError", ()=>PollerCancelledError);
/**
 * A class that represents the definition of a program that polls through consecutive requests
 * until it reaches a state of completion.
 *
 * A poller can be executed manually, by polling request by request by calling to the `poll()` method repeatedly, until its operation is completed.
 * It also provides a way to wait until the operation completes, by calling `pollUntilDone()` and waiting until the operation finishes.
 * Pollers can also request the cancellation of the ongoing process to whom is providing the underlying long running operation.
 *
 * ```ts
 * const poller = new MyPoller();
 *
 * // Polling just once:
 * await poller.poll();
 *
 * // We can try to cancel the request here, by calling:
 * //
 * //     await poller.cancelOperation();
 * //
 *
 * // Getting the final result:
 * const result = await poller.pollUntilDone();
 * ```
 *
 * The Poller is defined by two types, a type representing the state of the poller, which
 * must include a basic set of properties from `PollOperationState<TResult>`,
 * and a return type defined by `TResult`, which can be anything.
 *
 * The Poller class implements the `PollerLike` interface, which allows poller implementations to avoid having
 * to export the Poller's class directly, and instead only export the already instantiated poller with the PollerLike type.
 *
 * ```ts
 * class Client {
 *   public async makePoller: PollerLike<MyOperationState, MyResult> {
 *     const poller = new MyPoller({});
 *     // It might be preferred to return the poller after the first request is made,
 *     // so that some information can be obtained right away.
 *     await poller.poll();
 *     return poller;
 *   }
 * }
 *
 * const poller: PollerLike<MyOperationState, MyResult> = myClient.makePoller();
 * ```
 *
 * A poller can be created through its constructor, then it can be polled until it's completed.
 * At any point in time, the state of the poller can be obtained without delay through the getOperationState method.
 * At any point in time, the intermediate forms of the result type can be requested without delay.
 * Once the underlying operation is marked as completed, the poller will stop and the final value will be returned.
 *
 * ```ts
 * const poller = myClient.makePoller();
 * const state: MyOperationState = poller.getOperationState();
 *
 * // The intermediate result can be obtained at any time.
 * const result: MyResult | undefined = poller.getResult();
 *
 * // The final result can only be obtained after the poller finishes.
 * const result: MyResult = await poller.pollUntilDone();
 * ```
 *
 */ // eslint-disable-next-line no-use-before-define
parcelHelpers.export(exports, "Poller", ()=>Poller);
class PollerStoppedError extends Error {
    constructor(message){
        super(message);
        this.name = "PollerStoppedError";
        Object.setPrototypeOf(this, PollerStoppedError.prototype);
    }
}
class PollerCancelledError extends Error {
    constructor(message){
        super(message);
        this.name = "PollerCancelledError";
        Object.setPrototypeOf(this, PollerCancelledError.prototype);
    }
}
class Poller {
    /**
     * A poller needs to be initialized by passing in at least the basic properties of the `PollOperation<TState, TResult>`.
     *
     * When writing an implementation of a Poller, this implementation needs to deal with the initialization
     * of any custom state beyond the basic definition of the poller. The basic poller assumes that the poller's
     * operation has already been defined, at least its basic properties. The code below shows how to approach
     * the definition of the constructor of a new custom poller.
     *
     * ```ts
     * export class MyPoller extends Poller<MyOperationState, string> {
     *   constructor({
     *     // Anything you might need outside of the basics
     *   }) {
     *     let state: MyOperationState = {
     *       privateProperty: private,
     *       publicProperty: public,
     *     };
     *
     *     const operation = {
     *       state,
     *       update,
     *       cancel,
     *       toString
     *     }
     *
     *     // Sending the operation to the parent's constructor.
     *     super(operation);
     *
     *     // You can assign more local properties here.
     *   }
     * }
     * ```
     *
     * Inside of this constructor, a new promise is created. This will be used to
     * tell the user when the poller finishes (see `pollUntilDone()`). The promise's
     * resolve and reject methods are also used internally to control when to resolve
     * or reject anyone waiting for the poller to finish.
     *
     * The constructor of a custom implementation of a poller is where any serialized version of
     * a previous poller's operation should be deserialized into the operation sent to the
     * base constructor. For example:
     *
     * ```ts
     * export class MyPoller extends Poller<MyOperationState, string> {
     *   constructor(
     *     baseOperation: string | undefined
     *   ) {
     *     let state: MyOperationState = {};
     *     if (baseOperation) {
     *       state = {
     *         ...JSON.parse(baseOperation).state,
     *         ...state
     *       };
     *     }
     *     const operation = {
     *       state,
     *       // ...
     *     }
     *     super(operation);
     *   }
     * }
     * ```
     *
     * @param operation - Must contain the basic properties of `PollOperation<State, TResult>`.
     */ constructor(operation){
        /** controls whether to throw an error if the operation failed or was canceled. */ this.resolveOnUnsuccessful = false;
        this.stopped = true;
        this.pollProgressCallbacks = [];
        this.operation = operation;
        this.promise = new Promise((resolve, reject)=>{
            this.resolve = resolve;
            this.reject = reject;
        });
        // This prevents the UnhandledPromiseRejectionWarning in node.js from being thrown.
        // The above warning would get thrown if `poller.poll` is called, it returns an error,
        // and pullUntilDone did not have a .catch or await try/catch on it's return value.
        this.promise.catch(()=>{
        /* intentionally blank */ });
    }
    /**
     * Starts a loop that will break only if the poller is done
     * or if the poller is stopped.
     */ async startPolling(pollOptions = {}) {
        if (this.stopped) this.stopped = false;
        while(!this.isStopped() && !this.isDone()){
            await this.poll(pollOptions);
            await this.delay();
        }
    }
    /**
     * pollOnce does one polling, by calling to the update method of the underlying
     * poll operation to make any relevant change effective.
     *
     * It only optionally receives an object with an abortSignal property, from \@azure/abort-controller's AbortSignalLike.
     *
     * @param options - Optional properties passed to the operation's update method.
     */ async pollOnce(options = {}) {
        if (!this.isDone()) this.operation = await this.operation.update({
            abortSignal: options.abortSignal,
            fireProgress: this.fireProgress.bind(this)
        });
        this.processUpdatedState();
    }
    /**
     * fireProgress calls the functions passed in via onProgress the method of the poller.
     *
     * It loops over all of the callbacks received from onProgress, and executes them, sending them
     * the current operation state.
     *
     * @param state - The current operation state.
     */ fireProgress(state) {
        for (const callback of this.pollProgressCallbacks)callback(state);
    }
    /**
     * Invokes the underlying operation's cancel method.
     */ async cancelOnce(options = {}) {
        this.operation = await this.operation.cancel(options);
    }
    /**
     * Returns a promise that will resolve once a single polling request finishes.
     * It does this by calling the update method of the Poller's operation.
     *
     * It only optionally receives an object with an abortSignal property, from \@azure/abort-controller's AbortSignalLike.
     *
     * @param options - Optional properties passed to the operation's update method.
     */ poll(options = {}) {
        if (!this.pollOncePromise) {
            this.pollOncePromise = this.pollOnce(options);
            const clearPollOncePromise = ()=>{
                this.pollOncePromise = undefined;
            };
            this.pollOncePromise.then(clearPollOncePromise, clearPollOncePromise).catch(this.reject);
        }
        return this.pollOncePromise;
    }
    processUpdatedState() {
        if (this.operation.state.error) {
            this.stopped = true;
            if (!this.resolveOnUnsuccessful) {
                this.reject(this.operation.state.error);
                throw this.operation.state.error;
            }
        }
        if (this.operation.state.isCancelled) {
            this.stopped = true;
            if (!this.resolveOnUnsuccessful) {
                const error = new PollerCancelledError("Operation was canceled");
                this.reject(error);
                throw error;
            }
        }
        if (this.isDone() && this.resolve) // If the poller has finished polling, this means we now have a result.
        // However, it can be the case that TResult is instantiated to void, so
        // we are not expecting a result anyway. To assert that we might not
        // have a result eventually after finishing polling, we cast the result
        // to TResult.
        this.resolve(this.getResult());
    }
    /**
     * Returns a promise that will resolve once the underlying operation is completed.
     */ async pollUntilDone(pollOptions = {}) {
        if (this.stopped) this.startPolling(pollOptions).catch(this.reject);
        // This is needed because the state could have been updated by
        // `cancelOperation`, e.g. the operation is canceled or an error occurred.
        this.processUpdatedState();
        return this.promise;
    }
    /**
     * Invokes the provided callback after each polling is completed,
     * sending the current state of the poller's operation.
     *
     * It returns a method that can be used to stop receiving updates on the given callback function.
     */ onProgress(callback) {
        this.pollProgressCallbacks.push(callback);
        return ()=>{
            this.pollProgressCallbacks = this.pollProgressCallbacks.filter((c)=>c !== callback);
        };
    }
    /**
     * Returns true if the poller has finished polling.
     */ isDone() {
        const state = this.operation.state;
        return Boolean(state.isCompleted || state.isCancelled || state.error);
    }
    /**
     * Stops the poller from continuing to poll.
     */ stopPolling() {
        if (!this.stopped) {
            this.stopped = true;
            if (this.reject) this.reject(new PollerStoppedError("This poller is already stopped"));
        }
    }
    /**
     * Returns true if the poller is stopped.
     */ isStopped() {
        return this.stopped;
    }
    /**
     * Attempts to cancel the underlying operation.
     *
     * It only optionally receives an object with an abortSignal property, from \@azure/abort-controller's AbortSignalLike.
     *
     * If it's called again before it finishes, it will throw an error.
     *
     * @param options - Optional properties passed to the operation's update method.
     */ cancelOperation(options = {}) {
        if (!this.cancelPromise) this.cancelPromise = this.cancelOnce(options);
        else if (options.abortSignal) throw new Error("A cancel request is currently pending");
        return this.cancelPromise;
    }
    /**
     * Returns the state of the operation.
     *
     * Even though TState will be the same type inside any of the methods of any extension of the Poller class,
     * implementations of the pollers can customize what's shared with the public by writing their own
     * version of the `getOperationState` method, and by defining two types, one representing the internal state of the poller
     * and a public type representing a safe to share subset of the properties of the internal state.
     * Their definition of getOperationState can then return their public type.
     *
     * Example:
     *
     * ```ts
     * // Let's say we have our poller's operation state defined as:
     * interface MyOperationState extends PollOperationState<ResultType> {
     *   privateProperty?: string;
     *   publicProperty?: string;
     * }
     *
     * // To allow us to have a true separation of public and private state, we have to define another interface:
     * interface PublicState extends PollOperationState<ResultType> {
     *   publicProperty?: string;
     * }
     *
     * // Then, we define our Poller as follows:
     * export class MyPoller extends Poller<MyOperationState, ResultType> {
     *   // ... More content is needed here ...
     *
     *   public getOperationState(): PublicState {
     *     const state: PublicState = this.operation.state;
     *     return {
     *       // Properties from PollOperationState<TResult>
     *       isStarted: state.isStarted,
     *       isCompleted: state.isCompleted,
     *       isCancelled: state.isCancelled,
     *       error: state.error,
     *       result: state.result,
     *
     *       // The only other property needed by PublicState.
     *       publicProperty: state.publicProperty
     *     }
     *   }
     * }
     * ```
     *
     * You can see this in the tests of this repository, go to the file:
     * `../test/utils/testPoller.ts`
     * and look for the getOperationState implementation.
     */ getOperationState() {
        return this.operation.state;
    }
    /**
     * Returns the result value of the operation,
     * regardless of the state of the poller.
     * It can return undefined or an incomplete form of the final TResult value
     * depending on the implementation.
     */ getResult() {
        const state = this.operation.state;
        return state.result;
    }
    /**
     * Returns a serialized version of the poller's operation
     * by invoking the operation's toString method.
     */ toString() {
        return this.operation.toString();
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7LG63":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6C9e2":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Generate a range string. For example:
 *
 * "bytes=255-" or "bytes=0-511"
 *
 * @param iRange -
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "rangeToString", ()=>rangeToString);
function rangeToString(iRange) {
    if (iRange.offset < 0) throw new RangeError(`Range.offset cannot be smaller than 0.`);
    if (iRange.count && iRange.count <= 0) throw new RangeError(`Range.count must be larger than 0. Leave it undefined if you want a range from offset to the end.`);
    return iRange.count ? `bytes=${iRange.offset}-${iRange.offset + iRange.count - 1}` : `bytes=${iRange.offset}-`;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l9Xq9":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
// In browser, during webpack or browserify bundling, this module will be replaced by 'events'
// https://github.com/Gozala/events
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Batch provides basic parallel execution with concurrency limits.
 * Will stop execute left operations when one of the executed operation throws an error.
 * But Batch cannot cancel ongoing operations, you need to cancel them by yourself.
 */ parcelHelpers.export(exports, "Batch", ()=>Batch);
var _events = require("events");
/**
 * States for Batch.
 */ var BatchStates;
(function(BatchStates) {
    BatchStates[BatchStates["Good"] = 0] = "Good";
    BatchStates[BatchStates["Error"] = 1] = "Error";
})(BatchStates || (BatchStates = {}));
class Batch {
    /**
     * Creates an instance of Batch.
     * @param concurrency -
     */ constructor(concurrency = 5){
        /**
         * Number of active operations under execution.
         */ this.actives = 0;
        /**
         * Number of completed operations under execution.
         */ this.completed = 0;
        /**
         * Offset of next operation to be executed.
         */ this.offset = 0;
        /**
         * Operation array to be executed.
         */ this.operations = [];
        /**
         * States of Batch. When an error happens, state will turn into error.
         * Batch will stop execute left operations.
         */ this.state = BatchStates.Good;
        if (concurrency < 1) throw new RangeError("concurrency must be larger than 0");
        this.concurrency = concurrency;
        this.emitter = new (0, _events.EventEmitter)();
    }
    /**
     * Add a operation into queue.
     *
     * @param operation -
     */ addOperation(operation) {
        this.operations.push(async ()=>{
            try {
                this.actives++;
                await operation();
                this.actives--;
                this.completed++;
                this.parallelExecute();
            } catch (error) {
                this.emitter.emit("error", error);
            }
        });
    }
    /**
     * Start execute operations in the queue.
     *
     */ async do() {
        if (this.operations.length === 0) return Promise.resolve();
        this.parallelExecute();
        return new Promise((resolve, reject)=>{
            this.emitter.on("finish", resolve);
            this.emitter.on("error", (error)=>{
                this.state = BatchStates.Error;
                reject(error);
            });
        });
    }
    /**
     * Get next operation to be executed. Return null when reaching ends.
     *
     */ nextOperation() {
        if (this.offset < this.operations.length) return this.operations[this.offset++];
        return null;
    }
    /**
     * Start execute operations. One one the most important difference between
     * this method with do() is that do() wraps as an sync method.
     *
     */ parallelExecute() {
        if (this.state === BatchStates.Error) return;
        if (this.completed >= this.operations.length) {
            this.emitter.emit("finish");
            return;
        }
        while(this.actives < this.concurrency){
            const operation = this.nextOperation();
            if (operation) operation();
            else return;
        }
    }
}

},{"events":"1VQLm","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1VQLm":[function(require,module,exports) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
"use strict";
var R = typeof Reflect === "object" ? Reflect : null;
var ReflectApply = R && typeof R.apply === "function" ? R.apply : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
};
var ReflectOwnKeys;
if (R && typeof R.ownKeys === "function") ReflectOwnKeys = R.ownKeys;
else if (Object.getOwnPropertySymbols) ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target).concat(Object.getOwnPropertySymbols(target));
};
else ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
};
function ProcessEmitWarning(warning) {
    if (console && console.warn) console.warn(warning);
}
var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
    return value !== value;
};
function EventEmitter() {
    EventEmitter.init.call(this);
}
module.exports = EventEmitter;
module.exports.once = once;
// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;
EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;
// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;
function checkListener(listener) {
    if (typeof listener !== "function") throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
}
Object.defineProperty(EventEmitter, "defaultMaxListeners", {
    enumerable: true,
    get: function() {
        return defaultMaxListeners;
    },
    set: function(arg) {
        if (typeof arg !== "number" || arg < 0 || NumberIsNaN(arg)) throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + ".");
        defaultMaxListeners = arg;
    }
});
EventEmitter.init = function() {
    if (this._events === undefined || this._events === Object.getPrototypeOf(this)._events) {
        this._events = Object.create(null);
        this._eventsCount = 0;
    }
    this._maxListeners = this._maxListeners || undefined;
};
// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
    if (typeof n !== "number" || n < 0 || NumberIsNaN(n)) throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + ".");
    this._maxListeners = n;
    return this;
};
function _getMaxListeners(that) {
    if (that._maxListeners === undefined) return EventEmitter.defaultMaxListeners;
    return that._maxListeners;
}
EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
    return _getMaxListeners(this);
};
EventEmitter.prototype.emit = function emit(type) {
    var args = [];
    for(var i = 1; i < arguments.length; i++)args.push(arguments[i]);
    var doError = type === "error";
    var events = this._events;
    if (events !== undefined) doError = doError && events.error === undefined;
    else if (!doError) return false;
    // If there is no 'error' event listener then throw.
    if (doError) {
        var er;
        if (args.length > 0) er = args[0];
        if (er instanceof Error) // Note: The comments on the `throw` lines are intentional, they show
        // up in Node's output if this results in an unhandled exception.
        throw er; // Unhandled 'error' event
        // At least give some kind of context to the user
        var err = new Error("Unhandled error." + (er ? " (" + er.message + ")" : ""));
        err.context = er;
        throw err; // Unhandled 'error' event
    }
    var handler = events[type];
    if (handler === undefined) return false;
    if (typeof handler === "function") ReflectApply(handler, this, args);
    else {
        var len = handler.length;
        var listeners = arrayClone(handler, len);
        for(var i = 0; i < len; ++i)ReflectApply(listeners[i], this, args);
    }
    return true;
};
function _addListener(target, type, listener, prepend) {
    var m;
    var events;
    var existing;
    checkListener(listener);
    events = target._events;
    if (events === undefined) {
        events = target._events = Object.create(null);
        target._eventsCount = 0;
    } else {
        // To avoid recursion in the case that type === "newListener"! Before
        // adding it to the listeners, first emit "newListener".
        if (events.newListener !== undefined) {
            target.emit("newListener", type, listener.listener ? listener.listener : listener);
            // Re-assign `events` because a newListener handler could have caused the
            // this._events to be assigned to a new object
            events = target._events;
        }
        existing = events[type];
    }
    if (existing === undefined) {
        // Optimize the case of one listener. Don't need the extra array object.
        existing = events[type] = listener;
        ++target._eventsCount;
    } else {
        if (typeof existing === "function") // Adding the second element, need to change to array.
        existing = events[type] = prepend ? [
            listener,
            existing
        ] : [
            existing,
            listener
        ];
        else if (prepend) existing.unshift(listener);
        else existing.push(listener);
        // Check for listener leak
        m = _getMaxListeners(target);
        if (m > 0 && existing.length > m && !existing.warned) {
            existing.warned = true;
            // No error code for this since it is a Warning
            // eslint-disable-next-line no-restricted-syntax
            var w = new Error("Possible EventEmitter memory leak detected. " + existing.length + " " + String(type) + " listeners " + "added. Use emitter.setMaxListeners() to " + "increase limit");
            w.name = "MaxListenersExceededWarning";
            w.emitter = target;
            w.type = type;
            w.count = existing.length;
            ProcessEmitWarning(w);
        }
    }
    return target;
}
EventEmitter.prototype.addListener = function addListener(type, listener) {
    return _addListener(this, type, listener, false);
};
EventEmitter.prototype.on = EventEmitter.prototype.addListener;
EventEmitter.prototype.prependListener = function prependListener(type, listener) {
    return _addListener(this, type, listener, true);
};
function onceWrapper() {
    if (!this.fired) {
        this.target.removeListener(this.type, this.wrapFn);
        this.fired = true;
        if (arguments.length === 0) return this.listener.call(this.target);
        return this.listener.apply(this.target, arguments);
    }
}
function _onceWrap(target, type, listener) {
    var state = {
        fired: false,
        wrapFn: undefined,
        target: target,
        type: type,
        listener: listener
    };
    var wrapped = onceWrapper.bind(state);
    wrapped.listener = listener;
    state.wrapFn = wrapped;
    return wrapped;
}
EventEmitter.prototype.once = function once(type, listener) {
    checkListener(listener);
    this.on(type, _onceWrap(this, type, listener));
    return this;
};
EventEmitter.prototype.prependOnceListener = function prependOnceListener(type, listener) {
    checkListener(listener);
    this.prependListener(type, _onceWrap(this, type, listener));
    return this;
};
// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener = function removeListener(type, listener) {
    var list, events, position, i, originalListener;
    checkListener(listener);
    events = this._events;
    if (events === undefined) return this;
    list = events[type];
    if (list === undefined) return this;
    if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0) this._events = Object.create(null);
        else {
            delete events[type];
            if (events.removeListener) this.emit("removeListener", type, list.listener || listener);
        }
    } else if (typeof list !== "function") {
        position = -1;
        for(i = list.length - 1; i >= 0; i--)if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
        }
        if (position < 0) return this;
        if (position === 0) list.shift();
        else spliceOne(list, position);
        if (list.length === 1) events[type] = list[0];
        if (events.removeListener !== undefined) this.emit("removeListener", type, originalListener || listener);
    }
    return this;
};
EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
EventEmitter.prototype.removeAllListeners = function removeAllListeners(type) {
    var listeners, events, i;
    events = this._events;
    if (events === undefined) return this;
    // not listening for removeListener, no need to emit
    if (events.removeListener === undefined) {
        if (arguments.length === 0) {
            this._events = Object.create(null);
            this._eventsCount = 0;
        } else if (events[type] !== undefined) {
            if (--this._eventsCount === 0) this._events = Object.create(null);
            else delete events[type];
        }
        return this;
    }
    // emit removeListener for all listeners on all events
    if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for(i = 0; i < keys.length; ++i){
            key = keys[i];
            if (key === "removeListener") continue;
            this.removeAllListeners(key);
        }
        this.removeAllListeners("removeListener");
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
    }
    listeners = events[type];
    if (typeof listeners === "function") this.removeListener(type, listeners);
    else if (listeners !== undefined) // LIFO order
    for(i = listeners.length - 1; i >= 0; i--)this.removeListener(type, listeners[i]);
    return this;
};
function _listeners(target, type, unwrap) {
    var events = target._events;
    if (events === undefined) return [];
    var evlistener = events[type];
    if (evlistener === undefined) return [];
    if (typeof evlistener === "function") return unwrap ? [
        evlistener.listener || evlistener
    ] : [
        evlistener
    ];
    return unwrap ? unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}
EventEmitter.prototype.listeners = function listeners(type) {
    return _listeners(this, type, true);
};
EventEmitter.prototype.rawListeners = function rawListeners(type) {
    return _listeners(this, type, false);
};
EventEmitter.listenerCount = function(emitter, type) {
    if (typeof emitter.listenerCount === "function") return emitter.listenerCount(type);
    else return listenerCount.call(emitter, type);
};
EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
    var events = this._events;
    if (events !== undefined) {
        var evlistener = events[type];
        if (typeof evlistener === "function") return 1;
        else if (evlistener !== undefined) return evlistener.length;
    }
    return 0;
}
EventEmitter.prototype.eventNames = function eventNames() {
    return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};
function arrayClone(arr, n) {
    var copy = new Array(n);
    for(var i = 0; i < n; ++i)copy[i] = arr[i];
    return copy;
}
function spliceOne(list, index) {
    for(; index + 1 < list.length; index++)list[index] = list[index + 1];
    list.pop();
}
function unwrapListeners(arr) {
    var ret = new Array(arr.length);
    for(var i = 0; i < ret.length; ++i)ret[i] = arr[i].listener || arr[i];
    return ret;
}
function once(emitter, name) {
    return new Promise(function(resolve, reject) {
        function errorListener(err) {
            emitter.removeListener(name, resolver);
            reject(err);
        }
        function resolver() {
            if (typeof emitter.removeListener === "function") emitter.removeListener("error", errorListener);
            resolve([].slice.call(arguments));
        }
        eventTargetAgnosticAddListener(emitter, name, resolver, {
            once: true
        });
        if (name !== "error") addErrorHandlerIfEventEmitter(emitter, errorListener, {
            once: true
        });
    });
}
function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
    if (typeof emitter.on === "function") eventTargetAgnosticAddListener(emitter, "error", handler, flags);
}
function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
    if (typeof emitter.on === "function") {
        if (flags.once) emitter.once(name, listener);
        else emitter.on(name, listener);
    } else if (typeof emitter.addEventListener === "function") // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
        // IE does not have builtin `{ once: true }` support so we
        // have to do it manually.
        if (flags.once) emitter.removeEventListener(name, wrapListener);
        listener(arg);
    });
    else throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
}

},{}],"h0c80":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _bufferSchedulerBrowser = require("./BufferScheduler.browser");
parcelHelpers.exportAll(_bufferSchedulerBrowser, exports);

},{"./BufferScheduler.browser":"hSlhb","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hSlhb":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
// This file is used as a shim of "BufferScheduler" for some browser bundlers
// when trying to bundle "BufferScheduler"
// "BufferScheduler" class is only available in Node.js runtime
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BufferScheduler", ()=>BufferScheduler);
class BufferScheduler {
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8nPkP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Convert a Browser Blob object into ArrayBuffer.
 *
 * @param blob -
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "blobToArrayBuffer", ()=>blobToArrayBuffer);
/**
 * Convert a Browser Blob object into string.
 *
 * @param blob -
 */ parcelHelpers.export(exports, "blobToString", ()=>blobToString);
parcelHelpers.export(exports, "streamToBuffer", ()=>streamToBuffer);
parcelHelpers.export(exports, "streamToBuffer2", ()=>streamToBuffer2);
parcelHelpers.export(exports, "readStreamToLocalFile", ()=>readStreamToLocalFile);
parcelHelpers.export(exports, "fsStat", ()=>fsStat);
parcelHelpers.export(exports, "fsCreateReadStream", ()=>fsCreateReadStream);
async function blobToArrayBuffer(blob) {
    const fileReader = new FileReader();
    return new Promise((resolve, reject)=>{
        fileReader.onloadend = (ev)=>{
            resolve(ev.target.result);
        };
        fileReader.onerror = reject;
        fileReader.readAsArrayBuffer(blob);
    });
}
async function blobToString(blob) {
    const fileReader = new FileReader();
    return new Promise((resolve, reject)=>{
        fileReader.onloadend = (ev)=>{
            resolve(ev.target.result);
        };
        fileReader.onerror = reject;
        fileReader.readAsText(blob);
    });
}
function streamToBuffer() {
/* empty */ }
function streamToBuffer2() {
/* empty */ }
function readStreamToLocalFile() {
/* empty */ }
const fsStat = function stat() {
/* empty */ };
const fsCreateReadStream = function createReadStream() {
/* empty */ };

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iF02i":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A BlobBatchClient allows you to make batched requests to the Azure Storage Blob service.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch
 */ parcelHelpers.export(exports, "BlobBatchClient", ()=>BlobBatchClient);
var _batchResponseParser = require("./BatchResponseParser");
var _batchUtils = require("./BatchUtils");
var _blobBatch = require("./BlobBatch");
var _tracing = require("./utils/tracing");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _storageContextClient = require("./StorageContextClient");
var _pipeline = require("./Pipeline");
var _utilsCommon = require("./utils/utils.common");
class BlobBatchClient {
    constructor(url, credentialOrPipeline, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options){
        let pipeline;
        if ((0, _pipeline.isPipelineLike)(credentialOrPipeline)) pipeline = credentialOrPipeline;
        else if (!credentialOrPipeline) // no credential provided
        pipeline = (0, _pipeline.newPipeline)(new (0, _anonymousCredential.AnonymousCredential)(), options);
        else pipeline = (0, _pipeline.newPipeline)(credentialOrPipeline, options);
        const storageClientContext = new (0, _storageContextClient.StorageContextClient)(url, (0, _pipeline.getCoreClientOptions)(pipeline));
        const path = (0, _utilsCommon.getURLPath)(url);
        if (path && path !== "/") // Container scoped.
        this.serviceOrContainerContext = storageClientContext.container;
        else this.serviceOrContainerContext = storageClientContext.service;
    }
    /**
     * Creates a {@link BlobBatch}.
     * A BlobBatch represents an aggregated set of operations on blobs.
     */ createBatch() {
        return new (0, _blobBatch.BlobBatch)();
    }
    async deleteBlobs(urlsOrBlobClients, credentialOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options) {
        const batch = new (0, _blobBatch.BlobBatch)();
        for (const urlOrBlobClient of urlsOrBlobClients)if (typeof urlOrBlobClient === "string") await batch.deleteBlob(urlOrBlobClient, credentialOrOptions, options);
        else await batch.deleteBlob(urlOrBlobClient, credentialOrOptions);
        return this.submitBatch(batch);
    }
    async setBlobsAccessTier(urlsOrBlobClients, credentialOrTier, tierOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/ options) {
        const batch = new (0, _blobBatch.BlobBatch)();
        for (const urlOrBlobClient of urlsOrBlobClients)if (typeof urlOrBlobClient === "string") await batch.setBlobAccessTier(urlOrBlobClient, credentialOrTier, tierOrOptions, options);
        else await batch.setBlobAccessTier(urlOrBlobClient, credentialOrTier, tierOrOptions);
        return this.submitBatch(batch);
    }
    /**
     * Submit batch request which consists of multiple subrequests.
     *
     * Get `blobBatchClient` and other details before running the snippets.
     * `blobServiceClient.getBlobBatchClient()` gives the `blobBatchClient`
     *
     * Example usage:
     *
     * ```js
     * let batchRequest = new BlobBatch();
     * await batchRequest.deleteBlob(urlInString0, credential0);
     * await batchRequest.deleteBlob(urlInString1, credential1, {
     *  deleteSnapshots: "include"
     * });
     * const batchResp = await blobBatchClient.submitBatch(batchRequest);
     * console.log(batchResp.subResponsesSucceededCount);
     * ```
     *
     * Example using a lease:
     *
     * ```js
     * let batchRequest = new BlobBatch();
     * await batchRequest.setBlobAccessTier(blockBlobClient0, "Cool");
     * await batchRequest.setBlobAccessTier(blockBlobClient1, "Cool", {
     *  conditions: { leaseId: leaseId }
     * });
     * const batchResp = await blobBatchClient.submitBatch(batchRequest);
     * console.log(batchResp.subResponsesSucceededCount);
     * ```
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch
     *
     * @param batchRequest - A set of Delete or SetTier operations.
     * @param options -
     */ async submitBatch(batchRequest, options = {}) {
        if (!batchRequest || batchRequest.getSubRequests().size === 0) throw new RangeError("Batch request should contain one or more sub requests.");
        return (0, _tracing.tracingClient).withSpan("BlobBatchClient-submitBatch", options, async (updatedOptions)=>{
            const batchRequestBody = batchRequest.getHttpRequestBody();
            // ServiceSubmitBatchResponseModel and ContainerSubmitBatchResponse are compatible for now.
            const rawBatchResponse = (0, _utilsCommon.assertResponse)(await this.serviceOrContainerContext.submitBatch((0, _batchUtils.utf8ByteLength)(batchRequestBody), batchRequest.getMultiPartContentType(), batchRequestBody, Object.assign({}, updatedOptions)));
            // Parse the sub responses result, if logic reaches here(i.e. the batch request succeeded with status code 202).
            const batchResponseParser = new (0, _batchResponseParser.BatchResponseParser)(rawBatchResponse, batchRequest.getSubRequests());
            const responseSummary = await batchResponseParser.parseBatchResponse();
            const res = {
                _response: rawBatchResponse._response,
                contentType: rawBatchResponse.contentType,
                errorCode: rawBatchResponse.errorCode,
                requestId: rawBatchResponse.requestId,
                clientRequestId: rawBatchResponse.clientRequestId,
                version: rawBatchResponse.version,
                subResponses: responseSummary.subResponses,
                subResponsesSucceededCount: responseSummary.subResponsesSucceededCount,
                subResponsesFailedCount: responseSummary.subResponsesFailedCount
            };
            return res;
        });
    }
}

},{"./BatchResponseParser":"2RaIN","./BatchUtils":"39BTR","./BlobBatch":"Lat0V","./utils/tracing":"m0KjB","./credentials/AnonymousCredential":"f0sOe","./StorageContextClient":"agdqi","./Pipeline":"bsozg","./utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2RaIN":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Util class for parsing batch response.
 */ parcelHelpers.export(exports, "BatchResponseParser", ()=>BatchResponseParser);
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _coreHttpCompat = require("@azure/core-http-compat");
var _constants = require("./utils/constants");
var _batchUtils = require("./BatchUtils");
var _log = require("./log");
const HTTP_HEADER_DELIMITER = ": ";
const SPACE_DELIMITER = " ";
const NOT_FOUND = -1;
class BatchResponseParser {
    constructor(batchResponse, subRequests){
        if (!batchResponse || !batchResponse.contentType) // In special case(reported), server may return invalid content-type which could not be parsed.
        throw new RangeError("batchResponse is malformed or doesn't contain valid content-type.");
        if (!subRequests || subRequests.size === 0) // This should be prevent during coding.
        throw new RangeError("Invalid state: subRequests is not provided or size is 0.");
        this.batchResponse = batchResponse;
        this.subRequests = subRequests;
        this.responseBatchBoundary = this.batchResponse.contentType.split("=")[1];
        this.perResponsePrefix = `--${this.responseBatchBoundary}${0, _constants.HTTP_LINE_ENDING}`;
        this.batchResponseEnding = `--${this.responseBatchBoundary}--`;
    }
    // For example of response, please refer to https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch#response
    async parseBatchResponse() {
        // When logic reach here, suppose batch request has already succeeded with 202, so we can further parse
        // sub request's response.
        if (this.batchResponse._response.status !== (0, _constants.HTTPURLConnection).HTTP_ACCEPTED) throw new Error(`Invalid state: batch request failed with status: '${this.batchResponse._response.status}'.`);
        const responseBodyAsText = await (0, _batchUtils.getBodyAsText)(this.batchResponse);
        const subResponses = responseBodyAsText.split(this.batchResponseEnding)[0] // string after ending is useless
        .split(this.perResponsePrefix).slice(1); // string before first response boundary is useless
        const subResponseCount = subResponses.length;
        // Defensive coding in case of potential error parsing.
        // Note: subResponseCount == 1 is special case where sub request is invalid.
        // We try to prevent such cases through early validation, e.g. validate sub request count >= 1.
        // While in unexpected sub request invalid case, we allow sub response to be parsed and return to user.
        if (subResponseCount !== this.subRequests.size && subResponseCount !== 1) throw new Error("Invalid state: sub responses' count is not equal to sub requests' count.");
        const deserializedSubResponses = new Array(subResponseCount);
        let subResponsesSucceededCount = 0;
        let subResponsesFailedCount = 0;
        // Parse sub subResponses.
        for(let index = 0; index < subResponseCount; index++){
            const subResponse = subResponses[index];
            const deserializedSubResponse = {};
            deserializedSubResponse.headers = (0, _coreHttpCompat.toHttpHeadersLike)((0, _coreRestPipeline.createHttpHeaders)());
            const responseLines = subResponse.split(`${(0, _constants.HTTP_LINE_ENDING)}`);
            let subRespHeaderStartFound = false;
            let subRespHeaderEndFound = false;
            let subRespFailed = false;
            let contentId = NOT_FOUND;
            for (const responseLine of responseLines){
                if (!subRespHeaderStartFound) {
                    // Convention line to indicate content ID
                    if (responseLine.startsWith((0, _constants.HeaderConstants).CONTENT_ID)) contentId = parseInt(responseLine.split(HTTP_HEADER_DELIMITER)[1]);
                    // Http version line with status code indicates the start of sub request's response.
                    // Example: HTTP/1.1 202 Accepted
                    if (responseLine.startsWith((0, _constants.HTTP_VERSION_1_1))) {
                        subRespHeaderStartFound = true;
                        const tokens = responseLine.split(SPACE_DELIMITER);
                        deserializedSubResponse.status = parseInt(tokens[1]);
                        deserializedSubResponse.statusMessage = tokens.slice(2).join(SPACE_DELIMITER);
                    }
                    continue; // Skip convention headers not specifically for sub request i.e. Content-Type: application/http and Content-ID: *
                }
                if (responseLine.trim() === "") {
                    // Sub response's header start line already found, and the first empty line indicates header end line found.
                    if (!subRespHeaderEndFound) subRespHeaderEndFound = true;
                    continue; // Skip empty line
                }
                // Note: when code reach here, it indicates subRespHeaderStartFound == true
                if (!subRespHeaderEndFound) {
                    if (responseLine.indexOf(HTTP_HEADER_DELIMITER) === -1) // Defensive coding to prevent from missing valuable lines.
                    throw new Error(`Invalid state: find non-empty line '${responseLine}' without HTTP header delimiter '${HTTP_HEADER_DELIMITER}'.`);
                    // Parse headers of sub response.
                    const tokens = responseLine.split(HTTP_HEADER_DELIMITER);
                    deserializedSubResponse.headers.set(tokens[0], tokens[1]);
                    if (tokens[0] === (0, _constants.HeaderConstants).X_MS_ERROR_CODE) {
                        deserializedSubResponse.errorCode = tokens[1];
                        subRespFailed = true;
                    }
                } else {
                    // Assemble body of sub response.
                    if (!deserializedSubResponse.bodyAsText) deserializedSubResponse.bodyAsText = "";
                    deserializedSubResponse.bodyAsText += responseLine;
                }
            } // Inner for end
            // The response will contain the Content-ID header for each corresponding subrequest response to use for tracking.
            // The Content-IDs are set to a valid index in the subrequests we sent. In the status code 202 path, we could expect it
            // to be 1-1 mapping from the [0, subRequests.size) to the Content-IDs returned. If not, we simply don't return that
            // unexpected subResponse in the parsed reponse and we can always look it up in the raw response for debugging purpose.
            if (contentId !== NOT_FOUND && Number.isInteger(contentId) && contentId >= 0 && contentId < this.subRequests.size && deserializedSubResponses[contentId] === undefined) {
                deserializedSubResponse._request = this.subRequests.get(contentId);
                deserializedSubResponses[contentId] = deserializedSubResponse;
            } else (0, _log.logger).error(`subResponses[${index}] is dropped as the Content-ID is not found or invalid, Content-ID: ${contentId}`);
            if (subRespFailed) subResponsesFailedCount++;
            else subResponsesSucceededCount++;
        }
        return {
            subResponses: deserializedSubResponses,
            subResponsesSucceededCount: subResponsesSucceededCount,
            subResponsesFailedCount: subResponsesFailedCount
        };
    }
}

},{"@azure/core-rest-pipeline":"d0mqv","@azure/core-http-compat":"1I5Za","./utils/constants":"4gX5x","./BatchUtils":"39BTR","./log":"gc1Rl","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"39BTR":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getBodyAsText", ()=>getBodyAsText);
parcelHelpers.export(exports, "utf8ByteLength", ()=>utf8ByteLength);
var _utilsBrowser = require("./utils/utils.browser");
async function getBodyAsText(batchResponse) {
    const blob = await batchResponse.blobBody;
    return (0, _utilsBrowser.blobToString)(blob);
}
function utf8ByteLength(str) {
    return new Blob([
        str
    ]).size;
}

},{"./utils/utils.browser":"8nPkP","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Lat0V":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A BlobBatch represents an aggregated set of operations on blobs.
 * Currently, only `delete` and `setAccessTier` are supported.
 */ parcelHelpers.export(exports, "BlobBatch", ()=>BlobBatch);
var _coreUtil = require("@azure/core-util");
var _coreAuth = require("@azure/core-auth");
var _coreRestPipeline = require("@azure/core-rest-pipeline");
var _anonymousCredential = require("./credentials/AnonymousCredential");
var _clients = require("./Clients");
var _mutex = require("./utils/Mutex");
var _pipeline = require("./Pipeline");
var _utilsCommon = require("./utils/utils.common");
var _coreXml = require("@azure/core-xml");
var _constants = require("./utils/constants");
var _storageSharedKeyCredential = require("./credentials/StorageSharedKeyCredential");
var _tracing = require("./utils/tracing");
var _coreClient = require("@azure/core-client");
var _storageSharedKeyCredentialPolicyV2 = require("./policies/StorageSharedKeyCredentialPolicyV2");
class BlobBatch {
    constructor(){
        this.batch = "batch";
        this.batchRequest = new InnerBatchRequest();
    }
    /**
     * Get the value of Content-Type for a batch request.
     * The value must be multipart/mixed with a batch boundary.
     * Example: multipart/mixed; boundary=batch_a81786c8-e301-4e42-a729-a32ca24ae252
     */ getMultiPartContentType() {
        return this.batchRequest.getMultipartContentType();
    }
    /**
     * Get assembled HTTP request body for sub requests.
     */ getHttpRequestBody() {
        return this.batchRequest.getHttpRequestBody();
    }
    /**
     * Get sub requests that are added into the batch request.
     */ getSubRequests() {
        return this.batchRequest.getSubRequests();
    }
    async addSubRequestInternal(subRequest, assembleSubRequestFunc) {
        await (0, _mutex.Mutex).lock(this.batch);
        try {
            this.batchRequest.preAddSubRequest(subRequest);
            await assembleSubRequestFunc();
            this.batchRequest.postAddSubRequest(subRequest);
        } finally{
            await (0, _mutex.Mutex).unlock(this.batch);
        }
    }
    setBatchType(batchType) {
        if (!this.batchType) this.batchType = batchType;
        if (this.batchType !== batchType) throw new RangeError(`BlobBatch only supports one operation type per batch and it already is being used for ${this.batchType} operations.`);
    }
    async deleteBlob(urlOrBlobClient, credentialOrOptions, options) {
        let url;
        let credential;
        if (typeof urlOrBlobClient === "string" && ((0, _coreUtil.isNode) && credentialOrOptions instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrOptions instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrOptions))) {
            // First overload
            url = urlOrBlobClient;
            credential = credentialOrOptions;
        } else if (urlOrBlobClient instanceof (0, _clients.BlobClient)) {
            // Second overload
            url = urlOrBlobClient.url;
            credential = urlOrBlobClient.credential;
            options = credentialOrOptions;
        } else throw new RangeError("Invalid arguments. Either url and credential, or BlobClient need be provided.");
        if (!options) options = {};
        return (0, _tracing.tracingClient).withSpan("BatchDeleteRequest-addSubRequest", options, async (updatedOptions)=>{
            this.setBatchType("delete");
            await this.addSubRequestInternal({
                url: url,
                credential: credential
            }, async ()=>{
                await new (0, _clients.BlobClient)(url, this.batchRequest.createPipeline(credential)).delete(updatedOptions);
            });
        });
    }
    async setBlobAccessTier(urlOrBlobClient, credentialOrTier, tierOrOptions, options) {
        let url;
        let credential;
        let tier;
        if (typeof urlOrBlobClient === "string" && ((0, _coreUtil.isNode) && credentialOrTier instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential) || credentialOrTier instanceof (0, _anonymousCredential.AnonymousCredential) || (0, _coreAuth.isTokenCredential)(credentialOrTier))) {
            // First overload
            url = urlOrBlobClient;
            credential = credentialOrTier;
            tier = tierOrOptions;
        } else if (urlOrBlobClient instanceof (0, _clients.BlobClient)) {
            // Second overload
            url = urlOrBlobClient.url;
            credential = urlOrBlobClient.credential;
            tier = credentialOrTier;
            options = tierOrOptions;
        } else throw new RangeError("Invalid arguments. Either url and credential, or BlobClient need be provided.");
        if (!options) options = {};
        return (0, _tracing.tracingClient).withSpan("BatchSetTierRequest-addSubRequest", options, async (updatedOptions)=>{
            this.setBatchType("setAccessTier");
            await this.addSubRequestInternal({
                url: url,
                credential: credential
            }, async ()=>{
                await new (0, _clients.BlobClient)(url, this.batchRequest.createPipeline(credential)).setAccessTier(tier, updatedOptions);
            });
        });
    }
}
/**
 * Inner batch request class which is responsible for assembling and serializing sub requests.
 * See https://docs.microsoft.com/en-us/rest/api/storageservices/blob-batch#request-body for how requests are assembled.
 */ class InnerBatchRequest {
    constructor(){
        this.operationCount = 0;
        this.body = "";
        const tempGuid = (0, _coreUtil.randomUUID)();
        // batch_{batchid}
        this.boundary = `batch_${tempGuid}`;
        // --batch_{batchid}
        // Content-Type: application/http
        // Content-Transfer-Encoding: binary
        this.subRequestPrefix = `--${this.boundary}${0, _constants.HTTP_LINE_ENDING}${(0, _constants.HeaderConstants).CONTENT_TYPE}: application/http${0, _constants.HTTP_LINE_ENDING}${(0, _constants.HeaderConstants).CONTENT_TRANSFER_ENCODING}: binary`;
        // multipart/mixed; boundary=batch_{batchid}
        this.multipartContentType = `multipart/mixed; boundary=${this.boundary}`;
        // --batch_{batchid}--
        this.batchRequestEnding = `--${this.boundary}--`;
        this.subRequests = new Map();
    }
    /**
     * Create pipeline to assemble sub requests. The idea here is to use existing
     * credential and serialization/deserialization components, with additional policies to
     * filter unnecessary headers, assemble sub requests into request's body
     * and intercept request from going to wire.
     * @param credential -  Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     */ createPipeline(credential) {
        const corePipeline = (0, _coreRestPipeline.createEmptyPipeline)();
        corePipeline.addPolicy((0, _coreClient.serializationPolicy)({
            stringifyXML: (0, _coreXml.stringifyXML),
            serializerOptions: {
                xml: {
                    xmlCharKey: "#"
                }
            }
        }), {
            phase: "Serialize"
        });
        // Use batch header filter policy to exclude unnecessary headers
        corePipeline.addPolicy(batchHeaderFilterPolicy());
        // Use batch assemble policy to assemble request and intercept request from going to wire
        corePipeline.addPolicy(batchRequestAssemblePolicy(this), {
            afterPhase: "Sign"
        });
        if ((0, _coreAuth.isTokenCredential)(credential)) corePipeline.addPolicy((0, _coreRestPipeline.bearerTokenAuthenticationPolicy)({
            credential,
            scopes: (0, _constants.StorageOAuthScopes),
            challengeCallbacks: {
                authorizeRequestOnChallenge: (0, _coreClient.authorizeRequestOnTenantChallenge)
            }
        }), {
            phase: "Sign"
        });
        else if (credential instanceof (0, _storageSharedKeyCredential.StorageSharedKeyCredential)) corePipeline.addPolicy((0, _storageSharedKeyCredentialPolicyV2.storageSharedKeyCredentialPolicy)({
            accountName: credential.accountName,
            accountKey: credential.accountKey
        }), {
            phase: "Sign"
        });
        const pipeline = new (0, _pipeline.Pipeline)([]);
        // attach the v2 pipeline to this one
        pipeline._credential = credential;
        pipeline._corePipeline = corePipeline;
        return pipeline;
    }
    appendSubRequestToBody(request) {
        // Start to assemble sub request
        this.body += [
            this.subRequestPrefix,
            `${(0, _constants.HeaderConstants).CONTENT_ID}: ${this.operationCount}`,
            "",
            `${request.method.toString()} ${(0, _utilsCommon.getURLPathAndQuery)(request.url)} ${(0, _constants.HTTP_VERSION_1_1)}${(0, _constants.HTTP_LINE_ENDING)}`
        ].join((0, _constants.HTTP_LINE_ENDING));
        for (const [name, value] of request.headers)this.body += `${name}: ${value}${0, _constants.HTTP_LINE_ENDING}`;
        this.body += (0, _constants.HTTP_LINE_ENDING); // sub request's headers need be ending with an empty line
    // No body to assemble for current batch request support
    // End to assemble sub request
    }
    preAddSubRequest(subRequest) {
        if (this.operationCount >= (0, _constants.BATCH_MAX_REQUEST)) throw new RangeError(`Cannot exceed ${(0, _constants.BATCH_MAX_REQUEST)} sub requests in a single batch`);
        // Fast fail if url for sub request is invalid
        const path = (0, _utilsCommon.getURLPath)(subRequest.url);
        if (!path || path === "") throw new RangeError(`Invalid url for sub request: '${subRequest.url}'`);
    }
    postAddSubRequest(subRequest) {
        this.subRequests.set(this.operationCount, subRequest);
        this.operationCount++;
    }
    // Return the http request body with assembling the ending line to the sub request body.
    getHttpRequestBody() {
        return `${this.body}${this.batchRequestEnding}${0, _constants.HTTP_LINE_ENDING}`;
    }
    getMultipartContentType() {
        return this.multipartContentType;
    }
    getSubRequests() {
        return this.subRequests;
    }
}
function batchRequestAssemblePolicy(batchRequest) {
    return {
        name: "batchRequestAssemblePolicy",
        async sendRequest (request) {
            batchRequest.appendSubRequestToBody(request);
            return {
                request,
                status: 200,
                headers: (0, _coreRestPipeline.createHttpHeaders)()
            };
        }
    };
}
function batchHeaderFilterPolicy() {
    return {
        name: "batchHeaderFilterPolicy",
        async sendRequest (request, next) {
            let xMsHeaderName = "";
            for (const [name] of request.headers)if ((0, _utilsCommon.iEqual)(name, (0, _constants.HeaderConstants).X_MS_VERSION)) xMsHeaderName = name;
            if (xMsHeaderName !== "") request.headers.delete(xMsHeaderName); // The subrequests should not have the x-ms-version header.
            return next(request);
        }
    };
}

},{"@azure/core-util":"b31OK","@azure/core-auth":"2xRAB","@azure/core-rest-pipeline":"d0mqv","./credentials/AnonymousCredential":"f0sOe","./Clients":"kUV1b","./utils/Mutex":"2uuRL","./Pipeline":"bsozg","./utils/utils.common":"2SR3M","@azure/core-xml":"XDN0l","./utils/constants":"4gX5x","./credentials/StorageSharedKeyCredential":"jUFIX","./utils/tracing":"m0KjB","@azure/core-client":"eVlwR","./policies/StorageSharedKeyCredentialPolicyV2":"lPMqJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2uuRL":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * An async mutex lock.
 */ parcelHelpers.export(exports, "Mutex", ()=>Mutex);
var MutexLockStatus;
(function(MutexLockStatus) {
    MutexLockStatus[MutexLockStatus["LOCKED"] = 0] = "LOCKED";
    MutexLockStatus[MutexLockStatus["UNLOCKED"] = 1] = "UNLOCKED";
})(MutexLockStatus || (MutexLockStatus = {}));
class Mutex {
    /**
     * Lock for a specific key. If the lock has been acquired by another customer, then
     * will wait until getting the lock.
     *
     * @param key - lock key
     */ static async lock(key) {
        return new Promise((resolve)=>{
            if (this.keys[key] === undefined || this.keys[key] === MutexLockStatus.UNLOCKED) {
                this.keys[key] = MutexLockStatus.LOCKED;
                resolve();
            } else this.onUnlockEvent(key, ()=>{
                this.keys[key] = MutexLockStatus.LOCKED;
                resolve();
            });
        });
    }
    /**
     * Unlock a key.
     *
     * @param key -
     */ static async unlock(key) {
        return new Promise((resolve)=>{
            if (this.keys[key] === MutexLockStatus.LOCKED) this.emitUnlockEvent(key);
            delete this.keys[key];
            resolve();
        });
    }
    static onUnlockEvent(key, handler) {
        if (this.listeners[key] === undefined) this.listeners[key] = [
            handler
        ];
        else this.listeners[key].push(handler);
    }
    static emitUnlockEvent(key) {
        if (this.listeners[key] !== undefined && this.listeners[key].length > 0) {
            const handler = this.listeners[key].shift();
            setImmediate(()=>{
                handler.call(this);
            });
        }
    }
}
Mutex.keys = {};
Mutex.listeners = {};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8tbmf":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant permissions for that operation. Once all the
 * values are set, this should be serialized with toString and set as the permissions field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AccountSASPermissions", ()=>AccountSASPermissions);
class AccountSASPermissions {
    constructor(){
        /**
         * Permission to read resources and list queues and tables granted.
         */ this.read = false;
        /**
         * Permission to write resources granted.
         */ this.write = false;
        /**
         * Permission to delete blobs and files granted.
         */ this.delete = false;
        /**
         * Permission to delete versions granted.
         */ this.deleteVersion = false;
        /**
         * Permission to list blob containers, blobs, shares, directories, and files granted.
         */ this.list = false;
        /**
         * Permission to add messages, table entities, and append to blobs granted.
         */ this.add = false;
        /**
         * Permission to create blobs and files granted.
         */ this.create = false;
        /**
         * Permissions to update messages and table entities granted.
         */ this.update = false;
        /**
         * Permission to get and delete messages granted.
         */ this.process = false;
        /**
         * Specfies Tag access granted.
         */ this.tag = false;
        /**
         * Permission to filter blobs.
         */ this.filter = false;
        /**
         * Permission to set immutability policy.
         */ this.setImmutabilityPolicy = false;
        /**
         * Specifies that Permanent Delete is permitted.
         */ this.permanentDelete = false;
    }
    /**
     * Parse initializes the AccountSASPermissions fields from a string.
     *
     * @param permissions -
     */ static parse(permissions) {
        const accountSASPermissions = new AccountSASPermissions();
        for (const c of permissions)switch(c){
            case "r":
                accountSASPermissions.read = true;
                break;
            case "w":
                accountSASPermissions.write = true;
                break;
            case "d":
                accountSASPermissions.delete = true;
                break;
            case "x":
                accountSASPermissions.deleteVersion = true;
                break;
            case "l":
                accountSASPermissions.list = true;
                break;
            case "a":
                accountSASPermissions.add = true;
                break;
            case "c":
                accountSASPermissions.create = true;
                break;
            case "u":
                accountSASPermissions.update = true;
                break;
            case "p":
                accountSASPermissions.process = true;
                break;
            case "t":
                accountSASPermissions.tag = true;
                break;
            case "f":
                accountSASPermissions.filter = true;
                break;
            case "i":
                accountSASPermissions.setImmutabilityPolicy = true;
                break;
            case "y":
                accountSASPermissions.permanentDelete = true;
                break;
            default:
                throw new RangeError(`Invalid permission character: ${c}`);
        }
        return accountSASPermissions;
    }
    /**
     * Creates a {@link AccountSASPermissions} from a raw object which contains same keys as it
     * and boolean values for them.
     *
     * @param permissionLike -
     */ static from(permissionLike) {
        const accountSASPermissions = new AccountSASPermissions();
        if (permissionLike.read) accountSASPermissions.read = true;
        if (permissionLike.write) accountSASPermissions.write = true;
        if (permissionLike.delete) accountSASPermissions.delete = true;
        if (permissionLike.deleteVersion) accountSASPermissions.deleteVersion = true;
        if (permissionLike.filter) accountSASPermissions.filter = true;
        if (permissionLike.tag) accountSASPermissions.tag = true;
        if (permissionLike.list) accountSASPermissions.list = true;
        if (permissionLike.add) accountSASPermissions.add = true;
        if (permissionLike.create) accountSASPermissions.create = true;
        if (permissionLike.update) accountSASPermissions.update = true;
        if (permissionLike.process) accountSASPermissions.process = true;
        if (permissionLike.setImmutabilityPolicy) accountSASPermissions.setImmutabilityPolicy = true;
        if (permissionLike.permanentDelete) accountSASPermissions.permanentDelete = true;
        return accountSASPermissions;
    }
    /**
     * Produces the SAS permissions string for an Azure Storage account.
     * Call this method to set AccountSASSignatureValues Permissions field.
     *
     * Using this method will guarantee the resource types are in
     * an order accepted by the service.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */ toString() {
        // The order of the characters should be as specified here to ensure correctness:
        // https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
        // Use a string array instead of string concatenating += operator for performance
        const permissions = [];
        if (this.read) permissions.push("r");
        if (this.write) permissions.push("w");
        if (this.delete) permissions.push("d");
        if (this.deleteVersion) permissions.push("x");
        if (this.filter) permissions.push("f");
        if (this.tag) permissions.push("t");
        if (this.list) permissions.push("l");
        if (this.add) permissions.push("a");
        if (this.create) permissions.push("c");
        if (this.update) permissions.push("u");
        if (this.process) permissions.push("p");
        if (this.setImmutabilityPolicy) permissions.push("i");
        if (this.permanentDelete) permissions.push("y");
        return permissions.join("");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d00sP":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Generates a {@link SASQueryParameters} object which contains all SAS query parameters needed to make an actual
 * REST request.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
 *
 * @param accountSASSignatureValues -
 * @param sharedKeyCredential -
 */ parcelHelpers.export(exports, "generateAccountSASQueryParameters", ()=>generateAccountSASQueryParameters);
var _accountSASPermissions = require("./AccountSASPermissions");
var _accountSASResourceTypes = require("./AccountSASResourceTypes");
var _accountSASServices = require("./AccountSASServices");
var _sasIPRange = require("./SasIPRange");
var _sasqueryParameters = require("./SASQueryParameters");
var _constants = require("../utils/constants");
var _utilsCommon = require("../utils/utils.common");
function generateAccountSASQueryParameters(accountSASSignatureValues, sharedKeyCredential) {
    const version = accountSASSignatureValues.version ? accountSASSignatureValues.version : (0, _constants.SERVICE_VERSION);
    if (accountSASSignatureValues.permissions && accountSASSignatureValues.permissions.setImmutabilityPolicy && version < "2020-08-04") throw RangeError("'version' must be >= '2020-08-04' when provided 'i' permission.");
    if (accountSASSignatureValues.permissions && accountSASSignatureValues.permissions.deleteVersion && version < "2019-10-10") throw RangeError("'version' must be >= '2019-10-10' when provided 'x' permission.");
    if (accountSASSignatureValues.permissions && accountSASSignatureValues.permissions.permanentDelete && version < "2019-10-10") throw RangeError("'version' must be >= '2019-10-10' when provided 'y' permission.");
    if (accountSASSignatureValues.permissions && accountSASSignatureValues.permissions.tag && version < "2019-12-12") throw RangeError("'version' must be >= '2019-12-12' when provided 't' permission.");
    if (accountSASSignatureValues.permissions && accountSASSignatureValues.permissions.filter && version < "2019-12-12") throw RangeError("'version' must be >= '2019-12-12' when provided 'f' permission.");
    if (accountSASSignatureValues.encryptionScope && version < "2020-12-06") throw RangeError("'version' must be >= '2020-12-06' when provided 'encryptionScope' in SAS.");
    const parsedPermissions = (0, _accountSASPermissions.AccountSASPermissions).parse(accountSASSignatureValues.permissions.toString());
    const parsedServices = (0, _accountSASServices.AccountSASServices).parse(accountSASSignatureValues.services).toString();
    const parsedResourceTypes = (0, _accountSASResourceTypes.AccountSASResourceTypes).parse(accountSASSignatureValues.resourceTypes).toString();
    let stringToSign;
    if (version >= "2020-12-06") stringToSign = [
        sharedKeyCredential.accountName,
        parsedPermissions,
        parsedServices,
        parsedResourceTypes,
        accountSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(accountSASSignatureValues.startsOn, false) : "",
        (0, _utilsCommon.truncatedISO8061Date)(accountSASSignatureValues.expiresOn, false),
        accountSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(accountSASSignatureValues.ipRange) : "",
        accountSASSignatureValues.protocol ? accountSASSignatureValues.protocol : "",
        version,
        accountSASSignatureValues.encryptionScope ? accountSASSignatureValues.encryptionScope : "",
        ""
    ].join("\n");
    else stringToSign = [
        sharedKeyCredential.accountName,
        parsedPermissions,
        parsedServices,
        parsedResourceTypes,
        accountSASSignatureValues.startsOn ? (0, _utilsCommon.truncatedISO8061Date)(accountSASSignatureValues.startsOn, false) : "",
        (0, _utilsCommon.truncatedISO8061Date)(accountSASSignatureValues.expiresOn, false),
        accountSASSignatureValues.ipRange ? (0, _sasIPRange.ipRangeToString)(accountSASSignatureValues.ipRange) : "",
        accountSASSignatureValues.protocol ? accountSASSignatureValues.protocol : "",
        version,
        ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new (0, _sasqueryParameters.SASQueryParameters)(version, signature, parsedPermissions.toString(), parsedServices, parsedResourceTypes, accountSASSignatureValues.protocol, accountSASSignatureValues.startsOn, accountSASSignatureValues.expiresOn, accountSASSignatureValues.ipRange, undefined, undefined, undefined, undefined, undefined, undefined, undefined, undefined, undefined, undefined, accountSASSignatureValues.encryptionScope);
}

},{"./AccountSASPermissions":"8tbmf","./AccountSASResourceTypes":"fQgaZ","./AccountSASServices":"7HHJy","./SasIPRange":"aH3sX","./SASQueryParameters":"gMQnk","../utils/constants":"4gX5x","../utils/utils.common":"2SR3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fQgaZ":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the resources accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that resource type. Once all the
 * values are set, this should be serialized with toString and set as the resources field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the resources string without this class, but
 * the order of the resources is particular and this class guarantees correctness.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AccountSASResourceTypes", ()=>AccountSASResourceTypes);
class AccountSASResourceTypes {
    constructor(){
        /**
         * Permission to access service level APIs granted.
         */ this.service = false;
        /**
         * Permission to access container level APIs (Blob Containers, Tables, Queues, File Shares) granted.
         */ this.container = false;
        /**
         * Permission to access object level APIs (Blobs, Table Entities, Queue Messages, Files) granted.
         */ this.object = false;
    }
    /**
     * Creates an {@link AccountSASResourceTypes} from the specified resource types string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid resource type.
     *
     * @param resourceTypes -
     */ static parse(resourceTypes) {
        const accountSASResourceTypes = new AccountSASResourceTypes();
        for (const c of resourceTypes)switch(c){
            case "s":
                accountSASResourceTypes.service = true;
                break;
            case "c":
                accountSASResourceTypes.container = true;
                break;
            case "o":
                accountSASResourceTypes.object = true;
                break;
            default:
                throw new RangeError(`Invalid resource type: ${c}`);
        }
        return accountSASResourceTypes;
    }
    /**
     * Converts the given resource types to a string.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */ toString() {
        const resourceTypes = [];
        if (this.service) resourceTypes.push("s");
        if (this.container) resourceTypes.push("c");
        if (this.object) resourceTypes.push("o");
        return resourceTypes.join("");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7HHJy":[function(require,module,exports) {
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the services accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that service. Once all the
 * values are set, this should be serialized with toString and set as the services field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the services string without this class, but
 * the order of the services is particular and this class guarantees correctness.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AccountSASServices", ()=>AccountSASServices);
class AccountSASServices {
    constructor(){
        /**
         * Permission to access blob resources granted.
         */ this.blob = false;
        /**
         * Permission to access file resources granted.
         */ this.file = false;
        /**
         * Permission to access queue resources granted.
         */ this.queue = false;
        /**
         * Permission to access table resources granted.
         */ this.table = false;
    }
    /**
     * Creates an {@link AccountSASServices} from the specified services string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid service.
     *
     * @param services -
     */ static parse(services) {
        const accountSASServices = new AccountSASServices();
        for (const c of services)switch(c){
            case "b":
                accountSASServices.blob = true;
                break;
            case "f":
                accountSASServices.file = true;
                break;
            case "q":
                accountSASServices.queue = true;
                break;
            case "t":
                accountSASServices.table = true;
                break;
            default:
                throw new RangeError(`Invalid service character: ${c}`);
        }
        return accountSASServices;
    }
    /**
     * Converts the given services to a string.
     *
     */ toString() {
        const services = [];
        if (this.blob) services.push("b");
        if (this.table) services.push("t");
        if (this.queue) services.push("q");
        if (this.file) services.push("f");
        return services.join("");
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}]},["km5uZ","bB7Pu"], "bB7Pu", "parcelRequiref22f")

//# sourceMappingURL=index.3d214d75.js.map
